<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Hahally&#39;s BLOG</title>
  
  
  <link href="/atom.xml" rel="self"/>
  
  <link href="https://hahally.github.io/"/>
  <updated>2021-07-08T13:47:44.862Z</updated>
  <id>https://hahally.github.io/</id>
  
  <author>
    <name>hahally</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>基于形容词删除策略的语言隐写与密钥共享</title>
    <link href="https://hahally.github.io/articles/%E5%9F%BA%E4%BA%8E%E5%BD%A2%E5%AE%B9%E8%AF%8D%E5%88%A0%E9%99%A4%E7%AD%96%E7%95%A5%E7%9A%84%E8%AF%AD%E8%A8%80%E9%9A%90%E5%86%99%E4%B8%8E%E5%AF%86%E9%92%A5%E5%85%B1%E4%BA%AB/"/>
    <id>https://hahally.github.io/articles/%E5%9F%BA%E4%BA%8E%E5%BD%A2%E5%AE%B9%E8%AF%8D%E5%88%A0%E9%99%A4%E7%AD%96%E7%95%A5%E7%9A%84%E8%AF%AD%E8%A8%80%E9%9A%90%E5%86%99%E4%B8%8E%E5%AF%86%E9%92%A5%E5%85%B1%E4%BA%AB/</id>
    <published>2021-07-08T13:38:14.000Z</published>
    <updated>2021-07-08T13:47:44.862Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p><a href="https://aclanthology.org/C12-1031/" target="_blank" rel="noopener">Adjective Deletion for Linguistic Steganography and Secret Sharing</a></p></blockquote><p><strong>概念</strong></p><ul><li><p>Adjective Deletion 【形容词删除】</p></li><li><p>Linguistic Steganography 【语言隐写术】隐写术就是将秘密信息隐藏到看上去普通的信息中进行传送。</p><blockquote><p>Linguistic steganography is a form of covert communication in which information is embedded in a seemly innocent cover text so that the presence of the information is imperceptible to an outside observer (human or computer).</p><p>理想的 Linguistic Steganography满足两个基本要求：high imperceptibility（不易察觉） and high payload capacity（高信息承载容量）</p></blockquote></li><li><p>Secret Sharing 【密钥共享】一种分发、保存、恢复秘密密钥的方法。</p></li></ul><p><strong>文章所作工作</strong></p><ol><li><p>验证删除形容词的可行性的两种方法：「checking the acceptability of adjective deletion in noun phrases.」</p><ul><li>Google n-gram corpus 【谷歌语料库】「check 删除一个形容词后的 <strong>context</strong> 的流利程度」</li><li>SVM模型(使用n-gram counts和其他方法训练得到) 「classify 是否在 <strong>context</strong> 删除形容词」</li></ul></li><li><p>证明删除形容词技术可以集成到一个存在的语言系统(an existing linguistic stegosyste)</p></li><li><p>提出一种新的基于形容词删除技术(adjective deletion)的密钥共享(secret sharing)方法</p></li></ol><p><strong>(t,n)-threshold scheme</strong></p><p>论文中采用的 secret sharing方法是基于(2, 2)-threshold, 其中共享的必须是两个可比较的文本(two comparable texts)。通过形容词删除技术将【0s 和 1s 的加密位字符串(secret bitstring;)】嵌入到两个文本中，这两个文本可以组合起来，获得秘密位串。</p><blockquote><p>Hence the proposed method is a novel combination of secret sharing and linguistic steganography.</p></blockquote><p>一种密钥共享与语言隐写技术的新颖组合方法？！</p><p><strong>Adjective Deletion</strong></p><p>在不影响句子流利程度和语义的情况下，可以将一些形容词删除。在下面的例子中，删除 <em>own</em> 这个形容词后，句意并没有发生改变。</p><blockquote><p>he spent only his own money.</p><p>he spent only his money.</p></blockquote><p>一种极端情况 adjective-noun ：大致可以理解为正确的废话（正确但duck不必的形容）吧。</p><blockquote><p>unfair prejudice</p><p>horrible crime</p><p>fragile glass</p></blockquote><p><strong>隐写术种的语言转换(Linguistic Transformations for Steganography)</strong></p><p>如：词汇替换、短语意译、句子结构调整、语义转换等【PS：有种毕业论文降重的赶脚】</p><p>还有一种研究通过在翻译的文本中嵌入信息。在机器翻译算法中引入水印作为参数，对带有水印的译文进行概率识别。</p><p>【Watermarking the outputs of structured prediction with an application in statistical machine translation】</p><blockquote><p>Another recent work proposedby Venugopal et al. (2011) introduces a watermark as a parameter in the machine translation algorithm and probabilistically identifies the watermarked translation.</p></blockquote><p><strong>隐写系统评估</strong></p><p>可以从两个方面对系统进行评估：安全性(security level)和嵌入容量( embedding capacity)</p><ol><li><p>security level： automatic evaluation and human evaluation.</p><p>automatic evaluation 大概就是使用机器翻译评价指标 BLEU 和 NIST。计算隐藏文本与原始文本之间的距离。</p><p>human evaluation 就是认为指定的一套评估标准(seven-point scale)。</p></li><li><p>embedding capacity</p><p>将嵌入的信息按每个语言单位(每个句子或每个单词)比特进行量化。</p></li></ol><p>隐写系统的语言转换和编码方法，以及隐写文本的选择都会影响隐写系统的安全级别和有效负载能力。</p><p><strong>句子压缩</strong></p><p>句子压缩，文本简化和文本摘要通常涉及删除句子中不重要的词，以使文本更简洁。论文中指出，形容词删除可以用在句子压缩之前或之后。进一步简化句子。</p><blockquote><p>The proposed adjective deletion methods can be applied before and/or after a sentence compression system. Deleting unnecessary adjectives before can help the system focus on other content of a sentence. Deleting unnecessary adjectives after can generate an even more concise sentence.</p></blockquote><p><strong>Deletable Adjective Classification</strong></p><p>论文中，为了使一个形容词的删除是可以接受的，使用两个检查：语法性和自然性检查(grammaticality and naturalness checks)。</p><ol><li><p>N-gram Count 方法</p><p>计算删除形容词前后文本的 N-gram 统计得分，通过设置一个阈值，来判断删除后的文本是否可接受。</p></li><li><p>Features for the SVM</p><p>支持向量机的特征有：</p><ul><li>N-gram Counts</li><li>Lexical Association Measures【确定形容词和名词之间的关联程度。】</li><li>Noun and Adjective Entropy【名词和形容词熵】</li><li>Contextual α-Skew Divergence【上下文的倾斜散度？】</li></ul></li></ol><p><strong>Secret Sharing Scheme</strong></p><p>将一个密钥位串分成两个部分$share_0$和 $share_1$ 。若目标形容词在$share_0$ 中保留，则密钥值取0，若目标形容词在$share_1$中保留，则密钥值取1。</p><blockquote><p>Share0 holds secret bits as 0s and Share1 holds secret bits as 1s</p></blockquote><p>下面是一个密钥位串为 101 的例子：</p><p><img src="/articles/%E5%9F%BA%E4%BA%8E%E5%BD%A2%E5%AE%B9%E8%AF%8D%E5%88%A0%E9%99%A4%E7%AD%96%E7%95%A5%E7%9A%84%E8%AF%AD%E8%A8%80%E9%9A%90%E5%86%99%E4%B8%8E%E5%AF%86%E9%92%A5%E5%85%B1%E4%BA%AB/image-20210708213208658.png" alt="image-20210708213208658"></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;blockquote&gt;
&lt;p&gt;&lt;a href=&quot;https://aclanthology.org/C12-1031/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;Adjective Deletion for Linguistic Steganography 
      
    
    </summary>
    
    
    
      <category term="paper reading" scheme="https://hahally.github.io/tags/paper-reading/"/>
    
  </entry>
  
  <entry>
    <title>蛋白质结构预测之lgb的baseline</title>
    <link href="https://hahally.github.io/articles/%E8%9B%8B%E7%99%BD%E8%B4%A8%E7%BB%93%E6%9E%84%E9%A2%84%E6%B5%8B%E4%B9%8Blgb%E7%9A%84baseline/"/>
    <id>https://hahally.github.io/articles/%E8%9B%8B%E7%99%BD%E8%B4%A8%E7%BB%93%E6%9E%84%E9%A2%84%E6%B5%8B%E4%B9%8Blgb%E7%9A%84baseline/</id>
    <published>2021-07-03T11:30:36.000Z</published>
    <updated>2021-07-03T12:56:48.376Z</updated>
    
    <content type="html"><![CDATA[<p>赛题：<a href="https://challenge.xfyun.cn/topic/info?type=protein" target="_blank" rel="noopener">蛋白质结构预测挑战赛</a></p><p>代码：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">################## utils.py #####################</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">read_fa</span><span class="params">(file, mode=<span class="string">'train'</span>)</span>:</span></span><br><span class="line">    <span class="keyword">assert</span> mode <span class="keyword">in</span> &#123;<span class="string">'train'</span>,<span class="string">'test'</span>&#125;</span><br><span class="line">    labels = []</span><br><span class="line">    seqs_info = []</span><br><span class="line">    cates_id = []</span><br><span class="line">    seq = <span class="string">''</span></span><br><span class="line">    <span class="keyword">with</span> open(file,mode=<span class="string">'r'</span>) <span class="keyword">as</span> f:</span><br><span class="line">        line = f.readline().strip()</span><br><span class="line">        <span class="keyword">while</span> line:</span><br><span class="line">            <span class="keyword">if</span> line[<span class="number">0</span>]==<span class="string">'&gt;'</span>:</span><br><span class="line">                info = line[<span class="number">1</span>:].split(<span class="string">' '</span>)</span><br><span class="line">                cates_id.append(info[<span class="number">0</span>])</span><br><span class="line">                <span class="keyword">if</span> mode == <span class="string">'train'</span>:</span><br><span class="line">                    labels.append(<span class="string">''</span>.join(info[<span class="number">1</span>].split(<span class="string">'.'</span>)[:<span class="number">2</span>]))</span><br><span class="line">                <span class="keyword">if</span> seq:</span><br><span class="line">                    seqs_info.append(seq)</span><br><span class="line">                    seq = <span class="string">''</span></span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                seq += line</span><br><span class="line">            line = f.readline().strip()</span><br><span class="line">        seqs_info.append(seq)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> cates_id,seqs_info,labels</span><br><span class="line"></span><br><span class="line"><span class="comment">################## main.py #####################</span></span><br><span class="line"><span class="keyword">from</span> utils <span class="keyword">import</span> *</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> f1_score, fbeta_score, precision_score, recall_score, roc_auc_score</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> StratifiedKFold <span class="keyword">as</span> KFold</span><br><span class="line"><span class="keyword">import</span> lightgbm <span class="keyword">as</span> lgb</span><br><span class="line"></span><br><span class="line">train_file = <span class="string">'./训练集/astral_train.fa'</span></span><br><span class="line">test_file = <span class="string">'./测试集/astral_test.fa'</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">train_sample_id, train_seqs_info, train_labels = read_fa(train_file, mode=<span class="string">'train'</span>)</span><br><span class="line">test_sample_id, test_seqs_info, _ = read_fa(test_file, mode=<span class="string">'test'</span>)</span><br><span class="line">train_data = &#123;</span><br><span class="line">    <span class="string">'sample_id'</span>: train_sample_id,</span><br><span class="line">    <span class="string">'seq_info'</span>: train_seqs_info,</span><br><span class="line">    <span class="string">'label'</span>: train_labels</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">test_data = &#123;</span><br><span class="line">    <span class="string">'sample_id'</span>: test_sample_id,</span><br><span class="line">    <span class="string">'seq_info'</span>: test_seqs_info,</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">label_map = &#123;l:idx <span class="keyword">for</span> idx,l <span class="keyword">in</span> enumerate(set(train_labels))&#125;</span><br><span class="line"></span><br><span class="line">rev_label_map = &#123;v:k <span class="keyword">for</span> k,v <span class="keyword">in</span> label_map.items()&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment"># print(label_map)</span></span><br><span class="line"></span><br><span class="line">train = pd.DataFrame(data=train_data)</span><br><span class="line">test = pd.DataFrame(data=test_data)</span><br><span class="line"></span><br><span class="line">train[<span class="string">'label'</span>] = train[<span class="string">'label'</span>].map(label_map)</span><br><span class="line"></span><br><span class="line">alp = list(set(<span class="string">''</span>.join(train_seqs_info + test_seqs_info)))</span><br><span class="line"></span><br><span class="line">train[<span class="string">'seq_len'</span>] = train[<span class="string">'seq_info'</span>].apply(<span class="keyword">lambda</span> x:len(x))</span><br><span class="line">test[<span class="string">'seq_len'</span>] = test[<span class="string">'seq_info'</span>].apply(<span class="keyword">lambda</span> x:len(x))</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> s <span class="keyword">in</span> alp:</span><br><span class="line">    train[<span class="string">'count_'</span>+s] = train[<span class="string">'seq_info'</span>].apply(<span class="keyword">lambda</span> x:x.count(s))</span><br><span class="line">    train[<span class="string">'freq_'</span>+s] = train[<span class="string">'seq_info'</span>].apply(<span class="keyword">lambda</span> x:x.count(s)/len(x))</span><br><span class="line">    </span><br><span class="line">    test[<span class="string">'count_'</span>+s] = test[<span class="string">'seq_info'</span>].apply(<span class="keyword">lambda</span> x:x.count(s))</span><br><span class="line">    test[<span class="string">'freq_'</span>+s] = test[<span class="string">'seq_info'</span>].apply(<span class="keyword">lambda</span> x:x.count(s)/len(x))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">feats = [i <span class="keyword">for</span> i <span class="keyword">in</span> train.columns <span class="keyword">if</span> i <span class="keyword">not</span> <span class="keyword">in</span> [<span class="string">'label'</span>,<span class="string">'sample_id'</span>,<span class="string">'seq_info'</span>]]</span><br><span class="line"></span><br><span class="line"><span class="comment"># print(feats)</span></span><br><span class="line"></span><br><span class="line">x_train = train[feats]</span><br><span class="line">y_train = train[<span class="string">'label'</span>]</span><br><span class="line">x_test = test[feats]</span><br><span class="line"></span><br><span class="line">   </span><br><span class="line">params = &#123; </span><br><span class="line">    <span class="string">'boosting_type'</span>: <span class="string">'gbdt'</span>,  </span><br><span class="line">    <span class="string">'objective'</span>: <span class="string">'multiclass'</span>,  </span><br><span class="line">    <span class="string">'num_class'</span>: <span class="number">245</span>,  </span><br><span class="line">    <span class="string">'metric'</span>: <span class="string">'multi_error'</span>,  </span><br><span class="line">    <span class="string">'num_leaves'</span>: <span class="number">300</span>,  </span><br><span class="line">    <span class="string">'min_data_in_leaf'</span>: <span class="number">500</span>,  </span><br><span class="line">    <span class="string">'learning_rate'</span>: <span class="number">0.007</span>,  </span><br><span class="line">    <span class="string">'max_depth'</span>: <span class="number">8</span>,</span><br><span class="line">    <span class="string">'feature_fraction'</span>: <span class="number">0.8</span>,  </span><br><span class="line">    <span class="string">'bagging_fraction'</span>: <span class="number">0.8</span>,  </span><br><span class="line">    <span class="string">'bagging_freq'</span>: <span class="number">5</span>,  </span><br><span class="line">    <span class="string">'lambda_l1'</span>: <span class="number">0.4</span>,  </span><br><span class="line">    <span class="string">'lambda_l2'</span>: <span class="number">0.5</span>,  </span><br><span class="line">    <span class="string">'min_gain_to_split'</span>: <span class="number">0.2</span>,  </span><br><span class="line">    <span class="string">'verbose'</span>: <span class="number">-1</span>,</span><br><span class="line">    <span class="string">'num_threads'</span>:<span class="number">2</span>,</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment"># 五折交叉验证</span></span><br><span class="line">folds = KFold(n_splits=<span class="number">5</span>, shuffle=<span class="literal">True</span>, random_state=<span class="number">2021</span>)</span><br><span class="line"></span><br><span class="line">oof = np.zeros([len(x_train),<span class="number">245</span>])</span><br><span class="line">predictions = np.zeros([len(x_test),<span class="number">245</span>])</span><br><span class="line"> </span><br><span class="line"><span class="keyword">for</span> fold_, (trn_idx, val_idx) <span class="keyword">in</span> enumerate(folds.split(x_train, y_train)):</span><br><span class="line">    print(<span class="string">"fold n°&#123;&#125;"</span>.format(fold_+<span class="number">1</span>))</span><br><span class="line">    trn_data = lgb.Dataset(x_train.iloc[trn_idx], y_train.iloc[trn_idx])</span><br><span class="line">    val_data = lgb.Dataset(x_train.iloc[val_idx], y_train.iloc[val_idx])</span><br><span class="line"> </span><br><span class="line">    num_round = <span class="number">1000</span></span><br><span class="line">    clf = lgb.train(params, </span><br><span class="line">                    trn_data, </span><br><span class="line">                    num_round, </span><br><span class="line">                    valid_sets = [trn_data, val_data], </span><br><span class="line">                    verbose_eval = <span class="number">100</span>, </span><br><span class="line">                    early_stopping_rounds = <span class="number">50</span>)</span><br><span class="line">    oof[val_idx] = clf.predict(x_train.iloc[val_idx][feats], num_iteration=clf.best_iteration)    </span><br><span class="line">    predictions += clf.predict(x_test, num_iteration=clf.best_iteration) / folds.n_splits</span><br><span class="line">    <span class="comment">#print(predictions)</span></span><br><span class="line"></span><br><span class="line">x_test[<span class="string">'sample_id'</span>] = test[<span class="string">'sample_id'</span>]</span><br><span class="line">x_test[<span class="string">'category_id'</span>] = [rev_label_map[list(x).index(max(x))] <span class="keyword">for</span> x <span class="keyword">in</span> predictions]</span><br><span class="line">x_test[<span class="string">'category_id'</span>] = x_test[<span class="string">'category_id'</span>].apply(<span class="keyword">lambda</span> x: x[<span class="number">0</span>]+<span class="string">'.'</span>+x[<span class="number">1</span>:])</span><br><span class="line">x_test[[<span class="string">'sample_id'</span>, <span class="string">'category_id'</span>]].to_csv(<span class="string">'base_sub.csv'</span>, index=<span class="literal">False</span>)</span><br><span class="line"></span><br><span class="line">y_pre = oof.argmax(axis=<span class="number">1</span>)</span><br><span class="line">print(<span class="string">"F1 score: &#123;&#125;"</span>.format(f1_score(y_train, y_pre,average=<span class="string">'micro'</span>)))</span><br><span class="line">print(<span class="string">"Precision score: &#123;&#125;"</span>.format(precision_score(y_train, y_pre,average=<span class="string">'micro'</span>)))</span><br><span class="line">print(<span class="string">"Recall score: &#123;&#125;"</span>.format(recall_score(y_train, y_pre,average=<span class="string">'micro'</span>)))</span><br></pre></td></tr></table></figure><p>提交结果：目前【14/27(提交团队数)】</p><p><img src="/articles/%E8%9B%8B%E7%99%BD%E8%B4%A8%E7%BB%93%E6%9E%84%E9%A2%84%E6%B5%8B%E4%B9%8Blgb%E7%9A%84baseline/image-20210703193646587.png" alt="image-20210703193646587"></p><p>主要是提取了氨基酸组成(AAC)特征，即一些简单的统计特征。没有考虑氨基酸之间的相对位置信息，也没有必要调参，最后预测结果也很是拉跨。</p><p>下一步直接尝试<code>nlp</code> 相关模型。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;赛题：&lt;a href=&quot;https://challenge.xfyun.cn/topic/info?type=protein&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;蛋白质结构预测挑战赛&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;代码：&lt;/p&gt;
&lt;figure clas
      
    
    </summary>
    
    
    
      <category term="BDC" scheme="https://hahally.github.io/tags/BDC/"/>
    
  </entry>
  
  <entry>
    <title>GMAN</title>
    <link href="https://hahally.github.io/articles/GMAN/"/>
    <id>https://hahally.github.io/articles/GMAN/</id>
    <published>2021-03-02T14:27:22.000Z</published>
    <updated>2021-03-02T14:32:51.690Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p><a href="https://arxiv.org/abs/1911.08415" target="_blank" rel="noopener">GMAN: A Graph Multi-Attention Network for Traffic Prediction</a></p></blockquote><h3 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h3><p>由于交通系统的复杂性和众多影响因素的不断变化，长期交通预测具有很大的挑战性。本文针对时空因素，提出了一种基于图的多注意网络（GMAN）来预测路网图上不同位置时间步长头部的交通状况。GMAN采用编解码器架构，其中编码器和解码器均由多个时空注意模块组成，以模拟时空因素对交通状况的影响。 编码器对输入的流量特征进行编码，解码器预测输出序列。在编码器和解码器之间，应用变换注意层来转换编码的流量特征，以生成未来时间步长的序列表示作为解码器的输入。 变换注意机制对历史步骤和将来时间步骤之间的直接关系进行建模，这有助于减轻预测时间步骤之间的错误传播问题。 在两个实际交通预测任务（即交通量预测和交通速度预测）上的实验结果证明了GMAN的优越性。 特别是，在提前1小时的预测中，GMAN的MAE指标提高了4％，优于最新技术。<a href="https://github.com/zhengchuanpan/GMAN" target="_blank" rel="noopener">https://github.com/zhengchuanpan/GMAN</a></p><h3 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h3><p>交通预测的目的是根据历史观测（如通过传感器记录）预测道路网络中未来的交通状况（如交通量或速度）。它在许多实际应用中扮演着重要的角色。例如，准确的交通预测可以帮助运输机构更好地控制交通，以减少交通拥挤。</p><p>附近位置的交通状况的预测会相互影响。 为了捕获这种空间相关性，卷积神经网络（CNN）被广泛使用。 同时，一个地点的交通状况也与其历史观测值有关。循环神经网络（RNN）被广泛应用于这种对时间相关性问题进行建模。</p><p>由于交通条件受路网图的限制，近年来的研究将交通预测看作图形建模问题。利用图卷积网络（GCN），这些研究在短期（提前5∼15分钟）交通预测方面取得了不错的结果。然而，长期(提前几个小时)的交通预测在文献中仍然缺乏令人满意的进展，主要是由于以下挑战。</p><p>1) 复杂的时空相关性</p><ul><li>动态空间相关性。如图1所示，路网中传感器之间交通状况的相关性随着时间的推移而显著变化（例如，在高峰时间之前和期间）。如何动态选择相关传感器的数据来预测目标传感器的长期交通状况是一个具有挑战性的问题。</li><li>非线性时间相关。 同样在图1中，传感器处的交通状况可能急剧且突然地波动（例如，由于事故），从而影响不同时间步长之间的相关性。 当时间更远时，如何自适应地对非线性时间相关性建模仍然是一个挑战。</li></ul><p>2) 对误差传播的敏感性。从长期的角度来看，当对未来的预测更进一步时，每个时间步上的小误差可能会放大。这样的误差传播使得对遥远未来的预测非常具有挑战性。</p><p><img src="/articles/GMAN/image-20210223150430150.png" alt="image-20210223150430150"></p><p>为了应对上述挑战，我们提出了一种图形多注意网络（GMAN）来预测未来一段时间内道路网络图上的交通状况。此处，交通状况指的是对交通系统的观测，可以以数值形式报告 。 为了便于说明，我们将重点放在交通量和交通速度预测上，尽管我们的模型可以应用于其他数字交通数据的预测。</p><p>GMAN遵循编码器-解码器体系结构，其中编码器对输入的流量特征进行编码，而解码器预测输出序列。 在编码器和解码器之间添加了一个转换注意层，以转换编码的历史流量特征以生成将来的表示。编码器和解码器都由ST-Attention块的堆栈组成。 每个ST-Attention块由用于对动态空间相关性进行建模的空间注意机制，用于对非线性时间相关性进行建模的时间注意机制以及通过自适应融合时空表示的融合融合机制形成。变换注意力机制模型直接控制了历史和未来时间步长之间的关系，从而减轻了错误传播的影响。在两个真实数据集上的实验证实，GMAN具有最先进的性能。</p><p>这项工作的贡献概述如下:</p><ul><li>我们分别提出了空间和时间的注意机制来模拟动态的空间和非线性的时间相关。此外，我们还设计了一种自适应融合时空注意机制提取信息的门控融合方法。</li><li>提出了一种将历史交通特征转化为未来交通特征的注意力转化机制。该注意机制建立了历史时间步长与未来时间步长之间的直接关系模型，以缓解错误传播问题。</li><li>我们在两个实际流量数据集上对我们的图形多注意网络(GMAN)进行了评估，并且在1小时的预测中观察到了比最先进的基线方法提高4% 的改进和优越的容错能力。</li></ul><h3 id="Related-Work"><a href="#Related-Work" class="headerlink" title="Related Work"></a>Related Work</h3><h4 id="交通预测"><a href="#交通预测" class="headerlink" title="交通预测"></a>交通预测</h4><p>在过去的几十年中，交通预测得到了广泛的研究。与传统的时间序列方法（如自动回归综合移动影像匹配(ARIMA)）和机器学习模型（如支持向量回归(SVR)、 k 最近邻(KNN)）相比，深度学习方法（例如，长-短期记忆（LSTM））在捕获交通状况下的时间相关性方面表现出更优越的性能。为了建立空间相关性模型，研究人员应用卷积神经网络(CNN)来捕捉欧氏空间中的相关性。最近的研究制定了基于图的交通预测，并使用图卷积网络(GCN)建模道路网络中的非欧氏关联。这些基于图的模型通过一步一步的方法在预测前生成多个步骤，并可能受到不同预测步骤之间的误差传播的影响。</p><h4 id="图深度学习"><a href="#图深度学习" class="headerlink" title="图深度学习"></a>图深度学习</h4><p>将神经网络泛化为图结构化数据是一个新兴的话题。一系列研究概括了CNN，以在图谱或空间角度上对任意图形建模。另一类研究集中在图嵌入上，它学习保留图结构信息的顶点的低维表示将 WaveNet 集成到 GCN 中以进行时空建模。由于它学习静态邻接矩阵，因此该方法难以捕获动态空间相关性。</p><h4 id="注意力机制"><a href="#注意力机制" class="headerlink" title="注意力机制"></a>注意力机制</h4><p>由于注意力机制的高效性和建模依赖性的灵活性，其注意力机制已广泛应用于各个领域。注意机制的核心思想是根据输入的数据自适应地关注最相关的特征。最近，研究人员将注意力机制应用于图形结构化数据，来建模图形分类的空间相关性。我们将注意力机制扩展到图形时空数据预测。</p><h3 id="Preliminaries"><a href="#Preliminaries" class="headerlink" title="Preliminaries"></a>Preliminaries</h3><p>我们把道路网络表示为一个加权有向图 $ G=(V,E,A) $ 。这里，V 是 N = | V | 的顶点集合，代表道路网络上的点（例如交通传感器）。E 是一组边，代表顶点之间的连通性。$A \in R^{N \times N}$ 表示加权邻接矩阵。其中 $A_{v_i,v_j}$ 代表两个顶点之间的接近程度（由道路网络距离度量）。在时间步长为 t 的交通状况用图$G$ 上的图信号 $X_t \in R^{N \times C}$ 表示，其中 $C$ 是感兴趣的交通状况的数量（例如交通量，交通速度等。）</p><h4 id="Problem-Studied"><a href="#Problem-Studied" class="headerlink" title="Problem Studied"></a>Problem Studied</h4><p>给定在顶点 N 处的历史 P 时间步长 $X = (X_{t_1},X_{t_2},…,X_{t_P}) \in R^{P\times N \times C}$ ，我们的目标是预测所有顶点在下一个 Q 时间步长的交通情况，表示为 $\hat Y = (\hat X_{t_{P+1}},\hat X_{t_{P+2}},…,\hat X_{t_{P+Q}}) \in R^{Q\times N \times C}$ 。</p><h3 id="Graph-Multi-Attention-Network"><a href="#Graph-Multi-Attention-Network" class="headerlink" title="Graph Multi-Attention Network"></a>Graph Multi-Attention Network</h3><p>图2显示了我们提出的 GMAN 框架，包含一个 encoder-decoder 结构。编码器和解码器都包含 L 个残差连接的 STAtt Block。每一个 STAtt Block 都是由具有门控功能的时空注意机制组成的。在编码器与解码器之间，网络中加入了一个 <strong>transform</strong> 注意层将编码的交通特征转换为解码特征。我们还通过时空嵌入（STE）将图形结构和时间信息整合到多注意机制中。此外，为了方便残差连接，所有层输出维度都是 D。接下来将详细介绍这些模块。</p><p><img src="/articles/GMAN/image-20210301090744336.png" alt="image-20210301090744336"></p><h4 id="Spatio-Temporal-Embedding"><a href="#Spatio-Temporal-Embedding" class="headerlink" title="Spatio-Temporal Embedding"></a>Spatio-Temporal Embedding</h4><p>由于交通条件的演变受到了道路网络的限制，将道路网信息整合到预测模型中至关重要。为此，我们提出了一种将顶点编码为向量的局部嵌入方法，以保存图形结构信息。具体来说，我们利用 <strong>node2vec</strong> 方法来学习顶点表示。此外，为了协同训练预训练好的整个模型的向量，这些向量会被输入到一个两层完全连接的神经网络中。然后，我们将得到空间嵌入，表示为 $e^S_{v_i} \in R^D, v_i \in V$ 。</p><p>空间嵌入只能提供静态的表示，不能反映路网中交通传感器之间的动态相关性。因此，我们进一步提出了一种时间嵌入方法，将每个时间步编码成一个向量。具体来说，把一天分成 T 个时间步长。我们使用独热编码将每一个时间步长的 <em>day-of-week</em> 和 <em>time-of-day</em> 编码到 $R^7$ 和 $R^{T+7}$ 中，接下来，我们应用一个两层完全连接的神经网络将时间特征转化为向量。在我们的模型中，我们嵌入了历史 P 和未来 Q 时间步长的时间特征，表示为$e^T_{t_j} \in R^D$ ，其中$t_j = t_1,…,t_P,…,t_{P+Q}$ 。为了获得随时间变化的顶点表示，我们将上述空间嵌入和时间嵌入融合为时空嵌入（STE），如图2b所示。具体来说，对于时间步长 $t_j$ 时的顶点 $v_i$ ，其 STE 被定义为 $e_{v_i,t_j} = e^S_{v_i} + e^T_{t_j}$ 。因此，在 P+Q 时间步长中，N 个顶点的 STE 表示为 $E \in R^{(P+Q)\times N \times D}$ 。STE包含图形结构和时间信息，可用于空间、时间和 transform 注意机制。</p><h4 id="ST-Attention-Block"><a href="#ST-Attention-Block" class="headerlink" title="ST-Attention Block"></a>ST-Attention Block</h4><p>如图 2c 所示，ST-Attention 模块包含一个空间注意机制，一个时间注意机制和一个门控机制。我们将第 $l$ 个 block 的输入表示为 $H^{(l-1)}$ ，其中在步长$t_j$ 处顶点$v_i$ 的隐藏状态表示为 $h^{(l-1)}_{v_i,v_j}$ 。在第 $l$ 个 block 中，空间和时间注意机制的输出表示为 $H^{(l)}_S$ 和 $H^{(l)}_T$ ，其中在步长$t_j$ 处顶点$v_i$ 的隐藏状态表示为 $hs^{(l)}_{v_i,v_j},ht^{(l)}_{vi,tj}$ 。通过门控融合，得到了该模块的输出结果，表示为 $H^{(l)}$ 。</p><p>为了便于说明，我们将非线性变换表示为：</p><script type="math/tex; mode=display">f(x) = ReLU(xW+b),</script><h4 id="Spatial-Attention"><a href="#Spatial-Attention" class="headerlink" title="Spatial Attention"></a>Spatial Attention</h4><p>条道路的交通状况受到其他道路的不同影响。这种影响是动态的，随着时间的推移而变化。为了模拟这些特性，我们设计了一种空间注意机制来自适应地捕捉道路网络中传感器之间的相关性。其关键思想是在不同的时间步动态地将不同的权重分配给不同的顶点（例如，传感器），如图3所示。对于在时间步长 $t_j$ 处的顶点 $v_i$ ，我们计算所有顶点的加权和：</p><script type="math/tex; mode=display">hs^{(l)}_{v_i,v_j} = \sum_{v\in v} \alpha_{v_i,v} · h^{(l-1)}_{v,t_j} ,</script><p>表示 $V$ 所有顶点的集合， $\alpha_{v_i,v}$ 为注意机制得分，表示顶点 $v$ 到 $v_i$ 之间的重要程度，其分数之和等于 1：$\sum_{v \in V} \alpha_{v_i,v} = 1$</p><p><img src="/articles/GMAN/image-20210301104231532.png" alt="image-20210301104231532"></p><p>在一定的时间步长下，当前交通状况和路网结构都会影响传感器之间的相关性。例如，道路上的拥堵可能会严重影响其相邻道路的交通状况。基于这种直觉，我们同时考虑交通特征和图形结构来学习注意力得分。具体来说，我们将隐藏状态与时空嵌入连接起来，并采用标度点积方法计算顶点 $v_i$ 与 $V$ 之间的相关性。</p><script type="math/tex; mode=display">s_{v_i,v} = \frac{<h_{v_i,t_j}^{(l-1)}||e_{v_i,t_j},h^{(l-1)}_{v,t_j}||e_{v,t_j}>}{\sqrt{2D}},</script><p>其中 $||$ 表示连接操作，$〈•,•〉$ 表示内积操作，2D 是$h_{v_i,t_j}^{(l-1)}||e_{v_i,t_j}$ 的维度。然后，通过 Softmax 归一化为：</p><script type="math/tex; mode=display">\alpha_{v_i,v} = \frac{exp(s_{v_i,v})}{\sum_{v_r \in V}exp(s_{v_i,v_r})}</script><p>在获得注意得分 $\alpha_{v_i,v}$ 之后，可以通过等式2更新隐藏状态。</p><p>为了稳定学习过程，我们将空间注意力机制扩展为 <strong>multi-head</strong>。 具体来说，我们将K个并行注意机制与不同的可学习预测联系起来：</p><p><img src="/articles/GMAN/image-20210302084718874.png" alt="image-20210302084718874"></p><p><img src="/articles/GMAN/image-20210302084736425.png" alt="image-20210302084736425"></p><p>其中 $f^{(k)}_{s,1}(·),f^{(k)}_{s,2}(·),f^{(k)}_{s,3}(·)$ 表示在第 k 个 <strong>head attention</strong> 中三个不同的非线性预测，输出维度 $d = D/K$ 。</p><p>当顶点数量 N 很大时，由于我们需要计算 $N^2$ 个注意分数，因此时间和内存消耗都很大。 为了解决此限制，我们进一步提出了一个<em>group spatial attention</em>，其中包含了<em>intra-group spatial attention</em>和<em>inter-group spatial attention</em>，如图4所示。</p><p><img src="/articles/GMAN/image-20210302085935418.png" alt="image-20210302085935418"></p><p>我们随机将 N 个顶点划分为 G 个组，其中每个组包含 $M=N/G$ 个顶点。在每一组中，我们通过方程5、6、7 计算 <em>intra-group attention</em> 以模拟顶点之间的局部空间相关性，其中组间共享参数。然后，我们在每个组中应用最大池化方法，以获得每个组的单个表示。接下来，我们计算<em>inter-group spatial attention</em>来建模不同组之间的相关性，为每个组产生一个全局特征。局部特征被添加到相应的全局特征中，作为最终输出。</p><p>在<em>group spatial attention</em>上，我们需要计算每个时间步长的  $GM^2 + G^2 = NM+(N/M)^2$ 个 <em>attention scores</em> 。梯度为零时，我们知道 $M = \sqrt[3]{2N}$ 时 <em>attention score</em> 的值达到最小值 $2^{-1/3}N^{4/3}\ll N^2 $ 。</p><h4 id="Temporal-Attention"><a href="#Temporal-Attention" class="headerlink" title="Temporal Attention"></a>Temporal Attention</h4><p>一个地点的交通状况与它之前的观察结果是相关的，并且这种相关性随着时间步长的变化是非线性的。为了模拟这些特性，我们设计了一个 <em>Temporal Attention</em> 来自适应地模拟不同时间步骤之间的非线性关联，如图5所示。注意，时间相关性受交通条件和相应的时间背景的影响。例如，发生在早晨高峰时间的拥堵可能会影响几个小时的交通。因此，我们同时考虑流量特征和时间来度量不同时间步长之间的相关性。具体来说，我们将隐藏状态与时空嵌入相连接，并采用<em>multi-head</em>方法计算 <em>attention score</em> 。最后考虑顶点 $v_i$ ，时间步长 $t_j$ 与 $t$ 之间的相关性定义为：</p><p><img src="/articles/GMAN/image-20210302095459275.png" alt="image-20210302095459275"></p><p>其中 $u^{(k)}_{t_j,t}$ 表示时间步长 $t_j$ 与 $t$ 之间的相关性，$\beta^{(k)}_{t_j,t}$ 表示第 k 个 <em>head attention score</em> 表明时间步骤 $t$ 到$t_j$ 的重要性，$f^{(k)}_{t,1},f^{(k)}_{t,2}$ 表示两个不同的可学习的 <em>transforms</em> ，$N_{t_j}$ 表示时间步长 $t_j$ 之前的集合。仅考虑时间步中早于目标步的信息以启用因果关系(<strong>causality</strong>)。一旦获得 <em>attention score</em> 后，顶点 $v_i$ 在时间步长 $t_j$ 处 的 <em>hidden state</em> 个更新方式如下：</p><p><img src="/articles/GMAN/image-20210302204132568.png" alt="image-20210302204132568"></p><p>其中 $f^{(k)}_{t,3}$ 代表一个非线性投影。公式8、9和10中的可学习参数通过并行计算在所有顶点和时间步上共享。</p><h4 id="Gated-Fusion"><a href="#Gated-Fusion" class="headerlink" title="Gated Fusion"></a>Gated Fusion</h4><p>道路在某一特定时间步长下的交通状况与其前期值和其他道路的交通状况相关。如图2c所示，我们设计了门控融合来自适应地融合空间和时间表示。第 $l$ 个block ，时间和空间注意机制的输出表示为 $H^{(l)}_S,H^{(l)}_T$ ，两者在编码器与解码器中都有相同的形状 $R^{P\times N \times D},R^{Q\times N \times D}$ ，融合公式如下：</p><p><img src="/articles/GMAN/image-20210302205242473.png" alt="image-20210302205242473"></p><p><img src="/articles/GMAN/image-20210302205254514.png" alt="image-20210302205254514"></p><p>其中 $W_{z,1}\in R^{D\times D},W_{z,2}\in R^{D\times D},b_z \in R^D$ 是可学习参数，$\odot$ 表示按元素计算的乘积，$\sigma(·)$ 表示 sigmoid 激活函数，z 是门控。门控融合机制自适应地控制空间和时间依赖在每个顶点和时间步长的流。</p><h4 id="Transform-Attention"><a href="#Transform-Attention" class="headerlink" title="Transform Attention"></a>Transform Attention</h4><p>为了减轻长时间范围内不同预测时间步长之间的误差传播效应，在编码器和解码器之间增加了一个<em>Transform Attention</em>。它对每个未来时间步长和每个历史时间步长之间的直接关系进行建模，以转换已编码的交通特征，以生成未来表示，作为解码器的输入。如图6 所示，对顶点 $v_i$ ，通过 <em>spatio-temporal</em> 嵌入计算预测时间步长 $t_j(t_j = t_{P+1},…,t_{P+Q})$ 与历史时间步长 $t(t = t_1,..,t_P)$ 之间的相关性。</p><p><img src="/articles/GMAN/image-20210302221757111.png" alt="image-20210302221757111"></p><p>$\gamma^{(k)}_{t_j,t}$ 为 <em>attention score</em> ，通过在所有历史时间步骤中自适应地选择相关特征，将编码的流量特征转换到解码器。</p><p><img src="/articles/GMAN/image-20210302222011345.png" alt="image-20210302222011345"></p><p>方程13、14和15可以在所有顶点和时间步骤中并行计算，共享可学习的参数。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;blockquote&gt;
&lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/1911.08415&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;GMAN: A Graph Multi-Attention Network for Traffic 
      
    
    </summary>
    
    
    
  </entry>
  
  <entry>
    <title>Traffic-Network-Flow-Prediction</title>
    <link href="https://hahally.github.io/articles/Traffic-Network-Flow-Prediction/"/>
    <id>https://hahally.github.io/articles/Traffic-Network-Flow-Prediction/</id>
    <published>2021-02-22T12:24:33.000Z</published>
    <updated>2021-02-22T12:49:41.693Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p><a href="https://ieeexplore.ieee.org/document/9007678" target="_blank" rel="noopener">Traffic Network Flow Prediction Using ParallelTraining for Deep Convolutional NeuralNetworks on Spark Cloud</a></p></blockquote><h3 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h3><p>道路网络中的交通流量是相互交互和相互依存的。 用分析方法描述交通网络流量的动态变化具有挑战性。 在本文中，将使用深度卷积神经网络（DCNN）模型解决交通网络流量预测问题。为DCNN模型的并行训练算法开发了理论基础。在Spark Cloud上实现了交通网络流量预测的主从并行计算解决方案。应用交通网络流量数据验证了dcnn预测模型和并行训练算法的有效性。实验结果表明，DCNN交通网络流量预测模型的预测性能优于基于BP神经网络、支持向量回归、径向基函数和决策树回归的典型预测模型。所提出的并行训练方法可以提高训练效率，并通过对数据子集的局部学习获得整个数据集的全局特征。</p><p><strong>index-item</strong> : 深度卷积神经网络(DCNNs)、并行训练、Spark云计算、交通大数据、交通网络流量预测</p><h3 id="INTRODUCTION"><a href="#INTRODUCTION" class="headerlink" title="INTRODUCTION"></a>INTRODUCTION</h3><p>交通流预测可以引导出行行为，从而缓解道路网络拥堵，提高出行效率，促进交通安全。准确高效的交通流预测是数据驱动智能交通系统的关键部分。</p><p>分布在道路网络上的交通流量是相互依赖，相互影响的。 交通网络流量中存在复杂的动态变化，其中道路的拥堵可能直接或间接影响网络中其他道路的交通流量。传统的路段交通流预测方法只考虑了路段的时间序列特征，忽略了路段之间的闭合关系和交互演变。交通网络流量预测模型既要反映每条道路的时间序列演变，又要反映网络流量的空间耦合关系，其中涉及到图像式的数据处理。</p><p>深度卷积神经网络(DCNN)模型与其他深度学习模型相比，在提取图像等高维数据特征方面具有优势。它已广泛应用于特征学习，语音识别和医学健康诊断。本文尝试利用 DCNN 模型提取交通网络流量的<em>时空相关动态学</em> 特征。</p><p>在处理交通网络流量的大数据进行预测时，在DCNN模型中训练大量参数非常耗时。 云计算在计算资源调度和大数据实时处理方面具有显着优势。特别是最近流行的Spark Cloud 采用了基于内存的计算和主从并行处理的高级架构，突破了某些大数据处理架构（如Hadoop）中的内存限制。此外，它还适用于复杂逻辑算法的实时科学计算。因此，我们尝试为DCNN模型开发一种并行训练方法，该方法适用于采用基于内存的计算和主从并行处理的云计算平台。本文的主要贡献如下:</p><ol><li>基于自适应梯度下降原理，为DCNN模型开发了并行训练算法的理论基础。它保证了所提出的并行训练算法能够像串行训练算法一样，通过对多个计算节点和各自的数据集进行局部学习，从而学习整个数据集的全局特征，具有良好的收敛性。</li><li>将 DCNN 模型应用于交通网络流量预测，以获取交通网络的时空数据特征。该模型首先在 Spark cloud 计算平台上实现，以解决交通网络流量大数据面临的计算复杂性问题。利用实际交通网络工作流数据验证了基于云的并行训练算法的渐近收敛性和加速优势。</li></ol><p>本文的其余部分安排如下。 第二节总结了相关的研究工作。 第三部分描述了DCNN预测模型的网络结构和训练样本。 在第四部分，我们为DCNN模型开发了并行训练算法的理论基础。 我们还开发了基于Spark Cloud 的实施解决方案。 在第五节中，验证了DCNN模型对交通网络流量预测的预测准确性和通用性。 此外，使用实际交通流数据演示了并行训练算法的收敛性和加速性能。 最后，第六节总结了本文。</p><h3 id="RELATED-WORK"><a href="#RELATED-WORK" class="headerlink" title="RELATED WORK"></a>RELATED WORK</h3><p>以往的交通流预测工作大致可分为两类: 模型驱动方法和数据驱动方法。模型驱动技术在过去几十年中被广泛应用于交通预测。例如，根据历史交通流的周期性相似性，应用自适应卡尔曼滤波方法[5]预测未来的交通流情况。然而，在这些方法中，交通流的动态波动被假定为线性。此外，它们还可以有效地进行单链路流量的时间序列预测。</p><p>数据驱动方法采用间接建模的方法来描述交通流的随机非线性特征。这些方法主要包括神经网络(NN)、支持向量回归(SVR)、径向基核函数(RBF)、决策树回归(DTR)、集成学习回归和极限学习机等。这些方法是数据挖掘的有效工具，可以从一系列数据中提取有用的信息。数据驱动方法用于确定直接模型的结构和参数。开发了一种连续的蚁群优化算法，以加速支持向量回归模型在城际高速公路交通流量预测中的参数选择。通过自适应粒子群优化确定了多层神经网络的最佳结构和参数，提高了流量变量的预测精度。然而，这些研究主要集中在道路时间序列特征的提取上。此外，用浅层结构模型提取的交通流特征也是有限的。</p><p>通过模拟人脑的多层感知结构，深度学习可以有效的从高维数据中提取特征信息。它一直被用来处理通信领域的网络流量控制和路由管理。该方法在道路交通流预测领域也得到了应用。通过对交通流数据的重构，将堆叠式编码的 <em>Levenberg-Marquardt</em> 模型和深度信息网络模型应用于挖掘短时交通流固有的时间特征。此外，结合多源数据融合开发了混合深度学习模型方法，以提高业务流预测的准确性和鲁棒性。卷积神经网络模型被用来提取交通网络速度的时间和空间特征。采用 DCNN 模型提取空间特征，采用长短期记忆模型提取交通网速时间序列特征。提出了一种针对 DCNN 模型的随机子空间学习方法，通过寻址不完全交通数据来提高交通流预测的鲁棒性。然而，利用深度学习模型进行交通网络流量预测仍然是一个难题。此外，DCNN 模型在面对大数据时的长时间训练是实时应用中一个尚未解决的问题。针对细胞神经网络模型，提出了一种混合并行训练方法，结合卷积层的数据并行性和完全连接层的模型并行性，并在 GPUs上实现。GPUs 不能灵活地扩展和高效地提供基于内存的计算资源。同时，也没有为并行训练算法的收敛性和稳定性提供理论基础。</p><p>云计算为减少训练时间提供了一种可行的解决方案。这是因为处理器、内存和存储器可以灵活地扩展和集群。近年来，apache Spark云计算平台在大数据处理方面取得了令人瞩目的成绩。采用基于内存的计算架构，由一个主计算节点和多个从计算节点组成。Spark cloud已经展示了在大数据科学计算领域应用的潜力，如贝叶斯网络分类、药物发现中的目标预测，以及使用深度学习的移动大数据分析。</p><p>本文采用与串行训练算法相同的自适应梯度下降机制，提出了一种并行训练算法。因此，所提出的算法具有理论基础，其中全局特征可以从局部学习中提取出来，即使数据集被分解并提供用于局部学习。采用园区云计算的主从结构实现了交通网络流量预测DCNN模型的并行训练算法。主节点和子节点之间只传输非常有限的数据，如学习参数、局部梯度平方、全局学习率和局部损失函数值。</p><h3 id="TRAFFIC-NETWORK-FLOW-PREDICTION-MODE"><a href="#TRAFFIC-NETWORK-FLOW-PREDICTION-MODE" class="headerlink" title="TRAFFIC NETWORK FLOW PREDICTION MODE"></a>TRAFFIC NETWORK FLOW PREDICTION MODE</h3><h4 id="A-DCNN-Prediction-Mode"><a href="#A-DCNN-Prediction-Mode" class="headerlink" title="A.   DCNN Prediction Mode"></a>A.   DCNN Prediction Mode</h4><p>DCNN模型可以捕获交通图像数据样本中丰富的时空特征。特征图中的卷积核连续滑动可以感知不同道路之间交通流的局部相关性。同时，在卷积特征图上滑动的池化窗口被用来进一步保留交通流的基本相关性并减小参数的维数。 最终，具有不同重量和偏置的完全连接的神经进一步重构了交通全局特征。</p><p>图1演示了交通网络流量的 DCNN 预测模型的结构。最左边的矩形代表一个可变的流量输入矩阵，紫色的矩形代表一个可变的内核矩阵，绿色的矩形代表一个特征映射矩阵，白色的矩形代表一个池窗口。9层网络结构包括输入层(LI)、卷积层1(Lc1)、池化层1(Lp1)、卷积层2(Lc2)、池化层2(Lp2)、三层全连接层(Lf1、 Lf2、 Lf3)和输出层(Lo)。DCNN 模型的训练目标是建立海量数据样本输入矩阵与输出向量之间的复杂非线性映射关系。在不破坏图像空间结构的前提下，输入图像可以直接输入网络。</p><p><img src="/articles/Traffic-Network-Flow-Prediction/image-20210221234502743.png" alt="image-20210221234502743"></p><h4 id="B-Training-Sample-Construction"><a href="#B-Training-Sample-Construction" class="headerlink" title="B. Training Sample Construction"></a>B. Training Sample Construction</h4><p>交通网络结构是静态的，分布式协调流是动态的。类似于面部轮廓上的肌肉运动以形成不同的表情，流量分布和协调表示不同的流量形态。 交通网络流在空间维度上是相互依存和相互关联的。 同时，在时间维度上，每条道路的规则间隔都可能出现某些具有波动的相似交通模式。 因此，在大规模交通网络流量预测中应综合考虑交通网络流量的时空特征。</p><p>图2展示了时空训练图像样本的构建过程。 从多个传感器收集的原始数据被汇总到相应的时空序列中，以显示交通网络流量。</p><p><img src="/articles/Traffic-Network-Flow-Prediction/image-20210221234809890.png" alt="image-20210221234809890"></p><p>一个二维时空输入矩阵构造为</p><p><img src="/articles/Traffic-Network-Flow-Prediction/image-20210221234959933.png" alt="image-20210221234959933"></p><p>其中，$x_{m,k}$ 表示在第k时刻路网第m条链路上的交通流量，d表示时维数据的截断长度。 输入矩阵中的行向量揭示了流在每个链路上的时间序列特征，输入矩阵中的列向量表示流在空间上的耦合特征。M 表示网络中最大的链路数。下文中，变量的下标表示该变量与第n个训练样本相关。训练样本的最大数量定义为N。 如果将输入矩阵中的每个元素都视为图像中的像素，则将大量矩阵类型的数据样本转换为一系列图像，馈入DCNN模型。 该模型提取行和列之间的时空相关性特征。</p><p>训练样本的输出表示为：</p><p><img src="/articles/Traffic-Network-Flow-Prediction/image-20210222000325167.png" alt="image-20210222000325167"></p><p>其中 $y_{m,k+1}$ 是第 $k + 1$ 时刻在第$m$条链路上的输出业务流，$T$表示转置。 训练输入矩阵 $x_n$ 和相应的输出矢量$y_n$形成训练样本$D_n$。 </p><h3 id="PARALLEL-TRAINING-ON-SPARK-CLOUD"><a href="#PARALLEL-TRAINING-ON-SPARK-CLOUD" class="headerlink" title="PARALLEL TRAINING ON SPARK CLOUD"></a>PARALLEL TRAINING ON SPARK CLOUD</h3><h4 id="A-Problem-Statemen"><a href="#A-Problem-Statemen" class="headerlink" title="A. Problem Statemen"></a>A. Problem Statemen</h4><p>在交通大数据环境下，要优化的DCNN模型的大量参数需要进行计算密集型任务。 问题是在不降低精度的情况下提高模型参数的训练效率。一种解决方案是将总数据集分解为一些数据子集，并使用多个计算节点以并行方式针对特定于它们的数据子集训练模型参数（称为局部 学习）。 但是，必须协调仅提取数据子集的局部特征的局部学习，以获取整个数据集的全局特征。本节尝试为并行训练方法开发理论基础，并提出基于Spark cloud计算平台的并行训练方法的实现解决方案。 </p><h4 id="B-Objective-Function"><a href="#B-Objective-Function" class="headerlink" title="B. Objective Function"></a>B. Objective Function</h4><p>整个数据集D分为R个部分，每个部分定义为$D^r$（r = 1，2，…，R）。因此，数据集D可以表示为$D^{r}$的集合。其中变量中的 r 表示变量相对于第r个数据子集$D^r$，而$N^r$是第 r 个数据子集的大小。</p><p><img src="/articles/Traffic-Network-Flow-Prediction/image-20210222105827613.png" alt="image-20210222105827613"></p><p>基于(3)中提出的数据分解机制，给出了 DCNN 模型并行训练的目标函数</p><p><img src="/articles/Traffic-Network-Flow-Prediction/image-20210222110329834.png" alt="image-20210222110329834"></p><p>DCNN 模型训练的目的是最小化目标函数(4) ，并利用 数据集 D 获得权值和偏差。这些权重和偏差称为全局学习参数。对于数据子集，最小均方误差的权值和偏差称为局部学习参数。</p><h4 id="C-Parallel-Training-Approach"><a href="#C-Parallel-Training-Approach" class="headerlink" title="C. Parallel Training Approach"></a>C. Parallel Training Approach</h4><p>并行训练方法是通过并行局部学习获得全局学习参数。这包括两个主要的训练阶段：并行特征前向学习和并行误差反向传播。</p><p>1) 并行特征正向学习：对于并行特征前向学习，基于相应的数据子集，以并行方式执行各个网络层中的所有激活函数。对于卷积层、池化层和全连通层，分别表示为  $a^{r,l}_{n,j,c}$ 、 $a^{r,l}_{n,j,p}$  、$a^{r,l}_{n,j,f}$</p><p>计算方法如下</p><p><img src="/articles/Traffic-Network-Flow-Prediction/image-20210222111431596.png" alt="image-20210222111431596"></p><p>在 DCNN 模型中，c、 p 和 f 分别表示卷积层、池化层和全连接层；$l $表示第l层，$L$表示层数； $i $表示第 $l $层是卷积或池化层时的第 $i$个输入特征图，或第l层是完全连接层时的第 $i$ 个神经元；当第 $l$ 层是卷积或池化层时，$j$ 表示第$j$个输出特征图；当第$l$层是完全连接层时，$j$表示第$j$个神经元。$w^{r,l}_{j,i,c}$ 和 $b^{r,l}_{j,c}$ 分别是为卷积层的第 $l$ 层中的卷积核矩阵和偏差矩阵。 $N^{l-1}_p$ 表示($l-1$)层中输出特征映射的数量，该层是一个池层。$w^{r,l}_{j,i,f}$和$b^{r,l}_{j,f}$分别是为全连层的第 $l$ 层中的权值和偏置。$N^{l-1}_f$表示($l-1$)层中神经元的数量，该层是一个全连接层。 $σ( )$ 是激活函数，通常选择为整流线性单位，即 $σ(x) = max(0,x)$。* 表示卷积运算。 $H^l_p$ 和 $W^l_p$ 分别是第$l$层中池化窗口的高度和宽度。 $s^l_p$ 是最大池化操作的滑动步幅。</p><p>2) 并行误差 BP：基于传统的梯度下降原理[27]，在并行训练过程中确定了并行误差BP阶段的全局学习参数和局部学习参数之间的关系。在步骤 $t$，完全连接的层中的全局学习参数 $w^l_{j,i,f}$ 和 $b^l_{j,f}$ 更新为</p><p><img src="/articles/Traffic-Network-Flow-Prediction/image-20210222165242874.png" alt="image-20210222165242874"></p><p><img src="/articles/Traffic-Network-Flow-Prediction/image-20210222165325532.png" alt="image-20210222165325532"></p><p>全连通层中的局部权重和偏差表示为</p><p><img src="/articles/Traffic-Network-Flow-Prediction/image-20210222165411159.png" alt="image-20210222165411159"></p><p>类似地，在步骤t的卷积层中的全局学习参数 $w^l_{j,i,c}$ 和 $b^l_{j,c}$ 迭代计算为</p><p><img src="/articles/Traffic-Network-Flow-Prediction/image-20210222165646807.png" alt="image-20210222165646807"></p><p>卷积层中的局部权重和偏差表示为</p><p><img src="/articles/Traffic-Network-Flow-Prediction/image-20210222165723988.png" alt="image-20210222165723988"></p><p>式$(8)-(15)$表明，全局学习参数 $w^l_{j,i,c}$ ， $b^l_{j,c}$ ， $w^l_{j,i,f}$ 和 $b^l_{j,f}$ 分别是局部学习参数 $w^{r,l}_{j,i,c}$ ， $b^{r,l}_{j,c}$  和 $b^{r,l}_{j,f}$ 的平均值$(r = 1,2,…,R)$ 。</p><p>在$(8)-(15)$中，相对于数据子集$r$，迭代地计算出误差敏感性 $δ^{r,l}_{n,j,f}$ ， $δ^{r,l}_{n,j,p}$ 和 $δ^{r,l}_{n,j,c}$ ，如下所示：</p><p><img src="/articles/Traffic-Network-Flow-Prediction/image-20210222170851525.png" alt="image-20210222170851525"></p><p>其中 $N^{l+1}_f$ 是第$(l + 1)$层中的神经元数量，该层是完全连接的层。 $N^{l+1}_c$ 是第$(l + 1)$层（卷积层）中输出特征图的数量。 $rot180(w^{r,l+1}_{\tau,j,c})$ 表示 $w^{r,l+1}_{\tau,j,c}$ 中所有元素翻转 $180°$， $up(δ^{r,l+1}_{n,j,p})$ 表示 $δ^{r,l+1}_{n,j,p}$ 的向上采样操作，以使其大小等于 $z^{r,l}_{n,j,c}$ ， $\bigodot$ 表示元素相乘。</p><p>令$θ(ξ) = {w^l_{j,i,c}, b^l_{j,c}, w^l_{j,i,f}, b^l_{j,f}}$表示从步骤 $ξ$的全局权重和偏差置换的列向量。</p><p>局部梯度表示为 $g^r(ξ) = \frac{∂J^r}{∂θ(ξ)}=\sum_{n=1}^{N^r}\frac{∂J^r_n}{∂θ(ξ)}.$ </p><p>局部梯度平方表示为 $G^r(ξ)=[g^r(ξ)]^Tg^r(ξ) .$</p><p>全局自适应学习率可由传统学习率确定，表示为</p><p><img src="/articles/Traffic-Network-Flow-Prediction/image-20210222173540467.png" alt="image-20210222173540467"></p><p>其中ε是基本学习率，μ是极小的常数。公式$(19)$表示可以从前$(t-1)$个步骤的局部梯度平方$G^r(ξ)(ξ= 1,2,…,t-1)$的累积和中合成$η(t)$ 。</p><p>以上推导过程表明，DCNN模型的序列训练和并行训练算法都是相对于整个数据集从统一梯度下降原理出发的，也就是说，并行训练算法的收敛性类似于串行训练算法。 从理论上讲，这保证了整个数据集的全局特征都可以从局部学习中提取出来，而与各自的数据子集无关。</p><h4 id="D-Algorithm-Representation"><a href="#D-Algorithm-Representation" class="headerlink" title="D. Algorithm Representation"></a>D. Algorithm Representation</h4><p>算法1中详细说明了基于数据并行化的并行训练过程。主节点负责任务调度，资源分配，数据聚合以及从节点之间的数据分配。 同时，从节点主要承担特定的计算任务。 第1行和第2行初始化主节点和从节点。 第4行描述了主节点广播的全局参数。 第5-15行说明从属节点中的并行特征学习，第16–28行表示从属节点中的并行误差BP。 然后，从节点反馈局部学习参数，局部梯度平方和第29行的局部损失函数。主节点通过第30行聚合全局参数、学习速率和损失函数。</p><p><img src="/articles/Traffic-Network-Flow-Prediction/image-20210222174352908.png" alt="image-20210222174352908"></p><p><img src="/articles/Traffic-Network-Flow-Prediction/image-20210222174411353.png" alt="image-20210222174411353"></p><p><img src="/articles/Traffic-Network-Flow-Prediction/image-20210222174431003.png" alt="image-20210222174431003"></p><h4 id="E-Implementation-on-Spark-Cloud"><a href="#E-Implementation-on-Spark-Cloud" class="headerlink" title="E. Implementation on Spark Cloud"></a>E. Implementation on Spark Cloud</h4><p>DCNN模型的拟议并行训练方法已部署在Spark云上。 如图3所示，Spark云计算采用典型的主从结构，具有一个主节点和多个从节点。 红色箭头表示全局数据广播，而主节点和从节点之间的蓝色箭头表示本地数据收集。 资源管理器节点用于管理，调度和监视集群中节点的运行状态。数据并行性:将存储在Hadoop HDFS (distributed file system)中的流量网络流的大数据通过Spark应用程序编程接口进行分区。由此产生的交通数据分区被构造成弹性分布式数据集，并分布到相应的从节点上。并行训练：算法1中描述的并行训练过程适用于Spark云中的MapReduce编程系统。在迭代学习过程中，局部数据更新被视为Map阶段，而全局数据更新则在Reduce阶段实现。在Map阶段，所有从属节点以并行方式执行任务，尽管它们在不同的数据分区上。在Reduce阶段，主节点更新全局学习参数和学习率。然后，主节点将这些更新后的全局数据重新分配给每个从节点，作为后续迭代过程的初始值。该过程继续进行，直到达到最大迭代次数或训练精度条件。</p><p><img src="/articles/Traffic-Network-Flow-Prediction/image-20210222174921653.png" alt="image-20210222174921653"></p><p>在Spark云上并行训练交通网络流量预测模型的部署步骤如下:</p><p>1) 交通流训练数据集被提交到Spark cloud，并存储在所有slave nodes 中的HDFS中</p><p>2) 将DCNN预测模型的训练代码提交给Spark cloud</p><p>3) 计算节点信息是根据程序代码计算和配置的，程序代码包括执行器的数量、内存大小和每个执行器的CPU核数</p><p>4) 任务请求被提交给资源管理器(RM)，然后，RM 部署相应的计算节点，并在主节点和多个从节点之间建立连接</p><p>5) 主节点初始化网络结构和参数，并将模型副本分发给从节点</p><p>6) 主节点将全局学习参数和学习率分配给从节点</p><p>7) 从属节点以并行方式计算局部梯度、更新局部学习参数、梯度平方和损失函数，尽管在不同的数据分区上</p><p>8) 来自从节点的局部学习参数和梯度平方被累积以获取全局学习参数和主节点上的学习速率</p><p>9) 如果训练过程满足终止条件，则返回预测模型和预测结果。否则，转到步骤(6）</p><h3 id="EXPERIMENTS"><a href="#EXPERIMENTS" class="headerlink" title="EXPERIMENTS"></a>EXPERIMENTS</h3><h4 id="A-Dataset-Description"><a href="#A-Dataset-Description" class="headerlink" title="A. Dataset Description"></a>A. Dataset Description</h4><p>利用美国加州运输部交通绩效评估系统(PeMS)数据库中的路网交通流数据，通过并行训练对DCNN模型的预测性能进行评估。所需数据已从PeMS网站下载。道路网络中的日随机交通流呈现出相同的波动模式，反映了相对稳定的行驶需求和规则的交通流传播。这是一个很好的例子。可以观察到，一周中的同一天的交通流量呈现出一种与时间有关的周期性可重复性，并且受到道路的干扰。训练数据嵌入了高速公路上交通流量的时间序列波动特征及其与时空的耦合关系。 高速公路之间的交通流量。 DCNN模型用于捕获交通网络流的动态特征。</p><p>图4(a)示出加州高速公路交通网络结构，包括12条高速公路: $SR17-S,SR17-N,SR87-N,SR87-S,US101-N,US101-S,I280-N,I280-S,I680-N,I680-S,I880-N$以及$I880-S$ 。每30分钟收集一次交通数据，每5分钟收集一次来自39000多个探测器的数据，这些检测器分布在加州所有主要大城市的高速公路系统中。在本研究中，2016年的前9个月，从指定的12条高速公路收集的交通网络流量数据应用于实验。使用前8个月的数据作为训练数据集，剩余1个月的数据作为测试数据集。在Spark云计算平台上，将整个训练数据集分解为多个数据集，并分布到不同的计算节点上。通过多节点局部学习与对应数据子集的协调，学习整个数据集的全局数据特征。利用剩余的测试数据验证采用并行训练的DCNN模型是否具有提取稳定随机交通流模式的能力。将预测时间间隔定义为5、15、30、45和60min，将模型中的原始交通流数据聚合为相应的时间间隔。训练数据集和测试数据集分为输入数据和输出数据两部分。DCNN模型的输入和输出数据分别由(1)和式(2)构建。4(b)显示2016年5月9日的交通图像样本。红色区域代表拥堵，绿色区域代表交通顺畅。</p><p><img src="/articles/Traffic-Network-Flow-Prediction/image-20210222182324651.png" alt="image-20210222182324651"></p><h4 id="B-Evaluation-Indices-and-Parameter-Configuration"><a href="#B-Evaluation-Indices-and-Parameter-Configuration" class="headerlink" title="B. Evaluation Indices and Parameter Configuration"></a>B. Evaluation Indices and Parameter Configuration</h4><p>采用平均绝对误差（MAE）、平均相对误差（MRE）和均方根误差（RMSE）三个综合评价指标评价交通流预测模型的预测精度。计算方式如下：</p><p><img src="/articles/Traffic-Network-Flow-Prediction/image-20210222182613529.png" alt="image-20210222182613529"></p><p>其中$\hat{y}^m_n$是第m个链路上的预测流量，$y^m_n$是第m个链路上的观测流量，$M$是测试数据样本的输出维度，而$N_t$是测试数据样本的数量。为了衡量路网中不同路段之间的预测精度，本文提出了一种性能指标，即预测精度指标的累积比例（CP）。以MRE索引为例进行说明。将所有链路的MREs按升序排序。最小值和最大值分别表示为$MRE^{min},MRE^{max}$。在链路上的MRE准确性的示例被定义为MREs。CP表示为</p><p><img src="/articles/Traffic-Network-Flow-Prediction/image-20210222183518350.png" alt="image-20210222183518350"></p><p>其中$N_{MRE_S}$是$MRE_s$不大于$MRE_s$的链路数。 显然，当$MRE_s = MRE^{max}$时，$CP(MRE_s)= 1$。 CP与MRE的离散点曲线反映了随着MRE的增加，链路部分的累积分布。通过使用Spark云上不同数量的节点，加速Speedup用于评估并行训练算法的时间效率。 计算方式如下：</p><p><img src="/articles/Traffic-Network-Flow-Prediction/image-20210222184214461.png" alt="image-20210222184214461"></p><p>其中$T_s$是具有指定数据集的单台机器上DCNN模型的训练时间，而$T_p$是使用同一数据集的并行训练的训练时间。</p><p>DCNN模型的网络结构设计和参数调整对于预测准确性至关重要。 在这项研究中，我们通过大量实验获得了针对交通网络流量预测的不同预测间隔的适当模型结构。 这些在表$I$中列出。DCNN模型的所有模拟都部署在阿里云Elastic MapReduce计算平台上。</p><p><img src="/articles/Traffic-Network-Flow-Prediction/image-20210222184809248.png" alt="image-20210222184809248"></p><h4 id="C-Prediction-Accuracy-and-Generality-Capability"><a href="#C-Prediction-Accuracy-and-Generality-Capability" class="headerlink" title="C. Prediction Accuracy and Generality Capability"></a>C. Prediction Accuracy and Generality Capability</h4><p>为了充分说明基于 DCNN 模型的交通流预测在预测精度和通用性方面的优势，我们选择了其他4种交通流预测模型作为比较对象: BP 神经网络、 RBF、 SVR 和 DTR。</p><p>如表 $II$所示，对于不同的预测区间，DCNN模型的 MAE、 MRE 和 RMSE 明显小于其他预测模型。在 MRE 指标方面，对于不同的流量网络工作流预测任务，DCNN 模型的预测准确率一般在90% 以上。具体来说，对于5min 的流量预测，DCNN模型的预测精度比 BP、 RBF、 SVR 和 DTR 模型分别提高了4.51% 、7.24% 、10.15% 和6.27% 。对于15分钟交通流量预测，DCNN模型的预测精度分别比 BP、 RBF、 SVR 和 DTR 模型分别高5.26% 、7.17% 、5.23% 和6.07% 。对于30分钟、45分钟和60分钟的交通流量预测，DCNN 模型的预测精度一般比其他模型的预测精度高3.29-9.85%。DCNN 模型的 MAE和 RMSE 平均分别比 BP、 RBF、 SVR 和 DTR 预测模型的 MAEs和 RMSE 低7.49-40.07% 和4.38-38.22% 。这些结果表明，利用 DCNN 模型从海量交通数据中分离出时空特征，可以显著提高预测精度。与 BP、 RBF、 SVR 和 DTR 模型相比，DCNN 模型具有独特的卷积过程，能够处理网络流图像数据，在不丢失空间结构信息的情况下提取时间序列特征。此外，多层网络结构可以平衡隐藏在流量大数据集中的海量信息的学习。并行训练方法能够快速、全局地学习交通网络流的基本特征。</p><p>泛化能力是衡量DCNN模型对不同交通场景适应性程度的重要指标。通过一系列实验，将DCNN模型与其它四种典型预测模型进行比较，评价了DCNN模型在不同预测区间的通用性。表$II$表明，DCNN模型的预测精度在90.03%到92.16%之间。这说明DCNN模型对不同预测区间的适应能力较强。然而，BP和SVR模型的MRE随着预测间隔的变化而迅速波动。这两个模型对预测间隔的变化很敏感，这意味着这两个模型的泛化能力很低。对于不同的预测区间，RBF和DTR模型的预测精度相对稳定。当时间间隔较大时，该模型的交通流预测精度略有下降。这是因为模型提取的有效特征会随着数据量的减少而减少。图5显示了不同预测间隔下CP与MRE的关系曲线。对于5、15、30、45和60分钟的预测间隔，超过90％，85％，60％，80％以及70％的高速公路链接上，DCNN模型的MRE预测精度超过90％。 在不同的预测间隔下，DCNN模型的CP与MRE的曲线都位于其他预测模型的CP与MRE的曲线的左上侧。 这表明不同高速公路个体之间DCNN模型的预测准确性有所提高。</p><p><img src="/articles/Traffic-Network-Flow-Prediction/image-20210222184742766.png" alt="image-20210222184742766"></p><p><img src="/articles/Traffic-Network-Flow-Prediction/image-20210222192313448.png" alt="image-20210222192313448"></p><h4 id="D-Convergence-and-Efficiency"><a href="#D-Convergence-and-Efficiency" class="headerlink" title="D. Convergence and Efficiency"></a>D. Convergence and Efficiency</h4><p>表$III$中显示了Spark云上单机和多节点计算环境之间的类似预测性能。 显然，使用一台机器的预测精度为90.18％，而在相同的训练时期，使用Spark云上不同数量的计算节点的精度在91.46-92.69％之间。图6（a）描述了单机训练和使用不同计算节点的并行训练的相似收敛过程。图6（b）中，从迭代步骤100开始开始，我们可以进一步观察到损失函数随着训练时间的增加而减少。 它们最终在Spark云上的单机训练和分布式并行训练中收敛到几乎相同的阈值。 在不同的计算节点之间，预测精度和收敛过程的细微差异是由训练开始时随机函数产生的初始权重和偏差引起的。 尽管如此，由于理论上有保证的训练算法，训练过程最终收敛到几乎相同的阈值。表$III$和图6说明并行训练与单机训练训练结果的收敛性一致性。这与第四节的理论分析是一致的。</p><p><img src="/articles/Traffic-Network-Flow-Prediction/image-20210222193820080.png" alt="image-20210222193820080"></p><p><img src="/articles/Traffic-Network-Flow-Prediction/image-20210222193559417.png" alt="image-20210222193559417"></p><p>并行计算方法取得了良好的计算效率，如图7所示。与单机计算环境相比，随着图7中左y轴的增加，Spark云上计算节点的数量增加，计算时间逐渐减少。大量的训练样本分布在多个从节点之间，可以减少计算量。 此外，Spark云计算将训练过程的中间结果捕获到内存中。 这进一步提高了迭代数据处理的计算效率。如图7所示，在右y轴的基础上，随着节点数量的增加，加速比在早期阶段近似线性地增加。 但是，当后续阶段节点数增加到一定规模时，节点间的数据传输增加了通信开销，云上的资源调度和进程管理增加了并行管理开销。 这相应地影响了加速比并使其线性度降低。</p><p><img src="/articles/Traffic-Network-Flow-Prediction/image-20210222194702280.png" alt="image-20210222194702280"></p><h4 id="E-Tempo–Spatial-Demonstration"><a href="#E-Tempo–Spatial-Demonstration" class="headerlink" title="E. Tempo–Spatial Demonstration"></a>E. Tempo–Spatial Demonstration</h4><p>采用基于DCNN的交通网络流量预测模型，获取高速公路交通流量的时间序列特征和空间耦合特征。图8展示了2016年9月6日至14日5分钟间隔交通网络流量的观测和预测结果。图8(a)描述每5分钟在高速公路上观测一次的交通流量，分别用1-12编号。图8(b)表示高速公路上每5分钟的交通流量预测结果。从空间维度上，图8中，预测结果表明，在时间-空间动态中，流量形态与实际流量极为相似。同时，图8表明交通流量的周期性变化趋势和随机波动已经被 DCNN 模型沿时间维度近似捕获。同时，图8表明交通流量的周期性变化趋势和随机波动已经被 DCNN 模型沿时间维度近似捕获。</p><p><img src="/articles/Traffic-Network-Flow-Prediction/image-20210222200609677.png" alt="image-20210222200609677"></p><p>总体而言，基于DCNN的Spark云并行训练算法的交通网络流量预测模型具有明显的优势。通过对相应数据子集中分布计算节点的局部学习，显示了良好的全局特征学习能力和学习收敛的理论基础。与DCNN模型的串行学习算法相比，在Spark云上并行训练算法的实施提高了实时参数学习效率。</p><h3 id="CONCLUSION"><a href="#CONCLUSION" class="headerlink" title="CONCLUSION"></a>CONCLUSION</h3><p>本文提出了一种面向交通大数据处理的基于 DCNN 模型的交通网络流量预测方法。该算法结合了参数化网络模型的并行训练算法和计算机网络模型的并行训练算法。考虑到数据分解不会削弱对交通网络流全局特征的捕获，而是有利于计算复杂度的处理，为保证并行训练算法提供了理论基础。实验结果表明，该方法在预测精度和通用性方面优于 BP、 RBF、 SVR 和 DTR 模型。该并行训练算法既能提取不同路段交通流的时间序列特征，又能提取路段间交通流的空间耦合特征。全局特征可以通过分布式数据集的局部学习以并行方式重构。提出的并行训练算法提高了交通网络流量预测的计算效率。Spark云计算平台提供了灵活的机制来扩展计算资源和能力。这使得该实现方案适用于全网流量预测。基于Spark云计算的交通网络流量预测可以帮助交通指挥中心做出及时的控制决策，引导出行者选择最优路径规避拥堵。这是留给将来研究的。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;blockquote&gt;
&lt;p&gt;&lt;a href=&quot;https://ieeexplore.ieee.org/document/9007678&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;Traffic Network Flow Prediction Using 
      
    
    </summary>
    
    
    
      <category term="paper translation" scheme="https://hahally.github.io/tags/paper-translation/"/>
    
  </entry>
  
  <entry>
    <title>九品炼丹师</title>
    <link href="https://hahally.github.io/articles/%E4%B9%9D%E5%93%81%E7%82%BC%E4%B8%B9%E5%B8%88/"/>
    <id>https://hahally.github.io/articles/%E4%B9%9D%E5%93%81%E7%82%BC%E4%B8%B9%E5%B8%88/</id>
    <published>2021-02-19T14:09:07.000Z</published>
    <updated>2021-02-19T15:03:06.773Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>前言</p></blockquote><p>第一次参加<code>cv</code> 赛事，由清华举办的一场<code>AI 挑战赛</code> , 旨在推广 <code>jittor</code>框架的吧。<a href="https://www.educoder.net/competitions/index/Jittor-2" target="_blank" rel="noopener">传送门</a></p><p>共有两个赛道，一个细分类，一个目标检测。由于有一个毕设与目标检测相关，于是毫不犹豫的报名参加了。算是入坑<code>DL</code> 了。前期在<code>tensorflow</code> 、<code>pytorch</code> 、<code>jittor</code> 三大框架之间反复横跳，最后还是抛弃了<code>tf</code>。主要是服务器上的<code>tf</code>用不了显卡的算力。环境问题懒得去倒腾了。<code>pytorch</code> 上手也很快，而且与<code>jittor</code> 相似。</p><p>选着狗细分类这个赛道试水，结果差点每淹死在水里面。查阅了许多细分类的论文，一个个提到说效果达到<code>SOTA</code> ，结果到自己手里就废了。</p><blockquote><p>在好的配方，也能被炼废。 </p></blockquote><p>拿到配方，丹炉架好，药材就绪，大力按下回车键后，看着进度条缓缓加载，epoch 1,2,3,…</p><p>这是一个漫长的过程，睡一觉第二天醒来，观察各项指标变化，没有预期那么好，却也差强人意。点击提交后，果然，依旧没有好的效果。2021.2.19，在尝试好几种配方，反复炼丹数十余日后，最终还是以失败告终。</p><blockquote><p>高端的食材往往只需要简单的烹饪。</p></blockquote><p>按照 <code>baseline</code>的方法，仅仅只是使用了一个简单的<code>resnet50</code>分类网络而已，最后的效果却要高于我各种花里胡哨的方法好几个百分点。开源的基线已是我望尘莫及的极限了。着实有些颓废。</p><blockquote><p>I know nothing but my ignorance.</p></blockquote><p>炼丹之路注定是布满荆棘的坎坷之路。才疏学浅，当厚积薄发才是。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;blockquote&gt;
&lt;p&gt;前言&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;第一次参加&lt;code&gt;cv&lt;/code&gt; 赛事，由清华举办的一场&lt;code&gt;AI 挑战赛&lt;/code&gt; , 旨在推广 &lt;code&gt;jittor&lt;/code&gt;框架的吧。&lt;a href=&quot;https://
      
    
    </summary>
    
    
    
  </entry>
  
  <entry>
    <title>TsinghuaDogs-3</title>
    <link href="https://hahally.github.io/articles/TsinghuaDogs-3/"/>
    <id>https://hahally.github.io/articles/TsinghuaDogs-3/</id>
    <published>2021-02-09T08:43:23.000Z</published>
    <updated>2021-02-09T09:58:57.353Z</updated>
    
    <content type="html"><![CDATA[<h3 id="import-package"><a href="#import-package" class="headerlink" title="import package"></a>import package</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> json</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"><span class="keyword">from</span> tqdm <span class="keyword">import</span> tqdm</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> math <span class="keyword">import</span> sqrt</span><br><span class="line"><span class="keyword">import</span> cv2</span><br><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line">%matplotlib inline</span><br><span class="line"><span class="keyword">import</span> warnings</span><br><span class="line">warnings.filterwarnings(<span class="string">"ignore"</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> torchvision</span><br><span class="line"><span class="keyword">from</span> torchvision.models <span class="keyword">import</span> resnet18</span><br><span class="line"><span class="keyword">from</span> torchvision <span class="keyword">import</span> transforms</span><br><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> Dataset</span><br><span class="line"><span class="keyword">import</span> torch.optim <span class="keyword">as</span> optim</span><br><span class="line"></span><br><span class="line">print(<span class="string">'GPUs Available:'</span>,torch.cuda.is_available())</span><br><span class="line">device = torch.device(<span class="string">"cuda"</span> <span class="keyword">if</span> torch.cuda.is_available() <span class="keyword">else</span> <span class="string">"cpu"</span>)</span><br></pre></td></tr></table></figure><h3 id="build-model"><a href="#build-model" class="headerlink" title="build model"></a>build model</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Net</span><span class="params">(nn.Module)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self,n_classes)</span>:</span></span><br><span class="line">        super(Net, self).__init__()</span><br><span class="line">        self.features = nn.Sequential(resnet18().conv1,</span><br><span class="line">                                      resnet18().bn1,</span><br><span class="line">                                      resnet18().relu,</span><br><span class="line">                                      resnet18().maxpool,</span><br><span class="line">                                      resnet18().layer1,</span><br><span class="line">                                      resnet18().layer2,</span><br><span class="line">                                      resnet18().layer3,</span><br><span class="line">                                      resnet18().layer4)</span><br><span class="line">        self.classifiers = nn.Sequential(nn.Linear(<span class="number">512</span>**<span class="number">2</span>, n_classes))</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, x)</span>:</span></span><br><span class="line">        x = self.features(x)</span><br><span class="line">        batch_size = x.size(<span class="number">0</span>)</span><br><span class="line">        feature_size = x.size(<span class="number">2</span>) * x.size(<span class="number">3</span>)</span><br><span class="line">        x = x.view(batch_size, <span class="number">512</span>, feature_size)</span><br><span class="line">        x = (torch.bmm(x, torch.transpose(x, <span class="number">1</span>, <span class="number">2</span>)) / feature_size).view(</span><br><span class="line">            batch_size, <span class="number">-1</span>)</span><br><span class="line">        x = torch.nn.functional.normalize(</span><br><span class="line">            torch.sign(x) * torch.sqrt(torch.abs(x) + <span class="number">1e-10</span>))</span><br><span class="line">        x = self.classifiers(x)</span><br><span class="line">        <span class="keyword">return</span> x</span><br></pre></td></tr></table></figure><h3 id="load-data"><a href="#load-data" class="headerlink" title="load data"></a>load data</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># load data</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">LoadDogData</span><span class="params">(Dataset)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self,data_dir,mode=<span class="string">'train'</span>,transforms=None)</span>:</span></span><br><span class="line">        super().__init__()</span><br><span class="line">        self.mode = mode.upper()</span><br><span class="line">        self.data_dir = data_dir</span><br><span class="line">        self.transforms = transforms</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">assert</span> self.mode <span class="keyword">in</span> [<span class="string">'TRAIN'</span>,<span class="string">'VALID'</span>]</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">with</span> open(os.path.join(self.data_dir, self.mode + <span class="string">'_images.json'</span>), <span class="string">'r'</span>) <span class="keyword">as</span> j:</span><br><span class="line">            self.images = json.load(j)</span><br><span class="line">            </span><br><span class="line">        <span class="keyword">with</span> open(os.path.join(self.data_dir, self.mode + <span class="string">'_objects.json'</span>), <span class="string">'r'</span>) <span class="keyword">as</span> j:</span><br><span class="line">            self.objects = json.load(j)</span><br><span class="line">            </span><br><span class="line">        <span class="keyword">assert</span> len(self.images) == len(self.objects)</span><br><span class="line">        </span><br><span class="line">        self.total_len = len(self.images)</span><br><span class="line">        print(<span class="string">"[*] Loading &#123;&#125; &#123;&#125; images."</span>.format(self.mode,self.total_len))</span><br><span class="line">        </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__getitem__</span><span class="params">(self, idx)</span>:</span></span><br><span class="line">        </span><br><span class="line"><span class="comment">#         print('./dataset/low-resolution/'+self.images[idx])</span></span><br><span class="line">        img = Image.open(<span class="string">'./dataset/low-resolution/'</span>+self.images[idx]).convert(<span class="string">'RGB'</span>)</span><br><span class="line">        objects = self.objects[idx]</span><br><span class="line">        labels = np.array(objects[<span class="string">'labels'</span>])[<span class="number">0</span>]</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">if</span> self.transforms <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">            img = self.transforms(img)</span><br><span class="line">            </span><br><span class="line">        <span class="keyword">return</span> img, labels</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__len__</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="keyword">return</span> len(self.images)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># label map</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_label_map</span><span class="params">()</span>:</span></span><br><span class="line">    <span class="keyword">with</span> open(<span class="string">'./dataset/JsonData/label_map.json'</span>,<span class="string">'r'</span>) <span class="keyword">as</span> j:</span><br><span class="line">        labels = json.load(j)</span><br><span class="line">    <span class="keyword">return</span> labels</span><br></pre></td></tr></table></figure><h3 id="transforms"><a href="#transforms" class="headerlink" title="transforms"></a>transforms</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">data_transforms = &#123;</span><br><span class="line">    <span class="string">'train'</span>: transforms.Compose([</span><br><span class="line">        transforms.RandomResizedCrop(<span class="number">224</span>),</span><br><span class="line">        transforms.RandomHorizontalFlip(),</span><br><span class="line">        transforms.ToTensor(),</span><br><span class="line">        transforms.Normalize([<span class="number">0.485</span>, <span class="number">0.456</span>, <span class="number">0.406</span>], [<span class="number">0.229</span>, <span class="number">0.224</span>, <span class="number">0.225</span>])</span><br><span class="line">    ]),</span><br><span class="line">    <span class="string">'valid'</span>: transforms.Compose([</span><br><span class="line">        transforms.Resize(<span class="number">256</span>),</span><br><span class="line">        transforms.CenterCrop(<span class="number">224</span>),</span><br><span class="line">        transforms.ToTensor(),</span><br><span class="line">        transforms.Normalize([<span class="number">0.485</span>, <span class="number">0.456</span>, <span class="number">0.406</span>], [<span class="number">0.229</span>, <span class="number">0.224</span>, <span class="number">0.225</span>])</span><br><span class="line">    ]),</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="Visualize-a-few-images"><a href="#Visualize-a-few-images" class="headerlink" title="Visualize a few images"></a>Visualize a few images</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">dataset = LoadDogData(data_dir=<span class="string">'./dataset/JsonData/'</span>,</span><br><span class="line">                      mode=<span class="string">'Train'</span>,</span><br><span class="line">                      transforms=data_transforms[<span class="string">'train'</span>])</span><br><span class="line">dataloaders = torch.utils.data.DataLoader(dataset, batch_size=<span class="number">1</span>, shuffle=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">imshow</span><span class="params">(inp, title=None)</span>:</span></span><br><span class="line">    <span class="string">"""Imshow for Tensor."""</span></span><br><span class="line">    inp = inp.numpy().transpose(<span class="number">1</span>,<span class="number">2</span>,<span class="number">0</span>)</span><br><span class="line">    mean = np.array([<span class="number">0.485</span>, <span class="number">0.456</span>, <span class="number">0.406</span>])</span><br><span class="line">    std = np.array([<span class="number">0.229</span>, <span class="number">0.224</span>, <span class="number">0.225</span>])</span><br><span class="line">    inp = std * inp + mean</span><br><span class="line">    inp = np.clip(inp, <span class="number">0</span>, <span class="number">1</span>)</span><br><span class="line">    plt.imshow(inp)</span><br><span class="line">    <span class="keyword">if</span> title <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">        plt.title(title)</span><br><span class="line">    plt.pause(<span class="number">0.001</span>)  <span class="comment"># pause a bit so that plots are updated</span></span><br><span class="line"></span><br><span class="line">inputs, class_names = next(iter(dataloaders))</span><br><span class="line">labels_map = get_label_map()</span><br><span class="line">rev = &#123;str(v):k <span class="keyword">for</span> k,v <span class="keyword">in</span> get_label_map().items()&#125;</span><br><span class="line"></span><br><span class="line">out = torchvision.utils.make_grid(inputs)</span><br><span class="line"></span><br><span class="line">imshow(out, title=rev[str(int(class_names))])</span><br></pre></td></tr></table></figure><h3 id="train-model"><a href="#train-model" class="headerlink" title="train model"></a>train model</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">train_model</span><span class="params">(model, criterion, optimizer, scheduler, dataloaders,num_epochs=<span class="number">25</span>)</span>:</span></span><br><span class="line">    since = time.time()</span><br><span class="line"></span><br><span class="line">    best_model_wts = copy.deepcopy(model.state_dict())</span><br><span class="line">    best_acc = <span class="number">0.0</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> epoch <span class="keyword">in</span> range(num_epochs):</span><br><span class="line">        print(<span class="string">'Epoch &#123;&#125;/&#123;&#125;'</span>.format(epoch, num_epochs - <span class="number">1</span>))</span><br><span class="line">        print(<span class="string">'-'</span> * <span class="number">10</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Each epoch has a training and validation phase</span></span><br><span class="line">        <span class="keyword">for</span> phase <span class="keyword">in</span> [<span class="string">'train'</span>, <span class="string">'val'</span>]:</span><br><span class="line">            <span class="keyword">if</span> phase == <span class="string">'train'</span>:</span><br><span class="line">                model.train()  <span class="comment"># Set model to training mode</span></span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                model.eval()   <span class="comment"># Set model to evaluate mode</span></span><br><span class="line"></span><br><span class="line">            running_loss = <span class="number">0.0</span></span><br><span class="line">            running_corrects = <span class="number">0</span></span><br><span class="line"></span><br><span class="line">            <span class="comment"># Iterate over data.</span></span><br><span class="line">            <span class="keyword">for</span> step ,(inputs, labels) <span class="keyword">in</span> enumerate(dataloaders[phase]):</span><br><span class="line">                inputs = inputs.to(device)</span><br><span class="line">                labels = labels.to(device)</span><br><span class="line"></span><br><span class="line">                <span class="comment"># zero the parameter gradients</span></span><br><span class="line">                optimizer.zero_grad()</span><br><span class="line"></span><br><span class="line">                <span class="comment"># forward</span></span><br><span class="line">                <span class="comment"># track history if only in train</span></span><br><span class="line">                <span class="keyword">with</span> torch.set_grad_enabled(phase == <span class="string">'train'</span>):</span><br><span class="line">                    outputs = model(inputs)</span><br><span class="line">                    _, preds = torch.max(outputs, <span class="number">1</span>)</span><br><span class="line">                    loss = criterion(outputs, labels.long())</span><br><span class="line"></span><br><span class="line">                    <span class="comment"># backward + optimize only if in training phase</span></span><br><span class="line">                    <span class="keyword">if</span> phase == <span class="string">'train'</span>:</span><br><span class="line">                        loss.backward()</span><br><span class="line">                        optimizer.step()</span><br><span class="line">                </span><br><span class="line">                <span class="comment"># statistics</span></span><br><span class="line">                running_loss += loss.item() * inputs.size(<span class="number">0</span>)</span><br><span class="line">                running_corrects += torch.sum(preds == labels.data)</span><br><span class="line"><span class="comment">#                 print(type(running_loss),float(running_corrects))</span></span><br><span class="line">        </span><br><span class="line">            <span class="keyword">if</span> phase == <span class="string">'train'</span>:</span><br><span class="line">                scheduler.step()</span><br><span class="line"></span><br><span class="line">            epoch_loss = running_loss / len(dataloaders[phase])</span><br><span class="line">            epoch_acc = running_corrects / len(dataloaders[phase])</span><br><span class="line"></span><br><span class="line">            print(<span class="string">'&#123;&#125; Loss: &#123;:.4f&#125; Acc: &#123;:.4f&#125;'</span>.format(</span><br><span class="line">                phase, epoch_loss, epoch_acc))</span><br><span class="line"></span><br><span class="line">            <span class="comment"># deep copy the model</span></span><br><span class="line">            <span class="keyword">if</span> phase == <span class="string">'val'</span> <span class="keyword">and</span> epoch_acc &gt; best_acc:</span><br><span class="line">                best_acc = epoch_acc</span><br><span class="line">                best_model_wts = copy.deepcopy(model.state_dict())</span><br><span class="line"></span><br><span class="line">    time_elapsed = time.time() - since</span><br><span class="line">    print(<span class="string">'Training complete in &#123;:.0f&#125;m &#123;:.0f&#125;s'</span>.format(</span><br><span class="line">        time_elapsed // <span class="number">60</span>, time_elapsed % <span class="number">60</span>))</span><br><span class="line">    print(<span class="string">'Best val Acc: &#123;:4f&#125;'</span>.format(best_acc))</span><br><span class="line"></span><br><span class="line">    <span class="comment"># load best model weights</span></span><br><span class="line">    time_stamp = time.strftime(<span class="string">'%Y-%m-%d-%H-%M-%S'</span>,time.localtime(time.time()))</span><br><span class="line">    model.load_state_dict(best_model_wts,<span class="string">'./&#123;&#125;-best_model.pth'</span>.formator(time_stamp))</span><br><span class="line">    <span class="keyword">return</span> model</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">main</span><span class="params">()</span>:</span></span><br><span class="line">    <span class="comment"># --------------------- init parameter --------------------#</span></span><br><span class="line">    n_classes = <span class="number">131</span></span><br><span class="line">    batch_size = <span class="number">1</span></span><br><span class="line">    best_acc = <span class="number">0.</span></span><br><span class="line">    expochs = <span class="number">25</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># ------------------------- model------------------------- #</span></span><br><span class="line">    net = Net(n_classes=n_classes)</span><br><span class="line">    net.to(device)</span><br><span class="line">    </span><br><span class="line">    criterion = nn.CrossEntropyLoss()</span><br><span class="line">    optimizer = optim.SGD(net.parameters(), lr=<span class="number">0.001</span>, momentum=<span class="number">0.9</span>)</span><br><span class="line">    exp_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=<span class="number">7</span>, gamma=<span class="number">0.1</span>)</span><br><span class="line">    <span class="comment"># ------------------------ data load---------------------- #</span></span><br><span class="line">    dataset = LoadDogData(data_dir=<span class="string">'./dataset/JsonData/'</span>,</span><br><span class="line">                          mode=<span class="string">'train'</span>,</span><br><span class="line">                          transforms=data_transforms[<span class="string">'train'</span>])</span><br><span class="line">    train_loaders = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">    dataset = LoadDogData(data_dir=<span class="string">'./dataset/JsonData/'</span>,</span><br><span class="line">                          mode=<span class="string">'valid'</span>,</span><br><span class="line">                          transforms=data_transforms[<span class="string">'valid'</span>])</span><br><span class="line"></span><br><span class="line">    valid_loaders = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=<span class="literal">True</span>)</span><br><span class="line">    </span><br><span class="line">    dataloaders = &#123;</span><br><span class="line">        <span class="string">'train'</span>:train_loaders,</span><br><span class="line">        <span class="string">'val'</span>:valid_loaders</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    train_model(net, criterion, optimizer, exp_lr_scheduler,dataloaders,num_epochs=expochs)</span><br><span class="line">    </span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__==<span class="string">'__main__'</span>:</span><br><span class="line">    main()</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h3 id=&quot;import-package&quot;&gt;&lt;a href=&quot;#import-package&quot; class=&quot;headerlink&quot; title=&quot;import package&quot;&gt;&lt;/a&gt;import package&lt;/h3&gt;&lt;figure class=&quot;highlight 
      
    
    </summary>
    
    
    
      <category term="CV" scheme="https://hahally.github.io/tags/CV/"/>
    
  </entry>
  
  <entry>
    <title>TsinghuaDogs-2</title>
    <link href="https://hahally.github.io/articles/TsinghuaDogs-2/"/>
    <id>https://hahally.github.io/articles/TsinghuaDogs-2/</id>
    <published>2021-02-08T10:10:40.000Z</published>
    <updated>2021-02-08T10:16:14.267Z</updated>
    
    <content type="html"><![CDATA[<h3 id="import-package"><a href="#import-package" class="headerlink" title="import package"></a>import package</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> json</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"><span class="keyword">from</span> tqdm <span class="keyword">import</span> tqdm</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> math <span class="keyword">import</span> sqrt</span><br><span class="line"><span class="keyword">import</span> cv2</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line">%matplotlib inline</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> warnings</span><br><span class="line"></span><br><span class="line">warnings.filterwarnings(<span class="string">"ignore"</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">from</span> tensorflow.keras <span class="keyword">import</span> datasets, layers, Model</span><br><span class="line"><span class="keyword">from</span> tensorflow.keras.applications.vgg16 <span class="keyword">import</span> VGG16, preprocess_input, decode_predictions</span><br><span class="line"></span><br><span class="line">tf.debugging.set_log_device_placement(<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">print(<span class="string">"Tensorflow Version:"</span>, tf.__version__)</span><br><span class="line"></span><br><span class="line">print(<span class="string">"Num GPUs Available: "</span>,</span><br><span class="line">      len(tf.config.experimental.list_physical_devices(<span class="string">'GPU'</span>)))</span><br></pre></td></tr></table></figure><h3 id="load-dataset"><a href="#load-dataset" class="headerlink" title="load dataset"></a>load dataset</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># load data</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">LoadData</span><span class="params">()</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self,data_dir,mode=<span class="string">'train'</span>)</span>:</span></span><br><span class="line">        super().__init__()</span><br><span class="line">        self.mode = mode.upper()</span><br><span class="line">        self.data_dir = data_dir</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">assert</span> self.mode <span class="keyword">in</span> [<span class="string">'TRAIN'</span>,<span class="string">'VALID'</span>]</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">with</span> open(os.path.join(self.data_dir, self.mode + <span class="string">'_images.json'</span>), <span class="string">'r'</span>) <span class="keyword">as</span> j:</span><br><span class="line">            self.images = json.load(j)</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">with</span> open(os.path.join(self.data_dir, self.mode + <span class="string">'_objects.json'</span>), <span class="string">'r'</span>) <span class="keyword">as</span> j:</span><br><span class="line">            self.objects = json.load(j)</span><br><span class="line">            </span><br><span class="line">        <span class="keyword">assert</span> len(self.images) == len(self.objects)</span><br><span class="line"></span><br><span class="line">        self.total_len = len(self.images)</span><br><span class="line"></span><br><span class="line">        print(<span class="string">"[*] Loading &#123;&#125; &#123;&#125; images."</span>.format(self.mode,self.total_len))</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__getitem__</span><span class="params">(self, idx)</span>:</span></span><br><span class="line">        </span><br><span class="line"><span class="comment">#         image = cv2.imread('./dataset/low-resolution/'+self.images[idx])</span></span><br><span class="line"><span class="comment">#         image = cv2.cvtColor(image,cv2.COLOR_BGR2RGB).astype("float32")</span></span><br><span class="line">        image = self.images[idx]</span><br><span class="line">        objects = self.objects[idx]</span><br><span class="line">        </span><br><span class="line">        labels = np.array(objects[<span class="string">'labels'</span>]) - <span class="number">1</span></span><br><span class="line">        </span><br><span class="line">        <span class="keyword">return</span> image, labels</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">load_data</span><span class="params">(self)</span>:</span></span><br><span class="line">        </span><br><span class="line">        labels = [ np.array(item[<span class="string">'labels'</span>]) - <span class="number">1.</span> <span class="keyword">for</span> item <span class="keyword">in</span> self.objects]</span><br><span class="line">        </span><br><span class="line">        labels = np.array(labels).reshape([<span class="number">-1</span>])</span><br><span class="line"></span><br><span class="line">        images = self.images</span><br><span class="line">        <span class="keyword">return</span> images,labels</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__len__</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="keyword">return</span> len(self.images)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_data</span><span class="params">(data_dir,mode=<span class="string">'train'</span>,n_mode=<span class="number">100</span>,n_classes)</span>:</span></span><br><span class="line">    mode = mode.upper()</span><br><span class="line">    <span class="keyword">assert</span> mode <span class="keyword">in</span> [<span class="string">'TRAIN'</span>,<span class="string">'VALID'</span>]</span><br><span class="line">    <span class="keyword">with</span> open(os.path.join(data_dir, mode + <span class="string">'_images.json'</span>), <span class="string">'r'</span>) <span class="keyword">as</span> j:</span><br><span class="line">        images = json.load(j)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">with</span> open(os.path.join(data_dir, mode + <span class="string">'_objects.json'</span>), <span class="string">'r'</span>) <span class="keyword">as</span> j:</span><br><span class="line">        objects = json.load(j)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">assert</span> len(images) == len(objects)</span><br><span class="line"></span><br><span class="line">    labels = []</span><br><span class="line">    imgs = []</span><br><span class="line">    count = &#123;str(i):<span class="number">0</span> <span class="keyword">for</span> i <span class="keyword">in</span> range(n_classes)&#125;</span><br><span class="line">        </span><br><span class="line">    <span class="keyword">for</span> item <span class="keyword">in</span> images:</span><br><span class="line">        label = int(item.split(<span class="string">'-'</span>)[<span class="number">1</span>][<span class="number">-3</span>:]) - <span class="number">1</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> label&lt;n_classes:</span><br><span class="line">            <span class="keyword">if</span> count[str(label)]&gt;=n_mode:</span><br><span class="line">                <span class="keyword">continue</span></span><br><span class="line">            count[str(label)] += <span class="number">1</span></span><br><span class="line">            labels.append(label)</span><br><span class="line">            imgs.append(item)</span><br><span class="line">            </span><br><span class="line">    print(<span class="string">"[*] Loading &#123;&#125; &#123;&#125; images."</span>.format(mode,len(imgs)))</span><br><span class="line">    <span class="keyword">return</span> imgs,labels</span><br></pre></td></tr></table></figure><h3 id="images-precess"><a href="#images-precess" class="headerlink" title="images precess"></a>images precess</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">normalize</span><span class="params">(x)</span>:</span></span><br><span class="line">    <span class="comment"># 标准化</span></span><br><span class="line">    <span class="comment"># x: [224, 224, 3]</span></span><br><span class="line">    <span class="comment"># mean: [224, 224, 3], std: [3]</span></span><br><span class="line">    img_mean = tf.constant([<span class="number">0.485</span>, <span class="number">0.456</span>, <span class="number">0.406</span>])</span><br><span class="line">    img_std = tf.constant([<span class="number">0.229</span>, <span class="number">0.224</span>, <span class="number">0.225</span>])</span><br><span class="line">    </span><br><span class="line">    x = (x - img_mean)/img_std</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> x</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">preprocess</span><span class="params">(x,y)</span>:</span></span><br><span class="line">    con = []</span><br><span class="line">    <span class="keyword">for</span> item <span class="keyword">in</span> x:</span><br><span class="line">        item = item.numpy().decode()</span><br><span class="line"></span><br><span class="line">        img = plt.imread(<span class="string">'./dataset/low-resolution/'</span>+item)</span><br><span class="line">        img = cv2.resize(img,(<span class="number">244</span>,<span class="number">244</span>))</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 图像增强</span></span><br><span class="line">        img = tf.image.random_flip_left_right(img) <span class="comment"># 左右镜像</span></span><br><span class="line">        img= tf.image.random_crop(img, [<span class="number">224</span>, <span class="number">224</span>, <span class="number">3</span>]) <span class="comment"># 随机裁剪</span></span><br><span class="line">        img = tf.cast(img, dtype=tf.float32) / <span class="number">255.</span></span><br><span class="line">        img = normalize(img) <span class="comment"># 标准化</span></span><br><span class="line">        </span><br><span class="line">        con.append(tf.expand_dims(img,axis=<span class="number">0</span>))</span><br><span class="line">       </span><br><span class="line">    images = tf.concat(con,axis=<span class="number">0</span>)</span><br><span class="line">    labels = tf.convert_to_tensor(y) <span class="comment"># 转换成张量</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> images,labels</span><br></pre></td></tr></table></figure><h3 id="build-model"><a href="#build-model" class="headerlink" title="build model"></a>build model</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Build model</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">BCNN</span><span class="params">(Model)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self,num_classes)</span>:</span></span><br><span class="line">        super(BCNN,self).__init__()</span><br><span class="line"><span class="comment">#         self.resnet50 = ResNet50(weights='imagenet',</span></span><br><span class="line"><span class="comment">#                                  pooling=None,</span></span><br><span class="line"><span class="comment">#                                  include_top=False,</span></span><br><span class="line"><span class="comment">#                                  input_shape=(224, 224, 3))</span></span><br><span class="line">        self.vgg16 = VGG16(weights=<span class="string">'imagenet'</span>,</span><br><span class="line">                           pooling=<span class="literal">None</span>,</span><br><span class="line">                           include_top=<span class="literal">False</span>,</span><br><span class="line">                           input_shape=(<span class="number">224</span>, <span class="number">224</span>, <span class="number">3</span>))</span><br><span class="line"></span><br><span class="line">        self.model_vgg = Model(inputs=self.vgg16.input,</span><br><span class="line">                               outputs=self.vgg16.get_layer(<span class="string">'block5_conv3'</span>).output)</span><br><span class="line">        </span><br><span class="line"><span class="comment">#         self.model_resnet = Model(inputs=ResNet50.input, </span></span><br><span class="line"><span class="comment">#                                   outputs=ResNet50.get_layer('block5_conv3').output)</span></span><br><span class="line">        </span><br><span class="line">        self.flatten = layers.Flatten()</span><br><span class="line">        self.fc = layers.Dense(num_classes, activation=<span class="string">'softmax'</span>)</span><br><span class="line">        </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">call</span><span class="params">(self, images)</span>:</span></span><br><span class="line">        </span><br><span class="line">        feat = self.model_vgg(images)</span><br><span class="line">        </span><br><span class="line">        feat_size = feat.shape[<span class="number">1</span>]*feat.shape[<span class="number">2</span>]</span><br><span class="line"><span class="comment">#         feat2 = self.model_resnet(images)</span></span><br><span class="line">        <span class="comment"># feat.shape:(d,w,h,c)</span></span><br><span class="line">        x = tf.reshape(feat,(feat.shape[<span class="number">0</span>],feat_size,feat.shape[<span class="number">3</span>]))</span><br><span class="line">        </span><br><span class="line">        out = tf.matmul(x,tf.transpose(x,perm=[<span class="number">0</span>,<span class="number">2</span>,<span class="number">1</span>]))/feat_size</span><br><span class="line">        out = tf.reshape(out,(out.shape[<span class="number">0</span>],<span class="number">-1</span>))</span><br><span class="line">        out = tf.sign(out)*tf.sqrt(tf.abs(out)+<span class="number">1e-10</span>)</span><br><span class="line">        </span><br><span class="line">        out = tf.nn.l2_normalize(out,axis=<span class="number">1</span>)</span><br><span class="line">        </span><br><span class="line">        out = self.flatten(out)</span><br><span class="line">        </span><br><span class="line">        out = self.fc(out)</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">return</span> out</span><br></pre></td></tr></table></figure><h3 id="run-code"><a href="#run-code" class="headerlink" title="run code"></a>run code</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@tf.function</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">train_step</span><span class="params">(x, y)</span>:</span></span><br><span class="line">    <span class="keyword">with</span> tf.GradientTape() <span class="keyword">as</span> tape:</span><br><span class="line">        logits = model(x, training=<span class="literal">True</span>)</span><br><span class="line">        loss_value = loss_fn(y, logits)</span><br><span class="line">    grads = tape.gradient(loss_value, model.trainable_weights)</span><br><span class="line">    optimizer.apply_gradients(zip(grads, model.trainable_weights))</span><br><span class="line">    train_acc_metric.update_state(y, logits)</span><br><span class="line">    <span class="keyword">return</span> loss_value</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="meta">@tf.function</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">test_step</span><span class="params">(x, y)</span>:</span></span><br><span class="line">    val_logits = model(x, training=<span class="literal">False</span>)</span><br><span class="line">    val_acc_metric.update_state(y, val_logits)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># --------------------------config---------------------------------#</span></span><br><span class="line"></span><br><span class="line">epochs = <span class="number">50</span></span><br><span class="line">batch_size = <span class="number">16</span></span><br><span class="line">num_classes = <span class="number">130</span></span><br><span class="line">save_model_dir = <span class="string">'./modelfiles/'</span></span><br><span class="line"></span><br><span class="line">images, labels = get_data(<span class="string">'./dataset/JsonData/'</span>, mode=<span class="string">'train'</span>, n_mode=<span class="number">200</span>)</span><br><span class="line">trian_db = tf.data.Dataset.from_tensor_slices((images, labels))</span><br><span class="line">trian_db = trian_db.shuffle(<span class="number">50</span>).batch(<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">images, labels = get_data(<span class="string">'./dataset/JsonData/'</span>, mode=<span class="string">'valid'</span>, n_mode=<span class="number">20</span>)</span><br><span class="line">valid_db = tf.data.Dataset.from_tensor_slices((images, labels))</span><br><span class="line">valid_db = valid_db.shuffle(<span class="number">50</span>).batch(<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">loss_fn = tf.keras.losses.SparseCategoricalCrossentropy()</span><br><span class="line">optimizer = tf.keras.optimizers.Adam()</span><br><span class="line">train_acc_metric = tf.keras.metrics.SparseCategoricalAccuracy()</span><br><span class="line">val_acc_metric = tf.keras.metrics.SparseCategoricalAccuracy()</span><br><span class="line"></span><br><span class="line">model = BCNN(num_classes=num_classes)</span><br><span class="line">model.build(input_shape=(<span class="number">16</span>, <span class="number">224</span>, <span class="number">224</span>, <span class="number">3</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment"># ---------------------------------------------------------------- #</span></span><br><span class="line"></span><br><span class="line">best_acc = <span class="number">0</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> range(epochs):</span><br><span class="line">    print(<span class="string">"\nStart of epoch %d"</span> % (epoch, ))</span><br><span class="line">    start_time = time.time()</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Iterate over the batches of the dataset.</span></span><br><span class="line">    <span class="keyword">for</span> step, (x, y) <span class="keyword">in</span> enumerate(trian_db):</span><br><span class="line">        x_batch_train, y_batch_train = preprocess(x, y)</span><br><span class="line">        loss_value = train_step(x_batch_train, y_batch_train)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Log every 200 batches.</span></span><br><span class="line">        <span class="keyword">if</span> step % <span class="number">100</span> == <span class="number">0</span>:</span><br><span class="line">            print(<span class="string">'Epoch:'</span>, epoch, <span class="string">' Step:'</span>, step, <span class="string">'Training loss:'</span>,</span><br><span class="line">                  float(loss_value))</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Display metrics at the end of each epoch.</span></span><br><span class="line">    train_acc = train_acc_metric.result()</span><br><span class="line">    print(<span class="string">"Training acc over epoch: %.4f"</span> % (float(train_acc), ))</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Reset training metrics at the end of each epoch</span></span><br><span class="line">    train_acc_metric.reset_states()</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Run a validation loop at the end of each epoch.</span></span><br><span class="line">    <span class="keyword">for</span> step, (x, y) <span class="keyword">in</span> enumerate(valid_db):</span><br><span class="line">        x_batch_val, y_batch_val = preprocess(x, y)</span><br><span class="line">        test_step(x_batch_val, y_batch_val)</span><br><span class="line"></span><br><span class="line">    val_acc = val_acc_metric.result()</span><br><span class="line">    val_acc_metric.reset_states()</span><br><span class="line"></span><br><span class="line">    print(<span class="string">"Validation acc: %.4f"</span> % (float(val_acc), ))</span><br><span class="line">    print(<span class="string">"Time taken: %.2fs"</span> % (time.time() - start_time))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> best_acc &lt; val_acc:</span><br><span class="line">        best_acc = val_acc</span><br><span class="line">        print(<span class="string">'Valid in epoch'</span>, epoch, <span class="string">'Accuracy is'</span>, val_acc,</span><br><span class="line">              <span class="string">'Best accuracy is'</span>, best_acc)</span><br><span class="line"></span><br><span class="line">        time_stamp = time.strftime(<span class="string">'%Y-%m-%d-%H-%M-%S'</span>,</span><br><span class="line">                                   time.localtime(time.time()))</span><br><span class="line">        model.save_weights(</span><br><span class="line">            os.path.join(save_model_dirav, time_stamp + <span class="string">'.checkpoint'</span>))</span><br><span class="line">        print(<span class="string">'saved total model weights; timestamp:'</span>, time_stamp)</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h3 id=&quot;import-package&quot;&gt;&lt;a href=&quot;#import-package&quot; class=&quot;headerlink&quot; title=&quot;import package&quot;&gt;&lt;/a&gt;import package&lt;/h3&gt;&lt;figure class=&quot;highlight 
      
    
    </summary>
    
    
    
      <category term="CV" scheme="https://hahally.github.io/tags/CV/"/>
    
  </entry>
  
  <entry>
    <title>A09</title>
    <link href="https://hahally.github.io/articles/A09/"/>
    <id>https://hahally.github.io/articles/A09/</id>
    <published>2021-02-03T15:59:00.000Z</published>
    <updated>2021-02-03T16:04:12.781Z</updated>
    
    <content type="html"><![CDATA[<h3 id="数据说明"><a href="#数据说明" class="headerlink" title="数据说明"></a>数据说明</h3><p>来源：第十二届服创大赛A类数据<a href="http://www.fwwb.org.cn/topic/show/6c22faa0-c905-4482-a0bc-3dfe11657565" target="_blank" rel="noopener">【A09】轨道交通智慧客流分析预测【八维通】</a></p><p>示例数据包含:</p><ul><li>行程数据<code>trips.csv</code></li><li>用户数据<code>users.csv</code></li><li>站点名称数据<code>station.csv</code></li><li>2020年全年节假日数据<code>workdays.csv</code></li></ul><hr><p>trips.csv：</p><div class="table-container"><table><thead><tr><th>说明</th><th>类型说明</th></tr></thead><tbody><tr><td>用户id</td><td>与user.csv 表中用户id进行关联，可以获取用户对应的行程</td></tr><tr><td>进站名</td><td></td></tr><tr><td>进站时间</td><td>YYYY-MM-DD hh:mm:ss</td></tr><tr><td>出站</td><td></td></tr><tr><td>出站时间</td><td>YYYY-MM-DD hh:mm:ss</td></tr><tr><td>渠道类型</td><td>本例子中不使用</td></tr><tr><td>票价</td><td>单位分</td></tr></tbody></table></div><hr><p>users.csv:</p><div class="table-container"><table><thead><tr><th>说明</th><th>类型说明</th></tr></thead><tbody><tr><td>说明</td><td>类型说明</td></tr><tr><td>用户id</td><td>和trip.csv里面的用户ID关联可获取用户对应的行程</td></tr><tr><td>省市</td><td></td></tr><tr><td>出生年份</td><td></td></tr><tr><td>性别</td><td>0 男，1 女</td></tr></tbody></table></div><hr><p>station.csv:</p><div class="table-container"><table><thead><tr><th>说明</th><th>类型说明</th></tr></thead><tbody><tr><td>站点id</td><td>无业务意义</td></tr><tr><td>站点名</td><td></td></tr><tr><td>线路名</td><td></td></tr><tr><td>站点所在区</td></tr></tbody></table></div><hr><p>workdays.csv:</p><div class="table-container"><table><thead><tr><th>说明</th><th>类型</th><th>类型说明</th></tr></thead><tbody><tr><td>日期</td><td>string</td><td>YYYYMMDD</td></tr><tr><td>节假日属性</td><td>枚举</td><td>1，2，或3</td></tr></tbody></table></div><p>1为工作日（包括周末调休变成的工作日）；2为正常周末；3为节假日，包括法定节假日，以及与法定节假日相连的周末。</p><hr><h3 id="导入相关库"><a href="#导入相关库" class="headerlink" title="导入相关库"></a>导入相关库</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd </span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> seaborn <span class="keyword">as</span> sns</span><br><span class="line">%matplotlib inline</span><br><span class="line"></span><br><span class="line"><span class="comment">#ignore warnings</span></span><br><span class="line"><span class="keyword">import</span> warnings</span><br><span class="line">warnings.filterwarnings(<span class="string">'ignore'</span>)</span><br></pre></td></tr></table></figure><h3 id="trips-csv"><a href="#trips-csv" class="headerlink" title="trips.csv"></a>trips.csv</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">trips = pd.read_csv(<span class="string">'./trips.csv'</span>)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 基本信息</span></span><br><span class="line">trips.info()</span><br></pre></td></tr></table></figure><pre><code>&lt;class &#39;pandas.core.frame.DataFrame&#39;&gt;RangeIndex: 791995 entries, 0 to 791994Data columns (total 7 columns):用户ID    791995 non-null object进站名称    791995 non-null object进站时间    791995 non-null object出站名称    791995 non-null object出站时间    791995 non-null object渠道编号    791995 non-null int64价格      791995 non-null int64dtypes: int64(2), object(5)memory usage: 42.3+ MB</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 浏览数据集</span></span><br><span class="line">trips.sample(<span class="number">10</span>)</span><br></pre></td></tr></table></figure><div><table border="1" class="dataframe">  <thead>    <tr style="text-align: right;">      <th></th>      <th>用户ID</th>      <th>进站名称</th>      <th>进站时间</th>      <th>出站名称</th>      <th>出站时间</th>      <th>渠道编号</th>      <th>价格</th>    </tr>  </thead>  <tbody>    <tr>      <th>361317</th>      <td>309d068b9686b17c2eea0f7396d6a3ce</td>      <td>Sta34</td>      <td>2020-06-14 11:59:47</td>      <td>Sta108</td>      <td>2020-06-14 12:27:01</td>      <td>2</td>      <td>400</td>    </tr>    <tr>      <th>369815</th>      <td>5f60d49862e08647d83cba6b88826a7c</td>      <td>Sta163</td>      <td>2020-04-11 09:45:12</td>      <td>Sta161</td>      <td>2020-04-11 10:21:50</td>      <td>2</td>      <td>400</td>    </tr>    <tr>      <th>24683</th>      <td>456baf61774e89b0f0ecd66561dc1ec3</td>      <td>Sta134</td>      <td>2020-03-09 19:17:07</td>      <td>Sta135</td>      <td>2020-03-09 19:24:20</td>      <td>3</td>      <td>200</td>    </tr>    <tr>      <th>265739</th>      <td>8259141547ffe7508d9ed0640064222e</td>      <td>Sta63</td>      <td>2020-06-19 09:39:06</td>      <td>Sta151</td>      <td>2020-06-19 10:09:06</td>      <td>3</td>      <td>400</td>    </tr>    <tr>      <th>360005</th>      <td>8e630d272f05413355bd4054ec57e1e4</td>      <td>Sta46</td>      <td>2020-03-22 14:30:38</td>      <td>Sta55</td>      <td>2020-03-22 15:05:00</td>      <td>3</td>      <td>400</td>    </tr>    <tr>      <th>302739</th>      <td>93cdc65de998cdfa253308f9e7a722fa</td>      <td>Sta49</td>      <td>2020-01-15 20:08:53</td>      <td>Sta89</td>      <td>2020-01-15 20:38:15</td>      <td>3</td>      <td>500</td>    </tr>    <tr>      <th>577747</th>      <td>7829bcf454c66b5bac54b4592f30d1ff</td>      <td>Sta137</td>      <td>2020-07-03 08:09:22</td>      <td>Sta37</td>      <td>2020-07-03 08:41:17</td>      <td>2</td>      <td>400</td>    </tr>    <tr>      <th>449944</th>      <td>e45e528ef8575a550847f5b33b732207</td>      <td>Sta67</td>      <td>2020-06-01 07:52:00</td>      <td>Sta100</td>      <td>2020-06-01 08:21:47</td>      <td>3</td>      <td>400</td>    </tr>    <tr>      <th>317479</th>      <td>47750740c3ff91bffaac1b92e7d8ac2f</td>      <td>Sta25</td>      <td>2020-06-15 09:44:47</td>      <td>Sta63</td>      <td>2020-06-15 10:03:20</td>      <td>2</td>      <td>300</td>    </tr>    <tr>      <th>430358</th>      <td>9fd1d4dae1cbed06dec272607911ed02</td>      <td>Sta144</td>      <td>2020-06-15 07:56:18</td>      <td>Sta20</td>      <td>2020-06-15 08:27:03</td>      <td>2</td>      <td>400</td>    </tr>  </tbody></table><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 删除渠道编号</span></span><br><span class="line">trips = trips.drop(labels=<span class="string">'渠道编号'</span>,axis=<span class="number">1</span>)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">trips.head()</span><br></pre></td></tr></table></figure><p><div></div></p><table border="1" class="dataframe">  <thead>    <tr style="text-align: right;">      <th></th>      <th>用户ID</th>      <th>进站名称</th>      <th>进站时间</th>      <th>出站名称</th>      <th>出站时间</th>      <th>价格</th>    </tr>  </thead>  <tbody>    <tr>      <th>0</th>      <td>d4ec5a712f2b24ce226970a8d315dfce</td>      <td>Sta18</td>      <td>2020-07-15 14:21:58</td>      <td>Sta9</td>      <td>2020-07-15 14:39:29</td>      <td>200</td>    </tr>    <tr>      <th>1</th>      <td>328266c5e7a8fccb976029683f723725</td>      <td>Sta74</td>      <td>2020-07-15 19:40:46</td>      <td>Sta133</td>      <td>2020-07-15 20:49:00</td>      <td>700</td>    </tr>    <tr>      <th>2</th>      <td>4ff0e057af749864432d223ae0d0fa49</td>      <td>Sta69</td>      <td>2020-07-15 20:02:22</td>      <td>Sta96</td>      <td>2020-07-15 20:17:04</td>      <td>300</td>    </tr>    <tr>      <th>3</th>      <td>59add5aed8f0d030858c01a78c9c79fe</td>      <td>Sta110</td>      <td>2020-07-15 16:09:38</td>      <td>Sta123</td>      <td>2020-07-15 16:39:44</td>      <td>400</td>    </tr>    <tr>      <th>4</th>      <td>c285b7d3d347f4a1f46c826307bd1b8a</td>      <td>Sta36</td>      <td>2020-07-15 15:20:39</td>      <td>Sta28</td>      <td>2020-07-15 15:40:20</td>      <td>400</td>    </tr>  </tbody></table><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 用户id</span></span><br><span class="line"></span><br><span class="line">id_count = trips.groupby(by=[<span class="string">'用户ID'</span>]).agg(&#123;<span class="string">'用户ID'</span>:[<span class="string">'count'</span>]&#125;).reset_index()</span><br><span class="line">id_count[<span class="string">'用户ID'</span>].describe()</span><br></pre></td></tr></table></figure><p><div></div></p><table border="1" class="dataframe">  <thead>    <tr style="text-align: right;">      <th></th>      <th>count</th>    </tr>  </thead>  <tbody>    <tr>      <th>count</th>      <td>83049.000000</td>    </tr>    <tr>      <th>mean</th>      <td>9.536478</td>    </tr>    <tr>      <th>std</th>      <td>20.346030</td>    </tr>    <tr>      <th>min</th>      <td>1.000000</td>    </tr>    <tr>      <th>25%</th>      <td>1.000000</td>    </tr>    <tr>      <th>50%</th>      <td>3.000000</td>    </tr>    <tr>      <th>75%</th>      <td>8.000000</td>    </tr>    <tr>      <th>max</th>      <td>322.000000</td>    </tr>  </tbody></table><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 站点</span></span><br><span class="line">len(set(trips[<span class="string">'进站名称'</span>])),len(set(trips[<span class="string">'出站名称'</span>]))</span><br></pre></td></tr></table></figure><pre><code>(168, 168)</code></pre><h3 id="users-csv"><a href="#users-csv" class="headerlink" title="users.csv"></a>users.csv</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">users = pd.read_csv(<span class="string">'./users.csv'</span>)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">users.info()</span><br></pre></td></tr></table></figure><pre><code>&lt;class &#39;pandas.core.frame.DataFrame&#39;&gt;RangeIndex: 124782 entries, 0 to 124781Data columns (total 4 columns):用户ID    124782 non-null object区域      124782 non-null int64出生年份    124782 non-null int64性别      124782 non-null int64dtypes: int64(3), object(1)memory usage: 3.8+ MB</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">users.sample(<span class="number">10</span>)</span><br></pre></td></tr></table></figure><p><div></div></p><table border="1" class="dataframe">  <thead>    <tr style="text-align: right;">      <th></th>      <th>用户ID</th>      <th>区域</th>      <th>出生年份</th>      <th>性别</th>    </tr>  </thead>  <tbody>    <tr>      <th>124450</th>      <td>659eb8d7aaff22d8898cbab2ce901eb9</td>      <td>5224</td>      <td>1988</td>      <td>1</td>    </tr>    <tr>      <th>49769</th>      <td>ab67516f36608867726bea171cd47af1</td>      <td>5113</td>      <td>1996</td>      <td>1</td>    </tr>    <tr>      <th>95642</th>      <td>02dafe7577cba98cd85edf8b7b206e3f</td>      <td>5107</td>      <td>1993</td>      <td>1</td>    </tr>    <tr>      <th>30679</th>      <td>691fba5ba30776c4d94ecb9f850e9628</td>      <td>5001</td>      <td>1985</td>      <td>1</td>    </tr>    <tr>      <th>80127</th>      <td>f29fd257eb729a263900184e4a4177b4</td>      <td>5002</td>      <td>1985</td>      <td>1</td>    </tr>    <tr>      <th>43695</th>      <td>616b3fb46a82b41269cd9833d69d9847</td>      <td>3212</td>      <td>1975</td>      <td>1</td>    </tr>    <tr>      <th>118850</th>      <td>914962a14711cee5b7d916711c22b4fd</td>      <td>1201</td>      <td>1967</td>      <td>0</td>    </tr>    <tr>      <th>35179</th>      <td>d215e6be7597de23b94b79c577aa7569</td>      <td>5002</td>      <td>1993</td>      <td>1</td>    </tr>    <tr>      <th>37903</th>      <td>7634c54e4e8c1bb968ead3da0a38fc7b</td>      <td>5002</td>      <td>1991</td>      <td>0</td>    </tr>    <tr>      <th>91696</th>      <td>2e3134b064a1a082f0f204dac0cb9899</td>      <td>5002</td>      <td>1988</td>      <td>1</td>    </tr>  </tbody></table><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 男女比例</span></span><br><span class="line">users[<span class="string">'性别'</span>].value_counts()/users.shape[<span class="number">0</span>]</span><br></pre></td></tr></table></figure><pre><code>1    0.5865350    0.413465Name: 性别, dtype: float64</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 年龄</span></span><br><span class="line">users[<span class="string">'age'</span>] = <span class="number">2020</span> - users[<span class="string">'出生年份'</span>]</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">users.head()</span><br></pre></td></tr></table></figure><p><div></div></p><table border="1" class="dataframe">  <thead>    <tr style="text-align: right;">      <th></th>      <th>用户ID</th>      <th>区域</th>      <th>出生年份</th>      <th>性别</th>      <th>age</th>    </tr>  </thead>  <tbody>    <tr>      <th>0</th>      <td>4bd084423e63c9bcf3dd66761506d8cf</td>      <td>4115</td>      <td>1996</td>      <td>0</td>      <td>24</td>    </tr>    <tr>      <th>1</th>      <td>6ce72d2bccd92862119d86713dd4e6fa</td>      <td>3623</td>      <td>1980</td>      <td>1</td>      <td>40</td>    </tr>    <tr>      <th>2</th>      <td>adc40e61672136ba20fc41ed3736afe1</td>      <td>5001</td>      <td>1996</td>      <td>1</td>      <td>24</td>    </tr>    <tr>      <th>3</th>      <td>16daef5eb951b4132fdbeb5ede7de172</td>      <td>3706</td>      <td>1988</td>      <td>0</td>      <td>32</td>    </tr>    <tr>      <th>4</th>      <td>5e7c6803e0c584f444b20a96104628cb</td>      <td>3301</td>      <td>1993</td>      <td>1</td>      <td>27</td>    </tr>  </tbody></table><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">users.describe()</span><br></pre></td></tr></table></figure><p><div></div></p><table border="1" class="dataframe">  <thead>    <tr style="text-align: right;">      <th></th>      <th>区域</th>      <th>出生年份</th>      <th>性别</th>      <th>age</th>    </tr>  </thead>  <tbody>    <tr>      <th>count</th>      <td>124782.000000</td>      <td>124782.000000</td>      <td>124782.000000</td>      <td>124782.000000</td>    </tr>    <tr>      <th>mean</th>      <td>4711.264613</td>      <td>1989.136294</td>      <td>0.586535</td>      <td>30.863706</td>    </tr>    <tr>      <th>std</th>      <td>918.747877</td>      <td>9.986578</td>      <td>0.492457</td>      <td>9.986578</td>    </tr>    <tr>      <th>min</th>      <td>1101.000000</td>      <td>1930.000000</td>      <td>0.000000</td>      <td>10.000000</td>    </tr>    <tr>      <th>25%</th>      <td>5001.000000</td>      <td>1983.000000</td>      <td>0.000000</td>      <td>23.000000</td>    </tr>    <tr>      <th>50%</th>      <td>5002.000000</td>      <td>1992.000000</td>      <td>1.000000</td>      <td>28.000000</td>    </tr>    <tr>      <th>75%</th>      <td>5108.000000</td>      <td>1997.000000</td>      <td>1.000000</td>      <td>37.000000</td>    </tr>    <tr>      <th>max</th>      <td>6543.000000</td>      <td>2010.000000</td>      <td>1.000000</td>      <td>90.000000</td>    </tr>  </tbody></table><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 省市区域</span></span><br><span class="line">len(set(users[<span class="string">'区域'</span>]))</span><br></pre></td></tr></table></figure><pre><code>450</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">users[<span class="string">'区域'</span>].value_counts()</span><br></pre></td></tr></table></figure><pre><code>5002    284695001    149045102    121175003     54835116     3713        ...  3427        15121        14225        16208        16405        1Name: 区域, Length: 450, dtype: int64</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># top 20</span></span><br><span class="line">fig, ax = plt.subplots()</span><br><span class="line"></span><br><span class="line">labels = users[<span class="string">'区域'</span>].value_counts().index[:<span class="number">20</span>]</span><br><span class="line"></span><br><span class="line">y_pos = np.arange(len(labels))</span><br><span class="line"></span><br><span class="line">performance = users[<span class="string">'区域'</span>].value_counts().values[:<span class="number">20</span>]</span><br><span class="line"></span><br><span class="line">error = np.random.rand(len(labels))</span><br><span class="line"></span><br><span class="line">ax.barh(y_pos, performance, xerr=error, align=<span class="string">'center'</span>)</span><br><span class="line">ax.set_yticks(y_pos)</span><br><span class="line">ax.set_yticklabels(labels)</span><br><span class="line">ax.invert_yaxis()  <span class="comment"># labels read top-to-bottom</span></span><br><span class="line">ax.set_xlabel(<span class="string">'Counts'</span>)</span><br><span class="line">ax.set_title(<span class="string">'catagory distribution'</span>);<span class="comment"># 加分号只输出图像</span></span><br></pre></td></tr></table></figure><p><img src="/articles/A09/output_21_0.png" alt="png"></p><h3 id="station-csv"><a href="#station-csv" class="headerlink" title="station.csv"></a>station.csv</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">station = pd.read_csv(<span class="string">'./station.csv'</span>)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">station.info()</span><br></pre></td></tr></table></figure><pre><code>&lt;class &#39;pandas.core.frame.DataFrame&#39;&gt;RangeIndex: 163 entries, 0 to 162Data columns (total 4 columns):编号      163 non-null int64站点名称    163 non-null object线路      163 non-null object行政区域    163 non-null objectdtypes: int64(1), object(3)memory usage: 5.2+ KB</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">station.sample(<span class="number">10</span>)</span><br></pre></td></tr></table></figure><p><div></div></p><table border="1" class="dataframe">  <thead>    <tr style="text-align: right;">      <th></th>      <th>编号</th>      <th>站点名称</th>      <th>线路</th>      <th>行政区域</th>    </tr>  </thead>  <tbody>    <tr>      <th>138</th>      <td>1155</td>      <td>Sta145</td>      <td>10号线</td>      <td>Dist5</td>    </tr>    <tr>      <th>151</th>      <td>1172</td>      <td>Sta60</td>      <td>12号线</td>      <td>Dist2</td>    </tr>    <tr>      <th>16</th>      <td>1022</td>      <td>Sta149</td>      <td>1号线</td>      <td>Dist3</td>    </tr>    <tr>      <th>103</th>      <td>1118</td>      <td>Sta118</td>      <td>11号线</td>      <td>Dist5</td>    </tr>    <tr>      <th>118</th>      <td>1134</td>      <td>Sta152</td>      <td>11号线</td>      <td>Dist1</td>    </tr>    <tr>      <th>158</th>      <td>1185</td>      <td>Sta114</td>      <td>10号线</td>      <td>Dist5</td>    </tr>    <tr>      <th>9</th>      <td>1015</td>      <td>Sta80</td>      <td>1号线</td>      <td>Dist3</td>    </tr>    <tr>      <th>82</th>      <td>1094</td>      <td>Sta62</td>      <td>4号线</td>      <td>Dist8</td>    </tr>    <tr>      <th>96</th>      <td>1110</td>      <td>Sta146</td>      <td>11号线</td>      <td>Dist6</td>    </tr>    <tr>      <th>60</th>      <td>1069</td>      <td>Sta39</td>      <td>3号线</td>      <td>Dist5</td>    </tr>  </tbody></table><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">len(set(station[<span class="string">'行政区域'</span>])),len(set(station[<span class="string">'站点名称'</span>])),len(set(station[<span class="string">'编号'</span>]))</span><br></pre></td></tr></table></figure><pre><code>(9, 163, 163)</code></pre><h3 id="workdays-csv"><a href="#workdays-csv" class="headerlink" title="workdays.csv"></a>workdays.csv</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">wd = pd.read_csv(<span class="string">'./workdays2020.csv'</span>,header=<span class="literal">None</span>)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">wd.info()</span><br></pre></td></tr></table></figure><pre><code>&lt;class &#39;pandas.core.frame.DataFrame&#39;&gt;RangeIndex: 366 entries, 0 to 365Data columns (total 2 columns):0    366 non-null int641    366 non-null objectdtypes: int64(1), object(1)memory usage: 5.8+ KB</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">wd.sample(<span class="number">5</span>)</span><br></pre></td></tr></table></figure><p><div></div></p><table border="1" class="dataframe">  <thead>    <tr style="text-align: right;">      <th></th>      <th>0</th>      <th>1</th>    </tr>  </thead>  <tbody>    <tr>      <th>349</th>      <td>20201215</td>      <td>1</td>    </tr>    <tr>      <th>220</th>      <td>20200808</td>      <td>2</td>    </tr>    <tr>      <th>326</th>      <td>20201122</td>      <td>2</td>    </tr>    <tr>      <th>106</th>      <td>20200416</td>      <td>1</td>    </tr>    <tr>      <th>281</th>      <td>20201008</td>      <td>1</td>    </tr>  </tbody></table></div>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h3 id=&quot;数据说明&quot;&gt;&lt;a href=&quot;#数据说明&quot; class=&quot;headerlink&quot; title=&quot;数据说明&quot;&gt;&lt;/a&gt;数据说明&lt;/h3&gt;&lt;p&gt;来源：第十二届服创大赛A类数据&lt;a href=&quot;http://www.fwwb.org.cn/topic/show/6c22
      
    
    </summary>
    
    
    
  </entry>
  
  <entry>
    <title>Tianchi-base-v1</title>
    <link href="https://hahally.github.io/articles/Tianchi-base-v1/"/>
    <id>https://hahally.github.io/articles/Tianchi-base-v1/</id>
    <published>2021-02-02T14:47:06.000Z</published>
    <updated>2021-02-02T14:49:39.363Z</updated>
    
    <content type="html"><![CDATA[<h3 id="导入相关库"><a href="#导入相关库" class="headerlink" title="导入相关库"></a>导入相关库</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> cv2 <span class="keyword">as</span> cv</span><br><span class="line">%matplotlib inline</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> os</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#中文支持matplotlib</span></span><br><span class="line">plt.rcParams[<span class="string">'font.sans-serif'</span>] = [<span class="string">'SimHei'</span>]  <span class="comment"># 步骤一（替换sans-serif字体）</span></span><br><span class="line">plt.rcParams[<span class="string">'axes.unicode_minus'</span>] = <span class="literal">False</span>    <span class="comment"># 步骤二（解决坐标轴负数的负号显示问题）</span></span><br></pre></td></tr></table></figure><h3 id="合并-anno-train-json"><a href="#合并-anno-train-json" class="headerlink" title="合并 anno_train.json"></a>合并 anno_train.json</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">os.listdir(<span class="string">'./dataset/annotations/'</span>)</span><br></pre></td></tr></table></figure><pre><code>[&#39;anno_train1.json&#39;, &#39;anno_train2.json&#39;]</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 合并两个标准文件</span></span><br><span class="line"></span><br><span class="line">d1 = pd.read_json(<span class="string">'./dataset/annotations/anno_train1.json'</span>)</span><br><span class="line">d2 = pd.read_json(<span class="string">'./dataset/annotations/anno_train2.json'</span>)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">d = pd.concat([d1,d2],ignore_index=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">d.to_csv(<span class="string">'./dataset/annotations/anno_train.csv'</span>,index=<span class="literal">False</span>)</span><br></pre></td></tr></table></figure><h3 id="数据分析"><a href="#数据分析" class="headerlink" title="数据分析"></a>数据分析</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">dt = pd.read_csv(<span class="string">'./dataset/annotations/anno_train.csv'</span>)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">dt.info()</span><br></pre></td></tr></table></figure><pre><code>&lt;class &#39;pandas.core.frame.DataFrame&#39;&gt;RangeIndex: 21323 entries, 0 to 21322Data columns (total 3 columns):bbox           21323 non-null objectdefect_name    21323 non-null objectname           21323 non-null objectdtypes: object(3)memory usage: 499.9+ KB</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">fig, ax = plt.subplots()</span><br><span class="line"><span class="comment"># Example data</span></span><br><span class="line">labels = dt[<span class="string">'defect_name'</span>].value_counts().index</span><br><span class="line"></span><br><span class="line">y_pos = np.arange(len(labels))</span><br><span class="line"></span><br><span class="line">performance = dt[<span class="string">'defect_name'</span>].value_counts().values</span><br><span class="line"></span><br><span class="line">error = np.random.rand(len(labels))</span><br><span class="line"></span><br><span class="line">ax.barh(y_pos, performance, xerr=error, align=<span class="string">'center'</span>)</span><br><span class="line">ax.set_yticks(y_pos)</span><br><span class="line">ax.set_yticklabels(labels)</span><br><span class="line">ax.invert_yaxis()  <span class="comment"># labels read top-to-bottom</span></span><br><span class="line">ax.set_xlabel(<span class="string">'Counts'</span>)</span><br><span class="line">ax.set_title(<span class="string">'catagory distribution'</span>);<span class="comment"># 加分号只输出图像</span></span><br></pre></td></tr></table></figure><p><img src="/articles/Tianchi-base-v1/output_11_0.png" alt="png"></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h3 id=&quot;导入相关库&quot;&gt;&lt;a href=&quot;#导入相关库&quot; class=&quot;headerlink&quot; title=&quot;导入相关库&quot;&gt;&lt;/a&gt;导入相关库&lt;/h3&gt;&lt;figure class=&quot;highlight python&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter
      
    
    </summary>
    
    
    
      <category term="CV" scheme="https://hahally.github.io/tags/CV/"/>
    
  </entry>
  
  <entry>
    <title>Tsinghua Dogs v1</title>
    <link href="https://hahally.github.io/articles/TsinghuaDogs-1/"/>
    <id>https://hahally.github.io/articles/TsinghuaDogs-1/</id>
    <published>2021-01-30T03:00:58.000Z</published>
    <updated>2021-02-06T08:30:45.830Z</updated>
    
    <content type="html"><![CDATA[<h3 id="Tsinghua-Dogs数据集的结构"><a href="#Tsinghua-Dogs数据集的结构" class="headerlink" title="Tsinghua Dogs数据集的结构"></a>Tsinghua Dogs数据集的结构</h3><p>赛题地址:<a href="https://www.educoder.net/competitions/index/Jittor-2" target="_blank" rel="noopener">https://www.educoder.net/competitions/index/Jittor-2</a></p><p>来源：<a href="https://cg.cs.tsinghua.edu.cn/ThuDogs/" target="_blank" rel="noopener">Tsinghua Dogs数据集官网</a></p><ul><li>low-resolution：130类狗狗的图片集合</li><li>low-annotations：130类狗狗的标注结果，其中包括头部、整个身体的包围框</li><li>TrainAndValList：训练验证集切分</li></ul><p>每一类被分别保存在不同的文件夹里，该文件夹名称格式为：\$id-$class_id-\$class_name，其中 \$class_id 为类别标签，\$class_name为类别名称，如文件夹名为 220-n000069-Mexican_hairless 的文件对应的标签为 69，文件夹名为 480-n000125-Pekinese 的文件，对应的标签为 125。</p><h3 id="查看文件目录结构"><a href="#查看文件目录结构" class="headerlink" title="查看文件目录结构"></a>查看文件目录结构</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">os.listdir(<span class="string">'./dataset/'</span>)</span><br></pre></td></tr></table></figure><pre><code>[&#39;low-annotations&#39;, &#39;low-resolution&#39;, &#39;TEST_A&#39;, &#39;TrainAndValList&#39;]</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">low_annotations = os.listdir(<span class="string">'./dataset/low-annotations'</span>)</span><br><span class="line">low_resolution = os.listdir(<span class="string">'./dataset/low-resolution'</span>)</span><br><span class="line"></span><br><span class="line">len(low_annotations),len(low_resolution),low_annotations[:<span class="number">5</span>],low_resolution[:<span class="number">5</span>]</span><br></pre></td></tr></table></figure><pre><code>(130, 131, [&#39;1043-n000001-Shiba_Dog&#39;,  &#39;1121-n000002-French_bulldog&#39;,  &#39;1160-n000003-Siberian_husky&#39;,  &#39;1324-n000004-malamute&#39;,  &#39;1936-n000005-Pomeranian&#39;], [&#39;1043-n000001-Shiba_Dog&#39;,  &#39;1121-n000002-French_bulldog&#39;,  &#39;1160-n000003-Siberian_husky&#39;,  &#39;1324-n000004-malamute&#39;,  &#39;1936-n000005-Pomeranian&#39;])</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 无效文件</span></span><br><span class="line">low_resolution[<span class="number">-1</span>]</span><br></pre></td></tr></table></figure><pre><code>&#39;~$directoryfilecount.xlsx&#39;</code></pre><hr><h3 id="可视化Tsinghua-Dogs"><a href="#可视化Tsinghua-Dogs" class="headerlink" title="可视化Tsinghua Dogs"></a>可视化Tsinghua Dogs</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> xml.dom.minidom</span><br><span class="line"><span class="keyword">from</span> xml.dom.minidom <span class="keyword">import</span> parse</span><br><span class="line"><span class="keyword">import</span> cv2</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line">%matplotlib inline</span><br><span class="line"></span><br><span class="line">DOMTree = parse(<span class="string">'./dataset/low-annotations/1043-n000001-Shiba_Dog/n100001.jpeg.xml'</span>)</span><br><span class="line">collection = DOMTree.documentElement</span><br><span class="line">img = cv2.imread(<span class="string">'./dataset/low-resolution/1043-n000001-Shiba_Dog/n100001.jpeg'</span>)</span><br><span class="line">headbndbox = collection.getElementsByTagName(<span class="string">"headbndbox"</span>)[<span class="number">0</span>]</span><br><span class="line">xmin = int(headbndbox.getElementsByTagName(<span class="string">"xmin"</span>)[<span class="number">0</span>].childNodes[<span class="number">0</span>].data)</span><br><span class="line">ymin = int(headbndbox.getElementsByTagName(<span class="string">"ymin"</span>)[<span class="number">0</span>].childNodes[<span class="number">0</span>].data)</span><br><span class="line">xmax = int(headbndbox.getElementsByTagName(<span class="string">"xmax"</span>)[<span class="number">0</span>].childNodes[<span class="number">0</span>].data)</span><br><span class="line">ymax = int(headbndbox.getElementsByTagName(<span class="string">"ymax"</span>)[<span class="number">0</span>].childNodes[<span class="number">0</span>].data)</span><br><span class="line">cv2.rectangle(img, (xmin, ymin), (xmax, ymax), (<span class="number">0</span>,<span class="number">255</span>,<span class="number">0</span>), <span class="number">2</span>)</span><br><span class="line">bodybndbox = collection.getElementsByTagName(<span class="string">"bodybndbox"</span>)[<span class="number">0</span>]</span><br><span class="line">xmin = int(bodybndbox.getElementsByTagName(<span class="string">"xmin"</span>)[<span class="number">0</span>].childNodes[<span class="number">0</span>].data)</span><br><span class="line">ymin = int(bodybndbox.getElementsByTagName(<span class="string">"ymin"</span>)[<span class="number">0</span>].childNodes[<span class="number">0</span>].data)</span><br><span class="line">xmax = int(bodybndbox.getElementsByTagName(<span class="string">"xmax"</span>)[<span class="number">0</span>].childNodes[<span class="number">0</span>].data)</span><br><span class="line">ymax = int(bodybndbox.getElementsByTagName(<span class="string">"ymax"</span>)[<span class="number">0</span>].childNodes[<span class="number">0</span>].data)</span><br><span class="line">cv2.rectangle(img, (xmin, ymin), (xmax, ymax), (<span class="number">0</span>,<span class="number">255</span>,<span class="number">255</span>), <span class="number">2</span>)</span><br><span class="line"><span class="keyword">import</span> pylab <span class="keyword">as</span> pl</span><br><span class="line">pl.figure(figsize=(<span class="number">12</span>,<span class="number">12</span>))</span><br><span class="line">pl.imshow(img[:,:,::<span class="number">-1</span>]);</span><br></pre></td></tr></table></figure><p><img src="/articles/TsinghuaDogs-1/output_8_0.png" alt="png"></p><h3 id="xml2csv"><a href="#xml2csv" class="headerlink" title="xml2csv"></a>xml2csv</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> xml.dom.minidom</span><br><span class="line"><span class="keyword">from</span> xml.dom.minidom <span class="keyword">import</span> parse</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">from</span> tqdm <span class="keyword">import</span> tqdm</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 结构化</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">xml2df</span><span class="params">(root_path,xml_filename)</span>:</span></span><br><span class="line">    </span><br><span class="line">    DOMTree = parse(root_path+xml_filename)</span><br><span class="line">    collection = DOMTree.documentElement</span><br><span class="line">    </span><br><span class="line">    folder = str(collection.getElementsByTagName(<span class="string">"folder"</span>)[<span class="number">0</span>].childNodes[<span class="number">0</span>].data)</span><br><span class="line">    filename = str(collection.getElementsByTagName(<span class="string">"filename"</span>)[<span class="number">0</span>].childNodes[<span class="number">0</span>].data)</span><br><span class="line">    dog_type = str(collection.getElementsByTagName(<span class="string">"name"</span>)[<span class="number">0</span>].childNodes[<span class="number">0</span>].data)</span><br><span class="line">    </span><br><span class="line">    headbndbox = collection.getElementsByTagName(<span class="string">"headbndbox"</span>)[<span class="number">0</span>]</span><br><span class="line">    head_xmin = int(headbndbox.getElementsByTagName(<span class="string">"xmin"</span>)[<span class="number">0</span>].childNodes[<span class="number">0</span>].data)</span><br><span class="line">    head_ymin = int(headbndbox.getElementsByTagName(<span class="string">"ymin"</span>)[<span class="number">0</span>].childNodes[<span class="number">0</span>].data)</span><br><span class="line">    head_xmax = int(headbndbox.getElementsByTagName(<span class="string">"xmax"</span>)[<span class="number">0</span>].childNodes[<span class="number">0</span>].data)</span><br><span class="line">    head_ymax = int(headbndbox.getElementsByTagName(<span class="string">"ymax"</span>)[<span class="number">0</span>].childNodes[<span class="number">0</span>].data)</span><br><span class="line">    </span><br><span class="line">    bodybndbox = collection.getElementsByTagName(<span class="string">"bodybndbox"</span>)[<span class="number">0</span>]</span><br><span class="line">    body_xmin = int(bodybndbox.getElementsByTagName(<span class="string">"xmin"</span>)[<span class="number">0</span>].childNodes[<span class="number">0</span>].data)</span><br><span class="line">    body_ymin = int(bodybndbox.getElementsByTagName(<span class="string">"ymin"</span>)[<span class="number">0</span>].childNodes[<span class="number">0</span>].data)</span><br><span class="line">    body_xmax = int(bodybndbox.getElementsByTagName(<span class="string">"xmax"</span>)[<span class="number">0</span>].childNodes[<span class="number">0</span>].data)</span><br><span class="line">    body_ymax = int(bodybndbox.getElementsByTagName(<span class="string">"ymax"</span>)[<span class="number">0</span>].childNodes[<span class="number">0</span>].data)</span><br><span class="line">    </span><br><span class="line">    data = &#123;</span><br><span class="line">        <span class="string">'folder'</span>: [folder+<span class="string">'/'</span>+filename],</span><br><span class="line">        <span class="string">'dog_type'</span>: [dog_type],</span><br><span class="line">        <span class="string">'hbox'</span>: [[head_xmin,head_ymin,head_xmax,head_ymax]],</span><br><span class="line">        </span><br><span class="line">        <span class="string">'bbox'</span>: [[body_xmin,body_ymin,body_xmax,body_ymax]],</span><br><span class="line">        <span class="string">'label'</span>:[int(folder.split(<span class="string">'-'</span>)[<span class="number">1</span>][<span class="number">1</span>:].lstrip(<span class="string">'0'</span>))]</span><br><span class="line">    &#125;</span><br><span class="line">    df = pd.DataFrame(data=data)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> df</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">fun</span><span class="params">()</span>:</span></span><br><span class="line">    con = []</span><br><span class="line">    <span class="keyword">for</span> path <span class="keyword">in</span> tqdm(os.listdir(<span class="string">'./dataset/low-annotations/'</span>)):</span><br><span class="line">        <span class="keyword">for</span> file <span class="keyword">in</span> os.listdir(<span class="string">'./dataset/low-annotations/'</span> + path):</span><br><span class="line">            root = <span class="string">'./dataset/low-annotations/'</span> + path + <span class="string">'/'</span></span><br><span class="line">            con.append(xml2df(root, file))</span><br><span class="line">    <span class="keyword">return</span> con</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">con = fun()</span><br></pre></td></tr></table></figure><pre><code>100%|████████████████████████████████████████████████████████████████| 130/130 [03:02&lt;00:00,  1.41s/it]</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">df = pd.concat(con,ignore_index=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 70428 张图片</span></span><br><span class="line">df.info()</span><br></pre></td></tr></table></figure><pre><code>&lt;class &#39;pandas.core.frame.DataFrame&#39;&gt;RangeIndex: 70428 entries, 0 to 70427Data columns (total 5 columns):bbox        70428 non-null objectdog_type    70428 non-null objectfolder      70428 non-null objecthbox        70428 non-null objectlabel       70428 non-null int64dtypes: int64(1), object(4)memory usage: 2.7+ MB</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">df.head()</span><br></pre></td></tr></table></figure><div><table border="1" class="dataframe">  <thead>    <tr style="text-align: right;">      <th></th>      <th>bbox</th>      <th>dog_type</th>      <th>folder</th>      <th>hbox</th>      <th>label</th>    </tr>  </thead>  <tbody>    <tr>      <th>0</th>      <td>[241, 47, 720, 720]</td>      <td>Shiba_Dog</td>      <td>1043-n000001-Shiba_Dog/n100001.jpeg</td>      <td>[258, 43, 494, 322]</td>      <td>1</td>    </tr>    <tr>      <th>1</th>      <td>[126, 200, 462, 494]</td>      <td>Shiba_Dog</td>      <td>1043-n000001-Shiba_Dog/n100002.jpeg</td>      <td>[348, 206, 440, 300]</td>      <td>1</td>    </tr>    <tr>      <th>2</th>      <td>[81, 0, 587, 720]</td>      <td>Shiba_Dog</td>      <td>1043-n000001-Shiba_Dog/n100003.jpeg</td>      <td>[124, 5, 564, 458]</td>      <td>1</td>    </tr>    <tr>      <th>3</th>      <td>[81, 81, 342, 332]</td>      <td>Shiba_Dog</td>      <td>1043-n000001-Shiba_Dog/n100004.jpg</td>      <td>[244, 146, 333, 260]</td>      <td>1</td>    </tr>    <tr>      <th>4</th>      <td>[104, 97, 234, 391]</td>      <td>Shiba_Dog</td>      <td>1043-n000001-Shiba_Dog/n100005.jpg</td>      <td>[127, 118, 222, 247]</td>      <td>1</td>    </tr>  </tbody></table><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">df.to_csv(<span class="string">'./ImageInfo.csv'</span>,index=<span class="literal">False</span>)</span><br></pre></td></tr></table></figure><hr><h3 id="数据划分"><a href="#数据划分" class="headerlink" title="数据划分"></a>数据划分</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> cv2 <span class="keyword">as</span> cv</span><br><span class="line">%matplotlib inline</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">img_path = <span class="string">'./dataset/low-resolution/'</span></span><br><span class="line">info_path = <span class="string">'./dataset/low-annotations/'</span></span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 训练集</span></span><br><span class="line">train_data = pd.read_csv(<span class="string">'./dataset/TrainAndValList/train.lst'</span>,header=<span class="literal">None</span>)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 验证集</span></span><br><span class="line">val_data = pd.read_csv(<span class="string">'./dataset/TrainAndValList/validation.lst'</span>,header=<span class="literal">None</span>)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 完整数据</span></span><br><span class="line">all_data = pd.read_csv(<span class="string">'./ImageInfo.csv'</span>)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">train_data[<span class="string">'folder'</span>] = train_data[<span class="number">0</span>].apply(<span class="keyword">lambda</span> x:x[<span class="number">3</span>:])</span><br><span class="line">val_data[<span class="string">'folder'</span>] = val_data[<span class="number">0</span>].apply(<span class="keyword">lambda</span> x:x[<span class="number">3</span>:])</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">train_data = train_data.drop(columns=<span class="number">0</span>)</span><br><span class="line">val_data = val_data.drop(columns=<span class="number">0</span>)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 得到最终划分的数据：train/validation</span></span><br><span class="line">train_data = train_data.merge(all_data,on=[<span class="string">'folder'</span>],how=<span class="string">'left'</span>)</span><br><span class="line">val_data = val_data.merge(all_data,on=[<span class="string">'folder'</span>],how=<span class="string">'left'</span>)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">train_data.head()</span><br></pre></td></tr></table></figure><p><div></div></p><table border="1" class="dataframe">  <thead>    <tr style="text-align: right;">      <th></th>      <th>folder</th>      <th>bbox</th>      <th>dog_type</th>      <th>hbox</th>      <th>label</th>    </tr>  </thead>  <tbody>    <tr>      <th>0</th>      <td>1043-n000001-Shiba_Dog/n100001.jpeg</td>      <td>[241, 47, 720, 720]</td>      <td>Shiba_Dog</td>      <td>[258, 43, 494, 322]</td>      <td>1</td>    </tr>    <tr>      <th>1</th>      <td>1043-n000001-Shiba_Dog/n100002.jpeg</td>      <td>[126, 200, 462, 494]</td>      <td>Shiba_Dog</td>      <td>[348, 206, 440, 300]</td>      <td>1</td>    </tr>    <tr>      <th>2</th>      <td>1043-n000001-Shiba_Dog/n100003.jpeg</td>      <td>[81, 0, 587, 720]</td>      <td>Shiba_Dog</td>      <td>[124, 5, 564, 458]</td>      <td>1</td>    </tr>    <tr>      <th>3</th>      <td>1043-n000001-Shiba_Dog/n100004.jpg</td>      <td>[81, 81, 342, 332]</td>      <td>Shiba_Dog</td>      <td>[244, 146, 333, 260]</td>      <td>1</td>    </tr>    <tr>      <th>4</th>      <td>1043-n000001-Shiba_Dog/n100005.jpg</td>      <td>[104, 97, 234, 391]</td>      <td>Shiba_Dog</td>      <td>[127, 118, 222, 247]</td>      <td>1</td>    </tr>  </tbody></table><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">val_data.head()</span><br></pre></td></tr></table></figure><p><div></div></p><table border="1" class="dataframe">  <thead>    <tr style="text-align: right;">      <th></th>      <th>folder</th>      <th>bbox</th>      <th>dog_type</th>      <th>hbox</th>      <th>label</th>    </tr>  </thead>  <tbody>    <tr>      <th>0</th>      <td>1043-n000001-Shiba_Dog/n100032.jpeg</td>      <td>[109, 44, 471, 533]</td>      <td>Shiba_Dog</td>      <td>[282, 60, 455, 279]</td>      <td>1</td>    </tr>    <tr>      <th>1</th>      <td>1043-n000001-Shiba_Dog/n100069.jpg</td>      <td>[52, 1, 315, 221]</td>      <td>Shiba_Dog</td>      <td>[206, 15, 309, 141]</td>      <td>1</td>    </tr>    <tr>      <th>2</th>      <td>1043-n000001-Shiba_Dog/n100109.jpeg</td>      <td>[41, 61, 363, 295]</td>      <td>Shiba_Dog</td>      <td>[119, 70, 220, 222]</td>      <td>1</td>    </tr>    <tr>      <th>3</th>      <td>1043-n000001-Shiba_Dog/n100112.jpg</td>      <td>[59, 0, 296, 472]</td>      <td>Shiba_Dog</td>      <td>[58, 0, 281, 227]</td>      <td>1</td>    </tr>    <tr>      <th>4</th>      <td>1043-n000001-Shiba_Dog/n100171.jpg</td>      <td>[30, 80, 318, 271]</td>      <td>Shiba_Dog</td>      <td>[188, 91, 257, 187]</td>      <td>1</td>    </tr>  </tbody></table><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">len(train_data),len(val_data),len(all_data)</span><br></pre></td></tr></table></figure><pre><code>(65228, 5200, 70428)</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 保存(save to csv file)</span></span><br><span class="line">train_data.to_csv(<span class="string">'./train.data.csv'</span>,index=<span class="literal">False</span>)</span><br><span class="line">val_data.to_csv(<span class="string">'./valid.data.csv'</span>,index=<span class="literal">False</span>)</span><br></pre></td></tr></table></figure><h3 id="数据分布"><a href="#数据分布" class="headerlink" title="数据分布"></a>数据分布</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd </span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line">%matplotlib inline</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">all_data = pd.read_csv(<span class="string">'./ImageInfo.csv'</span>)</span><br><span class="line">train_data = pd.read_csv(<span class="string">'./train.data.csv'</span>)</span><br><span class="line">val_data = pd.read_csv(<span class="string">'./valid.data.csv'</span>)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># top 15 类型</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">show</span><span class="params">(d)</span>:</span></span><br><span class="line">    fig = plt.figure(figsize=(<span class="number">15</span>,<span class="number">10</span>))</span><br><span class="line">    plt.pie(d.values,  labels=d.index, autopct=<span class="string">'%1.2f%%'</span>, startangle=<span class="number">160</span>)</span><br><span class="line">    plt.tight_layout()</span><br><span class="line">    </span><br><span class="line"><span class="keyword">for</span> dt <span class="keyword">in</span> [all_data,train_data,val_data]:</span><br><span class="line">    d = dt[<span class="string">'dog_type'</span>].value_counts()[:<span class="number">15</span>]</span><br><span class="line">    show(d)</span><br></pre></td></tr></table></figure><p><img src="/articles/TsinghuaDogs-1/output_35_0.png" alt="png"></p><p><img src="/articles/TsinghuaDogs-1/output_35_1.png" alt="png"></p><p><img src="/articles/TsinghuaDogs-1/output_35_2.png" alt="png"></p><h3 id="check-data"><a href="#check-data" class="headerlink" title="check data"></a>check data</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 查看数据维度</span></span><br><span class="line">all_data = pd.read_csv(<span class="string">'./ImageInfo.csv'</span>)</span><br><span class="line"></span><br><span class="line">root = <span class="string">'./dataset/low-resolution/'</span></span><br><span class="line">all_data[<span class="string">'flag'</span>] = all_data[<span class="string">'folder'</span>].apply(</span><br><span class="line">    <span class="keyword">lambda</span> x: <span class="number">1</span> <span class="keyword">if</span> <span class="number">3</span> == plt.imread(root + x).shape[<span class="number">2</span>] <span class="keyword">else</span> <span class="number">0</span>)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 有一张图像维度不是 3</span></span><br><span class="line">all_data[<span class="string">'flag'</span>].value_counts()</span><br></pre></td></tr></table></figure><pre><code>1    704270        1Name: flag, dtype: int64</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># rgba 图像</span></span><br><span class="line">d = all_data[all_data[<span class="string">'flag'</span>]==<span class="number">0</span>][<span class="string">'folder'</span>].values[<span class="number">0</span>]</span><br><span class="line">plt.imread(<span class="string">'./dataset/low-resolution/'</span>+d).shape</span><br></pre></td></tr></table></figure><pre><code>(189, 213, 4)</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># delete </span></span><br><span class="line">train_data = pd.read_csv(<span class="string">'./train.data.csv'</span>)</span><br><span class="line">valid_data = pd.read_csv(<span class="string">'./valid.data.csv'</span>)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">train_data[train_data[<span class="string">'folder'</span>]==d]</span><br></pre></td></tr></table></figure><p><div></div></p><table border="1" class="dataframe">  <thead>    <tr style="text-align: right;">      <th></th>      <th>folder</th>      <th>bbox</th>      <th>dog_type</th>      <th>hbox</th>      <th>label</th>    </tr>  </thead>  <tbody>  </tbody></table><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">valid_data[valid_data[<span class="string">'folder'</span>]==d]</span><br></pre></td></tr></table></figure><p><div></div></p><table border="1" class="dataframe">  <thead>    <tr style="text-align: right;">      <th></th>      <th>folder</th>      <th>bbox</th>      <th>dog_type</th>      <th>hbox</th>      <th>label</th>    </tr>  </thead>  <tbody>    <tr>      <th>4375</th>      <td>274-n000110-Shetland_sheepdog/n136188.jpg</td>      <td>[3, 0, 203, 183]</td>      <td>Shetland_sheepdog</td>      <td>[10, 4, 85, 68]</td>      <td>110</td>    </tr>  </tbody></table><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">valid_data = valid_data.drop(</span><br><span class="line">    valid_data[valid_data[<span class="string">'folder'</span>] == d].index).reset_index(drop=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 重新保存</span></span><br><span class="line">valid_data.to_csv(<span class="string">'./valid.data.csv'</span>,index=<span class="literal">False</span>)</span><br></pre></td></tr></table></figure><h3 id="图像增强"><a href="#图像增强" class="headerlink" title="图像增强"></a>图像增强</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> random</span><br><span class="line"><span class="keyword">import</span> cv2 <span class="keyword">as</span> cv</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 亮度</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">random_bright</span><span class="params">(img, delta=<span class="number">32</span>)</span>:</span></span><br><span class="line">    <span class="string">"""Random change bright</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    Args:</span></span><br><span class="line"><span class="string">        im(numpy.array): one H,W,3 image</span></span><br><span class="line"><span class="string">        delta(int): bright ratio</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    im = np.copy(img)</span><br><span class="line">    <span class="keyword">if</span> random.random() &lt; <span class="number">0.5</span>:</span><br><span class="line">        delta = random.uniform(-delta, delta)</span><br><span class="line">        im += delta</span><br><span class="line">        im = im.clip(min=<span class="number">0</span>, max=<span class="number">255</span>)</span><br><span class="line">    <span class="keyword">return</span> im</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 对比度</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">random_contrast</span><span class="params">(img, lower=<span class="number">0.5</span>, upper=<span class="number">1.5</span>)</span>:</span></span><br><span class="line">    <span class="string">"""Random change contrast</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    Args:</span></span><br><span class="line"><span class="string">        im(numpy.array): one H,W,3 image</span></span><br><span class="line"><span class="string">        lower(float): change lower limit </span></span><br><span class="line"><span class="string">        upper(float): change upper limit</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    im = np.copy(img)</span><br><span class="line">    <span class="keyword">if</span> random.random() &lt; <span class="number">0.5</span>:</span><br><span class="line">        alpha = random.uniform(lower, upper)</span><br><span class="line">        im *= alpha</span><br><span class="line">        im = im.clip(min=<span class="number">0</span>, max=<span class="number">255</span>)</span><br><span class="line">    <span class="keyword">return</span> im</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 饱和度</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">random_saturation</span><span class="params">(img, lower=<span class="number">0.5</span>, upper=<span class="number">1.5</span>)</span>:</span></span><br><span class="line">    <span class="string">"""Random change saturation</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    Args:</span></span><br><span class="line"><span class="string">        im(numpy.array): one H,W,3 image</span></span><br><span class="line"><span class="string">        lower(float): change lower limit </span></span><br><span class="line"><span class="string">        upper(float): change upper limit</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    im = np.copy(img)</span><br><span class="line">    <span class="keyword">if</span> random.random() &lt; <span class="number">0.5</span>:</span><br><span class="line">        im[:, :, <span class="number">1</span>] *= random.uniform(lower, upper)</span><br><span class="line">    <span class="keyword">return</span> im</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 色调</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">random_hue</span><span class="params">(img, delta=<span class="number">18.0</span>)</span>:</span></span><br><span class="line">    <span class="string">"""Random change hue</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    Args:</span></span><br><span class="line"><span class="string">        im(numpy.array): one H,W,3 image</span></span><br><span class="line"><span class="string">        delta(int): hue ratio</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    im = np.copy(img)</span><br><span class="line">    <span class="keyword">if</span> random.random() &lt; <span class="number">0.5</span>:</span><br><span class="line">        im = cv.cvtColor(im, cv.COLOR_RGB2HSV)</span><br><span class="line">        im[:, :, <span class="number">0</span>] += random.uniform(-delta, delta)</span><br><span class="line">        im[:, :, <span class="number">0</span>][im[:, :, <span class="number">0</span>] &gt; <span class="number">360.0</span>] -= <span class="number">360.0</span></span><br><span class="line">        im[:, :, <span class="number">0</span>][im[:, :, <span class="number">0</span>] &lt; <span class="number">0.0</span>] += <span class="number">360.0</span></span><br><span class="line">        im = cv.cvtColor(im, cv.COLOR_HSV2RGB)</span><br><span class="line">    <span class="keyword">return</span> im</span><br></pre></td></tr></table></figure><h3 id="数据加载"><a href="#数据加载" class="headerlink" title="数据加载"></a>数据加载</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> cv2 <span class="keyword">as</span> cv</span><br><span class="line"><span class="keyword">import</span> random</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">DataLoad</span><span class="params">(object)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self,folder=<span class="string">'./'</span>,dtype=<span class="string">'train'</span>,shuffle=False)</span>:</span></span><br><span class="line">        self.folder = folder</span><br><span class="line">        self.shuffle = shuffle</span><br><span class="line">        self.dtype = dtype</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">assert</span> self.dtype <span class="keyword">in</span> [<span class="string">'train'</span>,<span class="string">'test'</span>,<span class="string">'valid'</span>]</span><br><span class="line">        </span><br><span class="line">        self.data = pd.read_csv(os.path.join(self.folder+self.dtype+<span class="string">'.data.csv'</span>))</span><br><span class="line">            </span><br><span class="line">        self.mean = [<span class="number">0.485</span>, <span class="number">0.456</span>, <span class="number">0.406</span>]</span><br><span class="line">        self.std = [<span class="number">0.229</span>, <span class="number">0.224</span>, <span class="number">0.225</span>]</span><br><span class="line">        <span class="keyword">if</span> self.shuffle:</span><br><span class="line">            self.data = self.data.sample(frac=<span class="number">1</span>).reset_index(drop=<span class="literal">True</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__getitem__</span><span class="params">(self,i)</span>:</span></span><br><span class="line">        dt = self.data.iloc[i]</span><br><span class="line">        image = cv.imread(<span class="string">'./dataset/low-resolution/'</span>+dt[<span class="string">'folder'</span>])</span><br><span class="line">        image = cv.cvtColor(image,cv.COLOR_BGR2RGB).astype(<span class="string">"float32"</span>)</span><br><span class="line">        </span><br><span class="line">        bbox = np.array([dt[<span class="string">'bbox'</span>].strip(<span class="string">"[]"</span>).split(<span class="string">','</span>)]).astype(<span class="string">"float32"</span>)</span><br><span class="line">        hbox = np.array([dt[<span class="string">'hbox'</span>].strip(<span class="string">"[]"</span>).split(<span class="string">','</span>)]).astype(<span class="string">"float32"</span>)</span><br><span class="line">        label = np.array(dt[<span class="string">'label'</span>])</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">if</span> self.dtype == <span class="string">'train'</span>:</span><br><span class="line">            data_enhance = [random_bright, </span><br><span class="line">                            random_contrast, </span><br><span class="line">                            random_saturation, </span><br><span class="line">                            random_hue]</span><br><span class="line">            </span><br><span class="line">            random.shuffle(data_enhance)</span><br><span class="line">            </span><br><span class="line">            <span class="keyword">for</span> d <span class="keyword">in</span> data_enhance:</span><br><span class="line">                image = d(image)</span><br><span class="line">            </span><br><span class="line"><span class="comment">#             if random.random() &lt; 0.5:</span></span><br><span class="line"><span class="comment">#                 image, boxes = random_expand(image, boxes)            </span></span><br><span class="line"><span class="comment">#             image, boxes, labels = random_crop(image, boxes, labels)           </span></span><br><span class="line"><span class="comment">#             image, boxes = random_flip(image, boxes)</span></span><br><span class="line">            </span><br><span class="line">        height, width, _ = image.shape</span><br><span class="line">        image = cv.resize(image, (<span class="number">300</span>, <span class="number">300</span>))</span><br><span class="line">        image /= <span class="number">255.</span></span><br><span class="line">        image = (image - self.mean) / self.std</span><br><span class="line"><span class="comment">#         image = image.transpose((2,0,1)).astype("float32")</span></span><br><span class="line">        bbox[:,[<span class="number">0</span>,<span class="number">2</span>]] /= width</span><br><span class="line">        </span><br><span class="line">        bbox[:,[<span class="number">1</span>,<span class="number">3</span>]] /= height</span><br><span class="line"></span><br><span class="line">        hbox[:,[<span class="number">0</span>,<span class="number">2</span>]] /= width</span><br><span class="line">        hbox[:,[<span class="number">1</span>,<span class="number">3</span>]] /= height</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">return</span> image, bbox, hbox, label</span><br></pre></td></tr></table></figure><h3 id="Build-Model"><a href="#Build-Model" class="headerlink" title="Build Model"></a>Build Model</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">from</span> tensorflow.keras <span class="keyword">import</span> datasets, layers, models</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># VGG16</span></span><br><span class="line"></span><br><span class="line">model = models.Sequential()</span><br><span class="line"></span><br><span class="line">model.add(</span><br><span class="line">    layers.Conv2D(<span class="number">64</span>, (<span class="number">3</span>, <span class="number">3</span>),</span><br><span class="line">                  padding=<span class="string">"same"</span>,</span><br><span class="line">                  activation=<span class="string">'relu'</span>,</span><br><span class="line">                  input_shape=(<span class="number">300</span>, <span class="number">300</span>, <span class="number">3</span>)))</span><br><span class="line">model.add(layers.Conv2D(<span class="number">64</span>, (<span class="number">3</span>, <span class="number">3</span>), padding=<span class="string">"same"</span>, activation=<span class="string">'relu'</span>))</span><br><span class="line">model.add(layers.MaxPooling2D((<span class="number">2</span>, <span class="number">2</span>), strides=<span class="number">2</span>))</span><br><span class="line"></span><br><span class="line">model.add(layers.Conv2D(<span class="number">128</span>, (<span class="number">3</span>, <span class="number">3</span>), padding=<span class="string">"same"</span>, activation=<span class="string">'relu'</span>))</span><br><span class="line">model.add(layers.Conv2D(<span class="number">128</span>, (<span class="number">3</span>, <span class="number">3</span>), padding=<span class="string">"same"</span>, activation=<span class="string">'relu'</span>))</span><br><span class="line">model.add(layers.MaxPooling2D((<span class="number">2</span>, <span class="number">2</span>), strides=<span class="number">2</span>))</span><br><span class="line"></span><br><span class="line">model.add(layers.Conv2D(<span class="number">256</span>, (<span class="number">3</span>, <span class="number">3</span>), padding=<span class="string">"same"</span>, activation=<span class="string">'relu'</span>))</span><br><span class="line">model.add(layers.Conv2D(<span class="number">256</span>, (<span class="number">3</span>, <span class="number">3</span>), padding=<span class="string">"same"</span>, activation=<span class="string">'relu'</span>))</span><br><span class="line">model.add(layers.Conv2D(<span class="number">256</span>, (<span class="number">3</span>, <span class="number">3</span>), padding=<span class="string">"same"</span>, activation=<span class="string">'relu'</span>))</span><br><span class="line">model.add(layers.MaxPooling2D((<span class="number">2</span>, <span class="number">2</span>), strides=<span class="number">2</span>))</span><br><span class="line"></span><br><span class="line">model.add(layers.Conv2D(<span class="number">512</span>, (<span class="number">3</span>, <span class="number">3</span>), padding=<span class="string">"same"</span>, activation=<span class="string">'relu'</span>))</span><br><span class="line">model.add(layers.Conv2D(<span class="number">512</span>, (<span class="number">3</span>, <span class="number">3</span>), padding=<span class="string">"same"</span>, activation=<span class="string">'relu'</span>))</span><br><span class="line">model.add(layers.Conv2D(<span class="number">512</span>, (<span class="number">3</span>, <span class="number">3</span>), padding=<span class="string">"same"</span>, activation=<span class="string">'relu'</span>))</span><br><span class="line">model.add(layers.MaxPooling2D((<span class="number">2</span>, <span class="number">2</span>), strides=<span class="number">2</span>))</span><br><span class="line"></span><br><span class="line">model.add(layers.Conv2D(<span class="number">512</span>, (<span class="number">3</span>, <span class="number">3</span>), padding=<span class="string">"same"</span>, activation=<span class="string">'relu'</span>))</span><br><span class="line">model.add(layers.Conv2D(<span class="number">512</span>, (<span class="number">3</span>, <span class="number">3</span>), padding=<span class="string">"same"</span>, activation=<span class="string">'relu'</span>))</span><br><span class="line">model.add(layers.Conv2D(<span class="number">512</span>, (<span class="number">3</span>, <span class="number">3</span>), padding=<span class="string">"same"</span>, activation=<span class="string">'relu'</span>))</span><br><span class="line">model.add(layers.MaxPooling2D((<span class="number">2</span>, <span class="number">2</span>), strides=<span class="number">2</span>))</span><br><span class="line"></span><br><span class="line">model.add(layers.Flatten())</span><br><span class="line">model.add(layers.Dense(<span class="number">256</span>, activation=<span class="string">'relu'</span>))</span><br><span class="line">model.add(layers.Dense(<span class="number">64</span>, activation=<span class="string">'relu'</span>))</span><br><span class="line">model.add(layers.Dense(<span class="number">130</span>))</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">train = DataLoad(shuffle=<span class="literal">True</span>)</span><br><span class="line">valid = DataLoad(dtype=<span class="string">'valid'</span>)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">cat_data</span><span class="params">(dt,n=<span class="number">100</span>)</span>:</span></span><br><span class="line">    con = []</span><br><span class="line">    lab = []</span><br><span class="line">    <span class="keyword">for</span> i,(image, bbox, hbox, label) <span class="keyword">in</span> enumerate(dt):</span><br><span class="line">        <span class="keyword">if</span> i == n:</span><br><span class="line">            <span class="keyword">break</span></span><br><span class="line">        con.append(image)</span><br><span class="line">        lab.append(label)</span><br><span class="line">    lab = np.array(lab)    </span><br><span class="line">    <span class="keyword">return</span> np.array(con),lab</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">x_train,y_train = cat_data(train,n=<span class="number">200</span>)</span><br><span class="line"></span><br><span class="line">x_test,y_test = cat_data(valid,n=<span class="number">5</span>)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">y_train = tf.constant(y_train)</span><br><span class="line">y_test = tf.constant(y_test)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">model.compile(</span><br><span class="line">    optimizer=<span class="string">'adam'</span>,</span><br><span class="line">    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=<span class="literal">True</span>),</span><br><span class="line">    metrics=[<span class="string">'accuracy'</span>])</span><br><span class="line"></span><br><span class="line">history = model.fit(</span><br><span class="line">    x_train,</span><br><span class="line">    y_train,</span><br><span class="line">    epochs=<span class="number">10</span>,</span><br><span class="line">    batch_size=<span class="number">1</span>,</span><br><span class="line">    shuffle=<span class="literal">True</span>,</span><br><span class="line">    validation_data=(x_test, y_test) </span><br><span class="line">)</span><br></pre></td></tr></table></figure><hr><h3 id="SSD-Jittor"><a href="#SSD-Jittor" class="headerlink" title="SSD-Jittor:"></a>SSD-Jittor:</h3><p>New a py file under the root dir: <code>process.py</code></p><p><code>new_parse_annotation()</code> :</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">new_parse_annotation</span><span class="params">(annotation_path)</span>:</span></span><br><span class="line">    </span><br><span class="line">    DOMTree = parse(annotation_path)</span><br><span class="line">    collection = DOMTree.documentElement</span><br><span class="line">    </span><br><span class="line">    folder = str(collection.getElementsByTagName(<span class="string">"folder"</span>)[<span class="number">0</span>].childNodes[<span class="number">0</span>].data)</span><br><span class="line"><span class="comment">#     filename = str(collection.getElementsByTagName("filename")[0].childNodes[0].data)</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#     dog_type = str(collection.getElementsByTagName("name")[0].childNodes[0].data)   </span></span><br><span class="line"><span class="comment">#     headbndbox = collection.getElementsByTagName("headbndbox")[0]</span></span><br><span class="line"><span class="comment">#     head_xmin = int(headbndbox.getElementsByTagName("xmin")[0].childNodes[0].data)</span></span><br><span class="line"><span class="comment">#     head_ymin = int(headbndbox.getElementsByTagName("ymin")[0].childNodes[0].data)</span></span><br><span class="line"><span class="comment">#     head_xmax = int(headbndbox.getElementsByTagName("xmax")[0].childNodes[0].data)</span></span><br><span class="line"><span class="comment">#     head_ymax = int(headbndbox.getElementsByTagName("ymax")[0].childNodes[0].data)</span></span><br><span class="line">    difficult = int(collection.getElementsByTagName(<span class="string">"difficult"</span>)[<span class="number">0</span>].childNodes[<span class="number">0</span>].data)</span><br><span class="line">    </span><br><span class="line">    bodybndbox = collection.getElementsByTagName(<span class="string">"bodybndbox"</span>)[<span class="number">0</span>]</span><br><span class="line">    body_xmin = int(bodybndbox.getElementsByTagName(<span class="string">"xmin"</span>)[<span class="number">0</span>].childNodes[<span class="number">0</span>].data)</span><br><span class="line">    body_ymin = int(bodybndbox.getElementsByTagName(<span class="string">"ymin"</span>)[<span class="number">0</span>].childNodes[<span class="number">0</span>].data)</span><br><span class="line">    body_xmax = int(bodybndbox.getElementsByTagName(<span class="string">"xmax"</span>)[<span class="number">0</span>].childNodes[<span class="number">0</span>].data)</span><br><span class="line">    body_ymax = int(bodybndbox.getElementsByTagName(<span class="string">"ymax"</span>)[<span class="number">0</span>].childNodes[<span class="number">0</span>].data)</span><br><span class="line">    </span><br><span class="line">    data = &#123;</span><br><span class="line">        <span class="string">'boxes'</span>: [[body_xmin - <span class="number">1</span>,body_ymin - <span class="number">1</span>,body_xmax - <span class="number">1</span>,body_ymax - <span class="number">1</span>]],</span><br><span class="line">        <span class="string">'labels'</span>:[int(folder.split(<span class="string">'-'</span>)[<span class="number">1</span>][<span class="number">1</span>:].lstrip(<span class="string">'0'</span>))],</span><br><span class="line">        <span class="string">'difficulties'</span>:[difficult]</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> data</span><br></pre></td></tr></table></figure><p><code>create_json_data()</code> :</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">create_json_data</span><span class="params">(Lst_dir,anno_dir)</span>:</span></span><br><span class="line">    train_images = list()</span><br><span class="line">    train_objects = list()</span><br><span class="line"></span><br><span class="line">    lst_path = os.path.join(Lst_dir, <span class="string">'train.lst'</span>)</span><br><span class="line">    dt = pd.read_csv(lst_path,header=<span class="literal">None</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">for</span> item <span class="keyword">in</span> tqdm(dt[<span class="number">0</span>]):</span><br><span class="line">        img = item.split(<span class="string">'/'</span>)[<span class="number">-2</span>] + <span class="string">'/'</span> + item.split(<span class="string">'/'</span>)[<span class="number">-1</span>]</span><br><span class="line">        train_images.append(img)</span><br><span class="line">        anno_path = os.path.join(anno_dir,img) + <span class="string">'.xml'</span></span><br><span class="line">        train_objects.append(new_parse_annotation(anno_path))</span><br><span class="line">        </span><br><span class="line">    <span class="keyword">assert</span> len(train_objects) == len(train_images)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Save to file</span></span><br><span class="line">    <span class="keyword">with</span> open(os.path.join(<span class="string">'./dataset/JsonData/'</span>, <span class="string">'TRAIN_images.json'</span>), <span class="string">'w'</span>) <span class="keyword">as</span> j:</span><br><span class="line">        json.dump(train_images, j)</span><br><span class="line">    <span class="keyword">with</span> open(os.path.join(<span class="string">'./dataset/JsonData/'</span>, <span class="string">'TRAIN_objects.json'</span>), <span class="string">'w'</span>) <span class="keyword">as</span> j:</span><br><span class="line">        json.dump(train_objects, j)</span><br><span class="line">    <span class="keyword">with</span> open(os.path.join(<span class="string">'./dataset/JsonData/'</span>, <span class="string">'label_map.json'</span>), <span class="string">'w'</span>) <span class="keyword">as</span> j:</span><br><span class="line">        json.dump(label_map, j)  <span class="comment"># save label map too</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Validation data</span></span><br><span class="line">    test_images = list()</span><br><span class="line">    test_objects = list()</span><br><span class="line">    </span><br><span class="line">    lst_path = os.path.join(Lst_dir, <span class="string">'validation.lst'</span>)</span><br><span class="line">    dt = pd.read_csv(lst_path,header=<span class="literal">None</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">for</span> item <span class="keyword">in</span> tqdm(dt[<span class="number">0</span>]):</span><br><span class="line">        img = item.split(<span class="string">'/'</span>)[<span class="number">-2</span>] + <span class="string">'/'</span> + item.split(<span class="string">'/'</span>)[<span class="number">-1</span>]</span><br><span class="line">        test_images.append(img)</span><br><span class="line">        </span><br><span class="line">        anno_path = os.path.join(anno_dir,img) + <span class="string">'.xml'</span></span><br><span class="line">        test_objects.append(new_parse_annotation(anno_path))</span><br><span class="line">        </span><br><span class="line">    <span class="keyword">assert</span> len(test_objects) == len(test_images)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># save to file</span></span><br><span class="line">    <span class="keyword">with</span> open(os.path.join(<span class="string">'./dataset/JsonData/'</span>, <span class="string">'VALID_images.json'</span>), <span class="string">'w'</span>) <span class="keyword">as</span> j:</span><br><span class="line">        json.dump(test_images, j)</span><br><span class="line">    <span class="keyword">with</span> open(os.path.join(<span class="string">'./dataset/JsonData/'</span>, <span class="string">'VALID_objects.json'</span>), <span class="string">'w'</span>) <span class="keyword">as</span> j:</span><br><span class="line">        json.dump(test_objects, j)</span><br><span class="line">        </span><br><span class="line">    print(<span class="string">'Train data:&#123;&#125;,Valid data:&#123;&#125;'</span>.format(len(train_objects),len(test_objects)))</span><br></pre></td></tr></table></figure></div>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h3 id=&quot;Tsinghua-Dogs数据集的结构&quot;&gt;&lt;a href=&quot;#Tsinghua-Dogs数据集的结构&quot; class=&quot;headerlink&quot; title=&quot;Tsinghua Dogs数据集的结构&quot;&gt;&lt;/a&gt;Tsinghua Dogs数据集的结构&lt;/h3&gt;&lt;p&gt;赛题
      
    
    </summary>
    
    
    
      <category term="CV" scheme="https://hahally.github.io/tags/CV/"/>
    
  </entry>
  
  <entry>
    <title>Titanic</title>
    <link href="https://hahally.github.io/articles/Titanic/"/>
    <id>https://hahally.github.io/articles/Titanic/</id>
    <published>2021-01-28T06:46:17.000Z</published>
    <updated>2021-01-29T06:03:54.701Z</updated>
    
    <content type="html"><![CDATA[<h3 id="大纲"><a href="#大纲" class="headerlink" title="大纲"></a>大纲</h3><p><code>Titanic Survival Predictions</code> 可以算是机器学习中的 <code>Hello World</code>了。像kaggle和天池这样的竞赛平台，都将此作为入门的经典题目。</p><ul><li><p>数据：Titanic Survival Predictions</p><ul><li>train.csv：训练集</li><li>test.csv：测试集</li></ul></li><li><p>任务：主要对 <code>train.csv</code> 数据进行处理分析。</p><ul><li>了解和掌握 <code>pandas</code> 透视表的一些基本操作(读取，查看，聚合…)</li><li>了解和掌握一些基本绘图方法</li><li>分析影响游客存活的因素</li><li>分析对缺失值的处理方法</li></ul></li><li><p>数据属性说明(可以参考这里的<a href="https://www.kaggle.com/c/titanic/data" target="_blank" rel="noopener">Data Dictionary</a>)</p><ul><li>PassengerId：id</li><li>Survived：是否存活(0/1)</li><li>Pclass: 舱位类型(1,2,3)</li><li>Name：姓名</li><li>Sex：性别</li><li>Age：年龄</li><li>SibSp：of siblings / spouses aboard the Titanic</li><li>Parch：of parents / children aboard the Titanic</li><li>Ticket：Ticket number</li><li>Fare：票价</li><li>Cabin：房间编号</li><li>Embarked：登船港口</li></ul><ul><li>相关文档：<ul><li><a href="https://pandas.pydata.org/pandas-docs/stable/" target="_blank" rel="noopener">https://pandas.pydata.org/pandas-docs/stable/</a></li><li><a href="https://www.pypandas.cn/" target="_blank" rel="noopener">https://www.pypandas.cn/</a></li><li><a href="https://www.matplotlib.org.cn/" target="_blank" rel="noopener">https://www.matplotlib.org.cn/</a></li><li><a href="https://matplotlib.org/" target="_blank" rel="noopener">https://matplotlib.org/</a></li><li><a href="https://www.numpy.org.cn/" target="_blank" rel="noopener">https://www.numpy.org.cn/</a></li><li><a href="https://numpy.org/doc/stable/reference/" target="_blank" rel="noopener">https://numpy.org/doc/stable/reference/</a></li><li><a href="http://seaborn.pydata.org/" target="_blank" rel="noopener">http://seaborn.pydata.org/</a></li></ul></li></ul></li></ul><h3 id="导入相关的库"><a href="#导入相关的库" class="headerlink" title="导入相关的库"></a>导入相关的库</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd </span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> seaborn <span class="keyword">as</span> sns</span><br><span class="line">%matplotlib inline</span><br><span class="line"></span><br><span class="line"><span class="comment">#ignore warnings</span></span><br><span class="line"><span class="keyword">import</span> warnings</span><br><span class="line">warnings.filterwarnings(<span class="string">'ignore'</span>)</span><br></pre></td></tr></table></figure><h3 id="数据预览"><a href="#数据预览" class="headerlink" title="数据预览"></a>数据预览</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">### 读取数据</span></span><br><span class="line">dt_train = pd.read_csv(<span class="string">'../dataset/train.csv'</span>)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># head() 函数默认查看前 5 条数据</span></span><br><span class="line">dt_train.head()</span><br></pre></td></tr></table></figure><p><div></div></p><table border="1" class="dataframe">  <thead>    <tr style="text-align: right;">      <th></th>      <th>PassengerId</th>      <th>Survived</th>      <th>Pclass</th>      <th>Name</th>      <th>Sex</th>      <th>Age</th>      <th>SibSp</th>      <th>Parch</th>      <th>Ticket</th>      <th>Fare</th>      <th>Cabin</th>      <th>Embarked</th>    </tr>  </thead>  <tbody>    <tr>      <th>0</th>      <td>1</td>      <td>0</td>      <td>3</td>      <td>Braund, Mr. Owen Harris</td>      <td>male</td>      <td>22.0</td>      <td>1</td>      <td>0</td>      <td>A/5 21171</td>      <td>7.2500</td>      <td>NaN</td>      <td>S</td>    </tr>    <tr>      <th>1</th>      <td>2</td>      <td>1</td>      <td>1</td>      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>      <td>female</td>      <td>38.0</td>      <td>1</td>      <td>0</td>      <td>PC 17599</td>      <td>71.2833</td>      <td>C85</td>      <td>C</td>    </tr>    <tr>      <th>2</th>      <td>3</td>      <td>1</td>      <td>3</td>      <td>Heikkinen, Miss. Laina</td>      <td>female</td>      <td>26.0</td>      <td>0</td>      <td>0</td>      <td>STON/O2. 3101282</td>      <td>7.9250</td>      <td>NaN</td>      <td>S</td>    </tr>    <tr>      <th>3</th>      <td>4</td>      <td>1</td>      <td>1</td>      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>      <td>female</td>      <td>35.0</td>      <td>1</td>      <td>0</td>      <td>113803</td>      <td>53.1000</td>      <td>C123</td>      <td>S</td>    </tr>    <tr>      <th>4</th>      <td>5</td>      <td>0</td>      <td>3</td>      <td>Allen, Mr. William Henry</td>      <td>male</td>      <td>35.0</td>      <td>0</td>      <td>0</td>      <td>373450</td>      <td>8.0500</td>      <td>NaN</td>      <td>S</td>    </tr>  </tbody></table><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># sample() 随机采样</span></span><br><span class="line">train.sample(<span class="number">5</span>)</span><br></pre></td></tr></table></figure><div><table border="1" class="dataframe">  <thead>    <tr style="text-align: right;">      <th></th>      <th>PassengerId</th>      <th>Survived</th>      <th>Pclass</th>      <th>Age</th>      <th>SibSp</th>      <th>Parch</th>      <th>Fare</th>    </tr>  </thead>  <tbody>    <tr>      <th>127</th>      <td>128</td>      <td>1</td>      <td>3</td>      <td>24.00</td>      <td>0</td>      <td>0</td>      <td>7.1417</td>    </tr>    <tr>      <th>669</th>      <td>670</td>      <td>1</td>      <td>1</td>      <td>NaN</td>      <td>1</td>      <td>0</td>      <td>52.0000</td>    </tr>    <tr>      <th>229</th>      <td>230</td>      <td>0</td>      <td>3</td>      <td>NaN</td>      <td>3</td>      <td>1</td>      <td>25.4667</td>    </tr>    <tr>      <th>644</th>      <td>645</td>      <td>1</td>      <td>3</td>      <td>0.75</td>      <td>2</td>      <td>1</td>      <td>19.2583</td>    </tr>    <tr>      <th>337</th>      <td>338</td>      <td>1</td>      <td>1</td>      <td>41.00</td>      <td>0</td>      <td>0</td>      <td>134.5000</td>    </tr>  </tbody></table><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># info() 查看数据基本信息</span></span><br><span class="line">dt_train.info()</span><br></pre></td></tr></table></figure><pre><code>&lt;class &#39;pandas.core.frame.DataFrame&#39;&gt;RangeIndex: 891 entries, 0 to 890Data columns (total 12 columns):PassengerId    891 non-null int64Survived       891 non-null int64Pclass         891 non-null int64Name           891 non-null objectSex            891 non-null objectAge            714 non-null float64SibSp          891 non-null int64Parch          891 non-null int64Ticket         891 non-null objectFare           891 non-null float64Cabin          204 non-null objectEmbarked       889 non-null objectdtypes: float64(2), int64(5), object(5)memory usage: 83.7+ KB</code></pre><p>可以看到总共有 12 columns(12个字段,通过 <code>dt_train.columns</code> 可以得到)。<br>info中也可以大致知道各个字段缺失情况：<code>Age</code>、<code>Fare</code>、<code>Cabin</code>、<code>Embarked</code>都是存在缺失值的。<br>除此外，各个字段的数据类型也一目了然。</p><ul><li>Survived: int</li><li>Pclass: int</li><li>Name: string</li><li>Sex: string</li><li>Age: float</li><li>SibSp: int</li><li>Parch: int</li><li>Ticket: string</li><li>Fare: float</li><li>Cabin: string</li><li>Embarked: string</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 获取字段名称</span></span><br><span class="line">dt_train.columns</span><br></pre></td></tr></table></figure><pre><code>Index([&#39;PassengerId&#39;, &#39;Survived&#39;, &#39;Pclass&#39;, &#39;Name&#39;, &#39;Sex&#39;, &#39;Age&#39;, &#39;SibSp&#39;,       &#39;Parch&#39;, &#39;Ticket&#39;, &#39;Fare&#39;, &#39;Cabin&#39;, &#39;Embarked&#39;],      dtype=&#39;object&#39;)</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 查看数值类型字段的大致数据分布情况</span></span><br><span class="line">dt_train.describe()</span><br></pre></td></tr></table></figure><div><table border="1" class="dataframe">  <thead>    <tr style="text-align: right;">      <th></th>      <th>PassengerId</th>      <th>Survived</th>      <th>Pclass</th>      <th>Age</th>      <th>SibSp</th>      <th>Parch</th>      <th>Fare</th>    </tr>  </thead>  <tbody>    <tr>      <th>count</th>      <td>891.000000</td>      <td>891.000000</td>      <td>891.000000</td>      <td>714.000000</td>      <td>891.000000</td>      <td>891.000000</td>      <td>891.000000</td>    </tr>    <tr>      <th>mean</th>      <td>446.000000</td>      <td>0.383838</td>      <td>2.308642</td>      <td>29.699118</td>      <td>0.523008</td>      <td>0.381594</td>      <td>32.204208</td>    </tr>    <tr>      <th>std</th>      <td>257.353842</td>      <td>0.486592</td>      <td>0.836071</td>      <td>14.526497</td>      <td>1.102743</td>      <td>0.806057</td>      <td>49.693429</td>    </tr>    <tr>      <th>min</th>      <td>1.000000</td>      <td>0.000000</td>      <td>1.000000</td>      <td>0.420000</td>      <td>0.000000</td>      <td>0.000000</td>      <td>0.000000</td>    </tr>    <tr>      <th>25%</th>      <td>223.500000</td>      <td>0.000000</td>      <td>2.000000</td>      <td>20.125000</td>      <td>0.000000</td>      <td>0.000000</td>      <td>7.910400</td>    </tr>    <tr>      <th>50%</th>      <td>446.000000</td>      <td>0.000000</td>      <td>3.000000</td>      <td>28.000000</td>      <td>0.000000</td>      <td>0.000000</td>      <td>14.454200</td>    </tr>    <tr>      <th>75%</th>      <td>668.500000</td>      <td>1.000000</td>      <td>3.000000</td>      <td>38.000000</td>      <td>1.000000</td>      <td>0.000000</td>      <td>31.000000</td>    </tr>    <tr>      <th>max</th>      <td>891.000000</td>      <td>1.000000</td>      <td>3.000000</td>      <td>80.000000</td>      <td>8.000000</td>      <td>6.000000</td>      <td>512.329200</td>    </tr>  </tbody></table><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 查看缺失值分布: 主要年龄特征缺失严重</span></span><br><span class="line">dt_train.isnull().sum()</span><br></pre></td></tr></table></figure><pre><code>PassengerId      0Survived         0Pclass           0Name             0Sex              0Age            177SibSp            0Parch            0Ticket           0Fare             0Cabin          687Embarked         2dtype: int64</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 缺失百分比</span></span><br><span class="line">pd.isnull(dt_train).sum()*<span class="number">100</span>/dt_train.shape[<span class="number">0</span>]</span><br></pre></td></tr></table></figure><pre><code>PassengerId     0.000000Survived        0.000000Pclass          0.000000Name            0.000000Sex             0.000000Age            19.865320SibSp           0.000000Parch           0.000000Ticket          0.000000Fare            0.000000Cabin          77.104377Embarked        0.224467dtype: float64</code></pre><p>PS：从数据出发，思考哪些因素或那类特征的人更容易从这场灾难中存活下来</p><h3 id="数据可视化"><a href="#数据可视化" class="headerlink" title="数据可视化"></a>数据可视化</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 绘制条形图观察 性别 特征</span></span><br><span class="line">sns.barplot(x=<span class="string">"Sex"</span>, y=<span class="string">"Survived"</span>, data=dt_train)</span><br><span class="line"></span><br><span class="line"><span class="comment">#print percentages of females vs. males that survive</span></span><br><span class="line">print(</span><br><span class="line">    <span class="string">"Percentage of females who survived:"</span>,</span><br><span class="line">    dt_train.Survived[dt_train.Sex == <span class="string">'female'</span>].value_counts(normalize=<span class="literal">True</span>)[<span class="number">1</span>] *</span><br><span class="line">    <span class="number">100</span>)</span><br><span class="line"></span><br><span class="line">print(</span><br><span class="line">    <span class="string">"Percentage of males who survived:"</span>,</span><br><span class="line">    dt_train.Survived[dt_train.Sex == <span class="string">'male'</span>].value_counts(normalize=<span class="literal">True</span>)[<span class="number">1</span>] * <span class="number">100</span>)</span><br></pre></td></tr></table></figure><pre><code>Percentage of females who survived: 74.20382165605095Percentage of males who survived: 18.890814558058924</code></pre><p><img src="/articles/Titanic/output_15_1.png" alt="png"></p><p>从上面可以看到，女性比男性其实具有更高的生存机会。其他特征，可自行类比做图分析。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 直方图</span></span><br><span class="line"></span><br><span class="line">cols = [<span class="string">'Age'</span>, <span class="string">'SibSp'</span>, <span class="string">'Parch'</span>, <span class="string">'Fare'</span>, <span class="string">'Pclass'</span>]</span><br><span class="line">dt_train[cols].hist(figsize = (<span class="number">15</span>, <span class="number">6</span>), color = <span class="string">'steelblue'</span>, edgecolor = <span class="string">'firebrick'</span>, linewidth = <span class="number">1.5</span>, layout = (<span class="number">2</span>, <span class="number">3</span>));</span><br></pre></td></tr></table></figure><p><img src="/articles/Titanic/output_17_0.png" alt="png"></p><p>从年龄来看，大部分是40岁以下的年轻人；Fare中大部分在一百美元内；Parch与SibSp可以知道独自乘船的人较多；Pclass说明大部分人订的是3等舱。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 年龄分布情况</span></span><br><span class="line">men = dt_train[dt_train[<span class="string">'Sex'</span>]  == <span class="string">'male'</span>]</span><br><span class="line">women = dt_train[dt_train[<span class="string">'Sex'</span>]  == <span class="string">'female'</span>]</span><br><span class="line"></span><br><span class="line">fig, (ax1, ax2, ax3) = plt.subplots(<span class="number">1</span>, <span class="number">3</span>, figsize = (<span class="number">13</span>, <span class="number">4</span>))</span><br><span class="line"></span><br><span class="line">sns.distplot(dt_train[dt_train[<span class="string">'Survived'</span>] == <span class="number">1</span>][<span class="string">'Age'</span>].dropna(), bins = <span class="number">20</span>, label = <span class="string">'Survived'</span>, ax = ax1, kde = <span class="literal">False</span>)</span><br><span class="line">sns.distplot(dt_train[dt_train[<span class="string">'Survived'</span>] == <span class="number">0</span>][<span class="string">'Age'</span>].dropna(), bins = <span class="number">20</span>, label = <span class="string">'Deceased'</span>, ax = ax1, kde = <span class="literal">False</span>)</span><br><span class="line">ax1.legend()</span><br><span class="line">ax1.set_title(<span class="string">'Age Distribution - All Passengers'</span>)</span><br><span class="line"></span><br><span class="line">sns.distplot(women[women[<span class="string">'Survived'</span>] == <span class="number">1</span>][<span class="string">'Age'</span>].dropna(), bins = <span class="number">20</span>, label = <span class="string">'Survived'</span>, ax = ax2, kde = <span class="literal">False</span>)</span><br><span class="line">sns.distplot(women[women[<span class="string">'Survived'</span>] == <span class="number">0</span>][<span class="string">'Age'</span>].dropna(), bins = <span class="number">20</span>, label = <span class="string">'Deceased'</span>, ax = ax2, kde = <span class="literal">False</span>)</span><br><span class="line">ax2.legend()</span><br><span class="line">ax2.set_title(<span class="string">'Age Distribution - Women'</span>)</span><br><span class="line"></span><br><span class="line">sns.distplot(men[men[<span class="string">'Survived'</span>] == <span class="number">1</span>][<span class="string">'Age'</span>].dropna(), bins = <span class="number">20</span>, label = <span class="string">'Survived'</span>, ax = ax3, kde = <span class="literal">False</span>)</span><br><span class="line">sns.distplot(men[men[<span class="string">'Survived'</span>] == <span class="number">0</span>][<span class="string">'Age'</span>].dropna(), bins = <span class="number">20</span>, label = <span class="string">'Deceased'</span>, ax = ax3, kde = <span class="literal">False</span>)</span><br><span class="line">ax3.legend()</span><br><span class="line">ax3.set_title(<span class="string">'Age Distribution - Men'</span>)</span><br><span class="line"></span><br><span class="line">plt.tight_layout()</span><br></pre></td></tr></table></figure><p><img src="/articles/Titanic/output_19_0.png" alt="png"></p><p>这三幅图似乎表明：</p><ul><li>二三四十岁的人存活率要更高</li><li>十岁以下的年龄段出现的峰值说明婴幼儿也更容易存活下来</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 相关性矩阵图</span></span><br><span class="line">names = [<span class="string">'Survived'</span>, <span class="string">'Pclass'</span>, <span class="string">'Sex'</span>, <span class="string">'Age'</span>, <span class="string">'SibSp'</span>, <span class="string">'Parch'</span>, <span class="string">'Fare'</span>]</span><br><span class="line"></span><br><span class="line">correlations = dt_train.corr()</span><br><span class="line">correction = abs(correlations)          <span class="comment"># 取绝对值，只看相关程度 ，不关心正相关还是负相关</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># plot correlation matrix</span></span><br><span class="line">fig = plt.figure()</span><br><span class="line">ax = fig.add_subplot(figsize=(<span class="number">20</span>, <span class="number">20</span>))  <span class="comment">#图的大小为20*20</span></span><br><span class="line"></span><br><span class="line">ax = sns.heatmap(correction,</span><br><span class="line">                 cmap=plt.cm.Greys,</span><br><span class="line">                 linewidths=<span class="number">0.05</span>,</span><br><span class="line">                 vmax=<span class="number">1</span>,</span><br><span class="line">                 vmin=<span class="number">0</span>,</span><br><span class="line">                 annot=<span class="literal">True</span>,</span><br><span class="line">                 annot_kws=&#123;</span><br><span class="line">                     <span class="string">'size'</span>: <span class="number">6</span>,</span><br><span class="line">                     <span class="string">'weight'</span>: <span class="string">'bold'</span></span><br><span class="line">                 &#125;)</span><br><span class="line"><span class="comment">#热力图参数设置（相关系数矩阵，颜色，每个值间隔等）</span></span><br><span class="line">plt.xticks(np.arange(len(names)) + <span class="number">0.5</span>, names)  <span class="comment">#横坐标标注点</span></span><br><span class="line">plt.yticks(np.arange(len(names)) + <span class="number">0.5</span>, names)  <span class="comment">#纵坐标标注点</span></span><br><span class="line">ax.set_title(<span class="string">'Characteristic correlation'</span>)      <span class="comment">#标题设置</span></span><br></pre></td></tr></table></figure><pre><code>Text(0.5,1,&#39;Characteristic correlation&#39;)</code></pre><p><img src="/articles/Titanic/output_17_1.png" alt="png"></p><h4 id="tips"><a href="#tips" class="headerlink" title="tips"></a>tips</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># value_counts():返回各个属性的数量</span></span><br><span class="line"><span class="comment"># 这里可以看到 男性 557人，女性 314人</span></span><br><span class="line"><span class="comment"># 参数 normalize=True 时，返回的是各自的比例</span></span><br><span class="line">dt_train[<span class="string">'Sex'</span>].value_counts()</span><br></pre></td></tr></table></figure><pre><code>(male      577 female    314 Name: Sex, dtype: int64, &#39; &#39;, male      0.647587 female    0.352413 Name: Sex, dtype: float64)</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">dt_train[<span class="string">'Sex'</span>].value_counts(normalize=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure><pre><code>male      0.647587female    0.352413Name: Sex, dtype: float64</code></pre><h3 id="关于缺失值"><a href="#关于缺失值" class="headerlink" title="关于缺失值"></a>关于缺失值</h3><p>对于数据中的缺失值如何处理是需要我们结合问题具体分析的。有时会用均值或中位数等统计值来填充，有的也可以用模型进行预测，对于缺失不是很严重的我们甚至可以直接丢弃。</p></div></div>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h3 id=&quot;大纲&quot;&gt;&lt;a href=&quot;#大纲&quot; class=&quot;headerlink&quot; title=&quot;大纲&quot;&gt;&lt;/a&gt;大纲&lt;/h3&gt;&lt;p&gt;&lt;code&gt;Titanic Survival Predictions&lt;/code&gt; 可以算是机器学习中的 &lt;code&gt;Hello World
      
    
    </summary>
    
    
    
      <category term="data analysis" scheme="https://hahally.github.io/tags/data-analysis/"/>
    
  </entry>
  
  <entry>
    <title>oneSimpleDL</title>
    <link href="https://hahally.github.io/articles/oneSimpleDL/"/>
    <id>https://hahally.github.io/articles/oneSimpleDL/</id>
    <published>2021-01-27T03:34:25.000Z</published>
    <updated>2021-01-27T03:37:09.922Z</updated>
    
    <content type="html"><![CDATA[<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">from</span> tensorflow.keras <span class="keyword">import</span> datasets, layers, models</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line">%matplotlib inline</span><br></pre></td></tr></table></figure><hr><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 数据加载</span></span><br><span class="line">f = np.load(<span class="string">'mnist.npz'</span>)</span><br><span class="line">f.files</span><br></pre></td></tr></table></figure><pre><code>[&#39;x_test&#39;, &#39;x_train&#39;, &#39;y_train&#39;, &#39;y_test&#39;]</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 提取数据</span></span><br><span class="line">data = &#123;&#125;</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> f.files:</span><br><span class="line"></span><br><span class="line">    data[i] = f[i]</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">data[<span class="string">'x_test'</span>].shape,data[<span class="string">'x_train'</span>].shape,data[<span class="string">'y_train'</span>].shape,data[<span class="string">'y_test'</span>].shape,</span><br></pre></td></tr></table></figure><pre><code>((10000, 28, 28), (60000, 28, 28), (60000,), (10000,))</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 可视化</span></span><br><span class="line">plt.imshow(data[<span class="string">'x_train'</span>][<span class="number">0</span>]),data[<span class="string">'y_train'</span>][<span class="number">0</span>]</span><br></pre></td></tr></table></figure><pre><code>(&lt;matplotlib.image.AxesImage at 0x1dcc0eb2860&gt;, 5)</code></pre><p><img src="/articles/oneSimpleDL/output_5_1.png" alt="png"></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 训练集</span></span><br><span class="line">x_train = data[<span class="string">'x_train'</span>]/<span class="number">255.0</span></span><br><span class="line">y_train = data[<span class="string">'y_train'</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 测试集</span></span><br><span class="line">x_test = data[<span class="string">'x_test'</span>]/<span class="number">255.0</span></span><br><span class="line">y_test = data[<span class="string">'y_test'</span>]</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 增加一个维度变成 [b,h,w,c]</span></span><br><span class="line">x_train = tf.expand_dims(x_train,axis=<span class="number">3</span>)</span><br><span class="line">x_test = tf.expand_dims(x_test,axis=<span class="number">3</span>)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 卷积网络 LeNet-5</span></span><br><span class="line"></span><br><span class="line">model = models.Sequential()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 卷积层</span></span><br><span class="line">model.add(layers.Conv2D(<span class="number">6</span>,(<span class="number">3</span>, <span class="number">3</span>), input_shape=(<span class="number">28</span>, <span class="number">28</span>,<span class="number">1</span>)))</span><br><span class="line"><span class="comment"># BN层</span></span><br><span class="line">model.add(layers.BatchNormalization())</span><br><span class="line"><span class="comment"># 池化层</span></span><br><span class="line">model.add(layers.MaxPooling2D((<span class="number">2</span>, <span class="number">2</span>),strides=<span class="number">2</span>))</span><br><span class="line">model.add(layers.ReLU())</span><br><span class="line"></span><br><span class="line"><span class="comment"># 卷积层</span></span><br><span class="line">model.add(layers.Conv2D(<span class="number">16</span>,(<span class="number">3</span>, <span class="number">3</span>)))</span><br><span class="line"><span class="comment"># BN层</span></span><br><span class="line">model.add(layers.BatchNormalization())</span><br><span class="line"><span class="comment"># 池化层</span></span><br><span class="line">model.add(layers.MaxPooling2D((<span class="number">2</span>, <span class="number">2</span>),strides=<span class="number">2</span>))</span><br><span class="line">model.add(layers.ReLU())</span><br><span class="line"></span><br><span class="line">model.add(layers.Flatten())</span><br><span class="line">model.add(layers.Dense(<span class="number">120</span>, activation=<span class="string">'relu'</span>))</span><br><span class="line">model.add(layers.Dense(<span class="number">84</span>, activation=<span class="string">'relu'</span>))</span><br><span class="line">model.add(layers.Dense(<span class="number">10</span>))</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">model.summary()</span><br></pre></td></tr></table></figure><pre><code>Model: &quot;sequential_2&quot;_________________________________________________________________Layer (type)                 Output Shape              Param #   =================================================================conv2d_2 (Conv2D)            (None, 26, 26, 6)         60        _________________________________________________________________batch_normalization_2 (Batch (None, 26, 26, 6)         24        _________________________________________________________________max_pooling2d_2 (MaxPooling2 (None, 13, 13, 6)         0         _________________________________________________________________re_lu_2 (ReLU)               (None, 13, 13, 6)         0         _________________________________________________________________conv2d_3 (Conv2D)            (None, 11, 11, 16)        880       _________________________________________________________________batch_normalization_3 (Batch (None, 11, 11, 16)        64        _________________________________________________________________max_pooling2d_3 (MaxPooling2 (None, 5, 5, 16)          0         _________________________________________________________________re_lu_3 (ReLU)               (None, 5, 5, 16)          0         _________________________________________________________________flatten_1 (Flatten)          (None, 400)               0         _________________________________________________________________dense_3 (Dense)              (None, 120)               48120     _________________________________________________________________dense_4 (Dense)              (None, 84)                10164     _________________________________________________________________dense_5 (Dense)              (None, 10)                850       =================================================================Total params: 60,162Trainable params: 60,118Non-trainable params: 44_________________________________________________________________</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 设置 from_logits=True 相当于在最后输出加了一个 softmax</span></span><br><span class="line">model.compile(</span><br><span class="line">    optimizer=<span class="string">'adam'</span>,</span><br><span class="line">    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=<span class="literal">True</span>),</span><br><span class="line">    metrics=[<span class="string">'accuracy'</span>])</span><br><span class="line"></span><br><span class="line">history = model.fit(x_train,</span><br><span class="line">                    y_train,</span><br><span class="line">                    epochs=<span class="number">10</span>,</span><br><span class="line">                    batch_size=<span class="number">200</span>,</span><br><span class="line">                    validation_data=(x_test, y_test))</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">plt.plot(history.history[<span class="string">'accuracy'</span>], label=<span class="string">'accuracy'</span>)</span><br><span class="line">plt.plot(history.history[<span class="string">'val_accuracy'</span>], label = <span class="string">'val_accuracy'</span>)</span><br><span class="line">plt.xlabel(<span class="string">'Epoch'</span>)</span><br><span class="line">plt.ylabel(<span class="string">'Accuracy'</span>)</span><br><span class="line">plt.ylim([<span class="number">0.5</span>, <span class="number">1</span>])</span><br><span class="line">plt.legend(loc=<span class="string">'lower right'</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">test_loss, test_acc = model.evaluate(x_test,  y_test, verbose=<span class="number">2</span>)</span><br></pre></td></tr></table></figure><pre><code>10000/10000 - 2s - loss: 0.0346 - accuracy: 0.9896</code></pre><p><img src="/articles/oneSimpleDL/output_11_1.png" alt="png"></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">test_loss, test_acc</span><br></pre></td></tr></table></figure><pre><code>(0.034577180710506215, 0.9896)</code></pre><hr><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">unpickle</span><span class="params">(file)</span>:</span></span><br><span class="line">    <span class="keyword">import</span> pickle</span><br><span class="line">    <span class="keyword">with</span> open(file, <span class="string">'rb'</span>) <span class="keyword">as</span> fo:</span><br><span class="line">        dict = pickle.load(fo, encoding=<span class="string">'bytes'</span>)</span><br><span class="line">    <span class="keyword">return</span> dict</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">path = <span class="string">'./cifar-10-python/cifar-10-batches-py/'</span></span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">os.listdir(path)</span><br></pre></td></tr></table></figure><pre><code>[&#39;batches.meta&#39;, &#39;data_batch_1&#39;, &#39;data_batch_2&#39;, &#39;data_batch_3&#39;, &#39;data_batch_4&#39;, &#39;data_batch_5&#39;, &#39;readme.html&#39;, &#39;test_batch&#39;]</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">unpickle(<span class="string">'./cifar-10-python/cifar-10-batches-py/batches.meta'</span>)</span><br></pre></td></tr></table></figure><pre><code>{b&#39;label_names&#39;: [b&#39;airplane&#39;,  b&#39;automobile&#39;,  b&#39;bird&#39;,  b&#39;cat&#39;,  b&#39;deer&#39;,  b&#39;dog&#39;,  b&#39;frog&#39;,  b&#39;horse&#39;,  b&#39;ship&#39;,  b&#39;truck&#39;], b&#39;num_cases_per_batch&#39;: 10000, b&#39;num_vis&#39;: 3072}</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">x_train = []</span><br><span class="line">y_train = []</span><br><span class="line"></span><br><span class="line">x_test = []</span><br><span class="line">y_test = []</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> os.listdir(path):</span><br><span class="line">    <span class="keyword">if</span> <span class="string">'data'</span> <span class="keyword">in</span> i:</span><br><span class="line">        data_dict = unpickle(path + i)</span><br><span class="line">        x_train.append(data_dict[<span class="string">b'data'</span>].reshape(data_dict[<span class="string">b'data'</span>].shape[<span class="number">0</span>],</span><br><span class="line">                                                  <span class="number">3</span>, <span class="number">32</span>,</span><br><span class="line">                                                  <span class="number">32</span>).transpose(<span class="number">0</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">1</span>))</span><br><span class="line">        y_train = y_train + data_dict[<span class="string">b'labels'</span>]</span><br><span class="line">    <span class="keyword">if</span> <span class="string">'test'</span> <span class="keyword">in</span> i:</span><br><span class="line">        test_dict = unpickle(path + i)</span><br><span class="line">        x_test.append(test_dict[<span class="string">b'data'</span>].reshape(test_dict[<span class="string">b'data'</span>].shape[<span class="number">0</span>],</span><br><span class="line">                                                 <span class="number">3</span>, <span class="number">32</span>,</span><br><span class="line">                                                 <span class="number">32</span>).transpose(<span class="number">0</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">1</span>))</span><br><span class="line">        y_test = y_test + test_dict[<span class="string">b'labels'</span>]</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">y_train = tf.constant(y_train)</span><br><span class="line">y_test = tf.constant(y_test)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">y_train.shape,y_test.shape</span><br></pre></td></tr></table></figure><pre><code>(TensorShape([50000]), TensorShape([10000]))</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">x_train = tf.concat(x_train,axis=<span class="number">0</span>)</span><br><span class="line">x_test = tf.concat(x_test,axis=<span class="number">0</span>)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">x_train.shape,x_test.shape</span><br></pre></td></tr></table></figure><pre><code>(TensorShape([50000, 32, 32, 3]), TensorShape([10000, 32, 32, 3]))</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># VGG16</span></span><br><span class="line"></span><br><span class="line">model = models.Sequential()</span><br><span class="line"></span><br><span class="line">model.add(</span><br><span class="line">    layers.Conv2D(<span class="number">64</span>, (<span class="number">3</span>, <span class="number">3</span>),</span><br><span class="line">                  padding=<span class="string">"same"</span>,</span><br><span class="line">                  activation=<span class="string">'relu'</span>,</span><br><span class="line">                  input_shape=(<span class="number">32</span>, <span class="number">32</span>, <span class="number">3</span>)))</span><br><span class="line">model.add(layers.Conv2D(<span class="number">64</span>, (<span class="number">3</span>, <span class="number">3</span>), padding=<span class="string">"same"</span>, activation=<span class="string">'relu'</span>))</span><br><span class="line">model.add(layers.MaxPooling2D((<span class="number">2</span>, <span class="number">2</span>), strides=<span class="number">2</span>))</span><br><span class="line"></span><br><span class="line">model.add(layers.Conv2D(<span class="number">128</span>, (<span class="number">3</span>, <span class="number">3</span>), padding=<span class="string">"same"</span>, activation=<span class="string">'relu'</span>))</span><br><span class="line">model.add(layers.Conv2D(<span class="number">128</span>, (<span class="number">3</span>, <span class="number">3</span>), padding=<span class="string">"same"</span>, activation=<span class="string">'relu'</span>))</span><br><span class="line">model.add(layers.MaxPooling2D((<span class="number">2</span>, <span class="number">2</span>), strides=<span class="number">2</span>))</span><br><span class="line"></span><br><span class="line">model.add(layers.Conv2D(<span class="number">256</span>, (<span class="number">3</span>, <span class="number">3</span>), padding=<span class="string">"same"</span>, activation=<span class="string">'relu'</span>))</span><br><span class="line">model.add(layers.Conv2D(<span class="number">256</span>, (<span class="number">3</span>, <span class="number">3</span>), padding=<span class="string">"same"</span>, activation=<span class="string">'relu'</span>))</span><br><span class="line">model.add(layers.Conv2D(<span class="number">256</span>, (<span class="number">3</span>, <span class="number">3</span>), padding=<span class="string">"same"</span>, activation=<span class="string">'relu'</span>))</span><br><span class="line">model.add(layers.MaxPooling2D((<span class="number">2</span>, <span class="number">2</span>), strides=<span class="number">2</span>))</span><br><span class="line"></span><br><span class="line">model.add(layers.Conv2D(<span class="number">512</span>, (<span class="number">3</span>, <span class="number">3</span>), padding=<span class="string">"same"</span>, activation=<span class="string">'relu'</span>))</span><br><span class="line">model.add(layers.Conv2D(<span class="number">512</span>, (<span class="number">3</span>, <span class="number">3</span>), padding=<span class="string">"same"</span>, activation=<span class="string">'relu'</span>))</span><br><span class="line">model.add(layers.Conv2D(<span class="number">512</span>, (<span class="number">3</span>, <span class="number">3</span>), padding=<span class="string">"same"</span>, activation=<span class="string">'relu'</span>))</span><br><span class="line">model.add(layers.MaxPooling2D((<span class="number">2</span>, <span class="number">2</span>), strides=<span class="number">2</span>))</span><br><span class="line"></span><br><span class="line">model.add(layers.Conv2D(<span class="number">512</span>, (<span class="number">3</span>, <span class="number">3</span>), padding=<span class="string">"same"</span>, activation=<span class="string">'relu'</span>))</span><br><span class="line">model.add(layers.Conv2D(<span class="number">512</span>, (<span class="number">3</span>, <span class="number">3</span>), padding=<span class="string">"same"</span>, activation=<span class="string">'relu'</span>))</span><br><span class="line">model.add(layers.Conv2D(<span class="number">512</span>, (<span class="number">3</span>, <span class="number">3</span>), padding=<span class="string">"same"</span>, activation=<span class="string">'relu'</span>))</span><br><span class="line">model.add(layers.MaxPooling2D((<span class="number">2</span>, <span class="number">2</span>), strides=<span class="number">2</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment"># model.add(layers.Flatten())</span></span><br><span class="line">model.add(layers.Dense(<span class="number">256</span>, activation=<span class="string">'relu'</span>))</span><br><span class="line">model.add(layers.Dense(<span class="number">64</span>, activation=<span class="string">'relu'</span>))</span><br><span class="line">model.add(layers.Dense(<span class="number">10</span>))</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">model.summary()</span><br></pre></td></tr></table></figure><pre><code>Model: &quot;sequential&quot;_________________________________________________________________Layer (type)                 Output Shape              Param #   =================================================================conv2d (Conv2D)              (None, 32, 32, 64)        1792      _________________________________________________________________conv2d_1 (Conv2D)            (None, 32, 32, 64)        36928     _________________________________________________________________max_pooling2d (MaxPooling2D) (None, 16, 16, 64)        0         _________________________________________________________________conv2d_2 (Conv2D)            (None, 16, 16, 128)       73856     _________________________________________________________________conv2d_3 (Conv2D)            (None, 16, 16, 128)       147584    _________________________________________________________________max_pooling2d_1 (MaxPooling2 (None, 8, 8, 128)         0         _________________________________________________________________conv2d_4 (Conv2D)            (None, 8, 8, 256)         295168    _________________________________________________________________conv2d_5 (Conv2D)            (None, 8, 8, 256)         590080    _________________________________________________________________conv2d_6 (Conv2D)            (None, 8, 8, 256)         590080    _________________________________________________________________max_pooling2d_2 (MaxPooling2 (None, 4, 4, 256)         0         _________________________________________________________________conv2d_7 (Conv2D)            (None, 4, 4, 512)         1180160   _________________________________________________________________conv2d_8 (Conv2D)            (None, 4, 4, 512)         2359808   _________________________________________________________________conv2d_9 (Conv2D)            (None, 4, 4, 512)         2359808   _________________________________________________________________max_pooling2d_3 (MaxPooling2 (None, 2, 2, 512)         0         _________________________________________________________________conv2d_10 (Conv2D)           (None, 2, 2, 512)         2359808   _________________________________________________________________conv2d_11 (Conv2D)           (None, 2, 2, 512)         2359808   _________________________________________________________________conv2d_12 (Conv2D)           (None, 2, 2, 512)         2359808   _________________________________________________________________max_pooling2d_4 (MaxPooling2 (None, 1, 1, 512)         0         _________________________________________________________________dense (Dense)                (None, 1, 1, 256)         131328    _________________________________________________________________dense_1 (Dense)              (None, 1, 1, 64)          16448     _________________________________________________________________dense_2 (Dense)              (None, 1, 1, 10)          650       =================================================================Total params: 14,863,114Trainable params: 14,863,114Non-trainable params: 0_________________________________________________________________</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">model.compile(</span><br><span class="line">    optimizer=<span class="string">'adam'</span>,</span><br><span class="line">    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=<span class="literal">True</span>),</span><br><span class="line">    metrics=[<span class="string">'accuracy'</span>])</span><br><span class="line"></span><br><span class="line">history = model.fit(</span><br><span class="line">    x_train,</span><br><span class="line">    y_train,</span><br><span class="line">    epochs=<span class="number">10</span>,</span><br><span class="line">    batch_size=<span class="number">1</span>,</span><br><span class="line">    shuffle=<span class="literal">True</span>,</span><br><span class="line">    validation_data=(x_test, y_test) </span><br><span class="line">)</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;figure class=&quot;highlight python&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span clas
      
    
    </summary>
    
    
    
      <category term="DeepLearning" scheme="https://hahally.github.io/tags/DeepLearning/"/>
    
  </entry>
  
  <entry>
    <title>Task5</title>
    <link href="https://hahally.github.io/articles/Task5/"/>
    <id>https://hahally.github.io/articles/Task5/</id>
    <published>2021-01-25T15:51:35.000Z</published>
    <updated>2021-01-25T15:54:55.697Z</updated>
    
    <content type="html"><![CDATA[<h2 id="任务说明"><a href="#任务说明" class="headerlink" title="任务说明"></a>任务说明</h2><ul><li>学习主题：作者关联（数据建模任务），对论文作者关系进行建模，统计最常出现的作者关系；</li><li>学习内容：构建作者关系图，挖掘作者关系</li><li>学习成果：论文作者知识图谱、图关系挖掘</li></ul><h2 id="数据处理步骤"><a href="#数据处理步骤" class="headerlink" title="数据处理步骤"></a>数据处理步骤</h2><p>将作者列表进行处理，并完成统计。具体步骤如下：</p><ul><li>将论文第一作者与其他作者（论文非第一作者）构建图；</li><li>使用图算法统计图中作者与其他作者的联系；</li></ul><h2 id="社交网络分析"><a href="#社交网络分析" class="headerlink" title="社交网络分析"></a>社交网络分析</h2><p>图是复杂网络研究中的一个重要概念。Graph是用<strong>点</strong>和<strong>线</strong>来刻画离散事物集合中的每对事物间以某种方式相联系的数学模型。Graph在现实世界中随处可见，如交通运输图、旅游图、流程图等。利用图可以描述现实生活中的许多事物，如用点可以表示交叉口，点之间的连线表示路径，这样就可以轻而易举的描绘出一个交通运输网络。</p><h3 id="图类型"><a href="#图类型" class="headerlink" title="图类型"></a>图类型</h3><ul><li><p>无向图，忽略了两节点间边的方向。</p></li><li><p>指有向图，考虑了边的有向性。</p></li><li><p>多重无向图，即两个结点之间的边数多于一条，又允许顶点通过同一条边和自己关联。</p></li></ul><h3 id="图统计指标"><a href="#图统计指标" class="headerlink" title="图统计指标"></a>图统计指标</h3><ul><li><p>度：是指和该节点相关联的边的条数，又称关联度。对于有向图，节点的入度 是指进入该节点的边的条数；节点的出度是指从该节点出发的边的条数；</p></li><li><p>迪杰斯特拉路径：.从一个源点到其它各点的最短路径，可使用迪杰斯特拉算法来求最短路径；</p></li><li><p>连通图：在一个无向图 G 中，若从顶点i到顶点j有路径相连，则称i和j是连通的。如果 G 是有向图，那么连接i和j的路径中所有的边都必须同向。如果图中任意两点都是连通的，那么图被称作连通图。如果此图是有向图，则称为强连通图。</p></li></ul><p>对于其他图算法，可以在networkx和igraph两个库中找到。</p><h2 id="具体代码以及讲解"><a href="#具体代码以及讲解" class="headerlink" title="具体代码以及讲解"></a>具体代码以及讲解</h2><p>首先读取我们想要的数据：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 导入所需的package</span></span><br><span class="line"><span class="keyword">import</span> seaborn <span class="keyword">as</span> sns <span class="comment">#用于画图</span></span><br><span class="line"><span class="keyword">from</span> bs4 <span class="keyword">import</span> BeautifulSoup <span class="comment">#用于爬取arxiv的数据</span></span><br><span class="line"><span class="keyword">import</span> re <span class="comment">#用于正则表达式，匹配字符串的模式</span></span><br><span class="line"><span class="keyword">import</span> requests <span class="comment">#用于网络连接，发送网络请求，使用域名获取对应信息</span></span><br><span class="line"><span class="keyword">import</span> json <span class="comment">#读取数据，我们的数据为json格式的</span></span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd <span class="comment">#数据处理，数据分析</span></span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt <span class="comment">#画图工具</span></span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">readArxivFile</span><span class="params">(path, columns=[<span class="string">'id'</span>, <span class="string">'submitter'</span>, <span class="string">'authors'</span>, <span class="string">'title'</span>, <span class="string">'comments'</span>, <span class="string">'journal-ref'</span>, <span class="string">'doi'</span>,</span></span></span><br><span class="line"><span class="function"><span class="params">       <span class="string">'report-no'</span>, <span class="string">'categories'</span>, <span class="string">'license'</span>, <span class="string">'abstract'</span>, <span class="string">'versions'</span>,</span></span></span><br><span class="line"><span class="function"><span class="params">       <span class="string">'update_date'</span>, <span class="string">'authors_parsed'</span>], count=None)</span>:</span></span><br><span class="line">    <span class="string">'''</span></span><br><span class="line"><span class="string">    定义读取文件的函数</span></span><br><span class="line"><span class="string">        path: 文件路径</span></span><br><span class="line"><span class="string">        columns: 需要选择的列</span></span><br><span class="line"><span class="string">        count: 读取行数</span></span><br><span class="line"><span class="string">    '''</span></span><br><span class="line">    </span><br><span class="line">    data  = []</span><br><span class="line">    <span class="keyword">with</span> open(path, <span class="string">'r'</span>) <span class="keyword">as</span> f: </span><br><span class="line">        <span class="keyword">for</span> idx, line <span class="keyword">in</span> enumerate(f): </span><br><span class="line">            <span class="keyword">if</span> idx == count:</span><br><span class="line">                <span class="keyword">break</span></span><br><span class="line">                </span><br><span class="line">            d = json.loads(line)</span><br><span class="line">            d = &#123;col : d[col] <span class="keyword">for</span> col <span class="keyword">in</span> columns&#125;</span><br><span class="line">            data.append(d)</span><br><span class="line"></span><br><span class="line">    data = pd.DataFrame(data)</span><br><span class="line">    <span class="keyword">return</span> data</span><br><span class="line"></span><br><span class="line">data = readArxivFile(<span class="string">'arxiv-metadata-oai-snapshot.json'</span>, </span><br><span class="line">                     [<span class="string">'id'</span>, <span class="string">'authors_parsed'</span>],</span><br><span class="line">                    <span class="number">200000</span>)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">data.head()</span><br></pre></td></tr></table></figure><p><div></div></p><table border="1" class="dataframe">  <thead>    <tr style="text-align: right;">      <th></th>      <th>authors_parsed</th>      <th>id</th>    </tr>  </thead>  <tbody>    <tr>      <th>0</th>      <td>[[Balázs, C., ], [Berger, E. L., ], [Nadolsky,...</td>      <td>0704.0001</td>    </tr>    <tr>      <th>1</th>      <td>[[Streinu, Ileana, ], [Theran, Louis, ]]</td>      <td>0704.0002</td>    </tr>    <tr>      <th>2</th>      <td>[[Pan, Hongjun, ]]</td>      <td>0704.0003</td>    </tr>    <tr>      <th>3</th>      <td>[[Callan, David, ]]</td>      <td>0704.0004</td>    </tr>    <tr>      <th>4</th>      <td>[[Abu-Shammala, Wael, ], [Torchinsky, Alberto, ]]</td>      <td>0704.0005</td>    </tr>  </tbody></table><p>创建作者链接的无向图：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> networkx <span class="keyword">as</span> nx </span><br><span class="line"><span class="comment"># 创建无向图</span></span><br><span class="line">G = nx.Graph()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 只用五篇论文进行构建</span></span><br><span class="line"><span class="keyword">for</span> row <span class="keyword">in</span> data.iloc[:<span class="number">5</span>].itertuples():</span><br><span class="line">    authors = row[<span class="number">1</span>]</span><br><span class="line">    authors = [<span class="string">' '</span>.join(x[:<span class="number">-1</span>]) <span class="keyword">for</span> x <span class="keyword">in</span> authors]</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 第一个作者 与 其他作者链接</span></span><br><span class="line">    <span class="keyword">for</span> author <span class="keyword">in</span> authors[<span class="number">1</span>:]:</span><br><span class="line">        G.add_edge(authors[<span class="number">0</span>],author) <span class="comment">#　添加节点２，３并链接２３节点</span></span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 将作者关系图进行绘制：</span></span><br><span class="line">nx.draw(G, with_labels=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure><p><img src="/articles/Task5/output_6_0.png" alt="png"></p><p>如果我们500片论文构建图，则可以得到更加完整作者关系，并选择最大联通子图进行绘制，折线图为子图节点度值。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> row <span class="keyword">in</span> data.iloc[:<span class="number">500</span>].itertuples():</span><br><span class="line">    authors = row[<span class="number">1</span>]</span><br><span class="line">    authors = [<span class="string">' '</span>.join(x[:<span class="number">-1</span>]) <span class="keyword">for</span> x <span class="keyword">in</span> authors]</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 第一个作者 与 其他作者链接</span></span><br><span class="line">    <span class="keyword">for</span> author <span class="keyword">in</span> authors[<span class="number">1</span>:]:</span><br><span class="line">        G.add_edge(authors[<span class="number">0</span>],author) <span class="comment">#　添加节点２，３并链接２３节点</span></span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">degree_sequence = sorted([d <span class="keyword">for</span> n, d <span class="keyword">in</span> G.degree()], reverse=<span class="literal">True</span>)</span><br><span class="line">dmax = max(degree_sequence)</span><br><span class="line"></span><br><span class="line">plt.loglog(degree_sequence, <span class="string">"b-"</span>, marker=<span class="string">"o"</span>)</span><br><span class="line">plt.title(<span class="string">"Degree rank plot"</span>)</span><br><span class="line">plt.ylabel(<span class="string">"degree"</span>)</span><br><span class="line">plt.xlabel(<span class="string">"rank"</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># draw graph in inset</span></span><br><span class="line">plt.axes([<span class="number">0.45</span>, <span class="number">0.45</span>, <span class="number">0.45</span>, <span class="number">0.45</span>])</span><br><span class="line">Gcc = G.subgraph(sorted(nx.connected_components(G), key=len, reverse=<span class="literal">True</span>)[<span class="number">0</span>])</span><br><span class="line"></span><br><span class="line">pos = nx.spring_layout(Gcc)</span><br><span class="line">plt.axis(<span class="string">"off"</span>)</span><br><span class="line">nx.draw_networkx_nodes(Gcc, pos, node_size=<span class="number">20</span>)</span><br><span class="line">nx.draw_networkx_edges(Gcc, pos, alpha=<span class="number">0.4</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="/articles/Task5/output_9_0.png" alt="png"></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;任务说明&quot;&gt;&lt;a href=&quot;#任务说明&quot; class=&quot;headerlink&quot; title=&quot;任务说明&quot;&gt;&lt;/a&gt;任务说明&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;学习主题：作者关联（数据建模任务），对论文作者关系进行建模，统计最常出现的作者关系；&lt;/li&gt;
&lt;li&gt;学习内容
      
    
    </summary>
    
    
    
      <category term="data analysis" scheme="https://hahally.github.io/tags/data-analysis/"/>
    
  </entry>
  
  <entry>
    <title>Task4</title>
    <link href="https://hahally.github.io/articles/Task4/"/>
    <id>https://hahally.github.io/articles/Task4/</id>
    <published>2021-01-22T13:58:19.000Z</published>
    <updated>2021-01-22T14:01:10.538Z</updated>
    
    <content type="html"><![CDATA[<h2 id="任务说明"><a href="#任务说明" class="headerlink" title="任务说明"></a>任务说明</h2><ul><li>学习主题：论文分类（数据建模任务），利用已有数据建模，对新论文进行类别分类；</li><li>学习内容：使用论文标题完成类别分类；</li><li>学习成果：学会文本分类的基本方法、<code>TF-IDF</code>等；</li></ul><h2 id="数据处理步骤"><a href="#数据处理步骤" class="headerlink" title="数据处理步骤"></a>数据处理步骤</h2><p>在原始arxiv论文中论文都有对应的类别，而论文类别是作者填写的。在本次任务中我们可以借助论文的标题和摘要完成：</p><ul><li>对论文标题和摘要进行处理；</li><li>对论文类别进行处理；</li><li>构建文本分类模型；</li></ul><h2 id="文本分类思路"><a href="#文本分类思路" class="headerlink" title="文本分类思路"></a>文本分类思路</h2><ul><li>思路1：TF-IDF+机器学习分类器</li></ul><p>直接使用TF-IDF对文本提取特征，使用分类器进行分类，分类器的选择上可以使用SVM、LR、XGboost等</p><ul><li>思路2：FastText</li></ul><p>FastText是入门款的词向量，利用Facebook提供的FastText工具，可以快速构建分类器</p><ul><li>思路3：WordVec+深度学习分类器</li></ul><p>WordVec是进阶款的词向量，并通过构建深度学习分类完成分类。深度学习分类的网络结构可以选择TextCNN、TextRnn或者BiLSTM。</p><ul><li>思路4：Bert词向量</li></ul><p>Bert是高配款的词向量，具有强大的建模学习能力。</p><h2 id="具体代码实现以及讲解"><a href="#具体代码实现以及讲解" class="headerlink" title="具体代码实现以及讲解"></a>具体代码实现以及讲解</h2><p>为了方便大家入门文本分类，我们选择思路1和思路2给大家讲解。首先完成字段读取：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 导入所需的package</span></span><br><span class="line"><span class="keyword">import</span> seaborn <span class="keyword">as</span> sns <span class="comment">#用于画图</span></span><br><span class="line"><span class="keyword">from</span> bs4 <span class="keyword">import</span> BeautifulSoup <span class="comment">#用于爬取arxiv的数据</span></span><br><span class="line"><span class="keyword">import</span> re <span class="comment">#用于正则表达式，匹配字符串的模式</span></span><br><span class="line"><span class="keyword">import</span> requests <span class="comment">#用于网络连接，发送网络请求，使用域名获取对应信息</span></span><br><span class="line"><span class="keyword">import</span> json <span class="comment">#读取数据，我们的数据为json格式的</span></span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd <span class="comment">#数据处理，数据分析</span></span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt <span class="comment">#画图工具</span></span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">readArxivFile</span><span class="params">(path, columns=[<span class="string">'id'</span>, <span class="string">'submitter'</span>, <span class="string">'authors'</span>, <span class="string">'title'</span>, <span class="string">'comments'</span>, <span class="string">'journal-ref'</span>, <span class="string">'doi'</span>,</span></span></span><br><span class="line"><span class="function"><span class="params">       <span class="string">'report-no'</span>, <span class="string">'categories'</span>, <span class="string">'license'</span>, <span class="string">'abstract'</span>, <span class="string">'versions'</span>,</span></span></span><br><span class="line"><span class="function"><span class="params">       <span class="string">'update_date'</span>, <span class="string">'authors_parsed'</span>], count=None)</span>:</span></span><br><span class="line">    <span class="string">'''</span></span><br><span class="line"><span class="string">    定义读取文件的函数</span></span><br><span class="line"><span class="string">        path: 文件路径</span></span><br><span class="line"><span class="string">        columns: 需要选择的列</span></span><br><span class="line"><span class="string">        count: 读取行数</span></span><br><span class="line"><span class="string">    '''</span></span><br><span class="line">    </span><br><span class="line">    data  = []</span><br><span class="line">    <span class="keyword">with</span> open(path, <span class="string">'r'</span>) <span class="keyword">as</span> f: </span><br><span class="line">        <span class="keyword">for</span> idx, line <span class="keyword">in</span> enumerate(f): </span><br><span class="line">            <span class="keyword">if</span> idx == count:</span><br><span class="line">                <span class="keyword">break</span></span><br><span class="line">                </span><br><span class="line">            d = json.loads(line)</span><br><span class="line">            d = &#123;col : d[col] <span class="keyword">for</span> col <span class="keyword">in</span> columns&#125;</span><br><span class="line">            data.append(d)</span><br><span class="line"></span><br><span class="line">    data = pd.DataFrame(data)</span><br><span class="line">    <span class="keyword">return</span> data</span><br><span class="line"></span><br><span class="line">data = readArxivFile(<span class="string">'arxiv-metadata-oai-snapshot.json'</span>, </span><br><span class="line">                     [<span class="string">'id'</span>, <span class="string">'title'</span>, <span class="string">'categories'</span>, <span class="string">'abstract'</span>],</span><br><span class="line">                    <span class="number">200000</span>)</span><br></pre></td></tr></table></figure><p>为了方便数据的处理，我们可以将标题和摘要拼接一起完成分类。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">data[<span class="string">'text'</span>] = data[<span class="string">'title'</span>] + data[<span class="string">'abstract'</span>]</span><br><span class="line"></span><br><span class="line">data[<span class="string">'text'</span>] = data[<span class="string">'text'</span>].apply(<span class="keyword">lambda</span> x: x.replace(<span class="string">'\n'</span>,<span class="string">' '</span>))</span><br><span class="line">data[<span class="string">'text'</span>] = data[<span class="string">'text'</span>].apply(<span class="keyword">lambda</span> x: x.lower())</span><br><span class="line">data = data.drop([<span class="string">'abstract'</span>, <span class="string">'title'</span>], axis=<span class="number">1</span>)</span><br></pre></td></tr></table></figure><p>由于原始论文有可能有多个类别，所以也需要处理：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 多个类别，包含子分类</span></span><br><span class="line">data[<span class="string">'categories'</span>] = data[<span class="string">'categories'</span>].apply(<span class="keyword">lambda</span> x : x.split(<span class="string">' '</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 单个类别，不包含子分类</span></span><br><span class="line">data[<span class="string">'categories_big'</span>] = data[<span class="string">'categories'</span>].apply(<span class="keyword">lambda</span> x : [xx.split(<span class="string">'.'</span>)[<span class="number">0</span>] <span class="keyword">for</span> xx <span class="keyword">in</span> x])</span><br></pre></td></tr></table></figure><p>然后将类别进行编码，这里类别是多个，所以需要多编码：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> MultiLabelBinarizer</span><br><span class="line">mlb = MultiLabelBinarizer()</span><br><span class="line">data_label = mlb.fit_transform(data[<span class="string">'categories_big'</span>].iloc[:])</span><br></pre></td></tr></table></figure><h3 id="思路1"><a href="#思路1" class="headerlink" title="思路1"></a>思路1</h3><p>思路1使用TFIDF提取特征，限制最多4000个单词：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.feature_extraction.text <span class="keyword">import</span> TfidfVectorizer</span><br><span class="line">vectorizer = TfidfVectorizer(max_features=<span class="number">4000</span>)</span><br><span class="line">data_tfidf = vectorizer.fit_transform(data[<span class="string">'text'</span>].iloc[:])</span><br></pre></td></tr></table></figure><p>由于这里是多标签分类，可以使用sklearn的多标签分类进行封装：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 划分训练集和验证集</span></span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line">x_train, x_test, y_train, y_test = train_test_split(data_tfidf, data_label,</span><br><span class="line">                                                 test_size = <span class="number">0.2</span>,random_state = <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 构建多标签分类模型</span></span><br><span class="line"><span class="keyword">from</span> sklearn.multioutput <span class="keyword">import</span> MultiOutputClassifier</span><br><span class="line"><span class="keyword">from</span> sklearn.naive_bayes <span class="keyword">import</span> MultinomialNB</span><br><span class="line">clf = MultiOutputClassifier(MultinomialNB()).fit(x_train, y_train)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> classification_report</span><br><span class="line">print(classification_report(y_test, clf.predict(x_test)))</span><br></pre></td></tr></table></figure><pre><code>              precision    recall  f1-score   support           0       0.95      0.85      0.89      7925           1       0.85      0.79      0.82      7339           2       0.77      0.72      0.74      2944           3       0.00      0.00      0.00         4           4       0.72      0.48      0.58      2123           5       0.51      0.66      0.58       987           6       0.86      0.38      0.52       544           7       0.71      0.69      0.70      3649           8       0.76      0.61      0.68      3388           9       0.85      0.88      0.87     10745          10       0.46      0.13      0.20      1757          11       0.79      0.04      0.07       729          12       0.45      0.35      0.39       507          13       0.54      0.36      0.43      1083          14       0.69      0.14      0.24      3441          15       0.84      0.20      0.33       655          16       0.93      0.16      0.27       268          17       0.87      0.43      0.58      2484          18       0.82      0.38      0.52       692   micro avg       0.81      0.65      0.72     51264   macro avg       0.70      0.43      0.50     51264weighted avg       0.80      0.65      0.69     51264 samples avg       0.72      0.72      0.70     51264</code></pre><p>​    </p><pre><code>d:\program files\python\lib\site-packages\sklearn\metrics\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.  _warn_prf(average, modifier, msg_start, len(result))d:\program files\python\lib\site-packages\sklearn\metrics\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.  _warn_prf(average, modifier, msg_start, len(result))d:\program files\python\lib\site-packages\sklearn\metrics\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.  _warn_prf(average, modifier, msg_start, len(result))d:\program files\python\lib\site-packages\sklearn\metrics\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.  _warn_prf(average, modifier, msg_start, len(result))</code></pre><h3 id="思路2"><a href="#思路2" class="headerlink" title="思路2"></a>思路2</h3><p>思路2使用深度学习模型，单词进行词嵌入然后训练。将数据集处理进行编码，并进行截断：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line">x_train, x_test, y_train, y_test = train_test_split(data[<span class="string">'text'</span>].iloc[:<span class="number">100000</span>],</span><br><span class="line">                                                    data_label[:<span class="number">100000</span>],</span><br><span class="line">                                                    test_size=<span class="number">0.95</span>,</span><br><span class="line">                                                    random_state=<span class="number">1</span>)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># parameter</span></span><br><span class="line">max_features= <span class="number">500</span></span><br><span class="line">max_len= <span class="number">150</span></span><br><span class="line">embed_size=<span class="number">100</span></span><br><span class="line">batch_size = <span class="number">128</span></span><br><span class="line">epochs = <span class="number">5</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> keras.preprocessing.text <span class="keyword">import</span> Tokenizer</span><br><span class="line"><span class="keyword">from</span> keras.preprocessing <span class="keyword">import</span> sequence</span><br><span class="line"></span><br><span class="line">tokens = Tokenizer(num_words = max_features)</span><br><span class="line">tokens.fit_on_texts(list(data[<span class="string">'text'</span>].iloc[:<span class="number">100000</span>]))</span><br><span class="line"></span><br><span class="line">y_train = data_label[:<span class="number">100000</span>]</span><br><span class="line">x_sub_train = tokens.texts_to_sequences(data[<span class="string">'text'</span>].iloc[:<span class="number">100000</span>])</span><br><span class="line">x_sub_train = sequence.pad_sequences(x_sub_train, maxlen=max_len)</span><br></pre></td></tr></table></figure><pre><code>Using TensorFlow backend.</code></pre><p>定义模型并完成训练：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># LSTM model</span></span><br><span class="line"><span class="comment"># Keras Layers:</span></span><br><span class="line"><span class="keyword">from</span> keras.layers <span class="keyword">import</span> Dense,Input,LSTM,Bidirectional,Activation,Conv1D,GRU</span><br><span class="line"><span class="keyword">from</span> keras.layers <span class="keyword">import</span> Dropout,Embedding,GlobalMaxPooling1D, MaxPooling1D, Add, Flatten</span><br><span class="line"><span class="keyword">from</span> keras.layers <span class="keyword">import</span> GlobalAveragePooling1D, GlobalMaxPooling1D, concatenate, SpatialDropout1D<span class="comment"># Keras Callback Functions:</span></span><br><span class="line"><span class="keyword">from</span> keras.callbacks <span class="keyword">import</span> Callback</span><br><span class="line"><span class="keyword">from</span> keras.callbacks <span class="keyword">import</span> EarlyStopping,ModelCheckpoint</span><br><span class="line"><span class="keyword">from</span> keras <span class="keyword">import</span> initializers, regularizers, constraints, optimizers, layers, callbacks</span><br><span class="line"><span class="keyword">from</span> keras.models <span class="keyword">import</span> Model</span><br><span class="line"><span class="keyword">from</span> keras.optimizers <span class="keyword">import</span> Adam</span><br><span class="line"></span><br><span class="line">sequence_input = Input(shape=(max_len, ))</span><br><span class="line">x = Embedding(max_features, embed_size, trainable=<span class="literal">True</span>)(sequence_input)</span><br><span class="line">x = SpatialDropout1D(<span class="number">0.2</span>)(x)</span><br><span class="line">x = Bidirectional(GRU(<span class="number">128</span>, return_sequences=<span class="literal">True</span>,dropout=<span class="number">0.1</span>,recurrent_dropout=<span class="number">0.1</span>))(x)</span><br><span class="line">x = Conv1D(<span class="number">64</span>, kernel_size = <span class="number">3</span>, padding = <span class="string">"valid"</span>, kernel_initializer = <span class="string">"glorot_uniform"</span>)(x)</span><br><span class="line">avg_pool = GlobalAveragePooling1D()(x)</span><br><span class="line">max_pool = GlobalMaxPooling1D()(x)</span><br><span class="line">x = concatenate([avg_pool, max_pool]) </span><br><span class="line">preds = Dense(<span class="number">19</span>, activation=<span class="string">"sigmoid"</span>)(x)</span><br><span class="line"></span><br><span class="line">model = Model(sequence_input, preds)</span><br><span class="line">model.compile(loss=<span class="string">'binary_crossentropy'</span>,optimizer=Adam(lr=<span class="number">1e-3</span>),metrics=[<span class="string">'accuracy'</span>])</span><br><span class="line">model.fit(x_sub_train, y_train, </span><br><span class="line">          batch_size=batch_size, </span><br><span class="line">          validation_split=<span class="number">0.2</span>,</span><br><span class="line">          epochs=epochs)</span><br></pre></td></tr></table></figure><pre><code>C:\Users\ACER\AppData\Roaming\Python\Python35\site-packages\tensorflow_core\python\framework\indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.  &quot;Converting sparse IndexedSlices to a dense Tensor of unknown shape. &quot;C:\Users\ACER\AppData\Roaming\Python\Python35\site-packages\tensorflow_core\python\framework\indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.  &quot;Converting sparse IndexedSlices to a dense Tensor of unknown shape. &quot;Train on 80000 samples, validate on 20000 samplesEpoch 1/580000/80000 [==============================] - 844s 11ms/step - loss: 0.1697 - accuracy: 0.9456 - val_loss: 0.1262 - val_accuracy: 0.9571Epoch 2/580000/80000 [==============================] - 858s 11ms/step - loss: 0.1221 - accuracy: 0.9582 - val_loss: 0.1144 - val_accuracy: 0.9599Epoch 3/580000/80000 [==============================] - 833s 10ms/step - loss: 0.1131 - accuracy: 0.9599 - val_loss: 0.1097 - val_accuracy: 0.9610Epoch 4/580000/80000 [==============================] - 807s 10ms/step - loss: 0.1087 - accuracy: 0.9610 - val_loss: 0.1055 - val_accuracy: 0.9624Epoch 5/580000/80000 [==============================] - 791s 10ms/step - loss: 0.1170 - accuracy: 0.9613 - val_loss: 0.1047 - val_accuracy: 0.9623&lt;keras.callbacks.callbacks.History at 0x2a50566ef98&gt;</code></pre>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;任务说明&quot;&gt;&lt;a href=&quot;#任务说明&quot; class=&quot;headerlink&quot; title=&quot;任务说明&quot;&gt;&lt;/a&gt;任务说明&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;学习主题：论文分类（数据建模任务），利用已有数据建模，对新论文进行类别分类；&lt;/li&gt;
&lt;li&gt;学习内容：使用论
      
    
    </summary>
    
    
    
      <category term="data analysis" scheme="https://hahally.github.io/tags/data-analysis/"/>
    
  </entry>
  
  <entry>
    <title>Task3</title>
    <link href="https://hahally.github.io/articles/Task3/"/>
    <id>https://hahally.github.io/articles/Task3/</id>
    <published>2021-01-19T05:52:54.000Z</published>
    <updated>2021-01-19T05:57:44.359Z</updated>
    
    <content type="html"><![CDATA[<h2 id="任务说明"><a href="#任务说明" class="headerlink" title="任务说明"></a>任务说明</h2><ul><li>任务主题：论文代码统计，统计所有论文出现代码的相关统计；</li><li>任务内容：使用正则表达式统计代码连接、页数和图表数据；</li><li>任务成果：学习正则表达式统计；</li></ul><h2 id="数据处理步骤"><a href="#数据处理步骤" class="headerlink" title="数据处理步骤"></a>数据处理步骤</h2><p>在原始arxiv数据集中作者经常会在论文的<code>comments</code>或<code>abstract</code>字段中给出具体的代码链接，所以我们需要从这些字段里面找出代码的链接。</p><ul><li>确定数据出现的位置；</li><li>使用正则表达式完成匹配；</li><li>完成相关的统计；</li></ul><h2 id="正则表达式"><a href="#正则表达式" class="headerlink" title="正则表达式"></a>正则表达式</h2><p>正则表达式(regular expression)描述了一种字符串匹配的模式（pattern），可以用来检查一个串是否含有某种子串、将匹配的子串替换或者从某个串中取出符合某个条件的子串等。</p><h4 id="普通字符：大写和小写字母、所有数字、所有标点符号和一些其他符号"><a href="#普通字符：大写和小写字母、所有数字、所有标点符号和一些其他符号" class="headerlink" title="普通字符：大写和小写字母、所有数字、所有标点符号和一些其他符号"></a>普通字符：大写和小写字母、所有数字、所有标点符号和一些其他符号</h4><div class="table-container"><table><thead><tr><th>字符</th><th>描述</th></tr></thead><tbody><tr><td><strong>[ABC]</strong></td><td>匹配 […] 中的所有字符，例如 [aeiou] 匹配字符串 “google runoob taobao” 中所有的 e o u a 字母。</td></tr><tr><td><strong><sup><a href="#fn_ABC" id="reffn_ABC">ABC</a></sup></strong></td><td>匹配除了 <strong>[…]</strong> 中字符的所有字符，例如 <strong><sup><a href="#fn_aeiou" id="reffn_aeiou">aeiou</a></sup></strong> 匹配字符串 “google runoob taobao” 中除了 e o u a 字母的所有字母。</td></tr><tr><td><strong>[A-Z]</strong></td><td>[A-Z] 表示一个区间，匹配所有大写字母，[a-z] 表示所有小写字母。</td></tr><tr><td>.</td><td>匹配除换行符（\n、\r）之外的任何单个字符，相等于 <strong><sup><a href="#fn_\n\r" id="reffn_\n\r">\n\r</a></sup></strong>。</td></tr><tr><td><strong>[\s\S]</strong></td><td>匹配所有。\s 是匹配所有空白符，包括换行，\S 非空白符，包括换行。</td></tr><tr><td><strong>\w</strong></td><td>匹配字母、数字、下划线。等价于 [A-Za-z0-9_]</td></tr></tbody></table></div><h4 id="特殊字符：有特殊含义的字符"><a href="#特殊字符：有特殊含义的字符" class="headerlink" title="特殊字符：有特殊含义的字符"></a>特殊字符：有特殊含义的字符</h4><div class="table-container"><table><thead><tr><th style="text-align:left">特别字符</th><th style="text-align:left">描述</th></tr></thead><tbody><tr><td style="text-align:left">( )</td><td style="text-align:left">标记一个子表达式的开始和结束位置。子表达式可以获取供以后使用。要匹配这些字符，请使用 ( 和 )。</td></tr><tr><td style="text-align:left">*</td><td style="text-align:left">匹配前面的子表达式零次或多次。要匹配 <em> 字符，请使用 \</em>。</td></tr><tr><td style="text-align:left">+</td><td style="text-align:left">匹配前面的子表达式一次或多次。要匹配 + 字符，请使用 +。</td></tr><tr><td style="text-align:left">.</td><td style="text-align:left">匹配除换行符 \n 之外的任何单字符。要匹配 . ，请使用 . 。</td></tr><tr><td style="text-align:left">[</td><td style="text-align:left">标记一个中括号表达式的开始。要匹配 [，请使用 [。</td></tr><tr><td style="text-align:left">?</td><td style="text-align:left">匹配前面的子表达式零次或一次，或指明一个非贪婪限定符。要匹配 ? 字符，请使用 \?。</td></tr><tr><td style="text-align:left">\</td><td style="text-align:left">将下一个字符标记为或特殊字符、或原义字符、或向后引用、或八进制转义符。例如， ‘n’ 匹配字符 ‘n’。’\n’ 匹配换行符。序列 ‘\\’ 匹配 “\”，而 ‘(‘ 则匹配 “(“。</td></tr><tr><td style="text-align:left">^</td><td style="text-align:left">匹配输入字符串的开始位置，除非在方括号表达式中使用，当该符号在方括号表达式中使用时，表示不接受该方括号表达式中的字符集合。要匹配 ^ 字符本身，请使用 \^。</td></tr><tr><td style="text-align:left">{</td><td style="text-align:left">标记限定符表达式的开始。要匹配 {，请使用 \{。</td></tr><tr><td style="text-align:left">\</td><td style="text-align:left"></td><td>指明两项之间的一个选择。要匹配 \</td><td>，请使用 \</td><td>。</td></tr></tbody></table></div><h4 id="限定符"><a href="#限定符" class="headerlink" title="限定符"></a>限定符</h4><div class="table-container"><table><thead><tr><th style="text-align:left">字符</th><th style="text-align:left">描述</th></tr></thead><tbody><tr><td style="text-align:left">*</td><td style="text-align:left">匹配前面的子表达式零次或多次。例如，zo<em> 能匹配 “z” 以及 “zoo”。</em> 等价于{0,}。</td></tr><tr><td style="text-align:left">+</td><td style="text-align:left">匹配前面的子表达式一次或多次。例如，’zo+’ 能匹配 “zo” 以及 “zoo”，但不能匹配 “z”。+ 等价于 {1,}。</td></tr><tr><td style="text-align:left">?</td><td style="text-align:left">匹配前面的子表达式零次或一次。例如，”do(es)?” 可以匹配 “do” 、 “does” 中的 “does” 、 “doxy” 中的 “do” 。? 等价于 {0,1}。</td></tr><tr><td style="text-align:left">{n}</td><td style="text-align:left">n 是一个非负整数。匹配确定的 n 次。例如，’o{2}’ 不能匹配 “Bob” 中的 ‘o’，但是能匹配 “food” 中的两个 o。</td></tr><tr><td style="text-align:left">{n,}</td><td style="text-align:left">n 是一个非负整数。至少匹配n 次。例如，’o{2,}’ 不能匹配 “Bob” 中的 ‘o’，但能匹配 “foooood” 中的所有 o。’o{1,}’ 等价于 ‘o+’。’o{0,}’ 则等价于 ‘o*’。</td></tr><tr><td style="text-align:left">{n,m}</td><td style="text-align:left">m 和 n 均为非负整数，其中n &lt;= m。最少匹配 n 次且最多匹配 m 次。例如，”o{1,3}” 将匹配 “fooooood” 中的前三个 o。’o{0,1}’ 等价于 ‘o?’。请注意在逗号和两个数之间不能有空格。</td></tr></tbody></table></div><h2 id="具体代码实现以及讲解"><a href="#具体代码实现以及讲解" class="headerlink" title="具体代码实现以及讲解"></a>具体代码实现以及讲解</h2><p>首先我们来统计论文页数，也就是在<code>comments</code>字段中抽取pages和figures和个数，首先完成字段读取。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 导入所需的package</span></span><br><span class="line"><span class="keyword">import</span> seaborn <span class="keyword">as</span> sns <span class="comment">#用于画图</span></span><br><span class="line"><span class="keyword">from</span> bs4 <span class="keyword">import</span> BeautifulSoup <span class="comment">#用于爬取arxiv的数据</span></span><br><span class="line"><span class="keyword">import</span> re <span class="comment">#用于正则表达式，匹配字符串的模式</span></span><br><span class="line"><span class="keyword">import</span> requests <span class="comment">#用于网络连接，发送网络请求，使用域名获取对应信息</span></span><br><span class="line"><span class="keyword">import</span> json <span class="comment">#读取数据，我们的数据为json格式的</span></span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd <span class="comment">#数据处理，数据分析</span></span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt <span class="comment">#画图工具</span></span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">readArxivFile</span><span class="params">(path,</span></span></span><br><span class="line"><span class="function"><span class="params">                  columns=[</span></span></span><br><span class="line"><span class="function"><span class="params">                      <span class="string">'id'</span>, <span class="string">'submitter'</span>, <span class="string">'authors'</span>, <span class="string">'title'</span>, <span class="string">'comments'</span>,</span></span></span><br><span class="line"><span class="function"><span class="params">                      <span class="string">'journal-ref'</span>, <span class="string">'doi'</span>, <span class="string">'report-no'</span>, <span class="string">'categories'</span>,</span></span></span><br><span class="line"><span class="function"><span class="params">                      <span class="string">'license'</span>, <span class="string">'abstract'</span>, <span class="string">'versions'</span>, <span class="string">'update_date'</span>,</span></span></span><br><span class="line"><span class="function"><span class="params">                      <span class="string">'authors_parsed'</span></span></span></span><br><span class="line"><span class="function"><span class="params">                  ],</span></span></span><br><span class="line"><span class="function"><span class="params">                  count=None)</span>:</span></span><br><span class="line">    <span class="string">'''</span></span><br><span class="line"><span class="string">    定义读取文件的函数</span></span><br><span class="line"><span class="string">        path: 文件路径</span></span><br><span class="line"><span class="string">        columns: 需要选择的列</span></span><br><span class="line"><span class="string">        count: 读取行数</span></span><br><span class="line"><span class="string">    '''</span></span><br><span class="line"></span><br><span class="line">    data = []</span><br><span class="line">    <span class="keyword">with</span> open(path, <span class="string">'r'</span>) <span class="keyword">as</span> f:</span><br><span class="line">        <span class="keyword">for</span> idx, line <span class="keyword">in</span> enumerate(f):</span><br><span class="line">            <span class="keyword">if</span> idx == count:</span><br><span class="line">                <span class="keyword">break</span></span><br><span class="line"></span><br><span class="line">            d = json.loads(line)</span><br><span class="line">            d = &#123;col: d[col] <span class="keyword">for</span> col <span class="keyword">in</span> columns&#125;</span><br><span class="line">            data.append(d)</span><br><span class="line"></span><br><span class="line">    data = pd.DataFrame(data)</span><br><span class="line">    <span class="keyword">return</span> data</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">data = readArxivFile(<span class="string">'arxiv-metadata-oai-2019.json'</span>,</span><br><span class="line">                     [<span class="string">'id'</span>, <span class="string">'abstract'</span>, <span class="string">'categories'</span>, <span class="string">'comments'</span>])</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">data.head()</span><br></pre></td></tr></table></figure><div><table border="1" class="dataframe">  <thead>    <tr style="text-align: right;">      <th></th>      <th>abstract</th>      <th>categories</th>      <th>comments</th>      <th>id</th>    </tr>  </thead>  <tbody>    <tr>      <th>0</th>      <td>We systematically explore the evolution of t...</td>      <td>astro-ph</td>      <td>15 pages, 15 figures, 3 tables, submitted to M...</td>      <td>0704.0297</td>    </tr>    <tr>      <th>1</th>      <td>Cofibrations are defined in the category of ...</td>      <td>math.AT</td>      <td>27 pages</td>      <td>0704.0342</td>    </tr>    <tr>      <th>2</th>      <td>We explore the effect of an inhomogeneous ma...</td>      <td>astro-ph</td>      <td>6 pages, 3 figures, accepted in A&amp;A</td>      <td>0704.0360</td>    </tr>    <tr>      <th>3</th>      <td>This paper has been removed by arXiv adminis...</td>      <td>gr-qc</td>      <td>This submission has been withdrawn by arXiv ad...</td>      <td>0704.0525</td>    </tr>    <tr>      <th>4</th>      <td>The most massive elliptical galaxies show a ...</td>      <td>astro-ph</td>      <td>32 pages (referee format), 9 figures, ApJ acce...</td>      <td>0704.0535</td>    </tr>  </tbody></table><p>对pages进行抽取：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 使用正则表达式匹配，XX pages</span></span><br><span class="line">data[<span class="string">'pages'</span>] = data[<span class="string">'comments'</span>].apply(<span class="keyword">lambda</span> x: re.findall(<span class="string">'[1-9][0-9]* pages'</span>, str(x)))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 筛选出有pages的论文</span></span><br><span class="line">data = data[data[<span class="string">'pages'</span>].apply(len) &gt; <span class="number">0</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 由于匹配得到的是一个list，如['19 pages']，需要进行转换</span></span><br><span class="line">data[<span class="string">'pages'</span>] = data[<span class="string">'pages'</span>].apply(<span class="keyword">lambda</span> x: float(x[<span class="number">0</span>].replace(<span class="string">' pages'</span>, <span class="string">''</span>)))</span><br></pre></td></tr></table></figure><p>对pages进行统计，统计结果如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">data[<span class="string">'pages'</span>].describe().astype(int)</span><br></pre></td></tr></table></figure><pre><code>count    80696mean        18std         20min          125%          950%         1475%         24max       1958Name: pages, dtype: int32</code></pre><p>接下来按照分类统计论文页数，选取了论文的第一个类别的主要类别：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 选择主要类别</span></span><br><span class="line">data[<span class="string">'categories'</span>] = data[<span class="string">'categories'</span>].apply(<span class="keyword">lambda</span> x: x.split(<span class="string">' '</span>)[<span class="number">0</span>])</span><br><span class="line">data[<span class="string">'categories'</span>] = data[<span class="string">'categories'</span>].apply(<span class="keyword">lambda</span> x: x.split(<span class="string">'.'</span>)[<span class="number">0</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 每类论文的平均页数</span></span><br><span class="line">plt.figure(figsize=(<span class="number">12</span>, <span class="number">6</span>))</span><br><span class="line">data.groupby([<span class="string">'categories'</span>])[<span class="string">'pages'</span>].mean().plot(kind=<span class="string">'bar'</span>)</span><br></pre></td></tr></table></figure><pre><code>&lt;matplotlib.axes._subplots.AxesSubplot at 0x1e7dc314748&gt;</code></pre><p><img src="/articles/Task3/output_11_1.png" alt="png"></p><p>接下来对论文图表个数进行抽取：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">data[<span class="string">'figures'</span>] = data[<span class="string">'comments'</span>].apply(<span class="keyword">lambda</span> x: re.findall(<span class="string">'[1-9][0-9]* figures'</span>, str(x)))</span><br><span class="line">data = data[data[<span class="string">'figures'</span>].apply(len) &gt; <span class="number">0</span>]</span><br><span class="line">data[<span class="string">'figures'</span>] = data[<span class="string">'figures'</span>].apply(<span class="keyword">lambda</span> x: float(x[<span class="number">0</span>].replace(<span class="string">' figures'</span>, <span class="string">''</span>)))</span><br></pre></td></tr></table></figure><p>最后我们对论文的代码链接进行提取，为了简化任务我们只抽取github链接：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 筛选包含github的论文</span></span><br><span class="line">data_with_code = data[(data.comments.str.contains(<span class="string">'github'</span>) == <span class="literal">True</span>) |</span><br><span class="line">                      (data.abstract.str.contains(<span class="string">'github'</span>) == <span class="literal">True</span>)]</span><br><span class="line">data_with_code[<span class="string">'text'</span>] = data_with_code[<span class="string">'abstract'</span>].fillna(</span><br><span class="line">    <span class="string">''</span>) + data_with_code[<span class="string">'comments'</span>].fillna(<span class="string">''</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 使用正则表达式匹配论文</span></span><br><span class="line">pattern = <span class="string">'[a-zA-z]+://github[^\s]*'</span></span><br><span class="line">data_with_code[<span class="string">'code_flag'</span>] = data_with_code[<span class="string">'text'</span>].str.findall(</span><br><span class="line">    pattern).apply(len)</span><br></pre></td></tr></table></figure><p>并对论文按照类别进行绘图：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">data_with_code = data_with_code[data_with_code[<span class="string">'code_flag'</span>] == <span class="number">1</span>]</span><br><span class="line">plt.figure(figsize=(<span class="number">12</span>, <span class="number">6</span>))</span><br><span class="line">data_with_code.groupby([<span class="string">'categories'</span>])[<span class="string">'code_flag'</span>].count().plot(kind=<span class="string">'bar'</span>)</span><br></pre></td></tr></table></figure><pre><code>&lt;matplotlib.axes._subplots.AxesSubplot at 0x1e710f15ef0&gt;</code></pre><p><img src="/articles/Task3/output_17_1.png" alt="png"></p></div>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;任务说明&quot;&gt;&lt;a href=&quot;#任务说明&quot; class=&quot;headerlink&quot; title=&quot;任务说明&quot;&gt;&lt;/a&gt;任务说明&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;任务主题：论文代码统计，统计所有论文出现代码的相关统计；&lt;/li&gt;
&lt;li&gt;任务内容：使用正则表达式统计代码连接
      
    
    </summary>
    
    
    
      <category term="data analysis" scheme="https://hahally.github.io/tags/data-analysis/"/>
    
  </entry>
  
  <entry>
    <title>Task2</title>
    <link href="https://hahally.github.io/articles/Task2/"/>
    <id>https://hahally.github.io/articles/Task2/</id>
    <published>2021-01-16T06:41:28.000Z</published>
    <updated>2021-01-16T07:02:35.093Z</updated>
    
    <content type="html"><![CDATA[<h2 id="任务说明"><a href="#任务说明" class="headerlink" title="任务说明"></a>任务说明</h2><ul><li>任务主题：论文作者统计，统计所有论文作者出现评率Top10的姓名；</li><li>任务内容：论文作者的统计、使用 <strong>Pandas</strong> 读取数据并使用字符串操作；</li><li>任务成果：学习 <strong>Pandas</strong> 的字符串操作；</li></ul><h2 id="数据处理步骤"><a href="#数据处理步骤" class="headerlink" title="数据处理步骤"></a>数据处理步骤</h2><p>在原始arxiv数据集中论文作者<code>authors</code>字段是一个字符串格式，其中每个作者使用逗号进行分隔分，所以我们我们首先需要完成以下步骤：</p><ul><li>使用逗号对作者进行切分；</li><li>剔除单个作者中非常规的字符；</li></ul><p>具体操作可以参考以下例子：</p><figure class="highlight mipsasm"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">C. <span class="keyword">Bal\\'azs, </span>E. L. <span class="keyword">Berger, </span>P. M. Nadolsky, C.-P. Yuan</span><br><span class="line"></span><br><span class="line"><span class="comment"># 切分为，其中\\为转义符</span></span><br><span class="line"></span><br><span class="line">C. <span class="keyword">Ba'lazs</span></span><br><span class="line"><span class="keyword">E. </span>L. <span class="keyword">Berger</span></span><br><span class="line"><span class="keyword">P. </span>M. Nadolsky</span><br><span class="line">C.-P. Yuan</span><br></pre></td></tr></table></figure><h2 id="字符串处理"><a href="#字符串处理" class="headerlink" title="字符串处理"></a>字符串处理</h2><p>在Python中字符串是最常用的数据类型，可以使用引号(‘或”)来创建字符串。Python中所有的字符都使用字符串存储，可以使用方括号来截取字符串，如下实例：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">var1 = <span class="string">'Hello Datawhale!'</span></span><br><span class="line">var2 = <span class="string">"Python Everwhere!"</span></span><br><span class="line"> </span><br><span class="line">print(<span class="string">"var1[-10:]: "</span>, var1[<span class="number">-10</span>:])</span><br><span class="line">print(<span class="string">"var2[1:5]: "</span>, var2[<span class="number">0</span>:<span class="number">7</span>])</span><br></pre></td></tr></table></figure><pre><code>var1[-10:]:  Datawhale!var2[1:5]:  Python </code></pre><p>同时在Python中还支持转义符：</p><div class="table-container"><table><thead><tr><th>(在行尾时)</th><th>续行符</th></tr></thead><tbody><tr><td>\\</td><td>反斜杠符号</td></tr><tr><td>\’</td><td>单引号</td></tr><tr><td>\”</td><td>双引号</td></tr><tr><td>\n</td><td>换行</td></tr><tr><td>\t</td><td>横向制表符</td></tr><tr><td>\r</td><td>回车</td></tr></tbody></table></div><p>Python中还内置了很多内置函数，非常方便使用：</p><div class="table-container"><table><thead><tr><th style="text-align:left"><strong>方法</strong></th><th style="text-align:left"><strong>描述</strong></th></tr></thead><tbody><tr><td style="text-align:left">string.capitalize()</td><td style="text-align:left">把字符串的第一个字符大写</td></tr><tr><td style="text-align:left">string.isalpha()</td><td style="text-align:left">如果 string 至少有一个字符并且所有字符都是字母则返回 True,否则返回 False</td></tr><tr><td style="text-align:left">string.title()</td><td style="text-align:left">返回”标题化”的 string,就是说所有单词都是以大写开始，其余字母均为小写(见 istitle())</td></tr><tr><td style="text-align:left">string.upper()</td><td style="text-align:left">转换 string 中的小写字母为大写</td></tr></tbody></table></div><h2 id="具体代码实现以及讲解"><a href="#具体代码实现以及讲解" class="headerlink" title="具体代码实现以及讲解"></a>具体代码实现以及讲解</h2><h3 id="数据读取"><a href="#数据读取" class="headerlink" title="数据读取"></a>数据读取</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 导入所需的package</span></span><br><span class="line"><span class="keyword">import</span> seaborn <span class="keyword">as</span> sns <span class="comment">#用于画图</span></span><br><span class="line"><span class="keyword">from</span> bs4 <span class="keyword">import</span> BeautifulSoup <span class="comment">#用于爬取arxiv的数据</span></span><br><span class="line"><span class="keyword">import</span> re <span class="comment">#用于正则表达式，匹配字符串的模式</span></span><br><span class="line"><span class="keyword">import</span> requests <span class="comment">#用于网络连接，发送网络请求，使用域名获取对应信息</span></span><br><span class="line"><span class="keyword">import</span> json <span class="comment">#读取数据，我们的数据为json格式的</span></span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd <span class="comment">#数据处理，数据分析</span></span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt <span class="comment">#画图工具</span></span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">readArxivFile</span><span class="params">(path, columns=[<span class="string">'id'</span>, <span class="string">'submitter'</span>, <span class="string">'authors'</span>, <span class="string">'title'</span>, <span class="string">'comments'</span>, <span class="string">'journal-ref'</span>, <span class="string">'doi'</span>,</span></span></span><br><span class="line"><span class="function"><span class="params">       <span class="string">'report-no'</span>, <span class="string">'categories'</span>, <span class="string">'license'</span>, <span class="string">'abstract'</span>, <span class="string">'versions'</span>,</span></span></span><br><span class="line"><span class="function"><span class="params">       <span class="string">'update_date'</span>, <span class="string">'authors_parsed'</span>], count=None)</span>:</span></span><br><span class="line">    <span class="string">'''</span></span><br><span class="line"><span class="string">    定义读取文件的函数</span></span><br><span class="line"><span class="string">        path: 文件路径</span></span><br><span class="line"><span class="string">        columns: 需要选择的列</span></span><br><span class="line"><span class="string">        count: 读取行数</span></span><br><span class="line"><span class="string">    '''</span></span><br><span class="line">    </span><br><span class="line">    data  = []</span><br><span class="line">    <span class="keyword">with</span> open(path, <span class="string">'r'</span>) <span class="keyword">as</span> f: </span><br><span class="line">        <span class="keyword">for</span> idx, line <span class="keyword">in</span> enumerate(f): </span><br><span class="line">            <span class="keyword">if</span> idx == count:</span><br><span class="line">                <span class="keyword">break</span></span><br><span class="line">                </span><br><span class="line">            d = json.loads(line)</span><br><span class="line">            d = &#123;col : d[col] <span class="keyword">for</span> col <span class="keyword">in</span> columns&#125;</span><br><span class="line">            data.append(d)</span><br><span class="line"></span><br><span class="line">    data = pd.DataFrame(data)</span><br><span class="line">    <span class="keyword">return</span> data</span><br><span class="line"></span><br><span class="line">data = readArxivFile(<span class="string">'arxiv-metadata-oai-snapshot.json'</span>, </span><br><span class="line">                     [<span class="string">'id'</span>, <span class="string">'authors'</span>, <span class="string">'categories'</span>, <span class="string">'authors_parsed'</span>],</span><br><span class="line">                    <span class="number">100000</span>)</span><br></pre></td></tr></table></figure><h3 id="数据统计"><a href="#数据统计" class="headerlink" title="数据统计"></a>数据统计</h3><p>接下来我们将完成以下统计操作：</p><ul><li>统计所有作者姓名出现频率的Top10；</li><li>统计所有作者姓（姓名最后一个单词）的出现频率的Top10；</li><li>统计所有作者姓第一个字符的评率；</li></ul><p>为了节约计算时间，下面选择部分类别下的论文进行处理：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 选择类别为cs.CV下面的论文</span></span><br><span class="line">data2 = data[data[<span class="string">'categories'</span>].apply(<span class="keyword">lambda</span> x: <span class="string">'cs.CV'</span> <span class="keyword">in</span> x)]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 拼接所有作者</span></span><br><span class="line">all_authors = sum(data2[<span class="string">'authors_parsed'</span>], [])</span><br></pre></td></tr></table></figure><p>处理完成后<code>all_authors</code>变成了所有一个list，其中每个元素为一个作者的姓名。我们首先来完成姓名频率的统计。</p><p>join() 函数</p><figure class="highlight armasm"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="symbol">Docstring</span>:</span><br><span class="line"><span class="symbol">S.join</span>(<span class="keyword">iterable) </span>-&gt; <span class="keyword">str</span></span><br><span class="line"><span class="keyword"></span></span><br><span class="line"><span class="keyword">Return </span>a <span class="keyword">string </span>which is the concatenation of the <span class="keyword">strings </span>in the</span><br><span class="line"><span class="keyword">iterable. </span> The separator <span class="keyword">between </span>elements is S.</span><br></pre></td></tr></table></figure><p><code>iterable</code> : 为可迭代对象</p><p>返回以 S 为分割符的拼接字符串</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 拼接所有的作者</span></span><br><span class="line">authors_names = [<span class="string">' '</span>.join(x) <span class="keyword">for</span> x <span class="keyword">in</span> all_authors]</span><br><span class="line">authors_names = pd.DataFrame(authors_names)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 根据作者频率绘制直方图</span></span><br><span class="line">plt.figure(figsize=(<span class="number">10</span>, <span class="number">6</span>))</span><br><span class="line">authors_names[<span class="number">0</span>].value_counts().head(<span class="number">10</span>).plot(kind=<span class="string">'barh'</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 修改图配置</span></span><br><span class="line">names = authors_names[<span class="number">0</span>].value_counts().index.values[:<span class="number">10</span>]</span><br><span class="line">_ = plt.yticks(range(<span class="number">0</span>, len(names)), names)</span><br><span class="line">plt.ylabel(<span class="string">'Author'</span>)</span><br><span class="line">plt.xlabel(<span class="string">'Count'</span>)</span><br></pre></td></tr></table></figure><pre><code>Text(0.5,0,&#39;Count&#39;)</code></pre><p><img src="/articles/Task2/output_14_1.png" alt="png"></p><p>接下来统计姓名姓，也就是<code>authors_parsed</code>字段中作者第一个单词：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">authors_lastnames = [x[<span class="number">0</span>] <span class="keyword">for</span> x <span class="keyword">in</span> all_authors]</span><br><span class="line">authors_lastnames = pd.DataFrame(authors_lastnames)</span><br><span class="line"></span><br><span class="line">plt.figure(figsize=(<span class="number">10</span>, <span class="number">6</span>))</span><br><span class="line">authors_lastnames[<span class="number">0</span>].value_counts().head(<span class="number">10</span>).plot(kind=<span class="string">'barh'</span>)</span><br><span class="line"></span><br><span class="line">names = authors_lastnames[<span class="number">0</span>].value_counts().index.values[:<span class="number">10</span>]</span><br><span class="line">_ = plt.yticks(range(<span class="number">0</span>, len(names)), names)</span><br><span class="line">plt.ylabel(<span class="string">'Author'</span>)</span><br><span class="line">plt.xlabel(<span class="string">'Count'</span>)</span><br></pre></td></tr></table></figure><pre><code>Text(0.5,0,&#39;Count&#39;)</code></pre><p><img src="/articles/Task2/output_16_1.png" alt="png"></p><p>绘制得到的结果，从结果看出这些都是华人或者中国姓氏~</p><p>统计所有作者姓第一个字符的评率，这个流程与上述的类似</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">authors_first = [x[<span class="number">0</span>][<span class="number">0</span>] <span class="keyword">for</span> x <span class="keyword">in</span> all_authors]</span><br><span class="line">authors_first = pd.DataFrame(authors_firs)</span><br><span class="line"></span><br><span class="line">plt.figure(figsize=(<span class="number">10</span>, <span class="number">6</span>))</span><br><span class="line">authors_first[<span class="number">0</span>].value_counts().head(<span class="number">10</span>).plot(kind=<span class="string">'barsh'</span>)</span><br><span class="line"></span><br><span class="line">s = authors_first[<span class="number">0</span>].value_counts().indesx.values[:<span class="number">10</span>]</span><br><span class="line">_ = plt.yticks(range(<span class="number">0</span>, len(s)), s)</span><br><span class="line">plt.ylabel(<span class="string">'Author'</span>)</span><br><span class="line">plt.xlabel(<span class="string">'Count'</span>)</span><br></pre></td></tr></table></figure><pre><code>Text(0.5,0,&#39;Count&#39;)</code></pre><p><img src="/articles/Task2/output_18_1.png" alt="png"></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;任务说明&quot;&gt;&lt;a href=&quot;#任务说明&quot; class=&quot;headerlink&quot; title=&quot;任务说明&quot;&gt;&lt;/a&gt;任务说明&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;任务主题：论文作者统计，统计所有论文作者出现评率Top10的姓名；&lt;/li&gt;
&lt;li&gt;任务内容：论文作者的统计、
      
    
    </summary>
    
    
    
      <category term="data analysis" scheme="https://hahally.github.io/tags/data-analysis/"/>
    
  </entry>
  
  <entry>
    <title>Task1</title>
    <link href="https://hahally.github.io/articles/Task1/"/>
    <id>https://hahally.github.io/articles/Task1/</id>
    <published>2021-01-10T15:26:15.000Z</published>
    <updated>2021-01-10T15:40:21.571Z</updated>
    
    <content type="html"><![CDATA[<h2 id="任务说明"><a href="#任务说明" class="headerlink" title="任务说明"></a>任务说明</h2><ul><li>任务主题：论文数量统计，即统计2019年全年计算机各个方向论文数量；</li><li>任务内容：赛题的理解、使用 <strong>Pandas</strong> 读取数据并进行统计；</li><li>任务成果：学习 <strong>Pandas</strong> 的基础操作；</li><li>可参考的学习资料：<a href="https://github.com/datawhalechina/joyful-pandas" target="_blank" rel="noopener">开源组织Datawhale joyful-pandas项目</a></li></ul><h2 id="数据集介绍"><a href="#数据集介绍" class="headerlink" title="数据集介绍"></a>数据集介绍</h2><ul><li>数据集来源：<a href="https://www.kaggle.com/Cornell-University/arxiv" target="_blank" rel="noopener">数据集链接</a>；</li><li>数据集的格式如下：<ul><li><code>id</code>：arXiv ID，可用于访问论文；</li><li><code>submitter</code>：论文提交者；</li><li><code>authors</code>：论文作者；</li><li><code>title</code>：论文标题；</li><li><code>comments</code>：论文页数和图表等其他信息；</li><li><code>journal-ref</code>：论文发表的期刊的信息；</li><li><code>doi</code>：数字对象标识符，<a href="https://www.doi.org" target="_blank" rel="noopener">https://www.doi.org</a>；</li><li><code>report-no</code>：报告编号；</li><li><code>categories</code>：论文在 arXiv 系统的所属类别或标签；</li><li><code>license</code>：文章的许可证；</li><li><code>abstract</code>：论文摘要；</li><li><code>versions</code>：论文版本；</li><li><code>authors_parsed</code>：作者的信息。</li><li><code>update_date</code>：更新时间</li></ul></li></ul><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">"root"</span>:&#123;</span><br><span class="line"><span class="string">"id"</span>:<span class="built_in">string</span><span class="string">"0704.0001"</span></span><br><span class="line"><span class="string">"submitter"</span>:<span class="built_in">string</span><span class="string">"Pavel Nadolsky"</span></span><br><span class="line"><span class="string">"authors"</span>:<span class="built_in">string</span><span class="string">"C. Bal\'azs, E. L. Berger, P. M. Nadolsky, C.-P. Yuan"</span></span><br><span class="line"><span class="string">"title"</span>:<span class="built_in">string</span><span class="string">"Calculation of prompt diphoton production cross sections at Tevatron and LHC energies"</span></span><br><span class="line"><span class="string">"comments"</span>:<span class="built_in">string</span><span class="string">"37 pages, 15 figures; published version"</span></span><br><span class="line"><span class="string">"journal-ref"</span>:<span class="built_in">string</span><span class="string">"Phys.Rev.D76:013009,2007"</span></span><br><span class="line"><span class="string">"doi"</span>:<span class="built_in">string</span><span class="string">"10.1103/PhysRevD.76.013009"</span></span><br><span class="line"><span class="string">"report-no"</span>:<span class="built_in">string</span><span class="string">"ANL-HEP-PR-07-12"</span></span><br><span class="line"><span class="string">"categories"</span>:<span class="built_in">string</span><span class="string">"hep-ph"</span></span><br><span class="line"><span class="string">"license"</span>:<span class="literal">NULL</span></span><br><span class="line"><span class="string">"abstract"</span>:<span class="built_in">string</span><span class="string">"  A fully differential calculation in perturbative quantum chromodynamics is presented for the production of massive photon pairs at hadron colliders. All next-to-leading order perturbative contributions from quark-antiquark, gluon-(anti)quark, and gluon-gluon subprocesses are included, as well as all-orders resummation of initial-state gluon radiation valid at next-to-next-to leading logarithmic accuracy. The region of phase space is specified in which the calculation is most reliable. Good agreement is demonstrated with data from the Fermilab Tevatron, and predictions are made for more detailed tests with CDF and DO data. Predictions are shown for distributions of diphoton pairs produced at the energy of the Large Hadron Collider (LHC). Distributions of the diphoton pairs from the decay of a Higgs boson are contrasted with those produced from QCD processes at the LHC, showing that enhanced sensitivity to the signal can be obtained with judicious selection of events."</span></span><br><span class="line"><span class="string">"versions"</span>:[</span><br><span class="line"><span class="number">0</span>:&#123;</span><br><span class="line"><span class="string">"version"</span>:<span class="built_in">string</span><span class="string">"v1"</span></span><br><span class="line"><span class="string">"created"</span>:<span class="built_in">string</span><span class="string">"Mon, 2 Apr 2007 19:18:42 GMT"</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="number">1</span>:&#123;</span><br><span class="line"><span class="string">"version"</span>:<span class="built_in">string</span><span class="string">"v2"</span></span><br><span class="line"><span class="string">"created"</span>:<span class="built_in">string</span><span class="string">"Tue, 24 Jul 2007 20:10:27 GMT"</span></span><br><span class="line">&#125;]</span><br><span class="line"><span class="string">"update_date"</span>:<span class="built_in">string</span><span class="string">"2008-11-26"</span></span><br><span class="line"><span class="string">"authors_parsed"</span>:[</span><br><span class="line"><span class="number">0</span>:[</span><br><span class="line"><span class="number">0</span>:<span class="built_in">string</span><span class="string">"Balázs"</span></span><br><span class="line"><span class="number">1</span>:<span class="built_in">string</span><span class="string">"C."</span></span><br><span class="line"><span class="number">2</span>:<span class="built_in">string</span><span class="string">""</span>]</span><br><span class="line"><span class="number">1</span>:[</span><br><span class="line"><span class="number">0</span>:<span class="built_in">string</span><span class="string">"Berger"</span></span><br><span class="line"><span class="number">1</span>:<span class="built_in">string</span><span class="string">"E. L."</span></span><br><span class="line"><span class="number">2</span>:<span class="built_in">string</span><span class="string">""</span>]</span><br><span class="line"><span class="number">2</span>:[</span><br><span class="line"><span class="number">0</span>:<span class="built_in">string</span><span class="string">"Nadolsky"</span></span><br><span class="line"><span class="number">1</span>:<span class="built_in">string</span><span class="string">"P. M."</span></span><br><span class="line"><span class="number">2</span>:<span class="built_in">string</span><span class="string">""</span>]</span><br><span class="line"><span class="number">3</span>:[</span><br><span class="line"><span class="number">0</span>:<span class="built_in">string</span><span class="string">"Yuan"</span></span><br><span class="line"><span class="number">1</span>:<span class="built_in">string</span><span class="string">"C. -P."</span></span><br><span class="line"><span class="number">2</span>:<span class="built_in">string</span><span class="string">""</span>]]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="arxiv论文类别介绍"><a href="#arxiv论文类别介绍" class="headerlink" title="arxiv论文类别介绍"></a>arxiv论文类别介绍</h2><p>我们从arxiv官网，查询到论文的类别名称以及其解释如下。</p><p>链接：<a href="https://arxiv.org/help/api/user-manual" target="_blank" rel="noopener">https://arxiv.org/help/api/user-manual</a>  的 5.3 小节的 Subject Classifications 的部分，或 <a href="https://arxiv.org/category_taxonomy" target="_blank" rel="noopener">https://arxiv.org/category_taxonomy</a>， 具体的153种paper的类别部分如下：</p><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">'astro-ph': 'Astrophysics',</span><br><span class="line">'astro-ph.CO': 'Cosmology and Nongalactic Astrophysics',</span><br><span class="line">'astro-ph.EP': 'Earth and Planetary Astrophysics',</span><br><span class="line">'astro-ph.GA': 'Astrophysics of Galaxies',</span><br><span class="line">'cs.AI': 'Artificial Intelligence',</span><br><span class="line">'cs.AR': 'Hardware Architecture',</span><br><span class="line">'cs.CC': 'Computational Complexity',</span><br><span class="line">'cs.CE': 'Computational Engineering, Finance, and Science',</span><br><span class="line">'cs.CV': 'Computer Vision and Pattern Recognition',</span><br><span class="line">'cs.CY': 'Computers and Society',</span><br><span class="line">'cs.DB': 'Databases',</span><br><span class="line">'cs.DC': 'Distributed, Parallel, and Cluster Computing',</span><br><span class="line">'cs.DL': 'Digital Libraries',</span><br><span class="line">'cs.NA': 'Numerical Analysis',</span><br><span class="line">'cs.NE': 'Neural and Evolutionary Computing',</span><br><span class="line">'cs.NI': 'Networking and Internet Architecture',</span><br><span class="line">'cs.OH': 'Other Computer Science',</span><br><span class="line">'cs.OS': 'Operating Systems',</span><br></pre></td></tr></table></figure><h2 id="具体代码实现以及讲解"><a href="#具体代码实现以及讲解" class="headerlink" title="具体代码实现以及讲解"></a>具体代码实现以及讲解</h2><h3 id="使用pyspark-处理数据"><a href="#使用pyspark-处理数据" class="headerlink" title="使用pyspark 处理数据"></a>使用pyspark 处理数据</h3><p>脆皮电脑扛不住这么大的内存消耗，所以选择先使用 pyspark 进行初步处理，因为之前用过</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> pyspark <span class="keyword">import</span> SparkContext,SparkConf</span><br><span class="line"><span class="keyword">from</span> pyspark.sql <span class="keyword">import</span> SparkSession</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 必要的配置</span></span><br><span class="line">conf = SparkConf().setMaster(<span class="string">"local"</span>).setAppName(<span class="string">"dataframe"</span>).set(</span><br><span class="line">    <span class="string">'spark.local.dir'</span>, <span class="string">'E:\SparkTemp'</span>)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 初始化一个spark对象</span></span><br><span class="line">spark = SparkSession.builder.appName(<span class="string">'my_first_app_name'</span>).config(</span><br><span class="line">    conf=conf).getOrCreate()</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 读取 2.69 GB大小的json数据</span></span><br><span class="line">json_data = spark.read.json(<span class="string">'./arxiv-metadata-oai-snapshot.json'</span>)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 查看列名,14 个item</span></span><br><span class="line">json_data.columns</span><br></pre></td></tr></table></figure><pre><code>[&#39;abstract&#39;, &#39;authors&#39;, &#39;authors_parsed&#39;, &#39;categories&#39;, &#39;comments&#39;, &#39;doi&#39;, &#39;id&#39;, &#39;journal-ref&#39;, &#39;license&#39;, &#39;report-no&#39;, &#39;submitter&#39;, &#39;title&#39;, &#39;update_date&#39;, &#39;versions&#39;]</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 显示 行数 和 列数</span></span><br><span class="line">json_data.count(), len(json_data.columns)</span><br></pre></td></tr></table></figure><pre><code>(1796911, 14)</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 查看前5行：没有透视表，有点烦人</span></span><br><span class="line">json_data.show(<span class="number">5</span>)</span><br></pre></td></tr></table></figure><pre><code>+--------------------+--------------------+--------------------+---------------+--------------------+--------------------+---------+--------------------+--------------------+----------------+------------------+--------------------+-----------+--------------------+|            abstract|             authors|      authors_parsed|     categories|            comments|                 doi|       id|         journal-ref|             license|       report-no|         submitter|               title|update_date|            versions|+--------------------+--------------------+--------------------+---------------+--------------------+--------------------+---------+--------------------+--------------------+----------------+------------------+--------------------+-----------+--------------------+|  A fully differe...|C. Bal\&#39;azs, E. L...|[[Balázs, C., ], ...|         hep-ph|37 pages, 15 figu...|10.1103/PhysRevD....|0704.0001|Phys.Rev.D76:0130...|                null|ANL-HEP-PR-07-12|    Pavel Nadolsky|Calculation of pr...| 2008-11-26|[[Mon, 2 Apr 2007...||  We describe a n...|Ileana Streinu an...|[[Streinu, Ileana...|  math.CO cs.CG|To appear in Grap...|                null|0704.0002|                null|http://arxiv.org/...|            null|      Louis Theran|Sparsity-certifyi...| 2008-12-13|[[Sat, 31 Mar 200...||  The evolution o...|         Hongjun Pan|  [[Pan, Hongjun, ]]| physics.gen-ph| 23 pages, 3 figures|                null|0704.0003|                null|                null|            null|       Hongjun Pan|The evolution of ...| 2008-01-13|[[Sun, 1 Apr 2007...||  We show that a ...|        David Callan| [[Callan, David, ]]|        math.CO|            11 pages|                null|0704.0004|                null|                null|            null|      David Callan|A determinant of ...| 2007-05-23|[[Sat, 31 Mar 200...||  In this paper w...|Wael Abu-Shammala...|[[Abu-Shammala, W...|math.CA math.FA|                null|                null|0704.0005|Illinois J. Math....|                null|            null|Alberto Torchinsky|From dyadic $\Lam...| 2013-10-15|[[Mon, 2 Apr 2007...|+--------------------+--------------------+--------------------+---------------+--------------------+--------------------+---------+--------------------+--------------------+----------------+------------------+--------------------+-----------+--------------------+only showing top 5 rows</code></pre><p>​    </p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 压缩保存为parquet格式</span></span><br><span class="line">json_data.coalesce(<span class="number">1</span>).write.parquet(<span class="string">'arxiv-metadata-oai-snapshot.parquet'</span>,</span><br><span class="line">                                    mode=<span class="string">'overwrite'</span>)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 选着要处理的三列数据</span></span><br><span class="line">data = json_data.select([<span class="string">'id'</span>, <span class="string">'categories'</span>, <span class="string">'update_date'</span>])</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 查看，默认前 20 行</span></span><br><span class="line">data.show()</span><br></pre></td></tr></table></figure><pre><code>+---------+-----------------+-----------+|       id|       categories|update_date|+---------+-----------------+-----------+|0704.0001|           hep-ph| 2008-11-26||0704.0002|    math.CO cs.CG| 2008-12-13||0704.0003|   physics.gen-ph| 2008-01-13||0704.0004|          math.CO| 2007-05-23||0704.0005|  math.CA math.FA| 2013-10-15||0704.0006|cond-mat.mes-hall| 2015-05-13||0704.0007|            gr-qc| 2008-11-26||0704.0008|cond-mat.mtrl-sci| 2009-02-05||0704.0009|         astro-ph| 2010-03-18||0704.0010|          math.CO| 2007-05-23||0704.0011|  math.NT math.AG| 2008-08-20||0704.0012|          math.NT| 2007-05-23||0704.0013|          math.NT| 2008-05-26||0704.0014|  math.CA math.AT| 2009-09-29||0704.0015|           hep-th| 2009-11-13||0704.0016|           hep-ph| 2008-12-18||0704.0017|         astro-ph| 2009-06-23||0704.0018|           hep-th| 2007-05-23||0704.0019|  math.PR math.AG| 2007-06-23||0704.0020|           hep-ex| 2015-06-30|+---------+-----------------+-----------+only showing top 20 rows</code></pre><p>​    </p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 转成 pandas对象，因为只选择了三列，内存消耗在自己电脑承受范围内</span></span><br><span class="line"><span class="comment"># 所以转成pandas对象，通过内存处理起来要快得多</span></span><br><span class="line">df = data.toPandas()</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">df</span><br></pre></td></tr></table></figure><div><table border="1" class="dataframe">  <thead>    <tr style="text-align: right;">      <th></th>      <th>id</th>      <th>categories</th>      <th>update_date</th>    </tr>  </thead>  <tbody>    <tr>      <th>0</th>      <td>0704.0001</td>      <td>hep-ph</td>      <td>2008-11-26</td>    </tr>    <tr>      <th>1</th>      <td>0704.0002</td>      <td>math.CO cs.CG</td>      <td>2008-12-13</td>    </tr>    <tr>      <th>2</th>      <td>0704.0003</td>      <td>physics.gen-ph</td>      <td>2008-01-13</td>    </tr>    <tr>      <th>3</th>      <td>0704.0004</td>      <td>math.CO</td>      <td>2007-05-23</td>    </tr>    <tr>      <th>4</th>      <td>0704.0005</td>      <td>math.CA math.FA</td>      <td>2013-10-15</td>    </tr>    <tr>      <th>...</th>      <td>...</td>      <td>...</td>      <td>...</td>    </tr>    <tr>      <th>1796906</th>      <td>supr-con/9608008</td>      <td>supr-con cond-mat.supr-con</td>      <td>2009-10-30</td>    </tr>    <tr>      <th>1796907</th>      <td>supr-con/9609001</td>      <td>supr-con cond-mat.supr-con</td>      <td>2016-11-18</td>    </tr>    <tr>      <th>1796908</th>      <td>supr-con/9609002</td>      <td>supr-con cond-mat.supr-con</td>      <td>2009-10-30</td>    </tr>    <tr>      <th>1796909</th>      <td>supr-con/9609003</td>      <td>supr-con cond-mat.supr-con</td>      <td>2009-10-30</td>    </tr>    <tr>      <th>1796910</th>      <td>supr-con/9609004</td>      <td>supr-con cond-mat.supr-con</td>      <td>2009-10-30</td>    </tr>  </tbody></table><p>1796911 rows × 3 columns</p>转成pandas 对象后，就可以方便的按照教程一步一步来了---### 导入package并读取原始数据<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 导入所需的package</span></span><br><span class="line"><span class="keyword">import</span> seaborn <span class="keyword">as</span> sns <span class="comment">#用于画图</span></span><br><span class="line"><span class="keyword">from</span> bs4 <span class="keyword">import</span> BeautifulSoup <span class="comment">#用于爬取arxiv的数据</span></span><br><span class="line"><span class="keyword">import</span> re <span class="comment">#用于正则表达式，匹配字符串的模式</span></span><br><span class="line"><span class="keyword">import</span> requests <span class="comment">#用于网络连接，发送网络请求，使用域名获取对应信息</span></span><br><span class="line"><span class="keyword">import</span> json <span class="comment">#读取数据，我们的数据为json格式的</span></span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd <span class="comment">#数据处理，数据分析</span></span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt <span class="comment">#画图工具</span></span><br></pre></td></tr></table></figure>### 数据预处理首先我们先来粗略统计论文的种类信息：- `count`：一列数据的元素个数；- `unique`：一列数据中元素的种类；- `top`：一列数据中出现频率最高的元素；- `freq`：一列数据中出现频率最高的元素的个数；<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">df[<span class="string">'categories'</span>].describe()</span><br></pre></td></tr></table></figure>    count      1796911    unique       62055    top       astro-ph    freq         86914    Name: categories, dtype: object以上的结果表明：共有1796911个数据，有62055个子类（因为有论文的类别是多个，例如一篇paper的类别是CS.AI & CS.MM和一篇paper的类别是CS.AI & CS.OS属于不同的子类别，这里仅仅是粗略统计），其中最多的种类是astro-ph，即Astrophysics（天体物理学），共出现了86914次。由于部分论文的类别不止一种，所以下面我们判断在本数据集中共出现了多少种独立的数据集。<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">unique_categories = set([i <span class="keyword">for</span> l <span class="keyword">in</span> [x.split(<span class="string">' '</span>) <span class="keyword">for</span> x <span class="keyword">in</span> df[<span class="string">"categories"</span>]] <span class="keyword">for</span> i <span class="keyword">in</span> l])</span><br><span class="line">len(unique_categories),unique_categories</span><br></pre></td></tr></table></figure>    (176,     {'acc-phys',      'adap-org',      'alg-geom',      'ao-sci',      'astro-ph',      'astro-ph.CO',      'astro-ph.EP',      'astro-ph.GA',      'astro-ph.HE',      'astro-ph.IM',      'astro-ph.SR',      'atom-ph',      'bayes-an',      'chao-dyn',      'chem-ph',      'cmp-lg',      'comp-gas',      'cond-mat',      'cond-mat.dis-nn',      'cond-mat.mes-hall',      'cond-mat.mtrl-sci',      'cond-mat.other',      'cond-mat.quant-gas',      'cond-mat.soft',      'cond-mat.stat-mech',      'cond-mat.str-el',      'cond-mat.supr-con',      'cs.AI',      'cs.AR',      'cs.CC',      'cs.CE',      'cs.CG',      'cs.CL',      'cs.CR',      'cs.CV',      'cs.CY',      'cs.DB',      'cs.DC',      'cs.DL',      'cs.DM',      'cs.DS',      'cs.ET',      'cs.FL',      'cs.GL',      'cs.GR',      'cs.GT',      'cs.HC',      'cs.IR',      'cs.IT',      'cs.LG',      'cs.LO',      'cs.MA',      'cs.MM',      'cs.MS',      'cs.NA',      'cs.NE',      'cs.NI',      'cs.OH',      'cs.OS',      'cs.PF',      'cs.PL',      'cs.RO',      'cs.SC',      'cs.SD',      'cs.SE',      'cs.SI',      'cs.SY',      'dg-ga',      'econ.EM',      'econ.GN',      'econ.TH',      'eess.AS',      'eess.IV',      'eess.SP',      'eess.SY',      'funct-an',      'gr-qc',      'hep-ex',      'hep-lat',      'hep-ph',      'hep-th',      'math-ph',      'math.AC',      'math.AG',      'math.AP',      'math.AT',      'math.CA',      'math.CO',      'math.CT',      'math.CV',      'math.DG',      'math.DS',      'math.FA',      'math.GM',      'math.GN',      'math.GR',      'math.GT',      'math.HO',      'math.IT',      'math.KT',      'math.LO',      'math.MG',      'math.MP',      'math.NA',      'math.NT',      'math.OA',      'math.OC',      'math.PR',      'math.QA',      'math.RA',      'math.RT',      'math.SG',      'math.SP',      'math.ST',      'mtrl-th',      'nlin.AO',      'nlin.CD',      'nlin.CG',      'nlin.PS',      'nlin.SI',      'nucl-ex',      'nucl-th',      'patt-sol',      'physics.acc-ph',      'physics.ao-ph',      'physics.app-ph',      'physics.atm-clus',      'physics.atom-ph',      'physics.bio-ph',      'physics.chem-ph',      'physics.class-ph',      'physics.comp-ph',      'physics.data-an',      'physics.ed-ph',      'physics.flu-dyn',      'physics.gen-ph',      'physics.geo-ph',      'physics.hist-ph',      'physics.ins-det',      'physics.med-ph',      'physics.optics',      'physics.plasm-ph',      'physics.pop-ph',      'physics.soc-ph',      'physics.space-ph',      'plasm-ph',      'q-alg',      'q-bio',      'q-bio.BM',      'q-bio.CB',      'q-bio.GN',      'q-bio.MN',      'q-bio.NC',      'q-bio.OT',      'q-bio.PE',      'q-bio.QM',      'q-bio.SC',      'q-bio.TO',      'q-fin.CP',      'q-fin.EC',      'q-fin.GN',      'q-fin.MF',      'q-fin.PM',      'q-fin.PR',      'q-fin.RM',      'q-fin.ST',      'q-fin.TR',      'quant-ph',      'solv-int',      'stat.AP',      'stat.CO',      'stat.ME',      'stat.ML',      'stat.OT',      'stat.TH',      'supr-con'})这里使用了 split 函数将多类别使用 “ ”（空格）分开，组成list，并使用 for 循环将独立出现的类别找出来，并使用 set 类别，将重复项去除得到最终所有的独立paper种类。从以上结果发现，共有176种论文种类，比我们直接从 [https://arxiv.org/help/api/user-manual](https://arxiv.org/help/api/user-manual)  的 5.3 小节的 Subject Classifications 的部分或 [https://arxiv.org/category_taxonomy](https://arxiv.org/category_taxonomy)中的到的类别少，这说明存在一些官网上没有的类别，这是一个小细节。不过对于我们的计算机方向的论文没有影响，依然是以下的40个类别，我们从原数据中提取的和从官网的到的种类是可以一一对应的。我们的任务要求对于2019年以后的paper进行分析，所以首先对于时间特征进行预处理，从而得到2019年以后的所有种类的论文：<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">df[<span class="string">"year"</span>] = pd.to_datetime(df[<span class="string">"update_date"</span>]).dt.year <span class="comment">#将update_date从例如2019-02-20的str变为datetime格式，并提取处year</span></span><br><span class="line"><span class="keyword">del</span> df[<span class="string">"update_date"</span>] <span class="comment">#删除 update_date特征，其使命已完成</span></span><br><span class="line">df = df[df[<span class="string">"year"</span>] &gt;= <span class="number">2019</span>] <span class="comment">#找出 year 中2019年以后的数据，并将其他数据删除</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># data.groupby(['categories','year']) #以 categories 进行排序，如果同一个categories 相同则使用 year 特征进行排序</span></span><br><span class="line">df.reset_index(drop=<span class="literal">True</span>, inplace=<span class="literal">True</span>) <span class="comment">#重新编号</span></span><br><span class="line">df <span class="comment">#查看结果</span></span><br></pre></td></tr></table></figure><div><table border="1" class="dataframe">  <thead>    <tr style="text-align: right;">      <th></th>      <th>id</th>      <th>categories</th>      <th>year</th>    </tr>  </thead>  <tbody>    <tr>      <th>0</th>      <td>0704.0297</td>      <td>astro-ph</td>      <td>2019</td>    </tr>    <tr>      <th>1</th>      <td>0704.0342</td>      <td>math.AT</td>      <td>2019</td>    </tr>    <tr>      <th>2</th>      <td>0704.0360</td>      <td>astro-ph</td>      <td>2019</td>    </tr>    <tr>      <th>3</th>      <td>0704.0525</td>      <td>gr-qc</td>      <td>2019</td>    </tr>    <tr>      <th>4</th>      <td>0704.0535</td>      <td>astro-ph</td>      <td>2019</td>    </tr>    <tr>      <th>...</th>      <td>...</td>      <td>...</td>      <td>...</td>    </tr>    <tr>      <th>395118</th>      <td>quant-ph/9911051</td>      <td>quant-ph</td>      <td>2020</td>    </tr>    <tr>      <th>395119</th>      <td>solv-int/9511005</td>      <td>solv-int nlin.SI</td>      <td>2019</td>    </tr>    <tr>      <th>395120</th>      <td>solv-int/9809008</td>      <td>solv-int nlin.SI</td>      <td>2019</td>    </tr>    <tr>      <th>395121</th>      <td>solv-int/9909010</td>      <td>solv-int adap-org hep-th nlin.AO nlin.SI</td>      <td>2019</td>    </tr>    <tr>      <th>395122</th>      <td>solv-int/9909014</td>      <td>solv-int nlin.SI</td>      <td>2019</td>    </tr>  </tbody></table><p>395123 rows × 3 columns</p>这里我们就已经得到了所有2019年以后的论文，下面我们挑选出计算机领域内的所有文章：<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#爬取所有的类别</span></span><br><span class="line">website_url = requests.get(<span class="string">'https://arxiv.org/category_taxonomy'</span>).text <span class="comment">#获取网页的文本数据</span></span><br><span class="line">soup = BeautifulSoup(website_url,<span class="string">'lxml'</span>) <span class="comment">#爬取数据，这里使用lxml的解析器，加速</span></span><br><span class="line">root = soup.find(<span class="string">'div'</span>,&#123;<span class="string">'id'</span>:<span class="string">'category_taxonomy_list'</span>&#125;) <span class="comment">#找出 BeautifulSoup 对应的标签入口</span></span><br><span class="line">tags = root.find_all([<span class="string">"h2"</span>,<span class="string">"h3"</span>,<span class="string">"h4"</span>,<span class="string">"p"</span>], recursive=<span class="literal">True</span>) <span class="comment">#读取 tags</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#初始化 str 和 list 变量</span></span><br><span class="line">level_1_name = <span class="string">""</span></span><br><span class="line">level_2_name = <span class="string">""</span></span><br><span class="line">level_2_code = <span class="string">""</span></span><br><span class="line">level_1_names = []</span><br><span class="line">level_2_codes = []</span><br><span class="line">level_2_names = []</span><br><span class="line">level_3_codes = []</span><br><span class="line">level_3_names = []</span><br><span class="line">level_3_notes = []</span><br><span class="line"></span><br><span class="line"><span class="comment">#进行</span></span><br><span class="line"><span class="keyword">for</span> t <span class="keyword">in</span> tags:</span><br><span class="line">    <span class="keyword">if</span> t.name == <span class="string">"h2"</span>:</span><br><span class="line">        level_1_name = t.text    </span><br><span class="line">        level_2_code = t.text</span><br><span class="line">        level_2_name = t.text</span><br><span class="line">    <span class="keyword">elif</span> t.name == <span class="string">"h3"</span>:</span><br><span class="line">        raw = t.text</span><br><span class="line">        level_2_code = re.sub(<span class="string">r"(.*)\((.*)\)"</span>,<span class="string">r"\2"</span>,raw) <span class="comment">#正则表达式：模式字符串：(.*)\((.*)\)；被替换字符串"\2"；被处理字符串：raw</span></span><br><span class="line">        level_2_name = re.sub(<span class="string">r"(.*)\((.*)\)"</span>,<span class="string">r"\1"</span>,raw)</span><br><span class="line">    <span class="keyword">elif</span> t.name == <span class="string">"h4"</span>:</span><br><span class="line">        raw = t.text</span><br><span class="line">        level_3_code = re.sub(<span class="string">r"(.*) \((.*)\)"</span>,<span class="string">r"\1"</span>,raw)</span><br><span class="line">        level_3_name = re.sub(<span class="string">r"(.*) \((.*)\)"</span>,<span class="string">r"\2"</span>,raw)</span><br><span class="line">    <span class="keyword">elif</span> t.name == <span class="string">"p"</span>:</span><br><span class="line">        notes = t.text</span><br><span class="line">        level_1_names.append(level_1_name)</span><br><span class="line">        level_2_names.append(level_2_name)</span><br><span class="line">        level_2_codes.append(level_2_code)</span><br><span class="line">        level_3_names.append(level_3_name)</span><br><span class="line">        level_3_codes.append(level_3_code)</span><br><span class="line">        level_3_notes.append(notes)</span><br><span class="line"></span><br><span class="line"><span class="comment">#根据以上信息生成dataframe格式的数据</span></span><br><span class="line">df_taxonomy = pd.DataFrame(&#123;</span><br><span class="line">    <span class="string">'group_name'</span> : level_1_names,</span><br><span class="line">    <span class="string">'archive_name'</span> : level_2_names,</span><br><span class="line">    <span class="string">'archive_id'</span> : level_2_codes,</span><br><span class="line">    <span class="string">'category_name'</span> : level_3_names,</span><br><span class="line">    <span class="string">'categories'</span> : level_3_codes,</span><br><span class="line">    <span class="string">'category_description'</span>: level_3_notes</span><br><span class="line">    </span><br><span class="line">&#125;)</span><br><span class="line"></span><br><span class="line"><span class="comment">#按照 "group_name" 进行分组，在组内使用 "archive_name" 进行排序</span></span><br><span class="line">df_taxonomy.groupby([<span class="string">"group_name"</span>,<span class="string">"archive_name"</span>])</span><br><span class="line">df_taxonomy</span><br></pre></td></tr></table></figure><div><table border="1" class="dataframe">  <thead>    <tr style="text-align: right;">      <th></th>      <th>archive_id</th>      <th>archive_name</th>      <th>categories</th>      <th>category_description</th>      <th>category_name</th>      <th>group_name</th>    </tr>  </thead>  <tbody>    <tr>      <th>0</th>      <td>Computer Science</td>      <td>Computer Science</td>      <td>cs.AI</td>      <td>Covers all areas of AI except Vision, Robotics...</td>      <td>Artificial Intelligence</td>      <td>Computer Science</td>    </tr>    <tr>      <th>1</th>      <td>Computer Science</td>      <td>Computer Science</td>      <td>cs.AR</td>      <td>Covers systems organization and hardware archi...</td>      <td>Hardware Architecture</td>      <td>Computer Science</td>    </tr>    <tr>      <th>2</th>      <td>Computer Science</td>      <td>Computer Science</td>      <td>cs.CC</td>      <td>Covers models of computation, complexity class...</td>      <td>Computational Complexity</td>      <td>Computer Science</td>    </tr>    <tr>      <th>3</th>      <td>Computer Science</td>      <td>Computer Science</td>      <td>cs.CE</td>      <td>Covers applications of computer science to the...</td>      <td>Computational Engineering, Finance, and Science</td>      <td>Computer Science</td>    </tr>    <tr>      <th>4</th>      <td>Computer Science</td>      <td>Computer Science</td>      <td>cs.CG</td>      <td>Roughly includes material in ACM Subject Class...</td>      <td>Computational Geometry</td>      <td>Computer Science</td>    </tr>    <tr>      <th>...</th>      <td>...</td>      <td>...</td>      <td>...</td>      <td>...</td>      <td>...</td>      <td>...</td>    </tr>    <tr>      <th>150</th>      <td>Statistics</td>      <td>Statistics</td>      <td>stat.CO</td>      <td>Algorithms, Simulation, Visualization</td>      <td>Computation</td>      <td>Statistics</td>    </tr>    <tr>      <th>151</th>      <td>Statistics</td>      <td>Statistics</td>      <td>stat.ME</td>      <td>Design, Surveys, Model Selection, Multiple Tes...</td>      <td>Methodology</td>      <td>Statistics</td>    </tr>    <tr>      <th>152</th>      <td>Statistics</td>      <td>Statistics</td>      <td>stat.ML</td>      <td>Covers machine learning papers (supervised, un...</td>      <td>Machine Learning</td>      <td>Statistics</td>    </tr>    <tr>      <th>153</th>      <td>Statistics</td>      <td>Statistics</td>      <td>stat.OT</td>      <td>Work in statistics that does not fit into the ...</td>      <td>Other Statistics</td>      <td>Statistics</td>    </tr>    <tr>      <th>154</th>      <td>Statistics</td>      <td>Statistics</td>      <td>stat.TH</td>      <td>stat.TH is an alias for math.ST. Asymptotics, ...</td>      <td>Statistics Theory</td>      <td>Statistics</td>    </tr>  </tbody></table><p>155 rows × 6 columns</p>这里主要说明一下上面代码中的正则操作，这里我们使用re.sub来用于替换字符串中的匹配项- pattern : 正则中的模式字符串。- repl : 替换的字符串，也可为一个函数。- string : 要被查找替换的原始字符串。- count : 模式匹配后替换的最大次数，默认 0 表示替换所有的匹配。- flags : 编译时用的匹配模式，数字形式。- 其中pattern、repl、string为必选参数re.sub(pattern, repl, string, count=0, flags=0)实例如下：<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> re</span><br><span class="line"></span><br><span class="line">phone = <span class="string">"2004-959-559 # 这是一个电话号码"</span></span><br><span class="line"> </span><br><span class="line"><span class="comment"># 删除注释</span></span><br><span class="line">num = re.sub(<span class="string">r'#.*$'</span>, <span class="string">""</span>, phone)</span><br><span class="line"><span class="keyword">print</span> (<span class="string">"电话号码 : "</span>, num)</span><br><span class="line"> </span><br><span class="line"><span class="comment"># 移除非数字的内容</span></span><br><span class="line">num = re.sub(<span class="string">r'\D'</span>, <span class="string">""</span>, phone)</span><br><span class="line"><span class="keyword">print</span> (<span class="string">"电话号码 : "</span>, num)</span><br></pre></td></tr></table></figure>    电话号码 :  2004-959-559     电话号码 :  2004959559详细了解可以参考：[https://www.runoob.com/python3/python3-reg-expressions.html](https://www.runoob.com/python3/python3-reg-expressions.html)对于我们的代码来说：<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">re.sub(<span class="string">r"(.*)\((.*)\)"</span>,<span class="string">r"\2"</span>, <span class="string">" Astrophysics(astro-ph)"</span>)</span><br></pre></td></tr></table></figure>    'astro-ph'对应的参数- 正则中的模式字符串 pattern 的格式为 “任意字符” + “(” + "任意字符" + ")"。- 替换的字符串 repl 为第2个分组的内容。- 要被查找替换的原始字符串 string 为原始的爬取的数据。这里推荐大家一个在线正则表达式测试的网站：[https://tool.oschina.net/regex/](https://tool.oschina.net/regex/)### 数据分析及可视化接下来我们首先看一下所有大类的paper数量分布：我们使用merge函数，以两个dataframe共同的属性 “categories” 进行合并，并以 “group_name” 作为类别进行统计，统计结果放入 “id” 列中并排序。<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># drop_duplicates去重</span></span><br><span class="line">_df = df.merge(df_taxonomy, on=<span class="string">"categories"</span>, how=<span class="string">"left"</span>).drop_duplicates([<span class="string">"id"</span>,<span class="string">"group_name"</span>]).groupby(<span class="string">"group_name"</span>).agg(&#123;<span class="string">"id"</span>:<span class="string">"count"</span>&#125;).sort_values(by=<span class="string">"id"</span>,ascending=<span class="literal">False</span>).reset_index()</span><br><span class="line"></span><br><span class="line">_df</span><br></pre></td></tr></table></figure><div><table border="1" class="dataframe">  <thead>    <tr style="text-align: right;">      <th></th>      <th>group_name</th>      <th>id</th>    </tr>  </thead>  <tbody>    <tr>      <th>0</th>      <td>Physics</td>      <td>79985</td>    </tr>    <tr>      <th>1</th>      <td>Mathematics</td>      <td>51567</td>    </tr>    <tr>      <th>2</th>      <td>Computer Science</td>      <td>40067</td>    </tr>    <tr>      <th>3</th>      <td>Statistics</td>      <td>4054</td>    </tr>    <tr>      <th>4</th>      <td>Electrical Engineering and Systems Science</td>      <td>3297</td>    </tr>    <tr>      <th>5</th>      <td>Quantitative Biology</td>      <td>1994</td>    </tr>    <tr>      <th>6</th>      <td>Quantitative Finance</td>      <td>826</td>    </tr>    <tr>      <th>7</th>      <td>Economics</td>      <td>576</td>    </tr>  </tbody></table><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 使用饼图进行上图结果的可视化：</span></span><br><span class="line">fig = plt.figure(figsize=(<span class="number">15</span>,<span class="number">12</span>))</span><br><span class="line">explode = (<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0.2</span>, <span class="number">0.3</span>, <span class="number">0.3</span>, <span class="number">0.2</span>, <span class="number">0.1</span>) </span><br><span class="line">plt.pie(_df[<span class="string">"id"</span>],  labels=_df[<span class="string">"group_name"</span>], autopct=<span class="string">'%1.2f%%'</span>, startangle=<span class="number">160</span>, explode=explode)</span><br><span class="line">plt.tight_layout()</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="/articles/Task1/output_39_0.png" alt></p><p>plt.pie参数说明：参考<a href="https://matplotlib.org/api/_as_gen/matplotlib.pyplot.pie.html?highlight=pie#matplotlib.pyplot.pie" target="_blank" rel="noopener">官方文档</a></p><p>下面统计在计算机各个子领域2019年后的paper数量，我们同样使用 merge 函数，对于两个dataframe 共同的特征 categories  进行合并并且进行查询。然后我们再对于数据进行统计和排序从而得到以下的结果：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">group_name = <span class="string">"Computer Science"</span></span><br><span class="line">cats = df.merge(df_taxonomy,</span><br><span class="line">                  on=<span class="string">"categories"</span>).query(<span class="string">"group_name == @group_name"</span>)</span><br><span class="line">cats.groupby([<span class="string">"year"</span>, <span class="string">"category_name"</span></span><br><span class="line">              ]).count().reset_index().pivot(index=<span class="string">"category_name"</span>,</span><br><span class="line">                                             columns=<span class="string">"year"</span>,</span><br><span class="line">                                             values=<span class="string">"id"</span>)</span><br></pre></td></tr></table></figure><div><table border="1" class="dataframe">  <thead>    <tr style="text-align: right;">      <th>year</th>      <th>2019</th>      <th>2020</th>    </tr>    <tr>      <th>category_name</th>      <th></th>      <th></th>    </tr>  </thead>  <tbody>    <tr>      <th>Artificial Intelligence</th>      <td>558</td>      <td>757</td>    </tr>    <tr>      <th>Computation and Language</th>      <td>2153</td>      <td>2906</td>    </tr>    <tr>      <th>Computational Complexity</th>      <td>131</td>      <td>188</td>    </tr>    <tr>      <th>Computational Engineering, Finance, and Science</th>      <td>108</td>      <td>205</td>    </tr>    <tr>      <th>Computational Geometry</th>      <td>199</td>      <td>216</td>    </tr>    <tr>      <th>Computer Science and Game Theory</th>      <td>281</td>      <td>323</td>    </tr>    <tr>      <th>Computer Vision and Pattern Recognition</th>      <td>5559</td>      <td>6517</td>    </tr>    <tr>      <th>Computers and Society</th>      <td>346</td>      <td>564</td>    </tr>    <tr>      <th>Cryptography and Security</th>      <td>1067</td>      <td>1238</td>    </tr>    <tr>      <th>Data Structures and Algorithms</th>      <td>711</td>      <td>902</td>    </tr>    <tr>      <th>Databases</th>      <td>282</td>      <td>342</td>    </tr>    <tr>      <th>Digital Libraries</th>      <td>125</td>      <td>157</td>    </tr>    <tr>      <th>Discrete Mathematics</th>      <td>84</td>      <td>81</td>    </tr>    <tr>      <th>Distributed, Parallel, and Cluster Computing</th>      <td>715</td>      <td>774</td>    </tr>    <tr>      <th>Emerging Technologies</th>      <td>101</td>      <td>84</td>    </tr>    <tr>      <th>Formal Languages and Automata Theory</th>      <td>152</td>      <td>137</td>    </tr>    <tr>      <th>General Literature</th>      <td>5</td>      <td>5</td>    </tr>    <tr>      <th>Graphics</th>      <td>116</td>      <td>151</td>    </tr>    <tr>      <th>Hardware Architecture</th>      <td>95</td>      <td>159</td>    </tr>    <tr>      <th>Human-Computer Interaction</th>      <td>420</td>      <td>580</td>    </tr>    <tr>      <th>Information Retrieval</th>      <td>245</td>      <td>331</td>    </tr>    <tr>      <th>Logic in Computer Science</th>      <td>470</td>      <td>504</td>    </tr>    <tr>      <th>Machine Learning</th>      <td>177</td>      <td>538</td>    </tr>    <tr>      <th>Mathematical Software</th>      <td>27</td>      <td>45</td>    </tr>    <tr>      <th>Multiagent Systems</th>      <td>85</td>      <td>90</td>    </tr>    <tr>      <th>Multimedia</th>      <td>76</td>      <td>66</td>    </tr>    <tr>      <th>Networking and Internet Architecture</th>      <td>864</td>      <td>783</td>    </tr>    <tr>      <th>Neural and Evolutionary Computing</th>      <td>235</td>      <td>279</td>    </tr>    <tr>      <th>Numerical Analysis</th>      <td>40</td>      <td>11</td>    </tr>    <tr>      <th>Operating Systems</th>      <td>36</td>      <td>33</td>    </tr>    <tr>      <th>Other Computer Science</th>      <td>67</td>      <td>69</td>    </tr>    <tr>      <th>Performance</th>      <td>45</td>      <td>51</td>    </tr>    <tr>      <th>Programming Languages</th>      <td>268</td>      <td>294</td>    </tr>    <tr>      <th>Robotics</th>      <td>917</td>      <td>1298</td>    </tr>    <tr>      <th>Social and Information Networks</th>      <td>202</td>      <td>325</td>    </tr>    <tr>      <th>Software Engineering</th>      <td>659</td>      <td>804</td>    </tr>    <tr>      <th>Sound</th>      <td>7</td>      <td>4</td>    </tr>    <tr>      <th>Symbolic Computation</th>      <td>44</td>      <td>36</td>    </tr>    <tr>      <th>Systems and Control</th>      <td>415</td>      <td>133</td>    </tr>  </tbody></table><p>我们可以从结果看出，Computer Vision and Pattern Recognition（计算机视觉与模式识别）类是CS中paper数量最多的子类，遥遥领先于其他的CS子类，并且paper的数量还在逐年增加；另外，Computation and Language（计算与语言）、Cryptography and Security（密码学与安全）以及 Robotics（机器人学）的2019年paper数量均超过1000或接近1000，这与我们的认知是一致的。</p></div></div></div></div></div>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;任务说明&quot;&gt;&lt;a href=&quot;#任务说明&quot; class=&quot;headerlink&quot; title=&quot;任务说明&quot;&gt;&lt;/a&gt;任务说明&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;任务主题：论文数量统计，即统计2019年全年计算机各个方向论文数量；&lt;/li&gt;
&lt;li&gt;任务内容：赛题的理解、使
      
    
    </summary>
    
    
    
      <category term="data analysis" scheme="https://hahally.github.io/tags/data-analysis/"/>
    
  </entry>
  
  <entry>
    <title>Algorithm</title>
    <link href="https://hahally.github.io/articles/Algorithm/"/>
    <id>https://hahally.github.io/articles/Algorithm/</id>
    <published>2020-12-09T04:22:13.000Z</published>
    <updated>2020-12-09T04:33:46.216Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>2015年  题3</p></blockquote><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span><span class="meta-string">&lt;stdio.h&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> ElemType int</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// 调整大根堆</span></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">HeapAjust</span><span class="params">(ElemType A[], <span class="keyword">int</span> k, <span class="keyword">int</span> len)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">int</span> i;</span><br><span class="line">    A[<span class="number">0</span>] = A[k];</span><br><span class="line">    <span class="keyword">for</span>(i=<span class="number">2</span>*k;i&lt;=len;i*=<span class="number">2</span>)&#123;</span><br><span class="line">        <span class="keyword">if</span>(i&lt;len&amp;&amp;A[i]&lt;A[i+<span class="number">1</span>]) i++;</span><br><span class="line">        <span class="keyword">if</span>(A[<span class="number">0</span>]&gt;=A[i]) <span class="keyword">break</span>;</span><br><span class="line">        <span class="keyword">else</span>&#123;</span><br><span class="line">            A[k] = A[i];</span><br><span class="line">            k = i;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    A[k] = A[<span class="number">0</span>];</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 建立大根堆</span></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">BuildMaxHeap</span><span class="params">(ElemType A[], <span class="keyword">int</span> len)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">int</span> i = len/<span class="number">2</span>;</span><br><span class="line">    <span class="keyword">for</span>(;i&gt;<span class="number">0</span>;i--)&#123;</span><br><span class="line">        HeapAjust(A,i,len);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">// 堆排序</span></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">HeapSort</span><span class="params">(ElemType A[],<span class="keyword">int</span> len,<span class="keyword">int</span> n)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">int</span> i;</span><br><span class="line">    <span class="keyword">int</span> topn = <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line">    ElemType temp;</span><br><span class="line">    BuildMaxHeap(A,len);</span><br><span class="line">    <span class="keyword">for</span>(i = len;i&gt;=<span class="number">1</span>;i--)&#123;</span><br><span class="line">        <span class="comment">// Swap(A[i],A[1]);</span></span><br><span class="line">        topn++;</span><br><span class="line">        <span class="keyword">if</span>(topn&lt;=n) <span class="built_in">printf</span>(<span class="string">"%d\t"</span>,A[<span class="number">1</span>]);</span><br><span class="line"></span><br><span class="line">        temp = A[i];</span><br><span class="line">        A[i] = A[<span class="number">1</span>];</span><br><span class="line">        A[<span class="number">1</span>] = temp;</span><br><span class="line"></span><br><span class="line">        HeapAjust(A,<span class="number">1</span>,i<span class="number">-1</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">int</span> len = <span class="number">10</span>;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// A[0] 存储长度</span></span><br><span class="line">    ElemType A[] = &#123;<span class="number">10</span>,<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>,<span class="number">6</span>,<span class="number">7</span>,<span class="number">8</span>,<span class="number">9</span>,<span class="number">10</span>&#125;;</span><br><span class="line">    HeapSort(A,len,<span class="number">5</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><blockquote><p>2015年 题1</p></blockquote><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span><span class="meta-string">&lt;stdio.h&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> MaxSize 50</span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> ElemType int</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">typedef</span> <span class="class"><span class="keyword">struct</span>&#123;</span></span><br><span class="line">    ElemType data[MaxSize];</span><br><span class="line">    <span class="keyword">int</span> top;</span><br><span class="line">&#125;SqStack;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 初始化</span></span><br><span class="line"><span class="function">SqStack <span class="title">InitStack</span><span class="params">(SqStack s)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    s.top = <span class="number">-1</span>;</span><br><span class="line">    <span class="keyword">return</span> s;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 判栈空</span></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">IsEmptyStack</span><span class="params">(SqStack s)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (s.top == <span class="number">-1</span>) <span class="keyword">return</span> <span class="number">1</span>;</span><br><span class="line">    <span class="keyword">else</span> <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 进栈</span></span><br><span class="line"><span class="function">SqStack <span class="title">Push</span><span class="params">(SqStack s, ElemType e)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (s.top == MaxSize - <span class="number">1</span>);</span><br><span class="line">    <span class="keyword">else</span> s.data[++s.top] = e;</span><br><span class="line">    <span class="keyword">return</span> s;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 出栈</span></span><br><span class="line"><span class="function">ElemType <span class="title">Pop</span><span class="params">(SqStack *s)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    ElemType e;</span><br><span class="line">    <span class="keyword">if</span> (s-&gt;top == <span class="number">-1</span>) <span class="built_in">printf</span>(<span class="string">"栈空\n"</span>);</span><br><span class="line">    <span class="keyword">else</span> e = s-&gt;data[s-&gt;top--];</span><br><span class="line">    <span class="keyword">return</span> e;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 进制转换</span></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">Conversion</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    SqStack s;</span><br><span class="line">    ElemType e;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">int</span> N;</span><br><span class="line"></span><br><span class="line">    s = InitStack(s);</span><br><span class="line"></span><br><span class="line">    <span class="built_in">scanf</span>(<span class="string">"%d"</span>,&amp;N);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">while</span>(N!=<span class="number">0</span>)&#123;</span><br><span class="line">        s = Push(s,N%<span class="number">8</span>);</span><br><span class="line">        N = N/<span class="number">8</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">while</span>(IsEmptyStack(s)==<span class="number">0</span>)&#123;</span><br><span class="line">        e = Pop(&amp;s);</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">"%d"</span>,e);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    Conversion();</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><blockquote><p>2015 题2</p></blockquote><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span><span class="meta-string">&lt;stdio.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span><span class="meta-string">&lt;malloc.h&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="keyword">typedef</span> <span class="class"><span class="keyword">struct</span> <span class="title">BiTNode</span>&#123;</span></span><br><span class="line">    <span class="keyword">int</span> data;</span><br><span class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">BiTNode</span> *<span class="title">lchild</span>,*<span class="title">rchild</span>;</span></span><br><span class="line">&#125;BiTNode,*BiTree;</span><br><span class="line"></span><br><span class="line"><span class="function">BiTree <span class="title">CreatBiTree</span><span class="params">(BiTree T)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">int</span> ch;</span><br><span class="line">    <span class="built_in">scanf</span>(<span class="string">"%d"</span>,&amp;ch);</span><br><span class="line">    <span class="keyword">if</span>(ch==<span class="number">0</span>) T=<span class="literal">NULL</span>;</span><br><span class="line">    <span class="keyword">else</span>&#123;</span><br><span class="line">        T = (BiTree)<span class="built_in">malloc</span>(<span class="keyword">sizeof</span>(BiTNode));</span><br><span class="line">        T-&gt;data = ch;</span><br><span class="line">        T-&gt;lchild = CreatBiTree(T-&gt;lchild);</span><br><span class="line">        T-&gt;rchild = CreatBiTree(T-&gt;rchild);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> T;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">PreOrder</span><span class="params">(BiTree T)</span></span></span><br><span class="line"><span class="function"></span>&#123;  <span class="comment">//前序遍历二叉树bt</span></span><br><span class="line">    <span class="keyword">if</span>(T)</span><br><span class="line">    &#123;</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">"%d"</span>,T-&gt;data);                <span class="comment">//访问节点的数据域</span></span><br><span class="line">    PreOrder(T-&gt;lchild);                 <span class="comment">//前序遍历bt的左子树</span></span><br><span class="line">    PreOrder(T-&gt;rchild);                 <span class="comment">//前序遍历bt的右子树</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">InOrder</span><span class="params">(BiTree T)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">if</span>(T!=<span class="literal">NULL</span>)&#123;</span><br><span class="line">        InOrder(T-&gt;lchild);</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">"%d"</span>,T-&gt;data);</span><br><span class="line">        InOrder(T-&gt;rchild);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">PostOrder</span><span class="params">(BiTree T)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">if</span>(T!=<span class="literal">NULL</span>)&#123;</span><br><span class="line">        InOrder(T-&gt;lchild);</span><br><span class="line">        InOrder(T-&gt;rchild);</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">"%d"</span>,T-&gt;data);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function">BiTree <span class="title">Destroy</span><span class="params">(BiTree T)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">if</span>(T!=<span class="literal">NULL</span>)&#123;</span><br><span class="line">        Destroy(T-&gt;lchild);</span><br><span class="line">        Destroy(T-&gt;rchild);</span><br><span class="line">        <span class="built_in">free</span>(T);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> T;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    BiTree T;</span><br><span class="line">    T = CreatBiTree(T);</span><br><span class="line">    PreOrder(T);</span><br><span class="line">    InOrder(T);</span><br><span class="line">    PostOrder(T);</span><br><span class="line">    T = Destroy(T);</span><br><span class="line">    <span class="keyword">if</span>(T) <span class="built_in">printf</span>(<span class="string">"空"</span>);</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><blockquote><p>2017 题1</p></blockquote><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span><span class="meta-string">&lt;stdio.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span><span class="meta-string">&lt;malloc.h&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment">判断回文</span></span><br><span class="line"><span class="comment">*/</span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> ElemType char</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">typedef</span> <span class="class"><span class="keyword">struct</span> <span class="title">LNode</span>&#123;</span></span><br><span class="line">    ElemType data;</span><br><span class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">LNode</span> *<span class="title">next</span>;</span></span><br><span class="line">&#125;LNode,*LinkList;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 尾插法</span></span><br><span class="line"><span class="function">LinkList <span class="title">List_TaiInsert</span><span class="params">(LinkList L)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">char</span> ch;</span><br><span class="line">    LNode *s;</span><br><span class="line">    LNode *r;</span><br><span class="line">    L = (LinkList)<span class="built_in">malloc</span>(<span class="keyword">sizeof</span>(LNode));</span><br><span class="line">    r = L;</span><br><span class="line">    <span class="built_in">scanf</span>(<span class="string">"%c"</span>,&amp;ch);</span><br><span class="line">    <span class="keyword">while</span>(ch!=<span class="string">'\n'</span>)&#123;</span><br><span class="line">        s = (LNode *)<span class="built_in">malloc</span>(<span class="keyword">sizeof</span>(LNode));</span><br><span class="line">        s-&gt;data = ch;</span><br><span class="line">        r-&gt;next = s;</span><br><span class="line">        r = s;</span><br><span class="line">        <span class="built_in">scanf</span>(<span class="string">"%c"</span>,&amp;ch);</span><br><span class="line">    &#125;</span><br><span class="line">    r-&gt;next = <span class="literal">NULL</span>;</span><br><span class="line">    <span class="keyword">return</span> L;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">GetLen</span><span class="params">(LinkList L)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">int</span> len = <span class="number">0</span>;</span><br><span class="line">    <span class="keyword">while</span>(L-&gt;next)&#123;</span><br><span class="line">        len++;</span><br><span class="line">        L = L-&gt;next;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> len;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function">LNode *<span class="title">GetElem</span><span class="params">(LinkList L,<span class="keyword">int</span> i)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">int</span> j = <span class="number">0</span>;</span><br><span class="line">    LNode *p = L;</span><br><span class="line">    <span class="keyword">if</span>(i&lt;<span class="number">1</span>||i&gt;GetLen(p)) <span class="keyword">return</span> <span class="literal">NULL</span>;</span><br><span class="line">    <span class="keyword">while</span>(j&lt;i)&#123;</span><br><span class="line">        p = p-&gt;next;</span><br><span class="line">        j++;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> p;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">check</span><span class="params">(LinkList L)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">int</span> i,len;</span><br><span class="line">    len = GetLen(L);</span><br><span class="line">    LNode *p,*s;</span><br><span class="line">    <span class="keyword">for</span>(i=<span class="number">1</span>;i&lt;=len/<span class="number">2</span>;i++)&#123;</span><br><span class="line">        p = GetElem(L,i);</span><br><span class="line">        s = GetElem(L,len-i+<span class="number">1</span>);</span><br><span class="line">        <span class="keyword">if</span>(p-&gt;data!=s-&gt;data) <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> <span class="number">1</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">int</span> flag;</span><br><span class="line">    LinkList L;</span><br><span class="line">    L = List_TaiInsert(L);</span><br><span class="line">    flag =check(L);</span><br><span class="line">    <span class="keyword">if</span>(flag) <span class="built_in">printf</span>(<span class="string">"Yes"</span>);</span><br><span class="line">    <span class="keyword">else</span> <span class="built_in">printf</span>(<span class="string">"No"</span>);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><blockquote><p>2016 题1</p></blockquote><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span><span class="meta-string">&lt;stdio.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span><span class="meta-string">&lt;malloc.h&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> MaxSize 50</span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> ElemType char</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">typedef</span> <span class="class"><span class="keyword">struct</span> <span class="title">QNode</span>&#123;</span></span><br><span class="line">    ElemType data;</span><br><span class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">QNode</span> *<span class="title">next</span>;</span></span><br><span class="line">&#125;QNode,*QueuePtr;</span><br><span class="line"></span><br><span class="line"><span class="keyword">typedef</span> <span class="class"><span class="keyword">struct</span></span></span><br><span class="line"><span class="class">&#123;</span></span><br><span class="line">    QueuePtr front,rear;</span><br><span class="line">&#125;LinkQueue;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">typedef</span> <span class="class"><span class="keyword">struct</span>&#123;</span></span><br><span class="line">    ElemType data[MaxSize];</span><br><span class="line">    <span class="keyword">int</span> top;</span><br><span class="line">&#125;SqStack;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 初始化</span></span><br><span class="line"><span class="function">SqStack <span class="title">InitStack</span><span class="params">(SqStack s)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    s.top = <span class="number">-1</span>;</span><br><span class="line">    <span class="keyword">return</span> s;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 判栈空</span></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">IsEmptyStack</span><span class="params">(SqStack s)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (s.top == <span class="number">-1</span>) <span class="keyword">return</span> <span class="number">1</span>;</span><br><span class="line">    <span class="keyword">else</span> <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 进栈</span></span><br><span class="line"><span class="function">SqStack <span class="title">Push</span><span class="params">(SqStack s, ElemType e)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (s.top == MaxSize - <span class="number">1</span>);</span><br><span class="line">    <span class="keyword">else</span> s.data[++s.top] = e;</span><br><span class="line">    <span class="keyword">return</span> s;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 出栈</span></span><br><span class="line"><span class="function">SqStack <span class="title">Pop</span><span class="params">(SqStack s,ElemType *e)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="comment">//ElemType e;</span></span><br><span class="line">    <span class="keyword">if</span> (s.top == <span class="number">-1</span>) <span class="built_in">printf</span>(<span class="string">"栈空\n"</span>);</span><br><span class="line">    <span class="keyword">else</span> *e = s.data[s.top--];</span><br><span class="line">    <span class="keyword">return</span> s;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 队列初始化</span></span><br><span class="line"><span class="function">LinkQueue <span class="title">InitQueue</span><span class="params">(LinkQueue Q)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    Q.front = (QNode *)<span class="built_in">malloc</span>(<span class="keyword">sizeof</span>(QNode));</span><br><span class="line">    Q.rear = Q.front;</span><br><span class="line">    Q.front-&gt;next = <span class="literal">NULL</span>;</span><br><span class="line">    <span class="keyword">return</span> Q;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 队空判断</span></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">IsEmptyQueue</span><span class="params">(LinkQueue Q)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">if</span>(Q.front==Q.rear) <span class="keyword">return</span> <span class="number">1</span>;</span><br><span class="line">    <span class="keyword">else</span> <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 入队</span></span><br><span class="line"><span class="function">LinkQueue <span class="title">EnQueue</span><span class="params">(LinkQueue Q,ElemType e)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    QNode *s = (QNode *)<span class="built_in">malloc</span>(<span class="keyword">sizeof</span>(QNode));</span><br><span class="line">    s-&gt;data = e;</span><br><span class="line">    s-&gt;next = <span class="literal">NULL</span>;</span><br><span class="line">    Q.rear-&gt;next = s;</span><br><span class="line">    Q.rear = s;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> Q;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 出队</span></span><br><span class="line"><span class="function">LinkQueue <span class="title">DeQueue</span><span class="params">(LinkQueue Q,ElemType *e)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    QNode *p;</span><br><span class="line">    <span class="keyword">if</span>(Q.rear==Q.front) <span class="keyword">return</span> Q;</span><br><span class="line">    p = Q.front-&gt;next;</span><br><span class="line">    Q.front-&gt;next = p-&gt;next;</span><br><span class="line">    *e = p-&gt;data;</span><br><span class="line">    <span class="keyword">if</span>(Q.rear==p) Q.rear = Q.front;</span><br><span class="line">    <span class="built_in">free</span>(p);</span><br><span class="line">    <span class="keyword">return</span> Q;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">check</span><span class="params">(SqStack S,LinkQueue Q)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    ElemType e1,e2;</span><br><span class="line">    <span class="keyword">while</span>((!IsEmptyStack(S))&amp;&amp;(!IsEmptyQueue(Q)))&#123;</span><br><span class="line">        S = Pop(S,&amp;e1);</span><br><span class="line">        Q = DeQueue(Q,&amp;e2);</span><br><span class="line">        <span class="keyword">if</span>(e1!=e2) <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> <span class="number">1</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    SqStack S;</span><br><span class="line">    LinkQueue Q;</span><br><span class="line">    ElemType ch;</span><br><span class="line"></span><br><span class="line">    S = InitStack(S);</span><br><span class="line">    Q = InitQueue(Q);</span><br><span class="line"></span><br><span class="line">    <span class="built_in">scanf</span>(<span class="string">"%c"</span>,&amp;ch);</span><br><span class="line">    <span class="keyword">while</span>(ch!=<span class="string">'\n'</span>)&#123;</span><br><span class="line">        S = Push(S,ch);</span><br><span class="line">        Q = EnQueue(Q,ch);</span><br><span class="line">        <span class="built_in">scanf</span>(<span class="string">"%c"</span>,&amp;ch);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span>(check(S,Q)) <span class="built_in">printf</span>(<span class="string">"Yes"</span>);</span><br><span class="line">    <span class="keyword">else</span> <span class="built_in">printf</span>(<span class="string">"No"</span>);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><blockquote><p>2018 题1</p></blockquote><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span><span class="meta-string">&lt;stdio.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span><span class="meta-string">&lt;malloc.h&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> ElemType char</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">typedef</span> <span class="class"><span class="keyword">struct</span> <span class="title">LNode</span></span></span><br><span class="line"><span class="class">&#123;</span></span><br><span class="line">    ElemType data;</span><br><span class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">LNode</span> *<span class="title">next</span>;</span></span><br><span class="line">&#125;LNode,*LinkList;</span><br><span class="line"></span><br><span class="line"><span class="function">LinkList <span class="title">List_TaiInsert</span><span class="params">(LinkList L)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    ElemType ch;</span><br><span class="line">    LNode *s,*r;</span><br><span class="line">    L = (LinkList)<span class="built_in">malloc</span>(<span class="keyword">sizeof</span>(LNode));</span><br><span class="line">    r = L;</span><br><span class="line">    <span class="built_in">scanf</span>(<span class="string">"%c"</span>,&amp;ch);</span><br><span class="line">    <span class="keyword">while</span>(ch!=<span class="string">'\n'</span>)&#123;</span><br><span class="line">        s = (LNode *)<span class="built_in">malloc</span>(<span class="keyword">sizeof</span>(LNode));</span><br><span class="line">        s-&gt;data = ch;</span><br><span class="line">        r-&gt;next = s;</span><br><span class="line">        r = s;</span><br><span class="line">        <span class="built_in">scanf</span>(<span class="string">"%c"</span>,&amp;ch);</span><br><span class="line">    &#125;</span><br><span class="line">    r-&gt;next = <span class="literal">NULL</span>;</span><br><span class="line">    <span class="keyword">return</span> L;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 合并两个有序单链表</span></span><br><span class="line"><span class="function">LinkList <span class="title">MergeList</span><span class="params">(LinkList A,LinkList B,LinkList Lc)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    LNode *C;</span><br><span class="line"></span><br><span class="line">    C = A;</span><br><span class="line">    Lc = C;</span><br><span class="line">    A = A-&gt;next;</span><br><span class="line">    B = B-&gt;next;</span><br><span class="line">    <span class="keyword">while</span>(A&amp;&amp;B)&#123;</span><br><span class="line">        <span class="keyword">if</span>(A-&gt;data&lt;=B-&gt;data)&#123;</span><br><span class="line">            C-&gt;next = A;</span><br><span class="line">            C = A;</span><br><span class="line">            A = A-&gt;next;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">else</span>&#123;</span><br><span class="line">            C-&gt;next = B;</span><br><span class="line">            C= B;</span><br><span class="line">            B = B-&gt;next;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    C-&gt;next = A?A:B;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> Lc;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    LinkList A,B,Lc;</span><br><span class="line">    A = List_TaiInsert(A);</span><br><span class="line">    B = List_TaiInsert(B);</span><br><span class="line"></span><br><span class="line">    Lc = MergeList(A,B,Lc);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">while</span>(Lc-&gt;next)&#123;</span><br><span class="line">        Lc = Lc-&gt;next;</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">"%c"</span>,Lc-&gt;data);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><blockquote><p>2019 题1</p></blockquote><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span><span class="meta-string">&lt;stdio.h&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> ElemType int</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> MaxSize 50</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">typedef</span> <span class="class"><span class="keyword">struct</span></span></span><br><span class="line"><span class="class">&#123;</span></span><br><span class="line">    ElemType data[MaxSize];</span><br><span class="line">    <span class="keyword">int</span> front,cont;</span><br><span class="line">&#125;Queue;</span><br><span class="line"></span><br><span class="line"><span class="function">Queue <span class="title">InitQueue</span><span class="params">(Queue Q)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    Q.front = <span class="number">-1</span>;</span><br><span class="line">    Q.cont = <span class="number">0</span>;</span><br><span class="line">    <span class="keyword">return</span> Q;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function">Queue <span class="title">EnQueue</span><span class="params">(Queue Q,ElemType e)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">if</span>(Q.cont==MaxSize) <span class="keyword">return</span> Q;</span><br><span class="line">    <span class="keyword">if</span>(Q.front==<span class="number">-1</span>) Q.front = <span class="number">0</span>;</span><br><span class="line">    ++Q.cont;</span><br><span class="line">    Q.data[(Q.front+Q.cont<span class="number">-1</span>)%MaxSize] = e;</span><br><span class="line">    <span class="keyword">return</span> Q;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function">Queue <span class="title">DeQueue</span><span class="params">(Queue Q,ElemType *e)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">if</span>(Q.cont==<span class="number">0</span>) <span class="keyword">return</span> Q;</span><br><span class="line">    *e = Q.data[Q.front];</span><br><span class="line">    Q.cont--;</span><br><span class="line">    Q.front = (++Q.front)%MaxSize;</span><br><span class="line">    <span class="keyword">return</span> Q;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    Queue Q;</span><br><span class="line">    <span class="keyword">int</span> e;</span><br><span class="line">    Q = InitQueue(Q);</span><br><span class="line">    Q = EnQueue(Q,<span class="number">1</span>);</span><br><span class="line">    Q = EnQueue(Q,<span class="number">2</span>);</span><br><span class="line">    Q = EnQueue(Q,<span class="number">3</span>);</span><br><span class="line">    Q = EnQueue(Q,<span class="number">4</span>);</span><br><span class="line"></span><br><span class="line">    Q = DeQueue(Q,&amp;e);</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">"%d\n"</span>,e);</span><br><span class="line"></span><br><span class="line">    Q = DeQueue(Q,&amp;e);</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">"%d\n"</span>,e);</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><blockquote><p>最大深度</p></blockquote><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span><span class="meta-string">&lt;stdio.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span><span class="meta-string">&lt;malloc.h&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> MaxSize 50</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> ElemType char</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">typedef</span> <span class="class"><span class="keyword">struct</span> <span class="title">BiTNode</span>&#123;</span></span><br><span class="line">    ElemType data;</span><br><span class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">BiTNode</span> *<span class="title">lchild</span>,*<span class="title">rchild</span>;</span></span><br><span class="line">&#125;BiTNode,*BiTree;</span><br><span class="line"></span><br><span class="line"><span class="function">BiTree <span class="title">CreatBiTree</span><span class="params">(BiTree T)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    ElemType ch;</span><br><span class="line">    <span class="built_in">scanf</span>(<span class="string">"%c"</span>,&amp;ch);</span><br><span class="line">    <span class="keyword">if</span>(ch==<span class="string">'\n'</span>) T=<span class="literal">NULL</span>;</span><br><span class="line">    <span class="keyword">else</span>&#123;</span><br><span class="line">        T = (BiTree)<span class="built_in">malloc</span>(<span class="keyword">sizeof</span>(BiTNode));</span><br><span class="line">        T-&gt;data = ch;</span><br><span class="line">        T-&gt;lchild = CreatBiTree(T-&gt;lchild);</span><br><span class="line">        T-&gt;rchild = CreatBiTree(T-&gt;rchild);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> T;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">typedef</span> <span class="class"><span class="keyword">struct</span></span></span><br><span class="line"><span class="class">&#123;</span></span><br><span class="line">    BiTree data[MaxSize];</span><br><span class="line">    <span class="keyword">int</span> top;</span><br><span class="line">&#125;SqStack;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 初始化</span></span><br><span class="line"><span class="function">SqStack <span class="title">InitStack</span><span class="params">(SqStack s)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    s.top = <span class="number">-1</span>;</span><br><span class="line">    <span class="keyword">return</span> s;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 判栈空</span></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">IsEmptyStack</span><span class="params">(SqStack s)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (s.top == <span class="number">-1</span>) <span class="keyword">return</span> <span class="number">1</span>;</span><br><span class="line">    <span class="keyword">else</span> <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 进栈</span></span><br><span class="line"><span class="function">SqStack <span class="title">Push</span><span class="params">(SqStack s, BiTree e)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (s.top == MaxSize - <span class="number">1</span>);</span><br><span class="line">    <span class="keyword">else</span> s.data[++s.top] = e;</span><br><span class="line">    <span class="keyword">return</span> s;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 出栈</span></span><br><span class="line"><span class="function">SqStack <span class="title">Pop</span><span class="params">(SqStack s,BiTree *e)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (s.top == <span class="number">-1</span>) <span class="built_in">printf</span>(<span class="string">"栈空\n"</span>);</span><br><span class="line">    <span class="keyword">else</span> *e = s.data[s.top--];</span><br><span class="line">    <span class="keyword">return</span> s;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">GetDepth</span><span class="params">(BiTree T)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">int</span> LD=<span class="number">0</span>,RD=<span class="number">0</span>;</span><br><span class="line">    <span class="keyword">if</span>(T)</span><br><span class="line">    &#123;</span><br><span class="line">        LD = GetDepth(T-&gt;lchild);</span><br><span class="line">        RD = GetDepth(T-&gt;rchild);</span><br><span class="line">        <span class="keyword">return</span> (LD&gt;RD?LD:RD)+<span class="number">1</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">else</span></span><br><span class="line">    &#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    BiTree T;</span><br><span class="line">    T = CreatBiTree(T);</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">"\n%d\n"</span>,GetDepth(T));</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;blockquote&gt;
&lt;p&gt;2015年  题3&lt;/p&gt;
&lt;/blockquote&gt;
&lt;figure class=&quot;highlight c&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;s
      
    
    </summary>
    
    
    
      <category term="c/c++" scheme="https://hahally.github.io/tags/c-c/"/>
    
  </entry>
  
  <entry>
    <title>单片机实习日记</title>
    <link href="https://hahally.github.io/articles/%E5%8D%95%E7%89%87%E6%9C%BA%E5%AE%9E%E4%B9%A0%E6%97%A5%E8%AE%B0/"/>
    <id>https://hahally.github.io/articles/%E5%8D%95%E7%89%87%E6%9C%BA%E5%AE%9E%E4%B9%A0%E6%97%A5%E8%AE%B0/</id>
    <published>2020-05-24T01:52:39.000Z</published>
    <updated>2020-05-28T16:00:32.406Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p><em>I know nothing but my ignorance.</em></p></blockquote><h3 id="5月18日"><a href="#5月18日" class="headerlink" title="5月18日"></a>5月18日</h3><p>今天是单片机实习的第一天，因为疫情原因变成了线上开展。</p><p>上午，老师把六个选题都一一讲解了一遍，并告诉我们一些在实习过程中可能会出现的一些问题和注意事项。老师讲完后，我们就开始组队和选题了。</p><p>在经过一番并不激烈的讨论后，我们组选择了第二个项目：<strong>数字频率计设计</strong> </p><p>一、基本要求：</p><p>测量待测 <code>TTL</code> 电平信号的频率</p><ol><li>频率范围：10 Hz ~ 50kHz，全测量范围误差不大于 1%；</li><li>用液晶屏 <code>LCD1602</code> 显示数值和单位，可显示频率及周期；</li><li>数据刷新率每秒三次以上；</li><li>在同一台单片机上自行设计测试用信号源；</li><li>通过串口通信在远程单片机（仿真环境）显示测量结果。</li></ol><p>二、扩展要求</p><ol><li>占空比测量</li><li>在保证数据刷新率和精度的基础上拓展测量频率范围</li></ol><p>下午，我们组四个人开始查文献讨论总体方案和分工。又是一番并不激烈的讨论后，我们确定好了分工。我选择了串口通信功能的实现。</p><h3 id="5月19日"><a href="#5月19日" class="headerlink" title="5月19日"></a>5月19日</h3><p>上午确定分工合作的一些细节部分的设计，资源的分配，引脚的功能等等。然后，听老师讲一些知识点。</p><p>下午，我开始查找串口通信的资料文献。最终确定采用异步通信的方式实现串口通信。接着开始着重异步通信方面的资料查询。经过一番并不困难的翻阅后，大致了解了异步通信的 4 种方式以及定时器的知识。</p><p>52单片机有三个定时器/计数器，与串口通信有关的就是 T1定时器了。定时器/计数器的实质是加 1 计数器(高 8 位 和低 8 位 两个寄存器组成)。<code>TMOD</code> 是确定工作方式和功能的寄存器；<code>TCON</code> 是控制 T0、T1 的启动和停止及设置溢出标志的寄存器。</p><p><strong><code>TMOD</code></strong>:</p><div class="table-container"><table><thead><tr><th style="text-align:center">位序号</th><th style="text-align:center">D7</th><th style="text-align:center">D6</th><th style="text-align:center">D5</th><th style="text-align:center">D4</th><th style="text-align:center">D3</th><th style="text-align:center">D2</th><th style="text-align:center">D1</th><th style="text-align:center">D0</th></tr></thead><tbody><tr><td style="text-align:center">位符号</td><td style="text-align:center">$GATE$</td><td style="text-align:center">$C/\overline{\text{T}}$</td><td style="text-align:center">$M1$</td><td style="text-align:center">$M0$</td><td style="text-align:center">$GATE$</td><td style="text-align:center">$C/\overline{\text{T}}$</td><td style="text-align:center">$M1$</td><td style="text-align:center">$M0$</td></tr></tbody></table></div><p><code>D7~D4</code> 为 <code>T1</code> 定时器，<code>D3~D0</code> 为 <code>T0</code> 定时器。$C/\overline{\text{T}}$ 为 0 时为定时器模式，为 1 时为计数器模式，<code>M1</code> 和 <code>M0</code> 是工作方式选择位。</p><div class="table-container"><table><thead><tr><th style="text-align:center">M1</th><th style="text-align:center">M0</th><th style="text-align:center">工作方式</th></tr></thead><tbody><tr><td style="text-align:center">0</td><td style="text-align:center">0</td><td style="text-align:center">方式0，为13位定时器/计数器</td></tr><tr><td style="text-align:center">0</td><td style="text-align:center">1</td><td style="text-align:center">方式1，为16位定时器/计数器</td></tr><tr><td style="text-align:center">1</td><td style="text-align:center">0</td><td style="text-align:center">方式2，8位初值自动重装的8位定时器/计数器</td></tr><tr><td style="text-align:center">1</td><td style="text-align:center">1</td><td style="text-align:center">方式3，仅适用于 T0，分成两个8位计数器，T1停止计数</td></tr></tbody></table></div><p><strong><code>TCON</code></strong></p><div class="table-container"><table><thead><tr><th style="text-align:center">位序号</th><th style="text-align:center">D7</th><th style="text-align:center">D6</th><th style="text-align:center">D5</th><th style="text-align:center">D4</th><th style="text-align:center">D3</th><th style="text-align:center">D2</th><th style="text-align:center">D1</th><th style="text-align:center">D0</th></tr></thead><tbody><tr><td style="text-align:center">位符号</td><td style="text-align:center">$TF1$</td><td style="text-align:center">$TR1$</td><td style="text-align:center">$TF0$</td><td style="text-align:center">$TR0$</td><td style="text-align:center">$IE1$</td><td style="text-align:center">$IT1$</td><td style="text-align:center">$IE0$</td><td style="text-align:center">$IT0$</td></tr></tbody></table></div><h3 id="5月20日"><a href="#5月20日" class="headerlink" title="5月20日"></a>5月20日</h3><p>经过昨天一天的查阅学习，已经对串口通信有了比较全面的了解。所以，今天就是先把串口通信的一些必要环境准备好。下载串口助手和虚拟串口工具，然后测试串口助手。在一番并不花里胡哨的操作后，基本操作都会了。接着就是准备仿真下的串口测试了。在 <code>protues</code> 上，点来点去，又是一番行云流水且不花里胡哨的操作后，仿真环境也搭建好了。然后开始敲代码，在 <code>keil</code> 这个外表朴实无华但功能强大的软件上，敲下第一个简单串口通信的代码。然后结合串口助手观察效果。这样一个发送单个字符的例子就测试成功了。</p><h3 id="5月21日"><a href="#5月21日" class="headerlink" title="5月21日"></a>5月21日</h3><p>今天是周四，上午老师照常开了小小的线上例会。交我们一些小小的调试技巧之类的。在昨天的基础上，今天继续修改代码，实现发送和接收功能。上午把整个代码框架写了出来，本以为会是顺顺利利的一天。但是下午的调试，着实不太顺利。先是，接收的数据并不是期望的数据，在一顿微操后，发现是接收数据的数组出现了溢出现象。调好后，又发现接收的数据有些错位了。又是一顿 <code>Debug</code> 后，自己定义一个简单通信协议，在数据头尾加上标志位，以确保接收方正确接收到期望数据。来来回回这样折腾后，仿真串口通信是没有问题了。</p><h3 id="5月22日"><a href="#5月22日" class="headerlink" title="5月22日"></a>5月22日</h3><p>一觉醒来还是周五，是的，昨晚熬到了十二点。精力显然有些不充沛的我，还是打开了电脑，接着干了。队友那边的频率测量 和<code>LCD</code> 显示功能已经就绪了。今天可以整一块测试一下了。拿到他们的代码后，便开始调试。红红火火恍恍惚惚，就这样一顿朴实无华而实用的 <code>CV</code>大法过后，加以小小微操作为辅助，就调好了。</p><h3 id="5月25日"><a href="#5月25日" class="headerlink" title="5月25日"></a>5月25日</h3><p>短暂的周末一晃就过去了。新的一周，继续干。现在只剩下信号源了。查资料，敲代码，仿真。陷入循环状态。进度十分缓慢。浑浑噩噩，一天就这样结束了。</p><h3 id="5月26日"><a href="#5月26日" class="headerlink" title="5月26日"></a>5月26日</h3><p>距离实习结束，迫在眉睫。但是，实在有些精神疲惫了。打开和昨天一样的软件一样的文件，开始改代码。一番操作，以为成了。结果，一到高频信号，就不受调制了，无法准确控制信号频率的改变。</p><h3 id="5月27日"><a href="#5月27日" class="headerlink" title="5月27日"></a>5月27日</h3><p>今天开始在开发板上进行真机测试，果然不出所料，仿真和真机不一样。一天的疯狂调试，勉强调好，差强人意的样子。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;blockquote&gt;
&lt;p&gt;&lt;em&gt;I know nothing but my ignorance.&lt;/em&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h3 id=&quot;5月18日&quot;&gt;&lt;a href=&quot;#5月18日&quot; class=&quot;headerlink&quot; title=&quot;5月18日&quot;
      
    
    </summary>
    
    
      <category term="Diary" scheme="https://hahally.github.io/categories/Diary/"/>
    
    
      <category term="单片机" scheme="https://hahally.github.io/tags/%E5%8D%95%E7%89%87%E6%9C%BA/"/>
    
  </entry>
  
  <entry>
    <title>CSRent</title>
    <link href="https://hahally.github.io/articles/CSRent/"/>
    <id>https://hahally.github.io/articles/CSRent/</id>
    <published>2020-05-17T16:57:44.000Z</published>
    <updated>2020-05-18T02:09:30.571Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>交互式Python爬虫分析实例小项目</p></blockquote><p>先抛出项目地址吧： <a href="http://dblab.xmu.edu.cn/blog/2355/#more-2355" target="_blank" rel="noopener">厦门大学数据库实验室</a></p><h3 id="项目简述"><a href="#项目简述" class="headerlink" title="项目简述"></a>项目简述</h3><p>实现一个简单的交互式的租房信息分析展示 $web$ 平台。</p><p>数据来源 ： <a href="http://www.xhj.com/zufang/" target="_blank" rel="noopener">http://www.xhj.com/zufang/</a></p><p><strong>技术栈</strong> ：</p><ul><li>$python$ 爬虫</li><li>$pyspark$ 数据分析</li><li>$flask$  $web$ 后端</li><li>$pyecharts$  可视化</li></ul><p><strong>最终呈现效果</strong> ：</p><p><img src="/articles/CSRent/image-20200517220605897.png" alt="image-20200517220605897"></p><p><img src="/articles/CSRent/image-20200517220645343.png" alt="image-20200517220645343"></p><h3 id="租房信息爬取"><a href="#租房信息爬取" class="headerlink" title="租房信息爬取"></a>租房信息爬取</h3><p>地址： <a href="http://www.xhj.com/zufang/" target="_blank" rel="noopener">http://www.xhj.com/zufang/</a></p><p><img src="/articles/CSRent/image-20200517222251986.png" alt="image-20200517222251986"></p><p><strong>网页分析</strong></p><h4 id="地址分析"><a href="#地址分析" class="headerlink" title="地址分析"></a>地址分析</h4><p>在 <em>区域找房</em>  一栏找到长沙的各个区域。这里选取了长沙的六个区：【天心区、芙蓉区、开福区、岳麓区、雨花区、望城】</p><p>逐个点击 六个区可以观察到每个区域都对应有 $40$ 页 ，而且地址可以简单按下面这样方式拼接：</p><figure class="highlight awk"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">http:<span class="regexp">//</span>www.xhj.com<span class="regexp">/zufang/</span> + 区域+<span class="regexp">/pg + 页码/</span></span><br></pre></td></tr></table></figure><p>所以代码中可以这样构造地址：</p><figure class="highlight ini"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">base_url</span> = <span class="string">'http://www.xhj.com/zufang/'</span></span><br><span class="line"><span class="attr">param</span> = [<span class="string">'tianxinqu'</span>,<span class="string">'furongqu'</span>,<span class="string">'kaifuqu'</span>,<span class="string">'yueluqu'</span>,<span class="string">'yuhuaqu'</span>,<span class="string">'wangcheng'</span>]</span><br><span class="line"><span class="comment"># region in param</span></span><br><span class="line"><span class="attr">url</span> = base_url + region + <span class="string">'/pg%d/'</span>%i <span class="comment"># region为区域，i 为页码</span></span><br></pre></td></tr></table></figure><p>这样很容易就可以通过两个循环来爬取我们需要的数据了。</p><h4 id="源码分析"><a href="#源码分析" class="headerlink" title="源码分析"></a>源码分析</h4><p>通过开发者工具查看源码：</p><p><img src="/articles/CSRent/image-20200517223429820.png" alt="image-20200517223429820"></p><p>显然，这个网站的前端非常的给力，结构一目了然，而且没有动态加载。要是能改为 $ajax$ 的请求方式加载数据或许会更友好。</p><p>不用仔细观察都可以看见，每个租房信息都被一个 <code>&lt;div​ class=&quot;lp_wrap&quot;&gt;...&lt;/div&gt;​</code> 包裹着。</p><p>我们很容易就可以通过 $xpath$ 定位到每个租房信息，像这样：</p><figure class="highlight ini"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># html is the source code of webpage.</span></span><br><span class="line"><span class="attr">div</span> = html.xpath(<span class="string">'//*/div[@class="lp_wrap"]'</span>)</span><br></pre></td></tr></table></figure><p>这样提取的 <code>div​</code> 对象为一个 $list$ 。最后将结果保存在 <code>rent_info.csv</code> 中。</p><h4 id="补充"><a href="#补充" class="headerlink" title="补充"></a>补充</h4><p>经过这么一波并不花里胡哨的简单操作和分析，基本上可以写出对应的代码了。但是，这看似普普通通的网站，还是会封你的 $ip$ 的。所以，一般的加 <code>headers[&#39;User-Agent&#39;]​</code>  已经不行了。这里，我选择了添加代理来绕过它的反爬机制。【备注：很久之前爬过免费高匿代理存放在 <code>mongodb</code> 中】</p><p>(此处省略个几百字)一顿花里胡哨的操作后，数据库中的代理 $ip$ 果然已经基本失效了。毕竟一年多了。</p><p>后面发现，这个网站只会封你半分钟不到好像(应该是的，被禁后，刷新了好几下网页，然后刷回来了)。所以说，代码中是不是可以通过设置休眠时间来降低访问速度呢。三思过后，放弃的这个想法，这样的做法好像一点都不干脆利落。还是决定自己做个代理池算了。</p><p>于是开启了免费代理的寻找之路，又是一顿的花里胡哨操作后(此处省略几百字)。很多 <strong>西刺代理</strong> 这样的免费代理网站已经迭代升级了，不在是曾经那个亚子了。它也开始封我 $ip$ 了。差点当场炸裂开来……因为它不是封你一两分钟酱紫玩玩。</p><p>不过没关系，多爬几个这样的网站就可以有比较多得代理了。如果不想爬也不打紧，不妨逛一逛这里<a href="https://ip.ihuan.me/" target="_blank" rel="noopener">小幻http代理</a>  </p><p>支持批量提取，十分友好，可以帮我们省十几行代码了。</p><p><strong>一点建议</strong></p><p>记得用我们的目标网站测试一下这些免费代理是否失效。</p><p><strong>下面是我选出来的比较好的</strong></p><figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">proxies = [</span><br><span class="line">    &#123;<span class="symbol">'https</span>':<span class="string">"https://221.6.201.18:9999"</span>&#125;,</span><br><span class="line">    &#123;<span class="symbol">'http</span>': <span class="symbol">'http</span>:<span class="comment">//39.137.69.9:80'&#125;,</span></span><br><span class="line">    &#123;<span class="symbol">'https</span>': <span class="symbol">'https</span>:<span class="comment">//221.122.91.64:80'&#125;,</span></span><br><span class="line">    &#123;<span class="symbol">'http</span>': <span class="symbol">'http</span>:<span class="comment">//39.137.69.8:8080'&#125;,</span></span><br><span class="line">    &#123;<span class="symbol">'http</span>': <span class="symbol">'http</span>:<span class="comment">//125.59.223.27:8380'&#125;,</span></span><br><span class="line">    &#123;<span class="symbol">'http</span><span class="string">':'</span>http:<span class="comment">//118.212.104.22:9999'&#125;,</span></span><br><span class="line">    &#123;<span class="symbol">'https</span><span class="string">':'</span>https:<span class="comment">//47.106.59.75:3128'&#125;,</span></span><br><span class="line">    &#123;<span class="symbol">'http</span><span class="string">':'</span>http:<span class="comment">//221.180.170.104:8080'&#125;,</span></span><br><span class="line">    &#123;<span class="symbol">'http</span>': <span class="symbol">'http</span>:<span class="comment">//113.59.99.138:8910'&#125;,</span></span><br><span class="line">    &#123;<span class="symbol">'http</span><span class="string">':'</span>http:<span class="comment">//123.194.231.55:8197'&#125;,</span></span><br><span class="line">    &#123;<span class="symbol">'https</span><span class="string">':'</span>https:<span class="comment">//218.60.8.99:3129'&#125;,</span></span><br><span class="line">    &#123;<span class="symbol">'http</span>': <span class="symbol">'http</span>:<span class="comment">//218.58.194.162:8060'&#125;,</span></span><br><span class="line">    &#123;<span class="symbol">'https</span>': <span class="symbol">'https</span>:<span class="comment">//221.122.91.64:80'&#125;</span></span><br><span class="line">]</span><br></pre></td></tr></table></figure><h3 id="pyspark-数据分析"><a href="#pyspark-数据分析" class="headerlink" title="pyspark 数据分析"></a>pyspark 数据分析</h3><p>这一步主要使用 <code>pyspark.sql.SparkSession</code> 来操作。从 <code>rent_info.csv</code> 中读取数据获得一个 <code>DataFrame</code> 对象，然后通过一系列动作(过滤筛选，聚合，统计)完成简单分析。</p><h3 id="flask-后端"><a href="#flask-后端" class="headerlink" title="flask 后端"></a>flask 后端</h3><p>使用 <code>flask_socketio.SocketIO</code>  来注册一个 <code>flask app</code> 对象。调用 <code>run</code> 方法启动服务。</p><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">app = Flask(__name__)</span><br><span class="line">app.config[<span class="string">'SECRET_KEY'</span>] = <span class="string">'xmudblab'</span></span><br><span class="line">socketio = SocketIO(app)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">    socketio.<span class="builtin-name">run</span>(app, <span class="attribute">debug</span>=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure><p>剩下的就是一些简单的路由配置(通过装饰器来实现)：</p><figure class="highlight ruby"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 客户端访问 http://127.0.0.1:5000/，可以看到index界面</span></span><br><span class="line">@app.route(<span class="string">"/"</span>)</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">handle_mes</span><span class="params">()</span></span><span class="symbol">:</span></span><br><span class="line">    <span class="keyword">return</span> render_template(<span class="string">"index.html"</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 对客户端发来的start_spider事件作出相应</span></span><br><span class="line">@socketio.on(<span class="string">"start_spider"</span>)</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">start_spider</span><span class="params">(message)</span></span><span class="symbol">:</span></span><br><span class="line">    print(message)</span><br><span class="line">    run_spider()</span><br><span class="line">    socketio.emit(<span class="string">'get_result'</span>, &#123;<span class="string">'data'</span>: <span class="string">"请获取最后结果"</span>&#125;)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 对客户端发来的/Get_result事件作出相应</span></span><br><span class="line">@app.route(<span class="string">"/Get_result"</span>)</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">Get_result</span><span class="params">()</span></span><span class="symbol">:</span></span><br><span class="line">    <span class="keyword">return</span> render_template(<span class="string">"result.html"</span>)</span><br></pre></td></tr></table></figure><h3 id="socketio-补充"><a href="#socketio-补充" class="headerlink" title="socketio 补充"></a>socketio 补充</h3><p>使用 <code>socketio</code> 可以轻松实现 <code>web</code> 后台和前端的信息交互，这种连接是基于 <code>websocket</code> 协议的全双工通信。</p><p>前端 <code>socketio</code> 库</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">script</span> <span class="attr">src</span>=<span class="string">"static/js/socket.io.js"</span>&gt;</span><span class="tag">&lt;/<span class="name">script</span>&gt;</span></span><br></pre></td></tr></table></figure><blockquote><p>未完待续…..</p></blockquote><h3 id="改进空间"><a href="#改进空间" class="headerlink" title="改进空间"></a>改进空间</h3><p>整个项目中，<code>spark</code> 的强大好像并没有发挥出来。毕竟 <code>spark</code> 在实时数据处理方面可是碾压 <code>mapreduce</code>的，好像一套组合拳，只使出了一点花拳绣腿。不妨大点想象一下，能不能实现一个实时房租信息交互系统，通过可视化工具在地图上直观的显示租房信息，每隔一小段时间更新数据，同时发送邮件提醒。甚至结合微信小程序在移动端也能查看。</p><p>嗯，想一想，挺好的。但是，这里的数据来源的可信度还有待考察。或许应该去 <a href="https://cs.zu.ke.com/zufang/changshaxian/" target="_blank" rel="noopener">贝壳找房</a> 看看(当事人非常后悔)。怎么开始就没想到去贝壳找。【不是打广告/手动滑稽】</p><hr>]]></content>
    
    <summary type="html">
    
      
      
        &lt;blockquote&gt;
&lt;p&gt;交互式Python爬虫分析实例小项目&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;先抛出项目地址吧： &lt;a href=&quot;http://dblab.xmu.edu.cn/blog/2355/#more-2355&quot; target=&quot;_blank&quot; rel
      
    
    </summary>
    
    
      <category term="projdemo" scheme="https://hahally.github.io/categories/projdemo/"/>
    
    
      <category term="爬虫" scheme="https://hahally.github.io/tags/%E7%88%AC%E8%99%AB/"/>
    
  </entry>
  
</feed>
