[{"title":"Problem-Container","url":"https://hahally.github.io//articles/Problem-Container/","content":"<blockquote>\n<p>前言</p>\n</blockquote>\n<p>这里收纳遇到的一些<code>Problem</code> ，不仅仅指<code>coding</code> 过程中遇到的问题，也包含一些生活中遇到的琐事。是泛指，绝不是某类问题。想法来源与<code>SCP</code> 基金会。</p>\n<p>————————————————————————-分割线——————-————————————————</p>\n<p>以下是收容的一些<code>Problem</code> 。</p>\n<blockquote>\n<p><code>Shuffle</code>  <code>StratifiedKFold</code> and  <code>reset_index</code></p>\n</blockquote>\n<p>使用不当，容易造成模型训练失败，<code>acc</code>低于50%。一般不易察觉，令人十分困惑。出现情况一般是需要打乱数据并且使用<code>StratifiedKFold</code>进行交叉验证时。</p>\n<p>比如数据：</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">train\t<span class=\"number\">1</span></span><br><span class=\"line\">train\t<span class=\"number\">1</span></span><br><span class=\"line\">train\t<span class=\"number\">1</span></span><br><span class=\"line\">train\t<span class=\"number\">1</span></span><br><span class=\"line\">train\t<span class=\"number\">1</span></span><br><span class=\"line\">···</span><br><span class=\"line\">train\t<span class=\"number\">0</span></span><br><span class=\"line\">train\t<span class=\"number\">0</span></span><br><span class=\"line\">train\t<span class=\"number\">0</span></span><br><span class=\"line\">train\t<span class=\"number\">0</span></span><br><span class=\"line\">train\t<span class=\"number\">0</span></span><br><span class=\"line\">···</span><br><span class=\"line\">test\t<span class=\"number\">1</span></span><br><span class=\"line\">test\t<span class=\"number\">1</span></span><br><span class=\"line\">test\t<span class=\"number\">1</span></span><br><span class=\"line\">test\t<span class=\"number\">1</span></span><br><span class=\"line\">test\t<span class=\"number\">1</span></span><br><span class=\"line\">···</span><br><span class=\"line\">test\t<span class=\"number\">0</span></span><br><span class=\"line\">test\t<span class=\"number\">0</span></span><br><span class=\"line\">test\t<span class=\"number\">0</span></span><br><span class=\"line\">test\t<span class=\"number\">0</span></span><br><span class=\"line\">test\t<span class=\"number\">0</span></span><br></pre></td></tr></table></figure>\n<p>对于这样规则排列的数据，直接采用交叉验证显然是有问题的，每一折的训练数据可能只有一类数据，故在验证时，很可能出现acc在50%徘徊。</p>\n<p>使用<code>shuffle</code>函数打乱：</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">from</span> sklearn.utils <span class=\"keyword\">import</span> shuffle</span><br><span class=\"line\">new_train = shuffle(train, random_state=<span class=\"number\">2021</span>)</span><br><span class=\"line\"><span class=\"keyword\">for</span> fold_, (trn_idx, val_idx) <span class=\"keyword\">in</span> enumerate(folds.split(new_train, new_train[<span class=\"string\">'label'</span>])):</span><br><span class=\"line\">    ···</span><br></pre></td></tr></table></figure>\n<p>可以预见这样的操作是无法避免上述问题的。<code>shuffle</code>后， 只是排列打乱了，但是<code>index</code> 没有改变。所以正确方式应该是：</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">new_train = shuffle(train, random_state=<span class=\"number\">2021</span>).reset_index(drop=<span class=\"literal\">True</span>)</span><br></pre></td></tr></table></figure>\n<p>值得一提的是，养成良好习惯设置<code>random_state</code>  。不然每次<code>shuffle</code>结果都不同，无法复现。若是竞赛中，则可以尝试改变种子，在千分位的对决中或许可以碰碰运气。</p>\n","categories":[],"tags":[]},{"title":"TS-Transformer","url":"https://hahally.github.io//articles/TS-Transformer/","content":"<blockquote>\n<p>前言</p>\n</blockquote>\n<p>最近，老师让复现几篇论文中的方法。打开一篇有关<code>cnn</code> 的论文，初略一看，这个模型结构不就是<code>textcnn</code> 吗？！论文中改头换面变成了<code>LS-CNN</code>，着实有些摸不着头脑。那就仔细看看模型说明吧，看看到底有什么神奇之处。</p>\n<p>十多分钟后······，大概懂了，<code>LS-CNN = TextCNN(w*stack(A,B))</code>  。A、B分别表示layer embedding特征、Google word2vec 词向量特征，*表示卷积，stack表示堆叠（两个大小维度相同的矩阵，堆叠后，通道变成2），通过一维卷积操作进行降维（融合两个嵌入特征）。</p>\n<blockquote>\n<p>I know nothing but my ignorance……</p>\n</blockquote>\n<p>2017年谷歌一篇<code>Attention is all you need</code> 在自然语言处理领域炸开了锅。此后<code>transformer</code> 成为了许多人发paper密码 。之后的<code>bert</code> 更是在各大nlp任务上霸榜。各种魔改层出不求。至此，如果不了解<code>transfomer</code> ，不会微调<code>bert</code> 都不好意思说自己是一个 <code>nlper</code> 。不仅如此，隔壁的<code>cv</code>圈都要沾一下光（<code>VIT</code>）。要我说以后投稿就喊一句：<em>哦斯，喊出我的名字吧！transformer.</em> 或者 <em>构筑未来，希望之光，特利迦，transformer type/bert type</em> 。颇有一股新生代奥特曼借力量的趣味（滑稽）。</p>\n<p>距离<code>transformer</code>发布已经过去4年，这一波热潮何时褪去，或者下一次革命性的模型什么时候出现，这似乎很难预测。<code>self-attention</code> 的尽头是什么？在这急功近利的时代，各大<code>AI Lab</code> 又有几个愿意沉下心来思考研究呢？毕竟资本家只在乎短期能不能变现。</p>\n<p>有意思的是，<code>transformer</code> 又名变形金刚，这也预示这它花里胡哨的各式变形成为可能。</p>\n<blockquote>\n<p>方兴未艾</p>\n</blockquote>\n<p>基于自己有限的认知，随便瞎扯了一下。</p>\n<p>回归正题，自然语言处理技术在其他领域的应用正在悄悄进行中，就像开头提到的那个团队所做的工作一样。仔细一想，他们似乎也是在填充这一块空白，为后继者提供一个新的基线，这是有利于领域发展的。这是一个十分优秀的团队，有责任有担当。</p>\n<p>而作为新入行者的我或者其他人，应该也是倍感压力的。眼下借助自然语言处理技术发光发热的路子似乎并没有那么简单了。</p>\n<blockquote>\n<p>班门弄斧</p>\n</blockquote>\n<p>所以，在此，不妨大胆预测一下，他们接下来会不会对<code>transformer</code> 那一大家子动手呢，又或者另辟蹊径采用<code>GNN(GCN)</code> 来建模呢？这两种可能性还是很大的。</p>\n<p>哈哈哈哈哈哈。在这里挖个坑，献丑提名个 <code>TS-Transformer</code> 来做隐写分析。</p>\n<p>采用<code>Transformer</code> 的<code>encoder</code> 部分提取句子中词与词之间的关系特征和甚至句子的语义特征，然后进行<code>max-pool</code>及<code>avg-pool</code>，然后<code>concat</code> 两个pool特征进行融合，在通过最后全连接进行分类。当然对于词嵌入向量也使用两种embedding，即<code>word2vec</code>和<code>layer embedding</code> 。基于此实现的<code>TS-Transformer</code> 已经在训练了。事实证明这是可以work的。至于效果，留个悬念，暂不公布，代码暂不开源（就图一乐，/滑稽.jpg）。</p>\n<p>【后续补个模型图】</p>\n<p>【后续补个实验结果】</p>\n<p>似乎使用大规模预训练<code>bert</code>模型来代替<code>word2vec</code> 效果应该更好吧。毕竟<code>word2vec</code> 还是属于浅层特征表示吧。【又挖个坑】</p>\n<p>按照这个路子，<code>TS-bert、TS-GNN、TS-GCN......</code> 都是可能work的。</p>\n<blockquote>\n<p>有空在更</p>\n</blockquote>\n<p>然后……中秋放假了。</p>\n<p>哦斯，喊出我的名字吧！<code>TS-Transformer</code> 。构筑未来，希望之光，<code>transformer</code>，<code>TS type</code> 。</p>\n<p>【高开低走的特特利迦竟然试图让泽塔串场来拯救低迷的收视率以及低到可怜的评分，笑死】</p>\n","categories":[],"tags":[]},{"title":"当我遇到tensorflow2.x时","url":"https://hahally.github.io//articles/当我遇到tensorflow2-x时/","content":"<blockquote>\n<p>前言</p>\n</blockquote>\n<p>近日，使用tensorflow的频率比较高，使用过程中也是遇到了一些大大小小的问题。有些着实让人脑瓜子疼。此刻借着模型训练的时间，开始码码字。本来标题想取：</p>\n<ul>\n<li>什么？2021了，还有人用Tensorflow?</li>\n<li>震惊！代码练习生竟然在用······Tensorflow?</li>\n<li>我和tensorflow不共戴天</li>\n<li>我想给tensorflow来一大嘴巴子</li>\n<li>······</li>\n</ul>\n<p>最后，用了这个<code>当我遇到tensorflow2.x时</code> 。无论学习还是生活中，我们都会遇到各种各样的人或事或物。当我们遇到时，会发生什么？我们是会充满期待的。<code>当我遇到···时，我会···</code> 。这个句式是我喜欢的，大部分人习惯在前半部分大胆设想，后半句夸下豪言壮语。这里取前半句，是因为已经发生了，而省去后半句，恰恰是因为豪言壮语很容易翻车。</p>\n<p>这是一篇记录使用tensorflow过程中遇到的一些小而折磨人的问题的博文。但我预言这也将是一篇持久的对tensorflow的血泪吐槽文。</p>\n<blockquote>\n<p>如何看待Keras正式从TensorFlow中分离？</p>\n</blockquote>\n<p>不知道为什么想到了这个知乎话题。六月份的某天，Keras 之父 Francois Chollet宣布将 Keras 的代码从 TensorFlow 代码库中分离出来，移回到了自己的 repo。乍一看，还以为以后tensorflow的keras接口用不了了。但人家只是把keras代码搬回了属于自己的repo。原本的<code>tf.keras</code> 还是能用的。</p>\n<blockquote>\n<p>For you as a user, absolutely nothing changes, now or in the future.</p>\n</blockquote>\n<p>底下全是一片叫好，天下苦tensorflow久已。而我也并不看好这对情侣或者说组合。各自单飞，独自美丽不好吗？keras何必委曲求全做别人的嫁衣。</p>\n<blockquote>\n<p>抛开keras，tensorflow还剩什么？</p>\n</blockquote>\n<p>我想这应该是吐槽后，该冷静思考的问题。而回答这个问题，是需要去阅读官方文档以及实践的。所以，那个句式的后半句也可以是下面的记录。才疏学浅，当厚积薄发。</p>\n<p>言归正传，之后遇到的bug都记录在下面部分。</p>\n<p>—————————————–———-—-————分割线——————-—————————————————–—</p>\n<blockquote>\n<p><code>tf.config.run_functions_eagerly(True)</code></p>\n</blockquote>\n<p>有关<code>Eager Execution</code> <a href=\"https://www.tensorflow.org/guide/eager\" target=\"_blank\" rel=\"noopener\">戳这里</a> </p>\n<p>然后以下是我粗俗的理解：</p>\n<p>这是即时运行和计算图运行相关的概念。即时运行可以让你的程序立马返回结果，计算图运行会先构建计算图（记录你的程序执行行为及顺序），在最后按照构建的图进行计算。</p>\n<p>有些晦涩难理解。</p>\n<p>模型训练时一般有：</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">@tf.function</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">train_step</span><span class=\"params\">()</span>:</span></span><br><span class=\"line\">    <span class=\"keyword\">with</span> tf.GradientTape() <span class=\"keyword\">as</span> tape:</span><br><span class=\"line\">        ···train model code···</span><br></pre></td></tr></table></figure>\n<p>这在模型训练过程中是会构建计算图的（具体参考<a href=\"https://www.tensorflow.org/guide/intro_to_graphs\" target=\"_blank\" rel=\"noopener\">戳这里</a>），构建计算图可以，这时如果在代码中<code>print(x)</code> 一下，就会发现这是没有具体值的，而且没有<code>.numpy()</code> 属性。返回的即<code>计算图中节点的符号句柄</code> 。所以我为什么要在这里<code>print</code>呢？当然是为了调试代码(/滑稽.jpg)。</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">Tensor(<span class=\"string\">\"x:0\"</span>, shape=(<span class=\"number\">32</span>, <span class=\"number\">32</span>), dtype=int32)</span><br></pre></td></tr></table></figure>\n<p>官网提到tensorflow2.x是默认开启<code>Eager Execution</code> 的，然而代码中(如上)使用了<code>@tf.function</code> 装饰器，默认以图的方式执行。</p>\n<figure class=\"highlight armasm\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"symbol\">The</span> <span class=\"meta\">code</span> in a <span class=\"meta\">Function</span> can <span class=\"keyword\">be </span>executed <span class=\"keyword\">both </span>eagerly <span class=\"keyword\">and </span>as a graph. <span class=\"keyword\">By </span>default, <span class=\"meta\">Function</span> executes <span class=\"keyword\">its </span><span class=\"meta\">code</span> as a graph.</span><br></pre></td></tr></table></figure>\n<p>要关闭默认方式，可以通过设置：<code>tf.config.run_functions_eagerly(True)</code> 来实现。或者干脆不要加这个装饰器。</p>\n<p>最后，<code>Eager Execution</code> 增强了开发和调试的交互性，而<code>@tf.function</code> 计算图执行在分布式训练、性能优化和生产部署方面具有优势。简而言之，<code>Eager Execution</code>适合开发过程中调试，<code>@tf.function</code>适合线上部署。</p>\n<p>——————-2021.9.17更新———————</p>\n<blockquote>\n<p>自定义</p>\n</blockquote>\n<p>参考-&gt;<a href=\"https://www.tensorflow.org/guide/basic_training_loops\" target=\"_blank\" rel=\"noopener\">这里</a></p>\n<p><strong>定义模型</strong></p>\n<p>抛开keras的<code>sequential</code>, 使用 tensorflow定义模型时，可以有两种继承选择：<code>tf.keras.Model</code> 和 <code>tf.Module</code></p>\n<p>例如：</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">TFModel</span><span class=\"params\">(tf.Module)</span>:</span></span><br><span class=\"line\">  <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">__init__</span><span class=\"params\">(self, **kwargs)</span>:</span></span><br><span class=\"line\">    super().__init__(**kwargs)</span><br><span class=\"line\">    self.w = tf.Variable(<span class=\"number\">5.0</span>)</span><br><span class=\"line\">    self.b = tf.Variable(<span class=\"number\">0.0</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">  <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">__call__</span><span class=\"params\">(self, x)</span>:</span></span><br><span class=\"line\">    <span class=\"keyword\">return</span> self.w * x + self.b</span><br><span class=\"line\">tf_model = TFModel()</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">KerasModel</span><span class=\"params\">(tf.keras.Model)</span>:</span></span><br><span class=\"line\">  <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">__init__</span><span class=\"params\">(self, **kwargs)</span>:</span></span><br><span class=\"line\">    super().__init__(**kwargs)</span><br><span class=\"line\">    self.w = tf.Variable(<span class=\"number\">5.0</span>)</span><br><span class=\"line\">    self.b = tf.Variable(<span class=\"number\">0.0</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">  <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">call</span><span class=\"params\">(self, x, **kwargs)</span>:</span></span><br><span class=\"line\">    <span class=\"keyword\">return</span> self.w * x + self.b</span><br><span class=\"line\">keras_model = KerasModel()</span><br></pre></td></tr></table></figure>\n<p>定义训练循环：</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> tensorflow <span class=\"keyword\">as</span> tf</span><br><span class=\"line\"><span class=\"keyword\">import</span> random</span><br><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">train_model</span><span class=\"params\">(x_train,y_train,x_valid,y_valid,model,epochs = <span class=\"number\">5</span>,batch_size = <span class=\"number\">64</span>, lr =<span class=\"number\">0.001</span>, print_freq = <span class=\"number\">10</span>)</span>:</span></span><br><span class=\"line\">    loss_object = tf.keras.losses.SparseCategoricalCrossentropy()</span><br><span class=\"line\">    optimizer = tf.keras.optimizers.Adam(learning_rate=lr)</span><br><span class=\"line\"></span><br><span class=\"line\">    train_loss = tf.keras.metrics.Mean(name=<span class=\"string\">'train_loss'</span>)</span><br><span class=\"line\">    train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name=<span class=\"string\">'train_accuracy'</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">    test_loss = tf.keras.metrics.Mean(name=<span class=\"string\">'test_loss'</span>)</span><br><span class=\"line\">    test_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name=<span class=\"string\">'test_accuracy'</span>)</span><br><span class=\"line\">    </span><br><span class=\"line\">    <span class=\"keyword\">for</span> epoch <span class=\"keyword\">in</span> range(epochs):</span><br><span class=\"line\">        <span class=\"comment\"># 在下一个epoch开始时，重置评估指标</span></span><br><span class=\"line\">        train_loss.reset_states()</span><br><span class=\"line\">        train_accuracy.reset_states()</span><br><span class=\"line\">        test_loss.reset_states()</span><br><span class=\"line\">        test_accuracy.reset_states()</span><br><span class=\"line\">        <span class=\"keyword\">for</span> step <span class=\"keyword\">in</span> range(int(len(x_train)/batch_size)):</span><br><span class=\"line\">            rand_id = np.asarray(random.sample(range(len(x_train)), batch_size))</span><br><span class=\"line\">            bs_x_train = x_train[rand_id]</span><br><span class=\"line\">            bs_y_train = y_train[rand_id]</span><br><span class=\"line\">            </span><br><span class=\"line\">            <span class=\"comment\"># train step</span></span><br><span class=\"line\">            <span class=\"keyword\">with</span> tf.GradientTape() <span class=\"keyword\">as</span> tape:</span><br><span class=\"line\">                predictions = model(bs_x_train)</span><br><span class=\"line\">                loss = loss_object(bs_y_train, predictions)</span><br><span class=\"line\">            gradients = tape.gradient(loss, model.trainable_variables)</span><br><span class=\"line\">            optimizer.apply_gradients(zip(gradients, model.trainable_variables))</span><br><span class=\"line\">            train_loss(loss)</span><br><span class=\"line\">            train_accuracy(bs_y_train, predictions)</span><br><span class=\"line\">            </span><br><span class=\"line\">            <span class=\"comment\"># test step</span></span><br><span class=\"line\">            predictions = model(x_valid)</span><br><span class=\"line\">            t_loss = loss_object(y_valid, predictions)</span><br><span class=\"line\">            test_loss(t_loss)</span><br><span class=\"line\">            test_accuracy(y_valid, predictions)</span><br><span class=\"line\">            </span><br><span class=\"line\">            <span class=\"comment\"># print info</span></span><br><span class=\"line\">            <span class=\"keyword\">if</span> step%<span class=\"number\">10</span>==<span class=\"number\">0</span>:</span><br><span class=\"line\">                template = <span class=\"string\">'Epoch &#123;&#125;,step &#123;&#125;, Loss: &#123;&#125;, Accuracy: &#123;&#125;, Test Loss: &#123;&#125;, Test Accuracy: &#123;&#125;'</span></span><br><span class=\"line\">                print(template.format(epoch+<span class=\"number\">1</span>,</span><br><span class=\"line\">                            step,</span><br><span class=\"line\">                            train_loss.result(),</span><br><span class=\"line\">                            train_accuracy.result()*<span class=\"number\">100</span>,</span><br><span class=\"line\">                            test_loss.result(),</span><br><span class=\"line\">                            test_accuracy.result()*<span class=\"number\">100</span>))</span><br><span class=\"line\"></span><br><span class=\"line\">        template = <span class=\"string\">'Epoch &#123;&#125;, Loss: &#123;&#125;, Accuracy: &#123;&#125;, Test Loss: &#123;&#125;, Test Accuracy: &#123;&#125;'</span></span><br><span class=\"line\">        print(template.format(epoch+<span class=\"number\">1</span>,</span><br><span class=\"line\">                    train_loss.result(),</span><br><span class=\"line\">                    train_accuracy.result()*<span class=\"number\">100</span>,</span><br><span class=\"line\">                    test_loss.result(),</span><br><span class=\"line\">                    test_accuracy.result()*<span class=\"number\">100</span>))</span><br><span class=\"line\">        </span><br><span class=\"line\">    <span class=\"keyword\">return</span> model</span><br></pre></td></tr></table></figure>\n<p>若是继承自<code>tf.keras.Model</code> 则可以使用 <code>model.compile()</code> 去设置参数, 使用<code>model.fit()</code> 进行训练。</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">keras_model = KerasModel()</span><br><span class=\"line\">keras_model.compile(</span><br><span class=\"line\">    <span class=\"comment\"># 默认情况下，fit()调用tf.function()。</span></span><br><span class=\"line\">    <span class=\"comment\"># Debug时你可以关闭这一功能，但是现在是打开的。</span></span><br><span class=\"line\">    run_eagerly=<span class=\"literal\">False</span>,</span><br><span class=\"line\">    optimizer=tf.keras.optimizers.SGD(learning_rate=<span class=\"number\">0.1</span>),</span><br><span class=\"line\">    loss=tf.keras.losses.mean_squared_error,</span><br><span class=\"line\">)</span><br></pre></td></tr></table></figure>\n<p>——————-2021.9.18更———————</p>\n<blockquote>\n<p>种子</p>\n</blockquote>\n<p>为了确保每次运行结果的稳定，设置固定种子是有必要的。</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">random.seed(<span class=\"number\">2021</span>)</span><br><span class=\"line\">np.random.seed(<span class=\"number\">2021</span>)</span><br><span class=\"line\">tf.random.set_seed(<span class=\"number\">2021</span>)</span><br></pre></td></tr></table></figure>\n<p>——————-2021.9.19更———————</p>\n<p>当自定义模型时，继承<code>tf.keras.Model</code> 则需要实现<code>call</code> 方法而不是<code>__call__</code> 。如果是<code>tf.Module</code> 就实现<code>__call__</code> 。尽量使用<code>tf.keras.Model</code> ，因为真的很方便。</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">KerasModel</span><span class=\"params\">(tf.keras.Model)</span>:</span></span><br><span class=\"line\">  <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">__init__</span><span class=\"params\">(self, **kwargs)</span>:</span></span><br><span class=\"line\">    super().__init__(**kwargs)</span><br><span class=\"line\">    self.w = tf.Variable(<span class=\"number\">5.0</span>)</span><br><span class=\"line\">    self.b = tf.Variable(<span class=\"number\">0.0</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">  <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">call</span><span class=\"params\">(self, x, **kwargs)</span>:</span></span><br><span class=\"line\">    <span class=\"keyword\">return</span> self.w * x + self.b</span><br><span class=\"line\">model = KerasModel()</span><br><span class=\"line\">bst_model_path = <span class=\"string\">\"./best.model.h5\"</span></span><br><span class=\"line\"></span><br><span class=\"line\">early_stopping = tf.keras.callbacks.EarlyStopping(monitor=<span class=\"string\">'val_accuracy'</span>, patience=<span class=\"number\">5</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">model_checkpoint = tf.keras.callbacks.ModelCheckpoint(bst_model_path, save_best_only=<span class=\"literal\">True</span>, save_weights_only=<span class=\"literal\">True</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">model.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=<span class=\"literal\">False</span>),</span><br><span class=\"line\">              optimizer=tf.keras.optimizers.Adam(<span class=\"number\">1e-3</span>),</span><br><span class=\"line\">              metrics=[<span class=\"string\">'accuracy'</span>])</span><br><span class=\"line\">model.fit(x_train, train_y, </span><br><span class=\"line\">          batch_size=<span class=\"number\">16</span>, </span><br><span class=\"line\">          validation_data=(x_valid,valid_y),</span><br><span class=\"line\">          epochs=<span class=\"number\">200</span>,</span><br><span class=\"line\">          callbacks=[early_stopping,model_checkpoint]</span><br><span class=\"line\">         )</span><br></pre></td></tr></table></figure>\n<blockquote>\n<p>TODO</p>\n</blockquote>\n","categories":[],"tags":["tensorflow"]},{"title":"蛋白质结构预测","url":"https://hahally.github.io//articles/蛋白质结构预测/","content":"<p>赛题：<a href=\"https://challenge.xfyun.cn/topic/info?type=protein\" target=\"_blank\" rel=\"noopener\">蛋白质结构预测挑战赛</a></p>\n<p>数据集一共包含245种折叠类型，11843条蛋白质序列样本，其中训练集中有9472个样本，测试集中有2371个样本。</p>\n<p>继上次<a href=\"https://hahally.github.io/articles/蛋白质结构预测之lgb的baseline/\">lgb的base模型</a> 后，尝试过word2vec + 神经网络的方法，最后效果甚微。今天尝试了一下双向GRU模型，相比之前，有几个百分点的提高。</p>\n<p>代码：</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br><span class=\"line\">77</span><br><span class=\"line\">78</span><br><span class=\"line\">79</span><br><span class=\"line\">80</span><br><span class=\"line\">81</span><br><span class=\"line\">82</span><br><span class=\"line\">83</span><br><span class=\"line\">84</span><br><span class=\"line\">85</span><br><span class=\"line\">86</span><br><span class=\"line\">87</span><br><span class=\"line\">88</span><br><span class=\"line\">89</span><br><span class=\"line\">90</span><br><span class=\"line\">91</span><br><span class=\"line\">92</span><br><span class=\"line\">93</span><br><span class=\"line\">94</span><br><span class=\"line\">95</span><br><span class=\"line\">96</span><br><span class=\"line\">97</span><br><span class=\"line\">98</span><br><span class=\"line\">99</span><br><span class=\"line\">100</span><br><span class=\"line\">101</span><br><span class=\"line\">102</span><br><span class=\"line\">103</span><br><span class=\"line\">104</span><br><span class=\"line\">105</span><br><span class=\"line\">106</span><br><span class=\"line\">107</span><br><span class=\"line\">108</span><br><span class=\"line\">109</span><br><span class=\"line\">110</span><br><span class=\"line\">111</span><br><span class=\"line\">112</span><br><span class=\"line\">113</span><br><span class=\"line\">114</span><br><span class=\"line\">115</span><br><span class=\"line\">116</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\"><span class=\"keyword\">import</span> pandas <span class=\"keyword\">as</span> pd</span><br><span class=\"line\"><span class=\"keyword\">from</span> sklearn.utils <span class=\"keyword\">import</span> shuffle</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 数据加载</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">read_fa</span><span class=\"params\">(file, mode=<span class=\"string\">'train'</span>)</span>:</span></span><br><span class=\"line\">    <span class=\"keyword\">assert</span> mode <span class=\"keyword\">in</span> &#123;<span class=\"string\">'train'</span>,<span class=\"string\">'test'</span>&#125;</span><br><span class=\"line\">    labels = []</span><br><span class=\"line\">    seqs_info = []</span><br><span class=\"line\">    cates_id = []</span><br><span class=\"line\">    seq = <span class=\"string\">''</span></span><br><span class=\"line\">    <span class=\"keyword\">with</span> open(file,mode=<span class=\"string\">'r'</span>) <span class=\"keyword\">as</span> f:</span><br><span class=\"line\">        line = f.readline().strip()</span><br><span class=\"line\">        <span class=\"keyword\">while</span> line:</span><br><span class=\"line\">            <span class=\"keyword\">if</span> line[<span class=\"number\">0</span>]==<span class=\"string\">'&gt;'</span>:</span><br><span class=\"line\">                info = line[<span class=\"number\">1</span>:].split(<span class=\"string\">' '</span>)</span><br><span class=\"line\">                cates_id.append(info[<span class=\"number\">0</span>])</span><br><span class=\"line\">                <span class=\"keyword\">if</span> mode == <span class=\"string\">'train'</span>:</span><br><span class=\"line\">                    label = <span class=\"string\">''</span>.join(info[<span class=\"number\">1</span>].split(<span class=\"string\">'.'</span>)[:<span class=\"number\">2</span>]</span><br><span class=\"line\">                    label = label[<span class=\"number\">0</span>]+<span class=\"string\">'.'</span>+label[<span class=\"number\">1</span>:]</span><br><span class=\"line\">                    labels.append(label)</span><br><span class=\"line\">                <span class=\"keyword\">if</span> seq:</span><br><span class=\"line\">                    seqs_info.append(seq)</span><br><span class=\"line\">                    seq = <span class=\"string\">''</span></span><br><span class=\"line\">            <span class=\"keyword\">else</span>:</span><br><span class=\"line\">                seq += line</span><br><span class=\"line\">            line = f.readline().strip()</span><br><span class=\"line\">        seqs_info.append(seq)</span><br><span class=\"line\">    </span><br><span class=\"line\">    <span class=\"keyword\">return</span> cates_id,seqs_info,labels</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">load_data</span><span class=\"params\">()</span>:</span></span><br><span class=\"line\">    train_file = <span class=\"string\">'/kaggle/input/textfiles/astral_train.fa'</span></span><br><span class=\"line\">    test_file = <span class=\"string\">'/kaggle/input/textfiles/astral_test.fa'</span></span><br><span class=\"line\"></span><br><span class=\"line\">    train_sample_id, train_seqs_info, train_labels = read_fa(train_file, mode=<span class=\"string\">'train'</span>)</span><br><span class=\"line\">    test_sample_id, test_seqs_info, _ = read_fa(test_file, mode=<span class=\"string\">'test'</span>)</span><br><span class=\"line\">    </span><br><span class=\"line\">    train_data = &#123;</span><br><span class=\"line\">    <span class=\"string\">'sample_id'</span>: train_sample_id,</span><br><span class=\"line\">    <span class=\"string\">'seq_info'</span>: train_seqs_info,</span><br><span class=\"line\">    <span class=\"string\">'label'</span>: train_labels</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    test_data = &#123;</span><br><span class=\"line\">        <span class=\"string\">'sample_id'</span>: test_sample_id,</span><br><span class=\"line\">        <span class=\"string\">'seq_info'</span>: test_seqs_info,</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">     </span><br><span class=\"line\">    train = pd.DataFrame(data=train_data)</span><br><span class=\"line\">    train = shuffle(train,random_state=<span class=\"number\">2021</span>).reset_index(drop=<span class=\"literal\">True</span>)</span><br><span class=\"line\">    test = pd.DataFrame(data=test_data)</span><br><span class=\"line\">    </span><br><span class=\"line\">    <span class=\"keyword\">return</span> train,test</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 滑窗分词</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">split_windows</span><span class=\"params\">(sentence,w = <span class=\"number\">3</span>)</span>:</span></span><br><span class=\"line\">    new_sentence = []</span><br><span class=\"line\">    <span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> range(len(sentence)-w+<span class=\"number\">1</span>):</span><br><span class=\"line\">        new_sentence.append(sentence[i:i+w])</span><br><span class=\"line\">    </span><br><span class=\"line\">    <span class=\"keyword\">return</span> new_sentence</span><br><span class=\"line\">     </span><br><span class=\"line\">data = pd.concat(load_data(),ignore_index=<span class=\"literal\">True</span>)</span><br><span class=\"line\"><span class=\"comment\"># label to idx</span></span><br><span class=\"line\">label2idx = &#123; l:idx <span class=\"keyword\">for</span> idx, l <span class=\"keyword\">in</span> enumerate(data[~data[<span class=\"string\">'label'</span>].isna()][<span class=\"string\">'label'</span>].unique().tolist())&#125;</span><br><span class=\"line\">idx2label = &#123; idx:l <span class=\"keyword\">for</span> l,idx <span class=\"keyword\">in</span> label2idx.items()&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">data[<span class=\"string\">'label'</span>] = data[<span class=\"string\">'label'</span>].map(label2idx)</span><br><span class=\"line\">data[<span class=\"string\">'new_seq_info'</span>] = data[<span class=\"string\">'seq_info'</span>].apply(<span class=\"keyword\">lambda</span> x:split_windows(x,w = <span class=\"number\">1</span>))</span><br><span class=\"line\">train,test = data[~data[<span class=\"string\">'label'</span>].isna()].reset_index(drop=<span class=\"literal\">True</span>),data[data[<span class=\"string\">'label'</span>].isna()].reset_index(drop=<span class=\"literal\">True</span>)</span><br><span class=\"line\">max_features= <span class=\"number\">1000</span></span><br><span class=\"line\">max_len= <span class=\"number\">256</span></span><br><span class=\"line\">embed_size=<span class=\"number\">128</span></span><br><span class=\"line\">batch_size = <span class=\"number\">24</span></span><br><span class=\"line\">epochs = <span class=\"number\">50</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">from</span> keras.preprocessing.text <span class=\"keyword\">import</span> Tokenizer</span><br><span class=\"line\"><span class=\"keyword\">from</span> keras.preprocessing <span class=\"keyword\">import</span> sequence</span><br><span class=\"line\"></span><br><span class=\"line\">tokens = Tokenizer(num_words = max_features)</span><br><span class=\"line\">tokens.fit_on_texts(list(data[<span class=\"string\">'new_seq_info'</span>]))</span><br><span class=\"line\"></span><br><span class=\"line\">x_data = tokens.texts_to_sequences(data[<span class=\"string\">'new_seq_info'</span>])</span><br><span class=\"line\">x_data = sequence.pad_sequences(x_data, maxlen=max_len)</span><br><span class=\"line\">x_train = x_data[:<span class=\"number\">9472</span>]</span><br><span class=\"line\">y_train = data[<span class=\"string\">'label'</span>][:<span class=\"number\">9472</span>]</span><br><span class=\"line\">x_test = x_data[<span class=\"number\">9472</span>:]</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">from</span> keras.layers <span class=\"keyword\">import</span> Dense,Input,LSTM,Bidirectional,Activation,Conv1D,GRU</span><br><span class=\"line\"><span class=\"keyword\">from</span> keras.layers <span class=\"keyword\">import</span> Dropout,Embedding,GlobalMaxPooling1D, MaxPooling1D, Add, Flatten</span><br><span class=\"line\"><span class=\"keyword\">from</span> keras.layers <span class=\"keyword\">import</span> GlobalAveragePooling1D, GlobalMaxPooling1D, concatenate, SpatialDropout1D<span class=\"comment\"># Keras Callback Functions:</span></span><br><span class=\"line\"><span class=\"keyword\">from</span> keras.callbacks <span class=\"keyword\">import</span> Callback</span><br><span class=\"line\"><span class=\"keyword\">from</span> keras.callbacks <span class=\"keyword\">import</span> EarlyStopping,ModelCheckpoint</span><br><span class=\"line\"><span class=\"keyword\">from</span> keras <span class=\"keyword\">import</span> initializers, regularizers, constraints, optimizers, layers, callbacks</span><br><span class=\"line\"><span class=\"keyword\">from</span> keras.models <span class=\"keyword\">import</span> Model</span><br><span class=\"line\"><span class=\"keyword\">from</span> keras.optimizers <span class=\"keyword\">import</span> Adam</span><br><span class=\"line\"><span class=\"keyword\">import</span> keras</span><br><span class=\"line\">sequence_input = Input(shape=(max_len, ))</span><br><span class=\"line\">x = Embedding(max_features, embed_size, trainable=<span class=\"literal\">True</span>)(sequence_input)</span><br><span class=\"line\">x = SpatialDropout1D(<span class=\"number\">0.2</span>)(x)</span><br><span class=\"line\">x = Bidirectional(GRU(<span class=\"number\">128</span>, return_sequences=<span class=\"literal\">True</span>,dropout=<span class=\"number\">0.1</span>,recurrent_dropout=<span class=\"number\">0.1</span>))(x)</span><br><span class=\"line\">x = Conv1D(<span class=\"number\">64</span>, kernel_size = <span class=\"number\">3</span>, padding = <span class=\"string\">\"valid\"</span>, kernel_initializer = <span class=\"string\">\"glorot_uniform\"</span>)(x)</span><br><span class=\"line\">avg_pool = GlobalAveragePooling1D()(x)</span><br><span class=\"line\">max_pool = GlobalMaxPooling1D()(x)</span><br><span class=\"line\">x = concatenate([avg_pool, max_pool]) </span><br><span class=\"line\">preds = Dense(<span class=\"number\">245</span>)(x)</span><br><span class=\"line\"></span><br><span class=\"line\">model = Model(sequence_input, preds)</span><br><span class=\"line\">model.compile(loss=keras.losses.SparseCategoricalCrossentropy(from_logits=<span class=\"literal\">True</span>),</span><br><span class=\"line\">              optimizer=keras.optimizers.Adam(<span class=\"number\">1e-3</span>),</span><br><span class=\"line\">              metrics=[<span class=\"string\">'accuracy'</span>])</span><br><span class=\"line\">model.fit(x_train, y_train, </span><br><span class=\"line\">          batch_size=batch_size, </span><br><span class=\"line\">          validation_split=<span class=\"number\">0.2</span>,</span><br><span class=\"line\">          epochs=epochs)</span><br></pre></td></tr></table></figure>\n<p>提交结果：目前【39/130(提交团队数)】</p>\n<p><img src=\"/articles/%E8%9B%8B%E7%99%BD%E8%B4%A8%E7%BB%93%E6%9E%84%E9%A2%84%E6%B5%8B/image-20210730140527003.png\" alt=\"image-20210730140527003\"></p>\n","categories":[],"tags":["BDC"]},{"title":"Attention-Is-All-You-Need","url":"https://hahally.github.io//articles/Attention-Is-All-You-Need/","content":"<blockquote>\n<p><a href=\"https://papers.nips.cc/paper/2017/file/3f5ee243547dee91fbd053c1c4a845aa-Paper.pdf\" target=\"_blank\" rel=\"noopener\">Attention Is All You Need</a></p>\n<p>“懂的都懂”</p>\n</blockquote>\n<p><strong>Bib TeX</strong></p>\n<blockquote>\n<p>@inproceedings{NIPS2017_3f5ee243,<br>author = {Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, \\L ukasz and Polosukhin, Illia},<br>booktitle = {Advances in Neural Information Processing Systems},<br>editor = {I. Guyon and U. V. Luxburg and S. Bengio and H. Wallach and R. Fergus and S. Vishwanathan and R. Garnett},<br>pages = {},<br>publisher = {Curran Associates, Inc.},<br>title = {Attention is All you Need},<br>url = {<a href=\"https://proceedings.neurips.cc/paper/2017/file/3f5ee243547dee91fbd053c1c4a845aa-Paper.pdf}\" target=\"_blank\" rel=\"noopener\">https://proceedings.neurips.cc/paper/2017/file/3f5ee243547dee91fbd053c1c4a845aa-Paper.pdf}</a>,<br>volume = {30},<br>year = {2017}<br>}</p>\n</blockquote>\n<h3 id=\"前言\"><a href=\"#前言\" class=\"headerlink\" title=\"前言\"></a>前言</h3><p><em>Attention is All you Need</em> 这篇论文是Google的又一神作。传统的 encoder-decoder序列转化模型架构主要以卷积和循环神经网络为基础。在引入 attention 后，其模型效果达到最佳。除了 <strong>cnn</strong> 或 <strong>rnn</strong> 进行编码解码，Google团队提出了一个更加简单有效的模型，即大名鼎鼎的  <strong>transformer</strong> 。正如论文标题所说，该模型的encoder和decoder都将基于attention机制实现。</p>\n<blockquote>\n<p> We propose a new simple network architecture, the Transformer,based solely on attention mechanisms, dispensing with recurrence and convolutions entirely.</p>\n</blockquote>\n<p>【PS：想来<em>simple</em> 一词 似乎有些凡尔赛的意味，正所谓大道至简，用在这篇论文似乎也毫不违和。相比于堆叠卷积层的 <em>cnn</em> 亦或是递归的 <em>rnn</em> 来说，确实 simple。不过标题着实有些“狂”了，可能也只有Google的名气才配的上吧，换做别人估计被喷惨了/滑稽】</p>\n<h3 id=\"模型架构\"><a href=\"#模型架构\" class=\"headerlink\" title=\"模型架构\"></a>模型架构</h3><p><img src=\"/articles/Attention-Is-All-You-Need/image-20210715161152396.png\" alt=\"image-20210715161152396\"></p>\n<p><strong>Encoder</strong></p>\n<p>这一部分由多个(N=6)相同的层堆叠而成。每一层又包括两个子层，对应图中部分。第一个是一个多头自注意力机制[<em>a multi-head self-attention</em>]，第二个是一个全连接的前馈神经网络[a position-wise feed-forward networks]。这两个子层通过残差连接（residual connection ）。所有子层和embedding 层的输出维度都统一为512（便于进行残差连接）。</p>\n<p><strong>Decoder</strong></p>\n<p>同样地，解码器也由多个(N=6)相同的层堆叠而成。每层包括三个子层。在编码器的子层基础上增加了一个<em>masked multi-head self-attention</em> 。三个子层通过残差连接起来。</p>\n<h3 id=\"Attention\"><a href=\"#Attention\" class=\"headerlink\" title=\"Attention\"></a>Attention</h3><p>论文中对 attention定义如下：</p>\n<script type=\"math/tex; mode=display\">\nAttention(Q,K,V) = softmax(\\frac{QK^T}{\\sqrt{d_k}})V</script><p>Q, k, V即quary、key、value对应的向量。$Q\\in R^{n\\times d_k},K\\in R^{m\\times d_k},V\\in R^{d_v}$。</p>\n<p>两种常见的注意力机制是：additive attention 和 dot-product attention ，显然从公式中可见使用的是后者。其中$\\sqrt{d_k}$ 起到了缩放的作用，使得softmax能更好的work。并且命名为 Scaled Dot-Product Attention：</p>\n<p><img src=\"/articles/Attention-Is-All-You-Need/image-20210715171719397.png\" alt=\"image-20210715171719397\"></p>\n<p><strong>Multi-Head Attention</strong></p>\n<p><img src=\"/articles/Attention-Is-All-You-Need/image-20210715172114776.png\" alt=\"image-20210715172114776\"></p>\n<p>Multi-Head Attention其实就是多个Scaled Dot-Product Attention并行，然后将结果 concat 拼接。从公式来看：</p>\n<script type=\"math/tex; mode=display\">\nMultiHead(Q,K,V)=Concat(head_1,...,head_h)W^O\\\\\nHead_i = Attention(QW_i^Q,KW_i^K,VW_i^V)</script><p>其中，$W_i^Q\\in R^{d_{model}\\times d_k},W_i^K\\in R^{d_{model}\\times d_k},W_i^V\\in R^{d_{model}\\times d_v},W^O\\in R^{hd_v\\times d_{model}}$ 。本文采用的self-attention，即取Q，K，V相同。</p>\n<h3 id=\"Position-wise-Feed-Forward-Networks\"><a href=\"#Position-wise-Feed-Forward-Networks\" class=\"headerlink\" title=\"Position-wise Feed-Forward Networks\"></a>Position-wise Feed-Forward Networks</h3><p>进行非线性变换：也就是 linear 后面加个 ReLU而已。</p>\n<script type=\"math/tex; mode=display\">\nFFN(X)=max(0,xW_1+b_1)W_2+b_2</script><blockquote>\n<p>While the linear transformations are the same across different positions, they use different parameters from layer to layer.   Another way of describing this is as two convolutions with kernel size 1.</p>\n</blockquote>\n<p>【PS：Another way of describing this is as <em>two convolutions with kernel size 1</em> /惊！看来还是有借鉴cnn的卷积思想嘛。/滑稽】</p>\n<h3 id=\"Positional-Encoding\"><a href=\"#Positional-Encoding\" class=\"headerlink\" title=\"Positional Encoding\"></a>Positional Encoding</h3><p>这一部分的作用就是为了引入序列中的顺序信息，或者说位置信息。positional encodings（位置编码） 与input embeddings（如：词向量） 具有相同的维度$d_{model}$ 。通过将两向量相加，从而将对应的位置信息嵌入进去。位置编码的方式如下：</p>\n<script type=\"math/tex; mode=display\">\nPE(pos,2i)=sin(pos/10000^{2i/d_{model}})\\\\\nPE(pos,2i+1)=cos(pos/10000^{2i/d_{model}})</script><p>其中，$pos$ 表示位置，$i$ 是维度，这样，每个位置编码都对应一个正弦信号。</p>\n<h3 id=\"总结\"><a href=\"#总结\" class=\"headerlink\" title=\"总结\"></a>总结</h3><p>抛弃cnn和rnn后，仅仅使用attention显然是不够的，为了捕获输入序列中词向量之间的前后位置信息，不得不引入Positional Encoding。不过很好解决了传统encoder-decoder无法并行训练的问题。因此，transformer 训练速度要快得多。transformer模型在nlp任务上的非凡表现，也引来了其他人将其应用在其他任务上的思考，目前在其他领域上，也出现了各种花里胡哨的transformer改版。</p>\n<p><a href=\"https://github.com/tensorflow/tensor2tensor\" target=\"_blank\" rel=\"noopener\">官方开源代码</a></p>\n<p>这里给上苏神大佬对《Attention is All You Need》的解读：<a href=\"https://kexue.fm/archives/4765\" target=\"_blank\" rel=\"noopener\">《Attention is All You Need》浅读（简介+代码） - 科学空间|Scientific Spaces (kexue.fm)</a></p>\n","categories":[],"tags":["paper reading"]},{"title":"基于注意力机制的神经机器翻译的有效方法","url":"https://hahally.github.io//articles/基于注意力机制的神经机器翻译的有效方法/","content":"<blockquote>\n<p><a href=\"https://aclanthology.org/D15-1166/\" target=\"_blank\" rel=\"noopener\">Effective Approaches to Attention-based Neural Machine Translation</a></p>\n<p>基于注意力机制的神经机器翻译的有效方法</p>\n</blockquote>\n<p><strong>Bib TeX</strong></p>\n<blockquote>\n<p>@inproceedings{luong-etal-2015-effective,<br> title = “Effective Approaches to Attention-based Neural Machine Translation”,<br> author = “Luong, Thang  and<br>   Pham, Hieu  and<br>   Manning, Christopher D.”,<br> booktitle = “Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing”,<br> month = sep,<br> year = “2015”,<br> address = “Lisbon, Portugal”,<br> publisher = “Association for Computational Linguistics”,<br> url = “<a href=\"https://aclanthology.org/D15-1166\" target=\"_blank\" rel=\"noopener\">https://aclanthology.org/D15-1166</a>“,<br> doi = “10.18653/v1/D15-1166”,<br> pages = “1412—1421”,<br>}</p>\n</blockquote>\n<h3 id=\"abstract\"><a href=\"#abstract\" class=\"headerlink\" title=\"abstract\"></a>abstract</h3><p>在神经机器翻译中引入注意力机制(Attention)，使模型在翻译过程中选择性的关注句子中的某一部分。本文研究了两种简单有效的注意力机制。</p>\n<ul>\n<li>a global approach which always attends to all source words【全局方法，每次关注所有源词】</li>\n<li>a local one that only looks at a subset of source words at a time【局部方法，每次关注原词的一个子集】</li>\n</ul>\n<p><em>global attention</em> 类似方法<strong>[1]</strong>，但架构上更加简单。<em>local attention</em> 更像是 <em>hard and soft attention</em> <strong>[2]</strong>的结合。两种方法在英德语双向翻译任务中取得了不错的成绩。与已经结合了已知技术（例如 dropout）的非注意力系统相比，高了5.0个BLEU点。在WMT’15英语到德语的翻译任务中表现 SOTA（state-of-the-art）。</p>\n<blockquote>\n<p>With local attention, we achieve a significant gain of　5.0 BLEU points over non-attentional systems that already incorporate known techniques such as dropout. Our ensemble model using different attention architectures yields a new state-of-the-art result in the WMT’15 English to German translation task with 25.9 BLEU points, an improvement of 1.0 BLEU points over the existing best system backed by NMT and an n-gram reranker.</p>\n</blockquote>\n<h3 id=\"Neural-Machine-Translation\"><a href=\"#Neural-Machine-Translation\" class=\"headerlink\" title=\"Neural Machine Translation\"></a>Neural Machine Translation</h3><p>模型结构：</p>\n<p><img src=\"/articles/%E5%9F%BA%E4%BA%8E%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6%E7%9A%84%E7%A5%9E%E7%BB%8F%E6%9C%BA%E5%99%A8%E7%BF%BB%E8%AF%91%E7%9A%84%E6%9C%89%E6%95%88%E6%96%B9%E6%B3%95/image-20210712173309790.png\" alt=\"image-20210712173309790\"></p>\n<p>采用堆叠的 <em>LSTM</em>结构<strong>[3]</strong>。其目标函数为：</p>\n<script type=\"math/tex; mode=display\">\nJ_t = \\sum_{(x,y)\\in D}-logP(y|x)</script><p>D为训练的语料。x 表示源句子，y表示翻译后的目标句子。</p>\n<h3 id=\"Attention-based-Models\"><a href=\"#Attention-based-Models\" class=\"headerlink\" title=\"Attention-based Models\"></a>Attention-based Models</h3><p>这部分包括两种注意力机制：global 和 local。两种方式在解码阶段，将使用堆叠LSTM顶层的隐藏状态 $h_t$ 作为输入。区别在于获取上下文向量表示$c_t$方法不同。然后通过一个 简单的 <em>concatenate layer</em> 获得一个注意力隐藏状态$\\hat h_t$:</p>\n<script type=\"math/tex; mode=display\">\n\\hat h_t = tanh(W_c[c_t;h_t])</script><p>最后通过 <em>softmax layer</em> 得出预测概率分布:</p>\n<script type=\"math/tex; mode=display\">\np(y_t|y<t,x)=softmax(W_s\\hat h_t)</script><p><strong>Global Attention</strong></p>\n<p><img src=\"/articles/%E5%9F%BA%E4%BA%8E%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6%E7%9A%84%E7%A5%9E%E7%BB%8F%E6%9C%BA%E5%99%A8%E7%BF%BB%E8%AF%91%E7%9A%84%E6%9C%89%E6%95%88%E6%96%B9%E6%B3%95/image-20210712174342526.png\" alt=\"image-20210712174342526\"></p>\n<p>主要思想是通过编码器的所有隐藏状态(hidden state)来获取上下文向量(context vector)表示 $c_t$。可变长度对齐向量$a_t$通过比较当前目标隐藏状态$h_t$和每个源隐藏状态$\\overline h_s$得到：</p>\n<script type=\"math/tex; mode=display\">\na_t(s) = align(h_t,\\overline h_s)=\\frac{exp(score(h_t,\\overline h_s))}{\\sum_{s'}exp(h_t,\\overline h_{s^{'}})}</script><p>score被称为 <em>content-based</em> 函数：</p>\n<script type=\"math/tex; mode=display\">\nscore(h_t,\\overline h_s)=\\begin{cases}\nh_t^{T}\\overline h_s, dot\\\\\nh_t^{T}W_a\\overline h_s, general\\\\\nW_a[h_t;\\overline h_s], concat\n\\end{cases}</script><p>与<strong>[1]</strong>的区别在于：</p>\n<ul>\n<li>只在编码器和解码器的顶部使用隐藏状态</li>\n<li>计算路径更加简单：$h_t-&gt;a_t-&gt;c_t-&gt;\\hat h_t$</li>\n</ul>\n<p><strong>Local Attention</strong></p>\n<p>global 模式下，模型需要关注全局信息，其代价是非常大的。因此也就出现了 local attention。让注意力机制只去关注其中的一个子集部分。<em>其灵感来自于</em> <strong>[2]</strong>。</p>\n<p><img src=\"/articles/%E5%9F%BA%E4%BA%8E%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6%E7%9A%84%E7%A5%9E%E7%BB%8F%E6%9C%BA%E5%99%A8%E7%BF%BB%E8%AF%91%E7%9A%84%E6%9C%89%E6%95%88%E6%96%B9%E6%B3%95/image-20210712185709989.png\" alt=\"image-20210712185709989\"></p>\n<p>对比两张模型图来看，其中的局部对齐权重$a_t$由一部分局部隐藏状态计算得到，其长度变成了固定的，并且还多了一个Aligned position $p_t$ ，然后上下文向量(context vector) $c_t$ 由窗口$[p_t-D,p_t+D]$内的隐藏状态集合的加权平均得到。<em>其中D根据经验所得</em>。</p>\n<p>考虑两种变体：</p>\n<ul>\n<li><p>Monotonic alignment (local-m)</p>\n<p>即简单设置 $p_t = t$ ，认为源序列于目标序列是单调对齐的，那么$a_t$ 其实就和公式（4）计算方法一样了。</p>\n</li>\n<li><p>Predictive alignment (local-p)</p>\n<p>$p_t=S·sigmoid(v_p^{T}tanh(W_ph_t))$ ，$v_p$和$W_p$是预测$p_t$ 的模型参数。S为源句子长度。最后$p_t\\in [0,S]$ 。同时为了使对齐点更靠近$p_t$，设置一个以$p_t$为中心 的高斯分布，即$a_t$ 为：$a_t(s)=align(h_t,\\overline h_s)exp(-\\frac{(s-p_t)^2}{2\\sigma^2}),\\sigma=\\frac{D}{2}$，s为高斯分布区间内的一个整数。</p>\n</li>\n</ul>\n<h3 id=\"Input-feeding-Approach\"><a href=\"#Input-feeding-Approach\" class=\"headerlink\" title=\"Input-feeding Approach\"></a>Input-feeding Approach</h3><p>这一部分，主要是为了捕获在翻译过程中哪些源单词已经被翻译过了。对齐决策应当综合考虑过去对齐的信息。该方法将注意力向量$\\hat h_t$ 作为下一个时间步的输入。主要有两个作用：</p>\n<ul>\n<li>希望模型充分关注到先前的对齐信息</li>\n<li>创建一个在水平和垂直方向上都很深的网络</li>\n</ul>\n<h3 id=\"总结\"><a href=\"#总结\" class=\"headerlink\" title=\"总结\"></a>总结</h3><p>整篇论文看下来，大概就是在别人的baseline中引入注意力机制（global and local），然后使用<em>Input-feeding</em> 方法将过去的对齐信息考虑进来（大概就是加入了一个先验知识吧）。【PS：震惊！这些创新的点的灵感都来自其让人的论文中的方法。】</p>\n<p>最后手动滑稽：</p>\n<blockquote>\n<p>Attention is all you need!</p>\n</blockquote>\n<h3 id=\"References\"><a href=\"#References\" class=\"headerlink\" title=\"References\"></a>References</h3><p>[1] Dzmitry Bahdanau, Kyunghyun Cho, and Yoshua Bengio.  2015. Neural machine translation by jointly learning to align and translate. InICLR.</p>\n<p>[2] Kelvin Xu,  Jimmy Ba,  Ryan Kiros,  Kyunghyun Cho, Aaron C. Courville, Ruslan Salakhutdinov, Richard S. Zemel, and Yoshua Bengio. 2015. Show,attend and tell: Neural image caption generation with visual attention. InICML.</p>\n<p>[3] Wojciech Zaremba, Ilya Sutskever, and Oriol Vinyals. 2015. Recurrent neural network regularization. InICLR.</p>\n","categories":[],"tags":["paper reading"]},{"title":"sequence-to-sequence-learning-with-neural-networks","url":"https://hahally.github.io//articles/sequence-to-sequence-learning-with-neural-networks/","content":"<blockquote>\n<p><a href=\"https://papers.nips.cc/paper/2014/file/a14ac55a4f27472c5d894ec1c3c743d2-Paper.pdf\" target=\"_blank\" rel=\"noopener\">Sequence to Sequence Learning with Neural Networks</a></p>\n<p>基于神经网络的seq2seq</p>\n</blockquote>\n<p>很好的解决了序列到序列之间的映射问题，在语音识别和机器翻译这种长度未知且具有顺序的问题能够得到很好的解决。该模型应用到英语到法语的翻译任务，数据集来自WMT’14，在整个测试集上的BLEU得到达到34.8。</p>\n<p>模型结构：</p>\n<p><img src=\"/articles/sequence-to-sequence-learning-with-neural-networks/image-20210710154526137.png\" alt=\"image-20210710154526137\"></p>\n<p>这里使用了两个串联的 lstm 网络，前一个用于读取输入序列，产生一个大的固定维度的向量表示，然后再用一个lstm 网络从向量表示中提取输出序列。一个编码器(Encoder)，一个解码器(Decoder)。</p>\n<p>值得注意的是，论文提到在实现时，有三点与 lstm 不一样。【Our actual models differ from the above description in three important ways.】</p>\n<ul>\n<li>使用两个不同的lstm</li>\n<li>4层 lstm</li>\n<li>将输入序列进行反转【a,b,c —&gt; c,b,a】【PS： 这就是传说中的反向操作吗？！莫名其妙的trick，滑稽.jpg】</li>\n</ul>\n<p>目标函数：</p>\n<script type=\"math/tex; mode=display\">\n\\frac{1}{|S|}\\sum_{(T,S)\\in S}logP(T|S)</script><p>S为训练集，T表示正确的翻译。训练结束后，进行翻译时，在模型产生的多个翻译结果中找到最可能正确的翻译：</p>\n<script type=\"math/tex; mode=display\">\n\\hat T = \\mathop{argmax}_{T}P(T|S)</script><p>通过一个简单的 <em>left-to-right beam search</em> 解码器(decoder)搜索最可能的翻译。</p>\n<blockquote>\n<p>We search for the most likely translation using a simple left-to-right beam search decoder which maintains a small number B of partial hypotheses, where a partial hypothesis is a prefix of some translation. At each timestep we extend each partial hypothesis in the beam with every possible word in the vocabulary. This greatly increases the number of the hypotheses so we discard all but the B most likely hypotheses according to the model’s log probability. As soon as the “<EOS>“ symbol is appended to a hypothesis, it is removed from the beam and is added to the set of complete hypotheses. While this decoder is approximate, it is simple to implement. Interestingly, our system performs well even with a beam size of 1, and a beam of size 2 provides most of the benefits of beam search(Table 1).</EOS></p>\n</blockquote>\n<p><strong>一个小的总结</strong></p>\n<p>总的来说， <em>Reversing the Source Sentences</em> 这个操作给模型带来了很大的提升。</p>\n<blockquote>\n<p>the LSTM’s test perplexity dropped from 5.8 to 4.7, and the test BLEU scores of its decoded translations increased from 25.9 to 30.6.</p>\n</blockquote>\n<p>至于为什么，论文中也没有给出很好的解释（大概是说，反转后，前面源句子的前几个词与目标句子的前几个词距离更近，模型能更好收敛。【a,b,c |w,x,y—&gt; c,b,a|w,x,y】w,x,y为a,b,c对应的翻译，反转后，a,b,c与w,x,y的平均距离不变，a离w更近了。但是c离y更远却没有影响模型精度。可能这就是玄学吧？！）。【PS：难道是因为误打误撞的尝试然后发现效果惊人，然后就发论文了？不过这篇论文确实奠定了之后的seq2seq模型的基础。】</p>\n","categories":[],"tags":["paper reading"]},{"title":"Lost-in-just-the-translation","url":"https://hahally.github.io//articles/Lost-in-just-the-translation/","content":"<blockquote>\n<p>Lost in just the translation</p>\n</blockquote>\n<h3 id=\"摘要\"><a href=\"#摘要\" class=\"headerlink\" title=\"摘要\"></a>摘要</h3><p>本文介绍了自然语言翻译文本信息隐藏系统的设计与实现，并给出了实验结果。与前人的工作不同，本文提出的协议<strong>只需要翻译文本就可以恢复隐藏信息</strong>。这是一个重大的改进，因为传输源文本既浪费资源又不安全。现在，系统的安全性得到了改善，这不仅是因为源文本不再对敌方有用，还因为现在可以使用更广泛的防御系统(如混合人机翻译)。</p>\n<h3 id=\"协议\"><a href=\"#协议\" class=\"headerlink\" title=\"协议\"></a>协议</h3><p><img src=\"/articles/Lost-in-just-the-translation/image-20210709214343204.png\" alt=\"image-20210709214343204\"></p>\n<ul>\n<li><p>Producing translations</p>\n<p>方法大致与论文【Translation-Based Steganography】中提到的一样</p>\n</li>\n<li><p>Tokenization</p>\n<p>双方使用相同的 Tokenization 算法，以获得相同的句子序列</p>\n</li>\n<li><p>Choosing h</p>\n<p>选择合适的 h ($h \\ge 0$)，h表示将信息隐藏在每个句子中的长度的位数。</p>\n</li>\n<li><p>Selecting translations</p>\n<p>对于所有翻译，编码器首先使用与接收方共享的密钥计算每个翻译的加密键值散列。其基本思想是在给定句子的所有译文中选择一个句子，然后对其进行适当的长度编码，并在隐藏的信息中选择合适的位置。然而，由于给定句子中的位编码数量是可变的，因此该算法在这方面有很大的自由度。</p>\n</li>\n<li><p>Optimized Handling of Hash Collisions</p>\n<p>哈希冲突的处理优化</p>\n</li>\n</ul>\n<h3 id=\"总结\"><a href=\"#总结\" class=\"headerlink\" title=\"总结\"></a>总结</h3><p>为了不传输源文本，从而，引入了哈希映射和 Tokenization以及参数 h。产生翻译文本过程中混合人机翻译结果，使得隐藏的信息更加难以检测。</p>\n","categories":[],"tags":["paper reading"]},{"title":"基于翻译的隐写术","url":"https://hahally.github.io//articles/基于翻译的隐写术/","content":"<blockquote>\n<p><a href=\"https://dl.acm.org/doi/10.1007/11558859_17\" target=\"_blank\" rel=\"noopener\">Translation-Based Steganography</a></p>\n<p>基于翻译的隐写术</p>\n</blockquote>\n<h3 id=\"abstract\"><a href=\"#abstract\" class=\"headerlink\" title=\"abstract\"></a>abstract</h3><p>这篇论文研究了用隐写术在自然语言文档自动翻译产生的噪音(“noise”)中隐藏信息的可能性。由于自然语言固有的冗余性为翻译的变化创造了足够的空间，因此机器翻译非常适合隐写。此外，因为在自动文本翻译中经常出现错误，信息隐藏机制插入的额外错误就很难检测出来，看起来就像是翻译过程中产生的正常噪音的一部分。正因如此，我们是很难确定翻译中的不准确是由隐写术的使用还是由翻译软件的缺陷造成的。</p>\n<h3 id=\"introduction\"><a href=\"#introduction\" class=\"headerlink\" title=\"introduction\"></a>introduction</h3><p>本文提出了一种用于自然语言文本中的隐蔽消息传输的新协议，为此我们有一个概念验证(proof-of-concept )实现。关键点就是将信息隐藏在自然语言翻译中经常出现的噪音中。在一对自然语言之间翻译[non-trivial]文本时，通常有许多可能的翻译结果。【大概意思应该是在不改变原文意思的情况下，翻译的结果是多种多样的】。选择这些翻译结果之一就可用于对信息进行编码。一个 <em>adversary</em> 要想检测出其中隐藏的信息，就必须明白包含隐藏信息的翻译是不可能由普通翻译生成的。由于翻译过程中本就夹杂一些噪声，这使得检测隐藏信息是十分困难的。例如，由于同义词的存在，在对原文进行翻译的过程中，使用同义词进行替换。随着翻译结果的增加，也增加了信息隐藏的可能性。</p>\n<p>本文评估了使用自动机器翻译 (MT) 的自然语言翻译中隐蔽消息传输的潜在性。为了描述在机器翻译中的哪种变化是合理的，我们研究了各种 MT 系统产生的不同类型的错误。在机器翻译中观察到的一些变化对于人工翻译也显然是合理的。除了让 <em>adversary</em> 难以检测到隐藏信息的存在之外，基于翻译的隐写术也更容易使用。与之前的基于文本、图像和声音的隐写系统不一样，基于翻译的隐写，其 <em>cover</em> 是不需要保密的【the cover does not have to be secret.】。在基于翻译的隐写术中，源语言的原始文本可以是公开的，可以从公共资源中获取，并与译文一起，在<em>adversary</em>的视线范围内，在两方之间进行交换。在传统的图像隐写术中，经常出现的问题是，随后隐藏消息的源图像必须由发送者保密并且只使用一次（否则“diff”攻击将揭示隐藏消息的存在）。这增加了用户为每条消息创建新的秘密封面(secret cover)【周杰伦的专辑《不能说的秘密》？！滑稽脸.jpg】的负担。</p>\n<blockquote>\n<p> In translation-based steganography, the original text in the source language can be publically known, obtained from public sources, and, together with the translation, exchanged between the two parties in plain sight of the adversary. In traditional image steganography, the problem often occurs that the source image in which the message is subsequently hidden must be kept secret by the sender and used only once (as otherwise a “diff” attack would reveal the presence of a hidden message). This burdens the user with creating a new, secret cover for each message.</p>\n</blockquote>\n<p>基于翻译的隐写术没有这个缺点，因为对手无法对翻译应用差异分析来检测隐藏的消息。对手可能会生成原始消息的翻译，但无论使用隐写术，翻译可能会有所不同，使得差异分析无法检测隐藏的消息。</p>\n<p>为了证明这一点，我们实现了一个隐写编码器和解码器。该系统通过以类似于在现有 MT 系统中观察到的变化和错误的方式更改机器翻译来隐藏消息。我们的网页上提供了原型的交互式版本。</p>\n<p>在本文的其余结构如下。首先，第 2 节回顾了相关工作。在第 3 节中，描述了隐写交换的基本协议。在第 4 节中，我们给出了现有机器翻译系统中产生的错误的特征。第 5 节概述了实现和一些实验结果。在第 6 节中，我们讨论了基本协议的变体，以及各种攻击和可能的防御。</p>\n<h3 id=\"Related-Work\"><a href=\"#Related-Work\" class=\"headerlink\" title=\"Related Work\"></a>Related Work</h3><h3 id=\"Protocol\"><a href=\"#Protocol\" class=\"headerlink\" title=\"Protocol\"></a>Protocol</h3><p>本文的基本隐写协议工作如下。发件人首先需要获得源语言的封面(cover)。封面不必是保密的(secret)，可以从公共来源获得 ， 例如，新闻网站。然后发送者使用隐写编码器将源文本中的句子翻译成目标语言。隐写编码器本质上为每个句子创建多个翻译，并选择其中之一来对隐藏消息中的位进行编码。然后将翻译后的文本连同足以获得源文本的信息一起发送给接收者。这可以是源文本本身或对源的引用。然后接收者还使用相同的隐写编码器配置执行源文本的翻译。通过比较结果句子，接收者重建隐藏消息的比特流。图 1 说明了基本协议。</p>\n<p><img src=\"/articles/%E5%9F%BA%E4%BA%8E%E7%BF%BB%E8%AF%91%E7%9A%84%E9%9A%90%E5%86%99%E6%9C%AF/image-20210709163311687.png\" alt=\"image-20210709163311687\"></p>\n<h4 id=\"Producing-translations\"><a href=\"#Producing-translations\" class=\"headerlink\" title=\"Producing translations\"></a>Producing translations</h4><p>获取源文本后，发送方和接收方的第一步是使用相同的算法生成源文本的多个翻译。此步骤的目标是确定性地生成源文本的多个不同翻译。实现这一目标的最简单方法是在源文本中的每个句子上应用所有可用 MT 系统的（子集）。如果各方可以完全访问统计 MT 系统的代码，他们可以通过使用不同的语料库训练，从同一代码库生成多个 MT 系统。</p>\n<p>除了使用多个翻译系统生成不同的句子外，还可以对结果翻译应用后处理以获得额外的变化。这种后处理包括模拟任何（MT）翻译中固有噪声的转换。例如，后处理器可以插入常见的翻译错误（如第 4 节所述）。</p>\n<p>由于不同引擎之间的翻译质量不同，并且还取决于应用了哪些后处理器来处理结果，因此翻译系统使用启发式方法为每个翻译分配一个概率，描述其与其他翻译相比的相对质量。启发式可以基于生成器的经验和基于语言模型对句子质量进行排名的算法 。用于生成翻译及其排名的特定翻译引擎、训练语料库和后处理操作集是想要进行秘密通信的两方密钥共享的一部分。</p>\n<h4 id=\"Selecting-a-translation\"><a href=\"#Selecting-a-translation\" class=\"headerlink\" title=\"Selecting a translation\"></a>Selecting a translation</h4><p>选择翻译以对隐藏消息进行编码时，编码器首先使用生成器算法分配的概率构建可用转换的霍夫曼树。然后算法选择与要编码的位序列对应的句子。 </p>\n<p>使用霍夫曼树根据翻译质量估计选择句子可确保较少选择翻译质量较低的句子。此外，所选翻译的质量越低，传输的比特数就越高。</p>\n<p>这减少了所需的封面文本总量，从而减少了对手可以分析的文本量。编码器可以使用相对翻译质量的下限来排除估计翻译质量低于某个阈值的句子，在这种情况下，该阈值成为发送者和接收者之间共享秘密的一部分。</p>\n<h4 id=\"Keeping-the-source-text-secret\"><a href=\"#Keeping-the-source-text-secret\" class=\"headerlink\" title=\"Keeping the source text secret\"></a>Keeping the source text secret</h4><p>所提出的方案可以适用于需要对源文本保密的水印。这可以按如下方式实现。编码器计算每个翻译句子的（加密）哈希。然后它选择一个句子，使得翻译句子的散列的最后一位对应于要传输的隐藏消息中的下一位。 然后解码器只计算接收到的句子的散列码并连接相应的最低位获取隐藏信息。</p>\n<p>该方案假设句子足够长，几乎总是有足够的变化来获得具有所需最低位的散列。每当没有一个句子产生可接受的哈希码时，就必须使用纠错码来纠正错误。使用这种变化会降低编码所能达到的比特率。更多细节可以在我们的技术报告中找到。</p>\n<h3 id=\"Lost-in-Translation\"><a href=\"#Lost-in-Translation\" class=\"headerlink\" title=\"Lost in Translation\"></a>Lost in Translation</h3><p>现代 MT 系统会在翻译中产生许多常见错误。本节描述了其中一些错误的特征。虽然我们描述的错误不是可能错误的完整列表，但它们代表了我们在示例翻译中经常观察到的错误类型。翻译错误的扩展特征可以在我们的技术报告中找到（由于篇幅限制，此处省略）。这些错误中的大多数是由于当代 MT 系统对统计和句法文本分析的依赖造成的，导致缺乏语义和上下文意识。这会产生一系列错误类型，我们可以使用它们来合理地改变文本，从而产生进一步的标记可能性。</p>\n<h4 id=\"Functional-Words\"><a href=\"#Functional-Words\" class=\"headerlink\" title=\"Functional Words\"></a>Functional Words</h4><p>一类经常发生但不破坏意义的错误是功能词翻译不正确，如冠词、代词和介词。因为这些功能词通常与句子中的另一个词或短语有很强的关联，复杂的结构似乎经常会导致这些词的翻译错误。此外，不同的语言对这些词的处理方式非常不同，因此在使用未考虑这些差异的引擎时会导致翻译错误。</p>\n<p>例如，许多使用冠词的语言并不在所有名词前使用它们。这在从文章规则不同的语言翻译时会导致问题。例如，法语句子“La vie est paralysee.”在英语中翻译为“Life is paralyzed.”。然而，翻译引擎可以预见地将其翻译为“The life is paralyzed.”；“life in general”意义上的“life”并没有用出现在一篇英文文章中。这与许多不可数名词如“水”和 “钱”一样，而导致类似的错误。</p>\n<p>通常，介词的正确选择完全取决于句子的上下文。例如，法语中的 $J’habite$ $\\grave{a}$ 100 $m\\grave{e}tres$ $de$ $lui$在英语中的意思是“我住在离他100米的地方”。然而，[20] 将其翻译为“我与他一起生活 100 米”，而 [71]将其翻译为“在他的 100 米处生活”。两者都使用“$\\grave{a}$”（“with/in”）的不同翻译这完全不适合上下文。</p>\n<h4 id=\"Blatant-Word-Choice-Errors\"><a href=\"#Blatant-Word-Choice-Errors\" class=\"headerlink\" title=\"Blatant Word Choice Errors\"></a>Blatant Word Choice Errors</h4><p>不太常见的是，在翻译中选择完全不相关的单词或短语。例如，<em>I’m staying home</em>和<em>I am staying home</em>都被[20]翻译成德语为<em>Ich bleibe Haupt</em>（<em>I’m staying head</em>）而不是<em>Ich bleibe zu Hause</em>。这些不同于语义错误，反映了实际引擎或其字典中的某种缺陷，明显影响了翻译质量。</p>\n<h4 id=\"Additional-Errors\"><a href=\"#Additional-Errors\" class=\"headerlink\" title=\"Additional Errors\"></a>Additional Errors</h4><p>遇到了其他几种有趣的错误类型，由于篇幅原因，我们将只简要介绍这些错误类型。</p>\n<ul>\n<li>基本语法错误导致翻译如<em>It do not work</em></li>\n<li>逐字翻译，尤其是惯用语的翻译，会产生诸如<em>The pencils are at me.</em>这样的结构</li>\n<li>源词典中没有的单词只是不翻译</li>\n<li>语言之间反身结构的不正确映射会导致反身冠词被错误地插入目标翻译中（例如，<em>Ich kamme mich</em>变成了<em>I comb myself</em>）。</li>\n</ul>\n<h4 id=\"Translations-between-Typologically-Dissimilar-Languages\"><a href=\"#Translations-between-Typologically-Dissimilar-Languages\" class=\"headerlink\" title=\"Translations between Typologically Dissimilar Languages\"></a>Translations between Typologically Dissimilar Languages</h4><p>类型学上相距遥远的语言是指形式结构彼此完全不同的语言。这些结构差异体现在许多领域（例如句法（短语和句子结构）、语义（含义结构）和形态（词结构））。毫不奇怪，由于这些差异，在类型上相距遥远的语言（中文和英文、英文和阿拉伯文等）之间的翻译经常很糟糕，以至于不连贯或不可读。我们在这项工作中没有考虑这些语言，因为翻译质量通常很差，结果翻译的交换可能是难以置信的。</p>\n<h3 id=\"Implementation\"><a href=\"#Implementation\" class=\"headerlink\" title=\"Implementation\"></a>Implementation</h3><p>本节描述了实现的一些方面，重点介绍了用于获得生成的翻译变化的不同技术。</p>\n<h4 id=\"Translation-Engines\"><a href=\"#Translation-Engines\" class=\"headerlink\" title=\"Translation Engines\"></a>Translation Engines</h4><p>当前实现使用 Internet 上可用的不同翻译服务来获得初始翻译。当前的实现支持三种不同的服务，我们计划在未来添加更多服务。添加新服务只需要编写一个函数，将给定的句子从源语言翻译成目标语言。应使用可用 MT 服务的哪个子集由用户决定，但必须至少选择一个引擎。</p>\n<p>选择多个不同翻译引擎的一个可能问题是它们可能具有不同的错误特征（例如，一个引擎可能无法翻译带有缩写的单词）。知道特定机器翻译系统存在此类问题的对手可能会发现所有句子中有一半存在与这些特征匹配的错误。由于普通用户不太可能在不同的翻译引擎之间交替，这将揭示隐藏消息的存在。</p>\n<p>更好的选择是使用相同的机器翻译软件，但使用不同的语料库对其进行训练。特定语料库成为隐写编码器使用的密钥的一部分； Victor Raskin 和 Umut Topkara 之前在另一个上下文（[2] 的上下文）中讨论了这种使用语料库作为关键字的情况。因此，对手无法再检测到不同机器翻译算法导致的差异。这种方法的一个问题是获得好的语料库很昂贵。此外，划分单个语料库以生成多个较小的语料库将导致更糟糕的翻译，这可能再次导致可疑文本。也就是说，完全控制翻译引擎还可以允许翻译算法本身的微小变化。例如，GIZA++系统提供了多种计算翻译的算法[9]。这些算法的主要区别在于如何生成翻译“候选结果”。更改这些选项也有助于生成多个翻译。</p>\n<p>从翻译引擎获得一个或多个翻译后，该工具会使用各种后处理算法生成其他变体。只需使用一个高质量的翻译引擎并依靠后处理生成替代翻译，就可以避免使用多个引擎的问题。</p>\n<h4 id=\"Semantic-Substitution\"><a href=\"#Semantic-Substitution\" class=\"headerlink\" title=\"Semantic Substitution\"></a>Semantic Substitution</h4><p>语义替换是一种非常有效的 post-pass，并且已在以前的方法中用于隐藏信息 [2,5]。与以前工作的一个主要区别是，与原始文本中的语义替换相比，由语义替换引起的错误在翻译中更合理。</p>\n<p>传统语义替换的一个典型问题是需要替换列表。替换列表是由语义上足够接近的词组成的元组列表，可以在任意句子中用一个词替换另一个词。对于传统的语义替换，这些列表是手工生成的。语义替换列表中的一对单词的示例将是舒适和方便的。不仅手工构建替换列表很乏味，而且列表中包含的内容也必须是保守的。例如，一般替换列表不能包含诸如明亮和光之类的词对，因为光可以用于不同的意义（意味着轻松、不精确甚至用作名词）。</p>\n<p>翻译的语义替换没有这个问题。使用原始句子，可以自动生成语义替换，甚至可以包含上述某些情况（无法添加到一般单语替换列表中）。基本思想是在两种语言之间来回翻译以找到语义相似的单词。假设翻译是准确的，源语言中的单词可以帮助提供必要的上下文信息，以限制对当前上下文中语义接近的单词的替换。</p>\n<p>假设源语言是德语（d），翻译的目标语言是英语（e）。原始句子包含一个德语单词 d1<br>并且翻译包含一个单词 e1，它是 d1的翻译。基本算法如下，如图2所示：</p>\n<p><img src=\"/articles/%E5%9F%BA%E4%BA%8E%E7%BF%BB%E8%AF%91%E7%9A%84%E9%9A%90%E5%86%99%E6%9C%AF/image-20210709175052191.png\" alt=\"image-20210709175052191\"></p>\n<ul>\n<li>找出 d1 的所有其他翻译的集合，并称这个集合为$E_{d1}$。 $E_{d1}$是语义替换的候选集。$e_1 \\in E_{d1}$。</li>\n<li>找出 e1 的所有翻译；将此集合称为 $D_{e1}$。此集合称为集合<em>witnesses</em>。</li>\n<li>对于每个单词$e \\in  E_{d1}-\\{e1\\}$找到所有的翻译 $D_{e1}$并计算$D_e \\cap D_{e1}$中元素的数量。如果该数字高于给定的阈值 t，则将 e 添加到 e1 的可能语义替代列表中。</li>\n</ul>\n<p>一个<em>witness</em>是源语言中的一个词，它也翻译成目标语言中的两个词，从而确认两个词的语义接近度。<em>witness</em>阈值 t 可用于将更多可能的替换与更高的不适当替换的可能性进行交换。</p>\n<h4 id=\"Adding-plausible-mistakes\"><a href=\"#Adding-plausible-mistakes\" class=\"headerlink\" title=\"Adding plausible mistakes\"></a>Adding plausible mistakes</h4><p>另一种可能的 post-pass 将 MT 系统常见的错误添加到翻译中。我们的实现可以使用的转换基于第 4 节中对 MT 错误的研究。当前系统支持使用手工制作的语言特定替换来更改冠词和介词，这些替换尝试模仿观察到的可能错误。</p>\n<h4 id=\"Results-from-the-Prototype\"><a href=\"#Results-from-the-Prototype\" class=\"headerlink\" title=\"Results from the Prototype\"></a>Results from the Prototype</h4><p>系统的不同配置产生不同质量的翻译，但即使质量下降也是不可预测的。有时我们的修改实际上（巧合）提高了翻译质量。</p>\n<p>应该注意的是，为简单起见，原型当前使用的引擎是公开可用的免费网络引擎，并且这不是自定义生成引擎或付费商业软件的输出的示范。为了更好地说明原型系统，给出了以下稍微更广泛的示例： 24 位字符串“lit”是在来自 Deutsche Welle 网站的电影评论部分的翻译中编码的。使用我们的原型将文本从德语翻译成英语，没有语义替换，启用冠词和介词替换，也没有“不良阈值”。源引擎是 Babelfish、Google 和 LinguaTec。德语文本是一段关于摩洛哥电影《风马》的评论的第一部分，内容如下：</p>\n<p>······省略······</p>\n<h3 id=\"Discussion\"><a href=\"#Discussion\" class=\"headerlink\" title=\"Discussion\"></a>Discussion</h3><p>本节讨论对隐写编码的各种攻击以及针对这些攻击的可能防御。讨论是非正式的，因为该系统基于 MT 的缺陷，这些缺陷很难正式分析（这也是 MT 是一个如此困难的话题的原因之一）。</p>\n<h4 id=\"Future-Machine-Translation-Systems\"><a href=\"#Future-Machine-Translation-Systems\" class=\"headerlink\" title=\"Future Machine Translation Systems\"></a>Future Machine Translation Systems</h4><p>【所提出的隐写编码在未来可能面临的一个可能问题是机器翻译的重大进展。如果机器翻译变得更加准确，那么可能出现的似是而非的错误可能会变得更小。然而，当前机器翻译错误的一大类是由于机器翻译器没有考虑到上下文。】</p>\n<p>为了显着改进现有的机器翻译系统，一个必要的功能是保存从一个句子到下一个句子的上下文信息。只有有了这些信息，才有可能消除某些错误。但是将这种上下文引入机器翻译系统也为在翻译中隐藏信息带来了新的机会。【一旦机器翻译软件开始保留上下文，使用隐写协议的两方就有可能使用这个上下文作为密钥。】通过为各自的翻译引擎植入 k 位上下文，他们可以使翻译中的偏差变得合理，迫使对手可能尝试$2^k$种可能的上下文输入，以便甚至确定使用该机制的可能性。这类似于基于密钥拆分语料库的想法，不同之处在于不会影响每句翻译的整体质量。</p>\n<h4 id=\"Repeated-Sentence-Problem\"><a href=\"#Repeated-Sentence-Problem\" class=\"headerlink\" title=\"Repeated Sentence Problem\"></a>Repeated Sentence Problem</h4><p>在翻译中隐藏消息的任何方法的一个普遍问题是，如果源语言中的文本包含两次相同的句子，它可能会被翻译成两个不同的句子，具体取决于隐藏位的值。由于机器翻译系统（不保留上下文）总是会产生相同的句子，这将允许攻击者怀疑使用了隐写术。解决这个问题的方法是不要在源文本中使用重复的句子来隐藏数据，而始终输出用于该句子第一次出现的翻译。</p>\n<p>这种攻击类似于图像隐写术中使用的攻击。如果图像经过数字化修改，图像某些不可信区域的颜色变化可能会揭示隐藏信息的存在。解决这个问题对于文本隐写术来说更容易，因为检测两个句子是否相同比检测图像中的一系列像素属于相同的数字构造形状并因此必须具有相同的颜色更容易。</p>\n<h4 id=\"Statistical-Attacks\"><a href=\"#Statistical-Attacks\" class=\"headerlink\" title=\"Statistical Attacks\"></a>Statistical Attacks</h4><p>统计攻击在击败图像、音频和视频的隐写术方面非常成功（参见，例如，[8,14,19]）。对手可能有一个统计模型（例如语言模型），所有可用 MT 系统的翻译都遵守该模型。例如，Zipf 定律 [15] 指出，一个单词的频率与其在所有单词的按频率排序的列表中的排名成反比。Zipf 定律适用于英语，事实上，甚至在名词、动词、形容词等个别类别中也适用。</p>\n<p>假设所有合理的翻译引擎通常都遵循这样的统计模型，隐写编码器必须小心不要导致与此类分布的明显偏差。一旦知道这样的统计规律，实际上很容易修改隐写编码器以消除明显偏离所需分布的翻译。例如，Golle 和 Farahat [10] 指出（在不同的加密上下文中）可以在不明显偏离 Zipf 定律的情况下广泛修改自然语言文本。换句话说，这是一个非常易于管理的困难，只要隐写系统是“Zipf-aware”的。</p>\n<p>我们不能排除尚未发现的翻译语言模型的存在，这些模型可能会被我们现有的实现所违反。然而，我们希望发现和验证这样的模型对于对手来说是一项重要的任务。另一方面，给定这样的模型（正如我们上面指出的）修改隐写系统很容易，通过避免被标记的句子来消除偏差。</p>\n","categories":[],"tags":["paper reading"]},{"title":"基于形容词删除策略的语言隐写与密钥共享","url":"https://hahally.github.io//articles/基于形容词删除策略的语言隐写与密钥共享/","content":"<blockquote>\n<p><a href=\"https://aclanthology.org/C12-1031/\" target=\"_blank\" rel=\"noopener\">Adjective Deletion for Linguistic Steganography and Secret Sharing</a></p>\n</blockquote>\n<p><strong>概念</strong></p>\n<ul>\n<li><p>Adjective Deletion 【形容词删除】</p>\n</li>\n<li><p>Linguistic Steganography 【语言隐写术】隐写术就是将秘密信息隐藏到看上去普通的信息中进行传送。</p>\n<blockquote>\n<p>Linguistic steganography is a form of covert communication in which information is embedded in a seemly innocent cover text so that the presence of the information is imperceptible to an outside observer (human or computer).</p>\n<p>理想的 Linguistic Steganography满足两个基本要求：high imperceptibility（不易察觉） and high payload capacity（高信息承载容量）</p>\n</blockquote>\n</li>\n<li><p>Secret Sharing 【密钥共享】一种分发、保存、恢复秘密密钥的方法。</p>\n</li>\n</ul>\n<p><strong>文章所作工作</strong></p>\n<ol>\n<li><p>验证删除形容词的可行性的两种方法：「checking the acceptability of adjective deletion in noun phrases.」</p>\n<ul>\n<li>Google n-gram corpus 【谷歌语料库】「check 删除一个形容词后的 <strong>context</strong> 的流利程度」</li>\n<li>SVM模型(使用n-gram counts和其他方法训练得到) 「classify 是否在 <strong>context</strong> 删除形容词」</li>\n</ul>\n</li>\n<li><p>证明删除形容词技术可以集成到一个存在的语言系统(an existing linguistic stegosyste)</p>\n</li>\n<li><p>提出一种新的基于形容词删除技术(adjective deletion)的密钥共享(secret sharing)方法</p>\n</li>\n</ol>\n<p><strong>(t,n)-threshold scheme</strong></p>\n<p>论文中采用的 secret sharing方法是基于(2, 2)-threshold, 其中共享的必须是两个可比较的文本(two comparable texts)。通过形容词删除技术将【0s 和 1s 的加密位字符串(secret bitstring;)】嵌入到两个文本中，这两个文本可以组合起来，获得秘密位串。</p>\n<blockquote>\n<p>Hence the proposed method is a novel combination of secret sharing and linguistic steganography.</p>\n</blockquote>\n<p>一种密钥共享与语言隐写技术的新颖组合方法？！</p>\n<p><strong>Adjective Deletion</strong></p>\n<p>在不影响句子流利程度和语义的情况下，可以将一些形容词删除。在下面的例子中，删除 <em>own</em> 这个形容词后，句意并没有发生改变。</p>\n<blockquote>\n<p>he spent only his own money.</p>\n<p>he spent only his money.</p>\n</blockquote>\n<p>一种极端情况 adjective-noun ：大致可以理解为正确的废话（正确但duck不必的形容）吧。</p>\n<blockquote>\n<p>unfair prejudice</p>\n<p>horrible crime</p>\n<p>fragile glass</p>\n</blockquote>\n<p><strong>隐写术种的语言转换(Linguistic Transformations for Steganography)</strong></p>\n<p>如：词汇替换、短语意译、句子结构调整、语义转换等【PS：有种毕业论文降重的赶脚】</p>\n<p>还有一种研究通过在翻译的文本中嵌入信息。在机器翻译算法中引入水印作为参数，对带有水印的译文进行概率识别。</p>\n<p>【Watermarking the outputs of structured prediction with an application in statistical machine translation】</p>\n<blockquote>\n<p>Another recent work proposedby Venugopal et al. (2011) introduces a watermark as a parameter in the machine translation algorithm and probabilistically identifies the watermarked translation.</p>\n</blockquote>\n<p><strong>隐写系统评估</strong></p>\n<p>可以从两个方面对系统进行评估：安全性(security level)和嵌入容量( embedding capacity)</p>\n<ol>\n<li><p>security level： automatic evaluation and human evaluation.</p>\n<p>automatic evaluation 大概就是使用机器翻译评价指标 BLEU 和 NIST。计算隐藏文本与原始文本之间的距离。</p>\n<p>human evaluation 就是认为指定的一套评估标准(seven-point scale)。</p>\n</li>\n<li><p>embedding capacity</p>\n<p>将嵌入的信息按每个语言单位(每个句子或每个单词)比特进行量化。</p>\n</li>\n</ol>\n<p>隐写系统的语言转换和编码方法，以及隐写文本的选择都会影响隐写系统的安全级别和有效负载能力。</p>\n<p><strong>句子压缩</strong></p>\n<p>句子压缩，文本简化和文本摘要通常涉及删除句子中不重要的词，以使文本更简洁。论文中指出，形容词删除可以用在句子压缩之前或之后。进一步简化句子。</p>\n<blockquote>\n<p>The proposed adjective deletion methods can be applied before and/or after a sentence compression system. Deleting unnecessary adjectives before can help the system focus on other content of a sentence. Deleting unnecessary adjectives after can generate an even more concise sentence.</p>\n</blockquote>\n<p><strong>Deletable Adjective Classification</strong></p>\n<p>论文中，为了使一个形容词的删除是可以接受的，使用两个检查：语法性和自然性检查(grammaticality and naturalness checks)。</p>\n<ol>\n<li><p>N-gram Count 方法</p>\n<p>计算删除形容词前后文本的 N-gram 统计得分，通过设置一个阈值，来判断删除后的文本是否可接受。</p>\n</li>\n<li><p>Features for the SVM</p>\n<p>支持向量机的特征有：</p>\n<ul>\n<li>N-gram Counts</li>\n<li>Lexical Association Measures【确定形容词和名词之间的关联程度。】</li>\n<li>Noun and Adjective Entropy【名词和形容词熵】</li>\n<li>Contextual α-Skew Divergence【上下文的倾斜散度？】</li>\n</ul>\n</li>\n</ol>\n<p><strong>Secret Sharing Scheme</strong></p>\n<p>将一个密钥位串分成两个部分$share_0$和 $share_1$ 。若目标形容词在$share_0$ 中保留，则密钥值取0，若目标形容词在$share_1$中保留，则密钥值取1。</p>\n<blockquote>\n<p>Share0 holds secret bits as 0s and Share1 holds secret bits as 1s</p>\n</blockquote>\n<p>下面是一个密钥位串为 101 的例子：</p>\n<p><img src=\"/articles/%E5%9F%BA%E4%BA%8E%E5%BD%A2%E5%AE%B9%E8%AF%8D%E5%88%A0%E9%99%A4%E7%AD%96%E7%95%A5%E7%9A%84%E8%AF%AD%E8%A8%80%E9%9A%90%E5%86%99%E4%B8%8E%E5%AF%86%E9%92%A5%E5%85%B1%E4%BA%AB/image-20210708213208658.png\" alt=\"image-20210708213208658\"></p>\n","categories":[],"tags":["paper reading"]},{"title":"蛋白质结构预测之lgb的baseline","url":"https://hahally.github.io//articles/蛋白质结构预测之lgb的baseline/","content":"<p>赛题：<a href=\"https://challenge.xfyun.cn/topic/info?type=protein\" target=\"_blank\" rel=\"noopener\">蛋白质结构预测挑战赛</a></p>\n<p>代码：</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br><span class=\"line\">77</span><br><span class=\"line\">78</span><br><span class=\"line\">79</span><br><span class=\"line\">80</span><br><span class=\"line\">81</span><br><span class=\"line\">82</span><br><span class=\"line\">83</span><br><span class=\"line\">84</span><br><span class=\"line\">85</span><br><span class=\"line\">86</span><br><span class=\"line\">87</span><br><span class=\"line\">88</span><br><span class=\"line\">89</span><br><span class=\"line\">90</span><br><span class=\"line\">91</span><br><span class=\"line\">92</span><br><span class=\"line\">93</span><br><span class=\"line\">94</span><br><span class=\"line\">95</span><br><span class=\"line\">96</span><br><span class=\"line\">97</span><br><span class=\"line\">98</span><br><span class=\"line\">99</span><br><span class=\"line\">100</span><br><span class=\"line\">101</span><br><span class=\"line\">102</span><br><span class=\"line\">103</span><br><span class=\"line\">104</span><br><span class=\"line\">105</span><br><span class=\"line\">106</span><br><span class=\"line\">107</span><br><span class=\"line\">108</span><br><span class=\"line\">109</span><br><span class=\"line\">110</span><br><span class=\"line\">111</span><br><span class=\"line\">112</span><br><span class=\"line\">113</span><br><span class=\"line\">114</span><br><span class=\"line\">115</span><br><span class=\"line\">116</span><br><span class=\"line\">117</span><br><span class=\"line\">118</span><br><span class=\"line\">119</span><br><span class=\"line\">120</span><br><span class=\"line\">121</span><br><span class=\"line\">122</span><br><span class=\"line\">123</span><br><span class=\"line\">124</span><br><span class=\"line\">125</span><br><span class=\"line\">126</span><br><span class=\"line\">127</span><br><span class=\"line\">128</span><br><span class=\"line\">129</span><br><span class=\"line\">130</span><br><span class=\"line\">131</span><br><span class=\"line\">132</span><br><span class=\"line\">133</span><br><span class=\"line\">134</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">################## utils.py #####################</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">read_fa</span><span class=\"params\">(file, mode=<span class=\"string\">'train'</span>)</span>:</span></span><br><span class=\"line\">    <span class=\"keyword\">assert</span> mode <span class=\"keyword\">in</span> &#123;<span class=\"string\">'train'</span>,<span class=\"string\">'test'</span>&#125;</span><br><span class=\"line\">    labels = []</span><br><span class=\"line\">    seqs_info = []</span><br><span class=\"line\">    cates_id = []</span><br><span class=\"line\">    seq = <span class=\"string\">''</span></span><br><span class=\"line\">    <span class=\"keyword\">with</span> open(file,mode=<span class=\"string\">'r'</span>) <span class=\"keyword\">as</span> f:</span><br><span class=\"line\">        line = f.readline().strip()</span><br><span class=\"line\">        <span class=\"keyword\">while</span> line:</span><br><span class=\"line\">            <span class=\"keyword\">if</span> line[<span class=\"number\">0</span>]==<span class=\"string\">'&gt;'</span>:</span><br><span class=\"line\">                info = line[<span class=\"number\">1</span>:].split(<span class=\"string\">' '</span>)</span><br><span class=\"line\">                cates_id.append(info[<span class=\"number\">0</span>])</span><br><span class=\"line\">                <span class=\"keyword\">if</span> mode == <span class=\"string\">'train'</span>:</span><br><span class=\"line\">                    labels.append(<span class=\"string\">''</span>.join(info[<span class=\"number\">1</span>].split(<span class=\"string\">'.'</span>)[:<span class=\"number\">2</span>]))</span><br><span class=\"line\">                <span class=\"keyword\">if</span> seq:</span><br><span class=\"line\">                    seqs_info.append(seq)</span><br><span class=\"line\">                    seq = <span class=\"string\">''</span></span><br><span class=\"line\">            <span class=\"keyword\">else</span>:</span><br><span class=\"line\">                seq += line</span><br><span class=\"line\">            line = f.readline().strip()</span><br><span class=\"line\">        seqs_info.append(seq)</span><br><span class=\"line\">    </span><br><span class=\"line\">    <span class=\"keyword\">return</span> cates_id,seqs_info,labels</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">################## main.py #####################</span></span><br><span class=\"line\"><span class=\"keyword\">from</span> utils <span class=\"keyword\">import</span> *</span><br><span class=\"line\"><span class=\"keyword\">import</span> pandas <span class=\"keyword\">as</span> pd</span><br><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\"><span class=\"keyword\">from</span> sklearn.metrics <span class=\"keyword\">import</span> f1_score, fbeta_score, precision_score, recall_score, roc_auc_score</span><br><span class=\"line\"><span class=\"keyword\">from</span> sklearn.model_selection <span class=\"keyword\">import</span> StratifiedKFold <span class=\"keyword\">as</span> KFold</span><br><span class=\"line\"><span class=\"keyword\">import</span> lightgbm <span class=\"keyword\">as</span> lgb</span><br><span class=\"line\"></span><br><span class=\"line\">train_file = <span class=\"string\">'./训练集/astral_train.fa'</span></span><br><span class=\"line\">test_file = <span class=\"string\">'./测试集/astral_test.fa'</span></span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">train_sample_id, train_seqs_info, train_labels = read_fa(train_file, mode=<span class=\"string\">'train'</span>)</span><br><span class=\"line\">test_sample_id, test_seqs_info, _ = read_fa(test_file, mode=<span class=\"string\">'test'</span>)</span><br><span class=\"line\">train_data = &#123;</span><br><span class=\"line\">    <span class=\"string\">'sample_id'</span>: train_sample_id,</span><br><span class=\"line\">    <span class=\"string\">'seq_info'</span>: train_seqs_info,</span><br><span class=\"line\">    <span class=\"string\">'label'</span>: train_labels</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">test_data = &#123;</span><br><span class=\"line\">    <span class=\"string\">'sample_id'</span>: test_sample_id,</span><br><span class=\"line\">    <span class=\"string\">'seq_info'</span>: test_seqs_info,</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">label_map = &#123;l:idx <span class=\"keyword\">for</span> idx,l <span class=\"keyword\">in</span> enumerate(set(train_labels))&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">rev_label_map = &#123;v:k <span class=\"keyword\">for</span> k,v <span class=\"keyword\">in</span> label_map.items()&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># print(label_map)</span></span><br><span class=\"line\"></span><br><span class=\"line\">train = pd.DataFrame(data=train_data)</span><br><span class=\"line\">test = pd.DataFrame(data=test_data)</span><br><span class=\"line\"></span><br><span class=\"line\">train[<span class=\"string\">'label'</span>] = train[<span class=\"string\">'label'</span>].map(label_map)</span><br><span class=\"line\"></span><br><span class=\"line\">alp = list(set(<span class=\"string\">''</span>.join(train_seqs_info + test_seqs_info)))</span><br><span class=\"line\"></span><br><span class=\"line\">train[<span class=\"string\">'seq_len'</span>] = train[<span class=\"string\">'seq_info'</span>].apply(<span class=\"keyword\">lambda</span> x:len(x))</span><br><span class=\"line\">test[<span class=\"string\">'seq_len'</span>] = test[<span class=\"string\">'seq_info'</span>].apply(<span class=\"keyword\">lambda</span> x:len(x))</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">for</span> s <span class=\"keyword\">in</span> alp:</span><br><span class=\"line\">    train[<span class=\"string\">'count_'</span>+s] = train[<span class=\"string\">'seq_info'</span>].apply(<span class=\"keyword\">lambda</span> x:x.count(s))</span><br><span class=\"line\">    train[<span class=\"string\">'freq_'</span>+s] = train[<span class=\"string\">'seq_info'</span>].apply(<span class=\"keyword\">lambda</span> x:x.count(s)/len(x))</span><br><span class=\"line\">    </span><br><span class=\"line\">    test[<span class=\"string\">'count_'</span>+s] = test[<span class=\"string\">'seq_info'</span>].apply(<span class=\"keyword\">lambda</span> x:x.count(s))</span><br><span class=\"line\">    test[<span class=\"string\">'freq_'</span>+s] = test[<span class=\"string\">'seq_info'</span>].apply(<span class=\"keyword\">lambda</span> x:x.count(s)/len(x))</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">feats = [i <span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> train.columns <span class=\"keyword\">if</span> i <span class=\"keyword\">not</span> <span class=\"keyword\">in</span> [<span class=\"string\">'label'</span>,<span class=\"string\">'sample_id'</span>,<span class=\"string\">'seq_info'</span>]]</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># print(feats)</span></span><br><span class=\"line\"></span><br><span class=\"line\">x_train = train[feats]</span><br><span class=\"line\">y_train = train[<span class=\"string\">'label'</span>]</span><br><span class=\"line\">x_test = test[feats]</span><br><span class=\"line\"></span><br><span class=\"line\">   </span><br><span class=\"line\">params = &#123; </span><br><span class=\"line\">    <span class=\"string\">'boosting_type'</span>: <span class=\"string\">'gbdt'</span>,  </span><br><span class=\"line\">    <span class=\"string\">'objective'</span>: <span class=\"string\">'multiclass'</span>,  </span><br><span class=\"line\">    <span class=\"string\">'num_class'</span>: <span class=\"number\">245</span>,  </span><br><span class=\"line\">    <span class=\"string\">'metric'</span>: <span class=\"string\">'multi_error'</span>,  </span><br><span class=\"line\">    <span class=\"string\">'num_leaves'</span>: <span class=\"number\">300</span>,  </span><br><span class=\"line\">    <span class=\"string\">'min_data_in_leaf'</span>: <span class=\"number\">500</span>,  </span><br><span class=\"line\">    <span class=\"string\">'learning_rate'</span>: <span class=\"number\">0.007</span>,  </span><br><span class=\"line\">    <span class=\"string\">'max_depth'</span>: <span class=\"number\">8</span>,</span><br><span class=\"line\">    <span class=\"string\">'feature_fraction'</span>: <span class=\"number\">0.8</span>,  </span><br><span class=\"line\">    <span class=\"string\">'bagging_fraction'</span>: <span class=\"number\">0.8</span>,  </span><br><span class=\"line\">    <span class=\"string\">'bagging_freq'</span>: <span class=\"number\">5</span>,  </span><br><span class=\"line\">    <span class=\"string\">'lambda_l1'</span>: <span class=\"number\">0.4</span>,  </span><br><span class=\"line\">    <span class=\"string\">'lambda_l2'</span>: <span class=\"number\">0.5</span>,  </span><br><span class=\"line\">    <span class=\"string\">'min_gain_to_split'</span>: <span class=\"number\">0.2</span>,  </span><br><span class=\"line\">    <span class=\"string\">'verbose'</span>: <span class=\"number\">-1</span>,</span><br><span class=\"line\">    <span class=\"string\">'num_threads'</span>:<span class=\"number\">2</span>,</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 五折交叉验证</span></span><br><span class=\"line\">folds = KFold(n_splits=<span class=\"number\">5</span>, shuffle=<span class=\"literal\">True</span>, random_state=<span class=\"number\">2021</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">oof = np.zeros([len(x_train),<span class=\"number\">245</span>])</span><br><span class=\"line\">predictions = np.zeros([len(x_test),<span class=\"number\">245</span>])</span><br><span class=\"line\"> </span><br><span class=\"line\"><span class=\"keyword\">for</span> fold_, (trn_idx, val_idx) <span class=\"keyword\">in</span> enumerate(folds.split(x_train, y_train)):</span><br><span class=\"line\">    print(<span class=\"string\">\"fold n°&#123;&#125;\"</span>.format(fold_+<span class=\"number\">1</span>))</span><br><span class=\"line\">    trn_data = lgb.Dataset(x_train.iloc[trn_idx], y_train.iloc[trn_idx])</span><br><span class=\"line\">    val_data = lgb.Dataset(x_train.iloc[val_idx], y_train.iloc[val_idx])</span><br><span class=\"line\"> </span><br><span class=\"line\">    num_round = <span class=\"number\">1000</span></span><br><span class=\"line\">    clf = lgb.train(params, </span><br><span class=\"line\">                    trn_data, </span><br><span class=\"line\">                    num_round, </span><br><span class=\"line\">                    valid_sets = [trn_data, val_data], </span><br><span class=\"line\">                    verbose_eval = <span class=\"number\">100</span>, </span><br><span class=\"line\">                    early_stopping_rounds = <span class=\"number\">50</span>)</span><br><span class=\"line\">    oof[val_idx] = clf.predict(x_train.iloc[val_idx][feats], num_iteration=clf.best_iteration)    </span><br><span class=\"line\">    predictions += clf.predict(x_test, num_iteration=clf.best_iteration) / folds.n_splits</span><br><span class=\"line\">    <span class=\"comment\">#print(predictions)</span></span><br><span class=\"line\"></span><br><span class=\"line\">x_test[<span class=\"string\">'sample_id'</span>] = test[<span class=\"string\">'sample_id'</span>]</span><br><span class=\"line\">x_test[<span class=\"string\">'category_id'</span>] = [rev_label_map[list(x).index(max(x))] <span class=\"keyword\">for</span> x <span class=\"keyword\">in</span> predictions]</span><br><span class=\"line\">x_test[<span class=\"string\">'category_id'</span>] = x_test[<span class=\"string\">'category_id'</span>].apply(<span class=\"keyword\">lambda</span> x: x[<span class=\"number\">0</span>]+<span class=\"string\">'.'</span>+x[<span class=\"number\">1</span>:])</span><br><span class=\"line\">x_test[[<span class=\"string\">'sample_id'</span>, <span class=\"string\">'category_id'</span>]].to_csv(<span class=\"string\">'base_sub.csv'</span>, index=<span class=\"literal\">False</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">y_pre = oof.argmax(axis=<span class=\"number\">1</span>)</span><br><span class=\"line\">print(<span class=\"string\">\"F1 score: &#123;&#125;\"</span>.format(f1_score(y_train, y_pre,average=<span class=\"string\">'micro'</span>)))</span><br><span class=\"line\">print(<span class=\"string\">\"Precision score: &#123;&#125;\"</span>.format(precision_score(y_train, y_pre,average=<span class=\"string\">'micro'</span>)))</span><br><span class=\"line\">print(<span class=\"string\">\"Recall score: &#123;&#125;\"</span>.format(recall_score(y_train, y_pre,average=<span class=\"string\">'micro'</span>)))</span><br></pre></td></tr></table></figure>\n<p>提交结果：目前【14/27(提交团队数)】</p>\n<p><img src=\"/articles/%E8%9B%8B%E7%99%BD%E8%B4%A8%E7%BB%93%E6%9E%84%E9%A2%84%E6%B5%8B%E4%B9%8Blgb%E7%9A%84baseline/image-20210703193646587.png\" alt=\"image-20210703193646587\"></p>\n<p>主要是提取了氨基酸组成(AAC)特征，即一些简单的统计特征。没有考虑氨基酸之间的相对位置信息，也没有必要调参，最后预测结果也很是拉跨。</p>\n<p>下一步直接尝试<code>nlp</code> 相关模型。</p>\n","categories":[],"tags":["BDC"]},{"title":"GMAN","url":"https://hahally.github.io//articles/GMAN/","content":"<blockquote>\n<p><a href=\"https://arxiv.org/abs/1911.08415\" target=\"_blank\" rel=\"noopener\">GMAN: A Graph Multi-Attention Network for Traffic Prediction</a></p>\n</blockquote>\n<h3 id=\"Abstract\"><a href=\"#Abstract\" class=\"headerlink\" title=\"Abstract\"></a>Abstract</h3><p>由于交通系统的复杂性和众多影响因素的不断变化，长期交通预测具有很大的挑战性。本文针对时空因素，提出了一种基于图的多注意网络（GMAN）来预测路网图上不同位置时间步长头部的交通状况。GMAN采用编解码器架构，其中编码器和解码器均由多个时空注意模块组成，以模拟时空因素对交通状况的影响。 编码器对输入的流量特征进行编码，解码器预测输出序列。在编码器和解码器之间，应用变换注意层来转换编码的流量特征，以生成未来时间步长的序列表示作为解码器的输入。 变换注意机制对历史步骤和将来时间步骤之间的直接关系进行建模，这有助于减轻预测时间步骤之间的错误传播问题。 在两个实际交通预测任务（即交通量预测和交通速度预测）上的实验结果证明了GMAN的优越性。 特别是，在提前1小时的预测中，GMAN的MAE指标提高了4％，优于最新技术。<a href=\"https://github.com/zhengchuanpan/GMAN\" target=\"_blank\" rel=\"noopener\">https://github.com/zhengchuanpan/GMAN</a></p>\n<h3 id=\"Introduction\"><a href=\"#Introduction\" class=\"headerlink\" title=\"Introduction\"></a>Introduction</h3><p>交通预测的目的是根据历史观测（如通过传感器记录）预测道路网络中未来的交通状况（如交通量或速度）。它在许多实际应用中扮演着重要的角色。例如，准确的交通预测可以帮助运输机构更好地控制交通，以减少交通拥挤。</p>\n<p>附近位置的交通状况的预测会相互影响。 为了捕获这种空间相关性，卷积神经网络（CNN）被广泛使用。 同时，一个地点的交通状况也与其历史观测值有关。循环神经网络（RNN）被广泛应用于这种对时间相关性问题进行建模。</p>\n<p>由于交通条件受路网图的限制，近年来的研究将交通预测看作图形建模问题。利用图卷积网络（GCN），这些研究在短期（提前5∼15分钟）交通预测方面取得了不错的结果。然而，长期(提前几个小时)的交通预测在文献中仍然缺乏令人满意的进展，主要是由于以下挑战。</p>\n<p>1) 复杂的时空相关性</p>\n<ul>\n<li>动态空间相关性。如图1所示，路网中传感器之间交通状况的相关性随着时间的推移而显著变化（例如，在高峰时间之前和期间）。如何动态选择相关传感器的数据来预测目标传感器的长期交通状况是一个具有挑战性的问题。</li>\n<li>非线性时间相关。 同样在图1中，传感器处的交通状况可能急剧且突然地波动（例如，由于事故），从而影响不同时间步长之间的相关性。 当时间更远时，如何自适应地对非线性时间相关性建模仍然是一个挑战。</li>\n</ul>\n<p>2) 对误差传播的敏感性。从长期的角度来看，当对未来的预测更进一步时，每个时间步上的小误差可能会放大。这样的误差传播使得对遥远未来的预测非常具有挑战性。</p>\n<p><img src=\"/articles/GMAN/image-20210223150430150.png\" alt=\"image-20210223150430150\"></p>\n<p>为了应对上述挑战，我们提出了一种图形多注意网络（GMAN）来预测未来一段时间内道路网络图上的交通状况。此处，交通状况指的是对交通系统的观测，可以以数值形式报告 。 为了便于说明，我们将重点放在交通量和交通速度预测上，尽管我们的模型可以应用于其他数字交通数据的预测。</p>\n<p>GMAN遵循编码器-解码器体系结构，其中编码器对输入的流量特征进行编码，而解码器预测输出序列。 在编码器和解码器之间添加了一个转换注意层，以转换编码的历史流量特征以生成将来的表示。编码器和解码器都由ST-Attention块的堆栈组成。 每个ST-Attention块由用于对动态空间相关性进行建模的空间注意机制，用于对非线性时间相关性进行建模的时间注意机制以及通过自适应融合时空表示的融合融合机制形成。变换注意力机制模型直接控制了历史和未来时间步长之间的关系，从而减轻了错误传播的影响。在两个真实数据集上的实验证实，GMAN具有最先进的性能。</p>\n<p>这项工作的贡献概述如下:</p>\n<ul>\n<li>我们分别提出了空间和时间的注意机制来模拟动态的空间和非线性的时间相关。此外，我们还设计了一种自适应融合时空注意机制提取信息的门控融合方法。</li>\n<li>提出了一种将历史交通特征转化为未来交通特征的注意力转化机制。该注意机制建立了历史时间步长与未来时间步长之间的直接关系模型，以缓解错误传播问题。</li>\n<li>我们在两个实际流量数据集上对我们的图形多注意网络(GMAN)进行了评估，并且在1小时的预测中观察到了比最先进的基线方法提高4% 的改进和优越的容错能力。</li>\n</ul>\n<h3 id=\"Related-Work\"><a href=\"#Related-Work\" class=\"headerlink\" title=\"Related Work\"></a>Related Work</h3><h4 id=\"交通预测\"><a href=\"#交通预测\" class=\"headerlink\" title=\"交通预测\"></a>交通预测</h4><p>在过去的几十年中，交通预测得到了广泛的研究。与传统的时间序列方法（如自动回归综合移动影像匹配(ARIMA)）和机器学习模型（如支持向量回归(SVR)、 k 最近邻(KNN)）相比，深度学习方法（例如，长-短期记忆（LSTM））在捕获交通状况下的时间相关性方面表现出更优越的性能。为了建立空间相关性模型，研究人员应用卷积神经网络(CNN)来捕捉欧氏空间中的相关性。最近的研究制定了基于图的交通预测，并使用图卷积网络(GCN)建模道路网络中的非欧氏关联。这些基于图的模型通过一步一步的方法在预测前生成多个步骤，并可能受到不同预测步骤之间的误差传播的影响。</p>\n<h4 id=\"图深度学习\"><a href=\"#图深度学习\" class=\"headerlink\" title=\"图深度学习\"></a>图深度学习</h4><p>将神经网络泛化为图结构化数据是一个新兴的话题。一系列研究概括了CNN，以在图谱或空间角度上对任意图形建模。另一类研究集中在图嵌入上，它学习保留图结构信息的顶点的低维表示将 WaveNet 集成到 GCN 中以进行时空建模。由于它学习静态邻接矩阵，因此该方法难以捕获动态空间相关性。</p>\n<h4 id=\"注意力机制\"><a href=\"#注意力机制\" class=\"headerlink\" title=\"注意力机制\"></a>注意力机制</h4><p>由于注意力机制的高效性和建模依赖性的灵活性，其注意力机制已广泛应用于各个领域。注意机制的核心思想是根据输入的数据自适应地关注最相关的特征。最近，研究人员将注意力机制应用于图形结构化数据，来建模图形分类的空间相关性。我们将注意力机制扩展到图形时空数据预测。</p>\n<h3 id=\"Preliminaries\"><a href=\"#Preliminaries\" class=\"headerlink\" title=\"Preliminaries\"></a>Preliminaries</h3><p>我们把道路网络表示为一个加权有向图 $ G=(V,E,A) $ 。这里，V 是 N = | V | 的顶点集合，代表道路网络上的点（例如交通传感器）。E 是一组边，代表顶点之间的连通性。$A \\in R^{N \\times N}$ 表示加权邻接矩阵。其中 $A_{v_i,v_j}$ 代表两个顶点之间的接近程度（由道路网络距离度量）。在时间步长为 t 的交通状况用图$G$ 上的图信号 $X_t \\in R^{N \\times C}$ 表示，其中 $C$ 是感兴趣的交通状况的数量（例如交通量，交通速度等。）</p>\n<h4 id=\"Problem-Studied\"><a href=\"#Problem-Studied\" class=\"headerlink\" title=\"Problem Studied\"></a>Problem Studied</h4><p>给定在顶点 N 处的历史 P 时间步长 $X = (X_{t_1},X_{t_2},…,X_{t_P}) \\in R^{P\\times N \\times C}$ ，我们的目标是预测所有顶点在下一个 Q 时间步长的交通情况，表示为 $\\hat Y = (\\hat X_{t_{P+1}},\\hat X_{t_{P+2}},…,\\hat X_{t_{P+Q}}) \\in R^{Q\\times N \\times C}$ 。</p>\n<h3 id=\"Graph-Multi-Attention-Network\"><a href=\"#Graph-Multi-Attention-Network\" class=\"headerlink\" title=\"Graph Multi-Attention Network\"></a>Graph Multi-Attention Network</h3><p>图2显示了我们提出的 GMAN 框架，包含一个 encoder-decoder 结构。编码器和解码器都包含 L 个残差连接的 STAtt Block。每一个 STAtt Block 都是由具有门控功能的时空注意机制组成的。在编码器与解码器之间，网络中加入了一个 <strong>transform</strong> 注意层将编码的交通特征转换为解码特征。我们还通过时空嵌入（STE）将图形结构和时间信息整合到多注意机制中。此外，为了方便残差连接，所有层输出维度都是 D。接下来将详细介绍这些模块。</p>\n<p><img src=\"/articles/GMAN/image-20210301090744336.png\" alt=\"image-20210301090744336\"></p>\n<h4 id=\"Spatio-Temporal-Embedding\"><a href=\"#Spatio-Temporal-Embedding\" class=\"headerlink\" title=\"Spatio-Temporal Embedding\"></a>Spatio-Temporal Embedding</h4><p>由于交通条件的演变受到了道路网络的限制，将道路网信息整合到预测模型中至关重要。为此，我们提出了一种将顶点编码为向量的局部嵌入方法，以保存图形结构信息。具体来说，我们利用 <strong>node2vec</strong> 方法来学习顶点表示。此外，为了协同训练预训练好的整个模型的向量，这些向量会被输入到一个两层完全连接的神经网络中。然后，我们将得到空间嵌入，表示为 $e^S_{v_i} \\in R^D, v_i \\in V$ 。</p>\n<p>空间嵌入只能提供静态的表示，不能反映路网中交通传感器之间的动态相关性。因此，我们进一步提出了一种时间嵌入方法，将每个时间步编码成一个向量。具体来说，把一天分成 T 个时间步长。我们使用独热编码将每一个时间步长的 <em>day-of-week</em> 和 <em>time-of-day</em> 编码到 $R^7$ 和 $R^{T+7}$ 中，接下来，我们应用一个两层完全连接的神经网络将时间特征转化为向量。在我们的模型中，我们嵌入了历史 P 和未来 Q 时间步长的时间特征，表示为$e^T_{t_j} \\in R^D$ ，其中$t_j = t_1,…,t_P,…,t_{P+Q}$ 。为了获得随时间变化的顶点表示，我们将上述空间嵌入和时间嵌入融合为时空嵌入（STE），如图2b所示。具体来说，对于时间步长 $t_j$ 时的顶点 $v_i$ ，其 STE 被定义为 $e_{v_i,t_j} = e^S_{v_i} + e^T_{t_j}$ 。因此，在 P+Q 时间步长中，N 个顶点的 STE 表示为 $E \\in R^{(P+Q)\\times N \\times D}$ 。STE包含图形结构和时间信息，可用于空间、时间和 transform 注意机制。</p>\n<h4 id=\"ST-Attention-Block\"><a href=\"#ST-Attention-Block\" class=\"headerlink\" title=\"ST-Attention Block\"></a>ST-Attention Block</h4><p>如图 2c 所示，ST-Attention 模块包含一个空间注意机制，一个时间注意机制和一个门控机制。我们将第 $l$ 个 block 的输入表示为 $H^{(l-1)}$ ，其中在步长$t_j$ 处顶点$v_i$ 的隐藏状态表示为 $h^{(l-1)}_{v_i,v_j}$ 。在第 $l$ 个 block 中，空间和时间注意机制的输出表示为 $H^{(l)}_S$ 和 $H^{(l)}_T$ ，其中在步长$t_j$ 处顶点$v_i$ 的隐藏状态表示为 $hs^{(l)}_{v_i,v_j},ht^{(l)}_{vi,tj}$ 。通过门控融合，得到了该模块的输出结果，表示为 $H^{(l)}$ 。</p>\n<p>为了便于说明，我们将非线性变换表示为：</p>\n<script type=\"math/tex; mode=display\">\nf(x) = ReLU(xW+b),</script><h4 id=\"Spatial-Attention\"><a href=\"#Spatial-Attention\" class=\"headerlink\" title=\"Spatial Attention\"></a>Spatial Attention</h4><p>条道路的交通状况受到其他道路的不同影响。这种影响是动态的，随着时间的推移而变化。为了模拟这些特性，我们设计了一种空间注意机制来自适应地捕捉道路网络中传感器之间的相关性。其关键思想是在不同的时间步动态地将不同的权重分配给不同的顶点（例如，传感器），如图3所示。对于在时间步长 $t_j$ 处的顶点 $v_i$ ，我们计算所有顶点的加权和：</p>\n<script type=\"math/tex; mode=display\">\nhs^{(l)}_{v_i,v_j} = \\sum_{v\\in v} \\alpha_{v_i,v} · h^{(l-1)}_{v,t_j} ,</script><p>表示 $V$ 所有顶点的集合， $\\alpha_{v_i,v}$ 为注意机制得分，表示顶点 $v$ 到 $v_i$ 之间的重要程度，其分数之和等于 1：$\\sum_{v \\in V} \\alpha_{v_i,v} = 1$</p>\n<p><img src=\"/articles/GMAN/image-20210301104231532.png\" alt=\"image-20210301104231532\"></p>\n<p>在一定的时间步长下，当前交通状况和路网结构都会影响传感器之间的相关性。例如，道路上的拥堵可能会严重影响其相邻道路的交通状况。基于这种直觉，我们同时考虑交通特征和图形结构来学习注意力得分。具体来说，我们将隐藏状态与时空嵌入连接起来，并采用标度点积方法计算顶点 $v_i$ 与 $V$ 之间的相关性。</p>\n<script type=\"math/tex; mode=display\">\ns_{v_i,v} = \\frac{<h_{v_i,t_j}^{(l-1)}||e_{v_i,t_j},h^{(l-1)}_{v,t_j}||e_{v,t_j}>}{\\sqrt{2D}},</script><p>其中 $||$ 表示连接操作，$〈•,•〉$ 表示内积操作，2D 是$h_{v_i,t_j}^{(l-1)}||e_{v_i,t_j}$ 的维度。然后，通过 Softmax 归一化为：</p>\n<script type=\"math/tex; mode=display\">\n\\alpha_{v_i,v} = \\frac{exp(s_{v_i,v})}{\\sum_{v_r \\in V}exp(s_{v_i,v_r})}</script><p>在获得注意得分 $\\alpha_{v_i,v}$ 之后，可以通过等式2更新隐藏状态。</p>\n<p>为了稳定学习过程，我们将空间注意力机制扩展为 <strong>multi-head</strong>。 具体来说，我们将K个并行注意机制与不同的可学习预测联系起来：</p>\n<p><img src=\"/articles/GMAN/image-20210302084718874.png\" alt=\"image-20210302084718874\"></p>\n<p><img src=\"/articles/GMAN/image-20210302084736425.png\" alt=\"image-20210302084736425\"></p>\n<p>其中 $f^{(k)}_{s,1}(·),f^{(k)}_{s,2}(·),f^{(k)}_{s,3}(·)$ 表示在第 k 个 <strong>head attention</strong> 中三个不同的非线性预测，输出维度 $d = D/K$ 。</p>\n<p>当顶点数量 N 很大时，由于我们需要计算 $N^2$ 个注意分数，因此时间和内存消耗都很大。 为了解决此限制，我们进一步提出了一个<em>group spatial attention</em>，其中包含了<em>intra-group spatial attention</em>和<em>inter-group spatial attention</em>，如图4所示。</p>\n<p><img src=\"/articles/GMAN/image-20210302085935418.png\" alt=\"image-20210302085935418\"></p>\n<p>我们随机将 N 个顶点划分为 G 个组，其中每个组包含 $M=N/G$ 个顶点。在每一组中，我们通过方程5、6、7 计算 <em>intra-group attention</em> 以模拟顶点之间的局部空间相关性，其中组间共享参数。然后，我们在每个组中应用最大池化方法，以获得每个组的单个表示。接下来，我们计算<em>inter-group spatial attention</em>来建模不同组之间的相关性，为每个组产生一个全局特征。局部特征被添加到相应的全局特征中，作为最终输出。</p>\n<p>在<em>group spatial attention</em>上，我们需要计算每个时间步长的  $GM^2 + G^2 = NM+(N/M)^2$ 个 <em>attention scores</em> 。梯度为零时，我们知道 $M = \\sqrt[3]{2N}$ 时 <em>attention score</em> 的值达到最小值 $2^{-1/3}N^{4/3}\\ll N^2 $ 。</p>\n<h4 id=\"Temporal-Attention\"><a href=\"#Temporal-Attention\" class=\"headerlink\" title=\"Temporal Attention\"></a>Temporal Attention</h4><p>一个地点的交通状况与它之前的观察结果是相关的，并且这种相关性随着时间步长的变化是非线性的。为了模拟这些特性，我们设计了一个 <em>Temporal Attention</em> 来自适应地模拟不同时间步骤之间的非线性关联，如图5所示。注意，时间相关性受交通条件和相应的时间背景的影响。例如，发生在早晨高峰时间的拥堵可能会影响几个小时的交通。因此，我们同时考虑流量特征和时间来度量不同时间步长之间的相关性。具体来说，我们将隐藏状态与时空嵌入相连接，并采用<em>multi-head</em>方法计算 <em>attention score</em> 。最后考虑顶点 $v_i$ ，时间步长 $t_j$ 与 $t$ 之间的相关性定义为：</p>\n<p><img src=\"/articles/GMAN/image-20210302095459275.png\" alt=\"image-20210302095459275\"></p>\n<p>其中 $u^{(k)}_{t_j,t}$ 表示时间步长 $t_j$ 与 $t$ 之间的相关性，$\\beta^{(k)}_{t_j,t}$ 表示第 k 个 <em>head attention score</em> 表明时间步骤 $t$ 到$t_j$ 的重要性，$f^{(k)}_{t,1},f^{(k)}_{t,2}$ 表示两个不同的可学习的 <em>transforms</em> ，$N_{t_j}$ 表示时间步长 $t_j$ 之前的集合。仅考虑时间步中早于目标步的信息以启用因果关系(<strong>causality</strong>)。一旦获得 <em>attention score</em> 后，顶点 $v_i$ 在时间步长 $t_j$ 处 的 <em>hidden state</em> 个更新方式如下：</p>\n<p><img src=\"/articles/GMAN/image-20210302204132568.png\" alt=\"image-20210302204132568\"></p>\n<p>其中 $f^{(k)}_{t,3}$ 代表一个非线性投影。公式8、9和10中的可学习参数通过并行计算在所有顶点和时间步上共享。</p>\n<h4 id=\"Gated-Fusion\"><a href=\"#Gated-Fusion\" class=\"headerlink\" title=\"Gated Fusion\"></a>Gated Fusion</h4><p>道路在某一特定时间步长下的交通状况与其前期值和其他道路的交通状况相关。如图2c所示，我们设计了门控融合来自适应地融合空间和时间表示。第 $l$ 个block ，时间和空间注意机制的输出表示为 $H^{(l)}_S,H^{(l)}_T$ ，两者在编码器与解码器中都有相同的形状 $R^{P\\times N \\times D},R^{Q\\times N \\times D}$ ，融合公式如下：</p>\n<p><img src=\"/articles/GMAN/image-20210302205242473.png\" alt=\"image-20210302205242473\"></p>\n<p><img src=\"/articles/GMAN/image-20210302205254514.png\" alt=\"image-20210302205254514\"></p>\n<p>其中 $W_{z,1}\\in R^{D\\times D},W_{z,2}\\in R^{D\\times D},b_z \\in R^D$ 是可学习参数，$\\odot$ 表示按元素计算的乘积，$\\sigma(·)$ 表示 sigmoid 激活函数，z 是门控。门控融合机制自适应地控制空间和时间依赖在每个顶点和时间步长的流。</p>\n<h4 id=\"Transform-Attention\"><a href=\"#Transform-Attention\" class=\"headerlink\" title=\"Transform Attention\"></a>Transform Attention</h4><p>为了减轻长时间范围内不同预测时间步长之间的误差传播效应，在编码器和解码器之间增加了一个<em>Transform Attention</em>。它对每个未来时间步长和每个历史时间步长之间的直接关系进行建模，以转换已编码的交通特征，以生成未来表示，作为解码器的输入。如图6 所示，对顶点 $v_i$ ，通过 <em>spatio-temporal</em> 嵌入计算预测时间步长 $t_j(t_j = t_{P+1},…,t_{P+Q})$ 与历史时间步长 $t(t = t_1,..,t_P)$ 之间的相关性。</p>\n<p><img src=\"/articles/GMAN/image-20210302221757111.png\" alt=\"image-20210302221757111\"></p>\n<p>$\\gamma^{(k)}_{t_j,t}$ 为 <em>attention score</em> ，通过在所有历史时间步骤中自适应地选择相关特征，将编码的流量特征转换到解码器。</p>\n<p><img src=\"/articles/GMAN/image-20210302222011345.png\" alt=\"image-20210302222011345\"></p>\n<p>方程13、14和15可以在所有顶点和时间步骤中并行计算，共享可学习的参数。</p>\n","categories":[],"tags":[]},{"title":"Traffic-Network-Flow-Prediction","url":"https://hahally.github.io//articles/Traffic-Network-Flow-Prediction/","content":"<blockquote>\n<p><a href=\"https://ieeexplore.ieee.org/document/9007678\" target=\"_blank\" rel=\"noopener\">Traffic Network Flow Prediction Using ParallelTraining for Deep Convolutional NeuralNetworks on Spark Cloud</a></p>\n</blockquote>\n<h3 id=\"Abstract\"><a href=\"#Abstract\" class=\"headerlink\" title=\"Abstract\"></a>Abstract</h3><p>道路网络中的交通流量是相互交互和相互依存的。 用分析方法描述交通网络流量的动态变化具有挑战性。 在本文中，将使用深度卷积神经网络（DCNN）模型解决交通网络流量预测问题。为DCNN模型的并行训练算法开发了理论基础。在Spark Cloud上实现了交通网络流量预测的主从并行计算解决方案。应用交通网络流量数据验证了dcnn预测模型和并行训练算法的有效性。实验结果表明，DCNN交通网络流量预测模型的预测性能优于基于BP神经网络、支持向量回归、径向基函数和决策树回归的典型预测模型。所提出的并行训练方法可以提高训练效率，并通过对数据子集的局部学习获得整个数据集的全局特征。</p>\n<p><strong>index-item</strong> : 深度卷积神经网络(DCNNs)、并行训练、Spark云计算、交通大数据、交通网络流量预测</p>\n<h3 id=\"INTRODUCTION\"><a href=\"#INTRODUCTION\" class=\"headerlink\" title=\"INTRODUCTION\"></a>INTRODUCTION</h3><p>交通流预测可以引导出行行为，从而缓解道路网络拥堵，提高出行效率，促进交通安全。准确高效的交通流预测是数据驱动智能交通系统的关键部分。</p>\n<p>分布在道路网络上的交通流量是相互依赖，相互影响的。 交通网络流量中存在复杂的动态变化，其中道路的拥堵可能直接或间接影响网络中其他道路的交通流量。传统的路段交通流预测方法只考虑了路段的时间序列特征，忽略了路段之间的闭合关系和交互演变。交通网络流量预测模型既要反映每条道路的时间序列演变，又要反映网络流量的空间耦合关系，其中涉及到图像式的数据处理。</p>\n<p>深度卷积神经网络(DCNN)模型与其他深度学习模型相比，在提取图像等高维数据特征方面具有优势。它已广泛应用于特征学习，语音识别和医学健康诊断。本文尝试利用 DCNN 模型提取交通网络流量的<em>时空相关动态学</em> 特征。</p>\n<p>在处理交通网络流量的大数据进行预测时，在DCNN模型中训练大量参数非常耗时。 云计算在计算资源调度和大数据实时处理方面具有显着优势。特别是最近流行的Spark Cloud 采用了基于内存的计算和主从并行处理的高级架构，突破了某些大数据处理架构（如Hadoop）中的内存限制。此外，它还适用于复杂逻辑算法的实时科学计算。因此，我们尝试为DCNN模型开发一种并行训练方法，该方法适用于采用基于内存的计算和主从并行处理的云计算平台。本文的主要贡献如下:</p>\n<ol>\n<li>基于自适应梯度下降原理，为DCNN模型开发了并行训练算法的理论基础。它保证了所提出的并行训练算法能够像串行训练算法一样，通过对多个计算节点和各自的数据集进行局部学习，从而学习整个数据集的全局特征，具有良好的收敛性。</li>\n<li>将 DCNN 模型应用于交通网络流量预测，以获取交通网络的时空数据特征。该模型首先在 Spark cloud 计算平台上实现，以解决交通网络流量大数据面临的计算复杂性问题。利用实际交通网络工作流数据验证了基于云的并行训练算法的渐近收敛性和加速优势。</li>\n</ol>\n<p>本文的其余部分安排如下。 第二节总结了相关的研究工作。 第三部分描述了DCNN预测模型的网络结构和训练样本。 在第四部分，我们为DCNN模型开发了并行训练算法的理论基础。 我们还开发了基于Spark Cloud 的实施解决方案。 在第五节中，验证了DCNN模型对交通网络流量预测的预测准确性和通用性。 此外，使用实际交通流数据演示了并行训练算法的收敛性和加速性能。 最后，第六节总结了本文。</p>\n<h3 id=\"RELATED-WORK\"><a href=\"#RELATED-WORK\" class=\"headerlink\" title=\"RELATED WORK\"></a>RELATED WORK</h3><p>以往的交通流预测工作大致可分为两类: 模型驱动方法和数据驱动方法。模型驱动技术在过去几十年中被广泛应用于交通预测。例如，根据历史交通流的周期性相似性，应用自适应卡尔曼滤波方法[5]预测未来的交通流情况。然而，在这些方法中，交通流的动态波动被假定为线性。此外，它们还可以有效地进行单链路流量的时间序列预测。</p>\n<p>数据驱动方法采用间接建模的方法来描述交通流的随机非线性特征。这些方法主要包括神经网络(NN)、支持向量回归(SVR)、径向基核函数(RBF)、决策树回归(DTR)、集成学习回归和极限学习机等。这些方法是数据挖掘的有效工具，可以从一系列数据中提取有用的信息。数据驱动方法用于确定直接模型的结构和参数。开发了一种连续的蚁群优化算法，以加速支持向量回归模型在城际高速公路交通流量预测中的参数选择。通过自适应粒子群优化确定了多层神经网络的最佳结构和参数，提高了流量变量的预测精度。然而，这些研究主要集中在道路时间序列特征的提取上。此外，用浅层结构模型提取的交通流特征也是有限的。</p>\n<p>通过模拟人脑的多层感知结构，深度学习可以有效的从高维数据中提取特征信息。它一直被用来处理通信领域的网络流量控制和路由管理。该方法在道路交通流预测领域也得到了应用。通过对交通流数据的重构，将堆叠式编码的 <em>Levenberg-Marquardt</em> 模型和深度信息网络模型应用于挖掘短时交通流固有的时间特征。此外，结合多源数据融合开发了混合深度学习模型方法，以提高业务流预测的准确性和鲁棒性。卷积神经网络模型被用来提取交通网络速度的时间和空间特征。采用 DCNN 模型提取空间特征，采用长短期记忆模型提取交通网速时间序列特征。提出了一种针对 DCNN 模型的随机子空间学习方法，通过寻址不完全交通数据来提高交通流预测的鲁棒性。然而，利用深度学习模型进行交通网络流量预测仍然是一个难题。此外，DCNN 模型在面对大数据时的长时间训练是实时应用中一个尚未解决的问题。针对细胞神经网络模型，提出了一种混合并行训练方法，结合卷积层的数据并行性和完全连接层的模型并行性，并在 GPUs上实现。GPUs 不能灵活地扩展和高效地提供基于内存的计算资源。同时，也没有为并行训练算法的收敛性和稳定性提供理论基础。</p>\n<p>云计算为减少训练时间提供了一种可行的解决方案。这是因为处理器、内存和存储器可以灵活地扩展和集群。近年来，apache Spark云计算平台在大数据处理方面取得了令人瞩目的成绩。采用基于内存的计算架构，由一个主计算节点和多个从计算节点组成。Spark cloud已经展示了在大数据科学计算领域应用的潜力，如贝叶斯网络分类、药物发现中的目标预测，以及使用深度学习的移动大数据分析。</p>\n<p>本文采用与串行训练算法相同的自适应梯度下降机制，提出了一种并行训练算法。因此，所提出的算法具有理论基础，其中全局特征可以从局部学习中提取出来，即使数据集被分解并提供用于局部学习。采用园区云计算的主从结构实现了交通网络流量预测DCNN模型的并行训练算法。主节点和子节点之间只传输非常有限的数据，如学习参数、局部梯度平方、全局学习率和局部损失函数值。</p>\n<h3 id=\"TRAFFIC-NETWORK-FLOW-PREDICTION-MODE\"><a href=\"#TRAFFIC-NETWORK-FLOW-PREDICTION-MODE\" class=\"headerlink\" title=\"TRAFFIC NETWORK FLOW PREDICTION MODE\"></a>TRAFFIC NETWORK FLOW PREDICTION MODE</h3><h4 id=\"A-DCNN-Prediction-Mode\"><a href=\"#A-DCNN-Prediction-Mode\" class=\"headerlink\" title=\"A.   DCNN Prediction Mode\"></a>A.   DCNN Prediction Mode</h4><p>DCNN模型可以捕获交通图像数据样本中丰富的时空特征。特征图中的卷积核连续滑动可以感知不同道路之间交通流的局部相关性。同时，在卷积特征图上滑动的池化窗口被用来进一步保留交通流的基本相关性并减小参数的维数。 最终，具有不同重量和偏置的完全连接的神经进一步重构了交通全局特征。</p>\n<p>图1演示了交通网络流量的 DCNN 预测模型的结构。最左边的矩形代表一个可变的流量输入矩阵，紫色的矩形代表一个可变的内核矩阵，绿色的矩形代表一个特征映射矩阵，白色的矩形代表一个池窗口。9层网络结构包括输入层(LI)、卷积层1(Lc1)、池化层1(Lp1)、卷积层2(Lc2)、池化层2(Lp2)、三层全连接层(Lf1、 Lf2、 Lf3)和输出层(Lo)。DCNN 模型的训练目标是建立海量数据样本输入矩阵与输出向量之间的复杂非线性映射关系。在不破坏图像空间结构的前提下，输入图像可以直接输入网络。</p>\n<p><img src=\"/articles/Traffic-Network-Flow-Prediction/image-20210221234502743.png\" alt=\"image-20210221234502743\"></p>\n<h4 id=\"B-Training-Sample-Construction\"><a href=\"#B-Training-Sample-Construction\" class=\"headerlink\" title=\"B. Training Sample Construction\"></a>B. Training Sample Construction</h4><p>交通网络结构是静态的，分布式协调流是动态的。类似于面部轮廓上的肌肉运动以形成不同的表情，流量分布和协调表示不同的流量形态。 交通网络流在空间维度上是相互依存和相互关联的。 同时，在时间维度上，每条道路的规则间隔都可能出现某些具有波动的相似交通模式。 因此，在大规模交通网络流量预测中应综合考虑交通网络流量的时空特征。</p>\n<p>图2展示了时空训练图像样本的构建过程。 从多个传感器收集的原始数据被汇总到相应的时空序列中，以显示交通网络流量。</p>\n<p><img src=\"/articles/Traffic-Network-Flow-Prediction/image-20210221234809890.png\" alt=\"image-20210221234809890\"></p>\n<p>一个二维时空输入矩阵构造为</p>\n<p><img src=\"/articles/Traffic-Network-Flow-Prediction/image-20210221234959933.png\" alt=\"image-20210221234959933\"></p>\n<p>其中，$x_{m,k}$ 表示在第k时刻路网第m条链路上的交通流量，d表示时维数据的截断长度。 输入矩阵中的行向量揭示了流在每个链路上的时间序列特征，输入矩阵中的列向量表示流在空间上的耦合特征。M 表示网络中最大的链路数。下文中，变量的下标表示该变量与第n个训练样本相关。训练样本的最大数量定义为N。 如果将输入矩阵中的每个元素都视为图像中的像素，则将大量矩阵类型的数据样本转换为一系列图像，馈入DCNN模型。 该模型提取行和列之间的时空相关性特征。</p>\n<p>训练样本的输出表示为：</p>\n<p><img src=\"/articles/Traffic-Network-Flow-Prediction/image-20210222000325167.png\" alt=\"image-20210222000325167\"></p>\n<p>其中 $y_{m,k+1}$ 是第 $k + 1$ 时刻在第$m$条链路上的输出业务流，$T$表示转置。 训练输入矩阵 $x_n$ 和相应的输出矢量$y_n$形成训练样本$D_n$。 </p>\n<h3 id=\"PARALLEL-TRAINING-ON-SPARK-CLOUD\"><a href=\"#PARALLEL-TRAINING-ON-SPARK-CLOUD\" class=\"headerlink\" title=\"PARALLEL TRAINING ON SPARK CLOUD\"></a>PARALLEL TRAINING ON SPARK CLOUD</h3><h4 id=\"A-Problem-Statemen\"><a href=\"#A-Problem-Statemen\" class=\"headerlink\" title=\"A. Problem Statemen\"></a>A. Problem Statemen</h4><p>在交通大数据环境下，要优化的DCNN模型的大量参数需要进行计算密集型任务。 问题是在不降低精度的情况下提高模型参数的训练效率。一种解决方案是将总数据集分解为一些数据子集，并使用多个计算节点以并行方式针对特定于它们的数据子集训练模型参数（称为局部 学习）。 但是，必须协调仅提取数据子集的局部特征的局部学习，以获取整个数据集的全局特征。本节尝试为并行训练方法开发理论基础，并提出基于Spark cloud计算平台的并行训练方法的实现解决方案。 </p>\n<h4 id=\"B-Objective-Function\"><a href=\"#B-Objective-Function\" class=\"headerlink\" title=\"B. Objective Function\"></a>B. Objective Function</h4><p>整个数据集D分为R个部分，每个部分定义为$D^r$（r = 1，2，…，R）。因此，数据集D可以表示为$D^{r}$的集合。其中变量中的 r 表示变量相对于第r个数据子集$D^r$，而$N^r$是第 r 个数据子集的大小。</p>\n<p><img src=\"/articles/Traffic-Network-Flow-Prediction/image-20210222105827613.png\" alt=\"image-20210222105827613\"></p>\n<p>基于(3)中提出的数据分解机制，给出了 DCNN 模型并行训练的目标函数</p>\n<p><img src=\"/articles/Traffic-Network-Flow-Prediction/image-20210222110329834.png\" alt=\"image-20210222110329834\"></p>\n<p>DCNN 模型训练的目的是最小化目标函数(4) ，并利用 数据集 D 获得权值和偏差。这些权重和偏差称为全局学习参数。对于数据子集，最小均方误差的权值和偏差称为局部学习参数。</p>\n<h4 id=\"C-Parallel-Training-Approach\"><a href=\"#C-Parallel-Training-Approach\" class=\"headerlink\" title=\"C. Parallel Training Approach\"></a>C. Parallel Training Approach</h4><p>并行训练方法是通过并行局部学习获得全局学习参数。这包括两个主要的训练阶段：并行特征前向学习和并行误差反向传播。</p>\n<p>1) 并行特征正向学习：对于并行特征前向学习，基于相应的数据子集，以并行方式执行各个网络层中的所有激活函数。对于卷积层、池化层和全连通层，分别表示为  $a^{r,l}_{n,j,c}$ 、 $a^{r,l}_{n,j,p}$  、$a^{r,l}_{n,j,f}$</p>\n<p>计算方法如下</p>\n<p><img src=\"/articles/Traffic-Network-Flow-Prediction/image-20210222111431596.png\" alt=\"image-20210222111431596\"></p>\n<p>在 DCNN 模型中，c、 p 和 f 分别表示卷积层、池化层和全连接层；$l $表示第l层，$L$表示层数； $i $表示第 $l $层是卷积或池化层时的第 $i$个输入特征图，或第l层是完全连接层时的第 $i$ 个神经元；当第 $l$ 层是卷积或池化层时，$j$ 表示第$j$个输出特征图；当第$l$层是完全连接层时，$j$表示第$j$个神经元。$w^{r,l}_{j,i,c}$ 和 $b^{r,l}_{j,c}$ 分别是为卷积层的第 $l$ 层中的卷积核矩阵和偏差矩阵。 $N^{l-1}_p$ 表示($l-1$)层中输出特征映射的数量，该层是一个池层。$w^{r,l}_{j,i,f}$和$b^{r,l}_{j,f}$分别是为全连层的第 $l$ 层中的权值和偏置。$N^{l-1}_f$表示($l-1$)层中神经元的数量，该层是一个全连接层。 $σ( )$ 是激活函数，通常选择为整流线性单位，即 $σ(x) = max(0,x)$。* 表示卷积运算。 $H^l_p$ 和 $W^l_p$ 分别是第$l$层中池化窗口的高度和宽度。 $s^l_p$ 是最大池化操作的滑动步幅。</p>\n<p>2) 并行误差 BP：基于传统的梯度下降原理[27]，在并行训练过程中确定了并行误差BP阶段的全局学习参数和局部学习参数之间的关系。在步骤 $t$，完全连接的层中的全局学习参数 $w^l_{j,i,f}$ 和 $b^l_{j,f}$ 更新为</p>\n<p><img src=\"/articles/Traffic-Network-Flow-Prediction/image-20210222165242874.png\" alt=\"image-20210222165242874\"></p>\n<p><img src=\"/articles/Traffic-Network-Flow-Prediction/image-20210222165325532.png\" alt=\"image-20210222165325532\"></p>\n<p>全连通层中的局部权重和偏差表示为</p>\n<p><img src=\"/articles/Traffic-Network-Flow-Prediction/image-20210222165411159.png\" alt=\"image-20210222165411159\"></p>\n<p>类似地，在步骤t的卷积层中的全局学习参数 $w^l_{j,i,c}$ 和 $b^l_{j,c}$ 迭代计算为</p>\n<p><img src=\"/articles/Traffic-Network-Flow-Prediction/image-20210222165646807.png\" alt=\"image-20210222165646807\"></p>\n<p>卷积层中的局部权重和偏差表示为</p>\n<p><img src=\"/articles/Traffic-Network-Flow-Prediction/image-20210222165723988.png\" alt=\"image-20210222165723988\"></p>\n<p>式$(8)-(15)$表明，全局学习参数 $w^l_{j,i,c}$ ， $b^l_{j,c}$ ， $w^l_{j,i,f}$ 和 $b^l_{j,f}$ 分别是局部学习参数 $w^{r,l}_{j,i,c}$ ， $b^{r,l}_{j,c}$  和 $b^{r,l}_{j,f}$ 的平均值$(r = 1,2,…,R)$ 。</p>\n<p>在$(8)-(15)$中，相对于数据子集$r$，迭代地计算出误差敏感性 $δ^{r,l}_{n,j,f}$ ， $δ^{r,l}_{n,j,p}$ 和 $δ^{r,l}_{n,j,c}$ ，如下所示：</p>\n<p><img src=\"/articles/Traffic-Network-Flow-Prediction/image-20210222170851525.png\" alt=\"image-20210222170851525\"></p>\n<p>其中 $N^{l+1}_f$ 是第$(l + 1)$层中的神经元数量，该层是完全连接的层。 $N^{l+1}_c$ 是第$(l + 1)$层（卷积层）中输出特征图的数量。 $rot180(w^{r,l+1}_{\\tau,j,c})$ 表示 $w^{r,l+1}_{\\tau,j,c}$ 中所有元素翻转 $180°$， $up(δ^{r,l+1}_{n,j,p})$ 表示 $δ^{r,l+1}_{n,j,p}$ 的向上采样操作，以使其大小等于 $z^{r,l}_{n,j,c}$ ， $\\bigodot$ 表示元素相乘。</p>\n<p>令$θ(ξ) = {w^l_{j,i,c}, b^l_{j,c}, w^l_{j,i,f}, b^l_{j,f}}$表示从步骤 $ξ$的全局权重和偏差置换的列向量。</p>\n<p>局部梯度表示为 $g^r(ξ) = \\frac{∂J^r}{∂θ(ξ)}=\\sum_{n=1}^{N^r}\\frac{∂J^r_n}{∂θ(ξ)}.$ </p>\n<p>局部梯度平方表示为 $G^r(ξ)=[g^r(ξ)]^Tg^r(ξ) .$</p>\n<p>全局自适应学习率可由传统学习率确定，表示为</p>\n<p><img src=\"/articles/Traffic-Network-Flow-Prediction/image-20210222173540467.png\" alt=\"image-20210222173540467\"></p>\n<p>其中ε是基本学习率，μ是极小的常数。公式$(19)$表示可以从前$(t-1)$个步骤的局部梯度平方$G^r(ξ)(ξ= 1,2,…,t-1)$的累积和中合成$η(t)$ 。</p>\n<p>以上推导过程表明，DCNN模型的序列训练和并行训练算法都是相对于整个数据集从统一梯度下降原理出发的，也就是说，并行训练算法的收敛性类似于串行训练算法。 从理论上讲，这保证了整个数据集的全局特征都可以从局部学习中提取出来，而与各自的数据子集无关。</p>\n<h4 id=\"D-Algorithm-Representation\"><a href=\"#D-Algorithm-Representation\" class=\"headerlink\" title=\"D. Algorithm Representation\"></a>D. Algorithm Representation</h4><p>算法1中详细说明了基于数据并行化的并行训练过程。主节点负责任务调度，资源分配，数据聚合以及从节点之间的数据分配。 同时，从节点主要承担特定的计算任务。 第1行和第2行初始化主节点和从节点。 第4行描述了主节点广播的全局参数。 第5-15行说明从属节点中的并行特征学习，第16–28行表示从属节点中的并行误差BP。 然后，从节点反馈局部学习参数，局部梯度平方和第29行的局部损失函数。主节点通过第30行聚合全局参数、学习速率和损失函数。</p>\n<p><img src=\"/articles/Traffic-Network-Flow-Prediction/image-20210222174352908.png\" alt=\"image-20210222174352908\"></p>\n<p><img src=\"/articles/Traffic-Network-Flow-Prediction/image-20210222174411353.png\" alt=\"image-20210222174411353\"></p>\n<p><img src=\"/articles/Traffic-Network-Flow-Prediction/image-20210222174431003.png\" alt=\"image-20210222174431003\"></p>\n<h4 id=\"E-Implementation-on-Spark-Cloud\"><a href=\"#E-Implementation-on-Spark-Cloud\" class=\"headerlink\" title=\"E. Implementation on Spark Cloud\"></a>E. Implementation on Spark Cloud</h4><p>DCNN模型的拟议并行训练方法已部署在Spark云上。 如图3所示，Spark云计算采用典型的主从结构，具有一个主节点和多个从节点。 红色箭头表示全局数据广播，而主节点和从节点之间的蓝色箭头表示本地数据收集。 资源管理器节点用于管理，调度和监视集群中节点的运行状态。数据并行性:将存储在Hadoop HDFS (distributed file system)中的流量网络流的大数据通过Spark应用程序编程接口进行分区。由此产生的交通数据分区被构造成弹性分布式数据集，并分布到相应的从节点上。并行训练：算法1中描述的并行训练过程适用于Spark云中的MapReduce编程系统。在迭代学习过程中，局部数据更新被视为Map阶段，而全局数据更新则在Reduce阶段实现。在Map阶段，所有从属节点以并行方式执行任务，尽管它们在不同的数据分区上。在Reduce阶段，主节点更新全局学习参数和学习率。然后，主节点将这些更新后的全局数据重新分配给每个从节点，作为后续迭代过程的初始值。该过程继续进行，直到达到最大迭代次数或训练精度条件。</p>\n<p><img src=\"/articles/Traffic-Network-Flow-Prediction/image-20210222174921653.png\" alt=\"image-20210222174921653\"></p>\n<p>在Spark云上并行训练交通网络流量预测模型的部署步骤如下:</p>\n<p>1) 交通流训练数据集被提交到Spark cloud，并存储在所有slave nodes 中的HDFS中</p>\n<p>2) 将DCNN预测模型的训练代码提交给Spark cloud</p>\n<p>3) 计算节点信息是根据程序代码计算和配置的，程序代码包括执行器的数量、内存大小和每个执行器的CPU核数</p>\n<p>4) 任务请求被提交给资源管理器(RM)，然后，RM 部署相应的计算节点，并在主节点和多个从节点之间建立连接</p>\n<p>5) 主节点初始化网络结构和参数，并将模型副本分发给从节点</p>\n<p>6) 主节点将全局学习参数和学习率分配给从节点</p>\n<p>7) 从属节点以并行方式计算局部梯度、更新局部学习参数、梯度平方和损失函数，尽管在不同的数据分区上</p>\n<p>8) 来自从节点的局部学习参数和梯度平方被累积以获取全局学习参数和主节点上的学习速率</p>\n<p>9) 如果训练过程满足终止条件，则返回预测模型和预测结果。否则，转到步骤(6）</p>\n<h3 id=\"EXPERIMENTS\"><a href=\"#EXPERIMENTS\" class=\"headerlink\" title=\"EXPERIMENTS\"></a>EXPERIMENTS</h3><h4 id=\"A-Dataset-Description\"><a href=\"#A-Dataset-Description\" class=\"headerlink\" title=\"A. Dataset Description\"></a>A. Dataset Description</h4><p>利用美国加州运输部交通绩效评估系统(PeMS)数据库中的路网交通流数据，通过并行训练对DCNN模型的预测性能进行评估。所需数据已从PeMS网站下载。道路网络中的日随机交通流呈现出相同的波动模式，反映了相对稳定的行驶需求和规则的交通流传播。这是一个很好的例子。可以观察到，一周中的同一天的交通流量呈现出一种与时间有关的周期性可重复性，并且受到道路的干扰。训练数据嵌入了高速公路上交通流量的时间序列波动特征及其与时空的耦合关系。 高速公路之间的交通流量。 DCNN模型用于捕获交通网络流的动态特征。</p>\n<p>图4(a)示出加州高速公路交通网络结构，包括12条高速公路: $SR17-S,SR17-N,SR87-N,SR87-S,US101-N,US101-S,I280-N,I280-S,I680-N,I680-S,I880-N$以及$I880-S$ 。每30分钟收集一次交通数据，每5分钟收集一次来自39000多个探测器的数据，这些检测器分布在加州所有主要大城市的高速公路系统中。在本研究中，2016年的前9个月，从指定的12条高速公路收集的交通网络流量数据应用于实验。使用前8个月的数据作为训练数据集，剩余1个月的数据作为测试数据集。在Spark云计算平台上，将整个训练数据集分解为多个数据集，并分布到不同的计算节点上。通过多节点局部学习与对应数据子集的协调，学习整个数据集的全局数据特征。利用剩余的测试数据验证采用并行训练的DCNN模型是否具有提取稳定随机交通流模式的能力。将预测时间间隔定义为5、15、30、45和60min，将模型中的原始交通流数据聚合为相应的时间间隔。训练数据集和测试数据集分为输入数据和输出数据两部分。DCNN模型的输入和输出数据分别由(1)和式(2)构建。4(b)显示2016年5月9日的交通图像样本。红色区域代表拥堵，绿色区域代表交通顺畅。</p>\n<p><img src=\"/articles/Traffic-Network-Flow-Prediction/image-20210222182324651.png\" alt=\"image-20210222182324651\"></p>\n<h4 id=\"B-Evaluation-Indices-and-Parameter-Configuration\"><a href=\"#B-Evaluation-Indices-and-Parameter-Configuration\" class=\"headerlink\" title=\"B. Evaluation Indices and Parameter Configuration\"></a>B. Evaluation Indices and Parameter Configuration</h4><p>采用平均绝对误差（MAE）、平均相对误差（MRE）和均方根误差（RMSE）三个综合评价指标评价交通流预测模型的预测精度。计算方式如下：</p>\n<p><img src=\"/articles/Traffic-Network-Flow-Prediction/image-20210222182613529.png\" alt=\"image-20210222182613529\"></p>\n<p>其中$\\hat{y}^m_n$是第m个链路上的预测流量，$y^m_n$是第m个链路上的观测流量，$M$是测试数据样本的输出维度，而$N_t$是测试数据样本的数量。为了衡量路网中不同路段之间的预测精度，本文提出了一种性能指标，即预测精度指标的累积比例（CP）。以MRE索引为例进行说明。将所有链路的MREs按升序排序。最小值和最大值分别表示为$MRE^{min},MRE^{max}$。在链路上的MRE准确性的示例被定义为MREs。CP表示为</p>\n<p><img src=\"/articles/Traffic-Network-Flow-Prediction/image-20210222183518350.png\" alt=\"image-20210222183518350\"></p>\n<p>其中$N_{MRE_S}$是$MRE_s$不大于$MRE_s$的链路数。 显然，当$MRE_s = MRE^{max}$时，$CP(MRE_s)= 1$。 CP与MRE的离散点曲线反映了随着MRE的增加，链路部分的累积分布。通过使用Spark云上不同数量的节点，加速Speedup用于评估并行训练算法的时间效率。 计算方式如下：</p>\n<p><img src=\"/articles/Traffic-Network-Flow-Prediction/image-20210222184214461.png\" alt=\"image-20210222184214461\"></p>\n<p>其中$T_s$是具有指定数据集的单台机器上DCNN模型的训练时间，而$T_p$是使用同一数据集的并行训练的训练时间。</p>\n<p>DCNN模型的网络结构设计和参数调整对于预测准确性至关重要。 在这项研究中，我们通过大量实验获得了针对交通网络流量预测的不同预测间隔的适当模型结构。 这些在表$I$中列出。DCNN模型的所有模拟都部署在阿里云Elastic MapReduce计算平台上。</p>\n<p><img src=\"/articles/Traffic-Network-Flow-Prediction/image-20210222184809248.png\" alt=\"image-20210222184809248\"></p>\n<h4 id=\"C-Prediction-Accuracy-and-Generality-Capability\"><a href=\"#C-Prediction-Accuracy-and-Generality-Capability\" class=\"headerlink\" title=\"C. Prediction Accuracy and Generality Capability\"></a>C. Prediction Accuracy and Generality Capability</h4><p>为了充分说明基于 DCNN 模型的交通流预测在预测精度和通用性方面的优势，我们选择了其他4种交通流预测模型作为比较对象: BP 神经网络、 RBF、 SVR 和 DTR。</p>\n<p>如表 $II$所示，对于不同的预测区间，DCNN模型的 MAE、 MRE 和 RMSE 明显小于其他预测模型。在 MRE 指标方面，对于不同的流量网络工作流预测任务，DCNN 模型的预测准确率一般在90% 以上。具体来说，对于5min 的流量预测，DCNN模型的预测精度比 BP、 RBF、 SVR 和 DTR 模型分别提高了4.51% 、7.24% 、10.15% 和6.27% 。对于15分钟交通流量预测，DCNN模型的预测精度分别比 BP、 RBF、 SVR 和 DTR 模型分别高5.26% 、7.17% 、5.23% 和6.07% 。对于30分钟、45分钟和60分钟的交通流量预测，DCNN 模型的预测精度一般比其他模型的预测精度高3.29-9.85%。DCNN 模型的 MAE和 RMSE 平均分别比 BP、 RBF、 SVR 和 DTR 预测模型的 MAEs和 RMSE 低7.49-40.07% 和4.38-38.22% 。这些结果表明，利用 DCNN 模型从海量交通数据中分离出时空特征，可以显著提高预测精度。与 BP、 RBF、 SVR 和 DTR 模型相比，DCNN 模型具有独特的卷积过程，能够处理网络流图像数据，在不丢失空间结构信息的情况下提取时间序列特征。此外，多层网络结构可以平衡隐藏在流量大数据集中的海量信息的学习。并行训练方法能够快速、全局地学习交通网络流的基本特征。</p>\n<p>泛化能力是衡量DCNN模型对不同交通场景适应性程度的重要指标。通过一系列实验，将DCNN模型与其它四种典型预测模型进行比较，评价了DCNN模型在不同预测区间的通用性。表$II$表明，DCNN模型的预测精度在90.03%到92.16%之间。这说明DCNN模型对不同预测区间的适应能力较强。然而，BP和SVR模型的MRE随着预测间隔的变化而迅速波动。这两个模型对预测间隔的变化很敏感，这意味着这两个模型的泛化能力很低。对于不同的预测区间，RBF和DTR模型的预测精度相对稳定。当时间间隔较大时，该模型的交通流预测精度略有下降。这是因为模型提取的有效特征会随着数据量的减少而减少。图5显示了不同预测间隔下CP与MRE的关系曲线。对于5、15、30、45和60分钟的预测间隔，超过90％，85％，60％，80％以及70％的高速公路链接上，DCNN模型的MRE预测精度超过90％。 在不同的预测间隔下，DCNN模型的CP与MRE的曲线都位于其他预测模型的CP与MRE的曲线的左上侧。 这表明不同高速公路个体之间DCNN模型的预测准确性有所提高。</p>\n<p><img src=\"/articles/Traffic-Network-Flow-Prediction/image-20210222184742766.png\" alt=\"image-20210222184742766\"></p>\n<p><img src=\"/articles/Traffic-Network-Flow-Prediction/image-20210222192313448.png\" alt=\"image-20210222192313448\"></p>\n<h4 id=\"D-Convergence-and-Efficiency\"><a href=\"#D-Convergence-and-Efficiency\" class=\"headerlink\" title=\"D. Convergence and Efficiency\"></a>D. Convergence and Efficiency</h4><p>表$III$中显示了Spark云上单机和多节点计算环境之间的类似预测性能。 显然，使用一台机器的预测精度为90.18％，而在相同的训练时期，使用Spark云上不同数量的计算节点的精度在91.46-92.69％之间。图6（a）描述了单机训练和使用不同计算节点的并行训练的相似收敛过程。图6（b）中，从迭代步骤100开始开始，我们可以进一步观察到损失函数随着训练时间的增加而减少。 它们最终在Spark云上的单机训练和分布式并行训练中收敛到几乎相同的阈值。 在不同的计算节点之间，预测精度和收敛过程的细微差异是由训练开始时随机函数产生的初始权重和偏差引起的。 尽管如此，由于理论上有保证的训练算法，训练过程最终收敛到几乎相同的阈值。表$III$和图6说明并行训练与单机训练训练结果的收敛性一致性。这与第四节的理论分析是一致的。</p>\n<p><img src=\"/articles/Traffic-Network-Flow-Prediction/image-20210222193820080.png\" alt=\"image-20210222193820080\"></p>\n<p><img src=\"/articles/Traffic-Network-Flow-Prediction/image-20210222193559417.png\" alt=\"image-20210222193559417\"></p>\n<p>并行计算方法取得了良好的计算效率，如图7所示。与单机计算环境相比，随着图7中左y轴的增加，Spark云上计算节点的数量增加，计算时间逐渐减少。大量的训练样本分布在多个从节点之间，可以减少计算量。 此外，Spark云计算将训练过程的中间结果捕获到内存中。 这进一步提高了迭代数据处理的计算效率。如图7所示，在右y轴的基础上，随着节点数量的增加，加速比在早期阶段近似线性地增加。 但是，当后续阶段节点数增加到一定规模时，节点间的数据传输增加了通信开销，云上的资源调度和进程管理增加了并行管理开销。 这相应地影响了加速比并使其线性度降低。</p>\n<p><img src=\"/articles/Traffic-Network-Flow-Prediction/image-20210222194702280.png\" alt=\"image-20210222194702280\"></p>\n<h4 id=\"E-Tempo–Spatial-Demonstration\"><a href=\"#E-Tempo–Spatial-Demonstration\" class=\"headerlink\" title=\"E. Tempo–Spatial Demonstration\"></a>E. Tempo–Spatial Demonstration</h4><p>采用基于DCNN的交通网络流量预测模型，获取高速公路交通流量的时间序列特征和空间耦合特征。图8展示了2016年9月6日至14日5分钟间隔交通网络流量的观测和预测结果。图8(a)描述每5分钟在高速公路上观测一次的交通流量，分别用1-12编号。图8(b)表示高速公路上每5分钟的交通流量预测结果。从空间维度上，图8中，预测结果表明，在时间-空间动态中，流量形态与实际流量极为相似。同时，图8表明交通流量的周期性变化趋势和随机波动已经被 DCNN 模型沿时间维度近似捕获。同时，图8表明交通流量的周期性变化趋势和随机波动已经被 DCNN 模型沿时间维度近似捕获。</p>\n<p><img src=\"/articles/Traffic-Network-Flow-Prediction/image-20210222200609677.png\" alt=\"image-20210222200609677\"></p>\n<p>总体而言，基于DCNN的Spark云并行训练算法的交通网络流量预测模型具有明显的优势。通过对相应数据子集中分布计算节点的局部学习，显示了良好的全局特征学习能力和学习收敛的理论基础。与DCNN模型的串行学习算法相比，在Spark云上并行训练算法的实施提高了实时参数学习效率。</p>\n<h3 id=\"CONCLUSION\"><a href=\"#CONCLUSION\" class=\"headerlink\" title=\"CONCLUSION\"></a>CONCLUSION</h3><p>本文提出了一种面向交通大数据处理的基于 DCNN 模型的交通网络流量预测方法。该算法结合了参数化网络模型的并行训练算法和计算机网络模型的并行训练算法。考虑到数据分解不会削弱对交通网络流全局特征的捕获，而是有利于计算复杂度的处理，为保证并行训练算法提供了理论基础。实验结果表明，该方法在预测精度和通用性方面优于 BP、 RBF、 SVR 和 DTR 模型。该并行训练算法既能提取不同路段交通流的时间序列特征，又能提取路段间交通流的空间耦合特征。全局特征可以通过分布式数据集的局部学习以并行方式重构。提出的并行训练算法提高了交通网络流量预测的计算效率。Spark云计算平台提供了灵活的机制来扩展计算资源和能力。这使得该实现方案适用于全网流量预测。基于Spark云计算的交通网络流量预测可以帮助交通指挥中心做出及时的控制决策，引导出行者选择最优路径规避拥堵。这是留给将来研究的。</p>\n","categories":[],"tags":["paper translation"]},{"title":"九品炼丹师","url":"https://hahally.github.io//articles/九品炼丹师/","content":"<blockquote>\n<p>前言</p>\n</blockquote>\n<p>第一次参加<code>cv</code> 赛事，由清华举办的一场<code>AI 挑战赛</code> , 旨在推广 <code>jittor</code>框架的吧。<a href=\"https://www.educoder.net/competitions/index/Jittor-2\" target=\"_blank\" rel=\"noopener\">传送门</a></p>\n<p>共有两个赛道，一个细分类，一个目标检测。由于有一个毕设与目标检测相关，于是毫不犹豫的报名参加了。算是入坑<code>DL</code> 了。前期在<code>tensorflow</code> 、<code>pytorch</code> 、<code>jittor</code> 三大框架之间反复横跳，最后还是抛弃了<code>tf</code>。主要是服务器上的<code>tf</code>用不了显卡的算力。环境问题懒得去倒腾了。<code>pytorch</code> 上手也很快，而且与<code>jittor</code> 相似。</p>\n<p>选着狗细分类这个赛道试水，结果差点每淹死在水里面。查阅了许多细分类的论文，一个个提到说效果达到<code>SOTA</code> ，结果到自己手里就废了。</p>\n<blockquote>\n<p>在好的配方，也能被炼废。 </p>\n</blockquote>\n<p>拿到配方，丹炉架好，药材就绪，大力按下回车键后，看着进度条缓缓加载，epoch 1,2,3,…</p>\n<p>这是一个漫长的过程，睡一觉第二天醒来，观察各项指标变化，没有预期那么好，却也差强人意。点击提交后，果然，依旧没有好的效果。2021.2.19，在尝试好几种配方，反复炼丹数十余日后，最终还是以失败告终。</p>\n<blockquote>\n<p>高端的食材往往只需要简单的烹饪。</p>\n</blockquote>\n<p>按照 <code>baseline</code>的方法，仅仅只是使用了一个简单的<code>resnet50</code>分类网络而已，最后的效果却要高于我各种花里胡哨的方法好几个百分点。开源的基线已是我望尘莫及的极限了。着实有些颓废。</p>\n<blockquote>\n<p>I know nothing but my ignorance.</p>\n</blockquote>\n<p>炼丹之路注定是布满荆棘的坎坷之路。才疏学浅，当厚积薄发才是。</p>\n","categories":[],"tags":[]},{"title":"TsinghuaDogs-3","url":"https://hahally.github.io//articles/TsinghuaDogs-3/","content":"<h3 id=\"import-package\"><a href=\"#import-package\" class=\"headerlink\" title=\"import package\"></a>import package</h3><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> json</span><br><span class=\"line\"><span class=\"keyword\">import</span> os</span><br><span class=\"line\"><span class=\"keyword\">import</span> time</span><br><span class=\"line\"><span class=\"keyword\">from</span> tqdm <span class=\"keyword\">import</span> tqdm</span><br><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\"><span class=\"keyword\">from</span> math <span class=\"keyword\">import</span> sqrt</span><br><span class=\"line\"><span class=\"keyword\">import</span> cv2</span><br><span class=\"line\"><span class=\"keyword\">from</span> PIL <span class=\"keyword\">import</span> Image</span><br><span class=\"line\"><span class=\"keyword\">import</span> matplotlib.pyplot <span class=\"keyword\">as</span> plt</span><br><span class=\"line\">%matplotlib inline</span><br><span class=\"line\"><span class=\"keyword\">import</span> warnings</span><br><span class=\"line\">warnings.filterwarnings(<span class=\"string\">\"ignore\"</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">import</span> torch</span><br><span class=\"line\"><span class=\"keyword\">import</span> torch.nn <span class=\"keyword\">as</span> nn</span><br><span class=\"line\"><span class=\"keyword\">import</span> torchvision</span><br><span class=\"line\"><span class=\"keyword\">from</span> torchvision.models <span class=\"keyword\">import</span> resnet18</span><br><span class=\"line\"><span class=\"keyword\">from</span> torchvision <span class=\"keyword\">import</span> transforms</span><br><span class=\"line\"><span class=\"keyword\">from</span> torch.utils.data <span class=\"keyword\">import</span> Dataset</span><br><span class=\"line\"><span class=\"keyword\">import</span> torch.optim <span class=\"keyword\">as</span> optim</span><br><span class=\"line\"></span><br><span class=\"line\">print(<span class=\"string\">'GPUs Available:'</span>,torch.cuda.is_available())</span><br><span class=\"line\">device = torch.device(<span class=\"string\">\"cuda\"</span> <span class=\"keyword\">if</span> torch.cuda.is_available() <span class=\"keyword\">else</span> <span class=\"string\">\"cpu\"</span>)</span><br></pre></td></tr></table></figure>\n<h3 id=\"build-model\"><a href=\"#build-model\" class=\"headerlink\" title=\"build model\"></a>build model</h3><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">Net</span><span class=\"params\">(nn.Module)</span>:</span></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">__init__</span><span class=\"params\">(self,n_classes)</span>:</span></span><br><span class=\"line\">        super(Net, self).__init__()</span><br><span class=\"line\">        self.features = nn.Sequential(resnet18().conv1,</span><br><span class=\"line\">                                      resnet18().bn1,</span><br><span class=\"line\">                                      resnet18().relu,</span><br><span class=\"line\">                                      resnet18().maxpool,</span><br><span class=\"line\">                                      resnet18().layer1,</span><br><span class=\"line\">                                      resnet18().layer2,</span><br><span class=\"line\">                                      resnet18().layer3,</span><br><span class=\"line\">                                      resnet18().layer4)</span><br><span class=\"line\">        self.classifiers = nn.Sequential(nn.Linear(<span class=\"number\">512</span>**<span class=\"number\">2</span>, n_classes))</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">forward</span><span class=\"params\">(self, x)</span>:</span></span><br><span class=\"line\">        x = self.features(x)</span><br><span class=\"line\">        batch_size = x.size(<span class=\"number\">0</span>)</span><br><span class=\"line\">        feature_size = x.size(<span class=\"number\">2</span>) * x.size(<span class=\"number\">3</span>)</span><br><span class=\"line\">        x = x.view(batch_size, <span class=\"number\">512</span>, feature_size)</span><br><span class=\"line\">        x = (torch.bmm(x, torch.transpose(x, <span class=\"number\">1</span>, <span class=\"number\">2</span>)) / feature_size).view(</span><br><span class=\"line\">            batch_size, <span class=\"number\">-1</span>)</span><br><span class=\"line\">        x = torch.nn.functional.normalize(</span><br><span class=\"line\">            torch.sign(x) * torch.sqrt(torch.abs(x) + <span class=\"number\">1e-10</span>))</span><br><span class=\"line\">        x = self.classifiers(x)</span><br><span class=\"line\">        <span class=\"keyword\">return</span> x</span><br></pre></td></tr></table></figure>\n<h3 id=\"load-data\"><a href=\"#load-data\" class=\"headerlink\" title=\"load data\"></a>load data</h3><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># load data</span></span><br><span class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">LoadDogData</span><span class=\"params\">(Dataset)</span>:</span></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">__init__</span><span class=\"params\">(self,data_dir,mode=<span class=\"string\">'train'</span>,transforms=None)</span>:</span></span><br><span class=\"line\">        super().__init__()</span><br><span class=\"line\">        self.mode = mode.upper()</span><br><span class=\"line\">        self.data_dir = data_dir</span><br><span class=\"line\">        self.transforms = transforms</span><br><span class=\"line\">        </span><br><span class=\"line\">        <span class=\"keyword\">assert</span> self.mode <span class=\"keyword\">in</span> [<span class=\"string\">'TRAIN'</span>,<span class=\"string\">'VALID'</span>]</span><br><span class=\"line\">        </span><br><span class=\"line\">        <span class=\"keyword\">with</span> open(os.path.join(self.data_dir, self.mode + <span class=\"string\">'_images.json'</span>), <span class=\"string\">'r'</span>) <span class=\"keyword\">as</span> j:</span><br><span class=\"line\">            self.images = json.load(j)</span><br><span class=\"line\">            </span><br><span class=\"line\">        <span class=\"keyword\">with</span> open(os.path.join(self.data_dir, self.mode + <span class=\"string\">'_objects.json'</span>), <span class=\"string\">'r'</span>) <span class=\"keyword\">as</span> j:</span><br><span class=\"line\">            self.objects = json.load(j)</span><br><span class=\"line\">            </span><br><span class=\"line\">        <span class=\"keyword\">assert</span> len(self.images) == len(self.objects)</span><br><span class=\"line\">        </span><br><span class=\"line\">        self.total_len = len(self.images)</span><br><span class=\"line\">        print(<span class=\"string\">\"[*] Loading &#123;&#125; &#123;&#125; images.\"</span>.format(self.mode,self.total_len))</span><br><span class=\"line\">        </span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">__getitem__</span><span class=\"params\">(self, idx)</span>:</span></span><br><span class=\"line\">        </span><br><span class=\"line\"><span class=\"comment\">#         print('./dataset/low-resolution/'+self.images[idx])</span></span><br><span class=\"line\">        img = Image.open(<span class=\"string\">'./dataset/low-resolution/'</span>+self.images[idx]).convert(<span class=\"string\">'RGB'</span>)</span><br><span class=\"line\">        objects = self.objects[idx]</span><br><span class=\"line\">        labels = np.array(objects[<span class=\"string\">'labels'</span>])[<span class=\"number\">0</span>]</span><br><span class=\"line\">        </span><br><span class=\"line\">        <span class=\"keyword\">if</span> self.transforms <span class=\"keyword\">is</span> <span class=\"keyword\">not</span> <span class=\"literal\">None</span>:</span><br><span class=\"line\">            img = self.transforms(img)</span><br><span class=\"line\">            </span><br><span class=\"line\">        <span class=\"keyword\">return</span> img, labels</span><br><span class=\"line\">    </span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">__len__</span><span class=\"params\">(self)</span>:</span></span><br><span class=\"line\">        <span class=\"keyword\">return</span> len(self.images)</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># label map</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">get_label_map</span><span class=\"params\">()</span>:</span></span><br><span class=\"line\">    <span class=\"keyword\">with</span> open(<span class=\"string\">'./dataset/JsonData/label_map.json'</span>,<span class=\"string\">'r'</span>) <span class=\"keyword\">as</span> j:</span><br><span class=\"line\">        labels = json.load(j)</span><br><span class=\"line\">    <span class=\"keyword\">return</span> labels</span><br></pre></td></tr></table></figure>\n<h3 id=\"transforms\"><a href=\"#transforms\" class=\"headerlink\" title=\"transforms\"></a>transforms</h3><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">data_transforms = &#123;</span><br><span class=\"line\">    <span class=\"string\">'train'</span>: transforms.Compose([</span><br><span class=\"line\">        transforms.RandomResizedCrop(<span class=\"number\">224</span>),</span><br><span class=\"line\">        transforms.RandomHorizontalFlip(),</span><br><span class=\"line\">        transforms.ToTensor(),</span><br><span class=\"line\">        transforms.Normalize([<span class=\"number\">0.485</span>, <span class=\"number\">0.456</span>, <span class=\"number\">0.406</span>], [<span class=\"number\">0.229</span>, <span class=\"number\">0.224</span>, <span class=\"number\">0.225</span>])</span><br><span class=\"line\">    ]),</span><br><span class=\"line\">    <span class=\"string\">'valid'</span>: transforms.Compose([</span><br><span class=\"line\">        transforms.Resize(<span class=\"number\">256</span>),</span><br><span class=\"line\">        transforms.CenterCrop(<span class=\"number\">224</span>),</span><br><span class=\"line\">        transforms.ToTensor(),</span><br><span class=\"line\">        transforms.Normalize([<span class=\"number\">0.485</span>, <span class=\"number\">0.456</span>, <span class=\"number\">0.406</span>], [<span class=\"number\">0.229</span>, <span class=\"number\">0.224</span>, <span class=\"number\">0.225</span>])</span><br><span class=\"line\">    ]),</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<h3 id=\"Visualize-a-few-images\"><a href=\"#Visualize-a-few-images\" class=\"headerlink\" title=\"Visualize a few images\"></a>Visualize a few images</h3><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">dataset = LoadDogData(data_dir=<span class=\"string\">'./dataset/JsonData/'</span>,</span><br><span class=\"line\">                      mode=<span class=\"string\">'Train'</span>,</span><br><span class=\"line\">                      transforms=data_transforms[<span class=\"string\">'train'</span>])</span><br><span class=\"line\">dataloaders = torch.utils.data.DataLoader(dataset, batch_size=<span class=\"number\">1</span>, shuffle=<span class=\"literal\">True</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">imshow</span><span class=\"params\">(inp, title=None)</span>:</span></span><br><span class=\"line\">    <span class=\"string\">\"\"\"Imshow for Tensor.\"\"\"</span></span><br><span class=\"line\">    inp = inp.numpy().transpose(<span class=\"number\">1</span>,<span class=\"number\">2</span>,<span class=\"number\">0</span>)</span><br><span class=\"line\">    mean = np.array([<span class=\"number\">0.485</span>, <span class=\"number\">0.456</span>, <span class=\"number\">0.406</span>])</span><br><span class=\"line\">    std = np.array([<span class=\"number\">0.229</span>, <span class=\"number\">0.224</span>, <span class=\"number\">0.225</span>])</span><br><span class=\"line\">    inp = std * inp + mean</span><br><span class=\"line\">    inp = np.clip(inp, <span class=\"number\">0</span>, <span class=\"number\">1</span>)</span><br><span class=\"line\">    plt.imshow(inp)</span><br><span class=\"line\">    <span class=\"keyword\">if</span> title <span class=\"keyword\">is</span> <span class=\"keyword\">not</span> <span class=\"literal\">None</span>:</span><br><span class=\"line\">        plt.title(title)</span><br><span class=\"line\">    plt.pause(<span class=\"number\">0.001</span>)  <span class=\"comment\"># pause a bit so that plots are updated</span></span><br><span class=\"line\"></span><br><span class=\"line\">inputs, class_names = next(iter(dataloaders))</span><br><span class=\"line\">labels_map = get_label_map()</span><br><span class=\"line\">rev = &#123;str(v):k <span class=\"keyword\">for</span> k,v <span class=\"keyword\">in</span> get_label_map().items()&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">out = torchvision.utils.make_grid(inputs)</span><br><span class=\"line\"></span><br><span class=\"line\">imshow(out, title=rev[str(int(class_names))])</span><br></pre></td></tr></table></figure>\n<h3 id=\"train-model\"><a href=\"#train-model\" class=\"headerlink\" title=\"train model\"></a>train model</h3><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br><span class=\"line\">77</span><br><span class=\"line\">78</span><br><span class=\"line\">79</span><br><span class=\"line\">80</span><br><span class=\"line\">81</span><br><span class=\"line\">82</span><br><span class=\"line\">83</span><br><span class=\"line\">84</span><br><span class=\"line\">85</span><br><span class=\"line\">86</span><br><span class=\"line\">87</span><br><span class=\"line\">88</span><br><span class=\"line\">89</span><br><span class=\"line\">90</span><br><span class=\"line\">91</span><br><span class=\"line\">92</span><br><span class=\"line\">93</span><br><span class=\"line\">94</span><br><span class=\"line\">95</span><br><span class=\"line\">96</span><br><span class=\"line\">97</span><br><span class=\"line\">98</span><br><span class=\"line\">99</span><br><span class=\"line\">100</span><br><span class=\"line\">101</span><br><span class=\"line\">102</span><br><span class=\"line\">103</span><br><span class=\"line\">104</span><br><span class=\"line\">105</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">train_model</span><span class=\"params\">(model, criterion, optimizer, scheduler, dataloaders,num_epochs=<span class=\"number\">25</span>)</span>:</span></span><br><span class=\"line\">    since = time.time()</span><br><span class=\"line\"></span><br><span class=\"line\">    best_model_wts = copy.deepcopy(model.state_dict())</span><br><span class=\"line\">    best_acc = <span class=\"number\">0.0</span></span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">for</span> epoch <span class=\"keyword\">in</span> range(num_epochs):</span><br><span class=\"line\">        print(<span class=\"string\">'Epoch &#123;&#125;/&#123;&#125;'</span>.format(epoch, num_epochs - <span class=\"number\">1</span>))</span><br><span class=\"line\">        print(<span class=\"string\">'-'</span> * <span class=\"number\">10</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"comment\"># Each epoch has a training and validation phase</span></span><br><span class=\"line\">        <span class=\"keyword\">for</span> phase <span class=\"keyword\">in</span> [<span class=\"string\">'train'</span>, <span class=\"string\">'val'</span>]:</span><br><span class=\"line\">            <span class=\"keyword\">if</span> phase == <span class=\"string\">'train'</span>:</span><br><span class=\"line\">                model.train()  <span class=\"comment\"># Set model to training mode</span></span><br><span class=\"line\">            <span class=\"keyword\">else</span>:</span><br><span class=\"line\">                model.eval()   <span class=\"comment\"># Set model to evaluate mode</span></span><br><span class=\"line\"></span><br><span class=\"line\">            running_loss = <span class=\"number\">0.0</span></span><br><span class=\"line\">            running_corrects = <span class=\"number\">0</span></span><br><span class=\"line\"></span><br><span class=\"line\">            <span class=\"comment\"># Iterate over data.</span></span><br><span class=\"line\">            <span class=\"keyword\">for</span> step ,(inputs, labels) <span class=\"keyword\">in</span> enumerate(dataloaders[phase]):</span><br><span class=\"line\">                inputs = inputs.to(device)</span><br><span class=\"line\">                labels = labels.to(device)</span><br><span class=\"line\"></span><br><span class=\"line\">                <span class=\"comment\"># zero the parameter gradients</span></span><br><span class=\"line\">                optimizer.zero_grad()</span><br><span class=\"line\"></span><br><span class=\"line\">                <span class=\"comment\"># forward</span></span><br><span class=\"line\">                <span class=\"comment\"># track history if only in train</span></span><br><span class=\"line\">                <span class=\"keyword\">with</span> torch.set_grad_enabled(phase == <span class=\"string\">'train'</span>):</span><br><span class=\"line\">                    outputs = model(inputs)</span><br><span class=\"line\">                    _, preds = torch.max(outputs, <span class=\"number\">1</span>)</span><br><span class=\"line\">                    loss = criterion(outputs, labels.long())</span><br><span class=\"line\"></span><br><span class=\"line\">                    <span class=\"comment\"># backward + optimize only if in training phase</span></span><br><span class=\"line\">                    <span class=\"keyword\">if</span> phase == <span class=\"string\">'train'</span>:</span><br><span class=\"line\">                        loss.backward()</span><br><span class=\"line\">                        optimizer.step()</span><br><span class=\"line\">                </span><br><span class=\"line\">                <span class=\"comment\"># statistics</span></span><br><span class=\"line\">                running_loss += loss.item() * inputs.size(<span class=\"number\">0</span>)</span><br><span class=\"line\">                running_corrects += torch.sum(preds == labels.data)</span><br><span class=\"line\"><span class=\"comment\">#                 print(type(running_loss),float(running_corrects))</span></span><br><span class=\"line\">        </span><br><span class=\"line\">            <span class=\"keyword\">if</span> phase == <span class=\"string\">'train'</span>:</span><br><span class=\"line\">                scheduler.step()</span><br><span class=\"line\"></span><br><span class=\"line\">            epoch_loss = running_loss / len(dataloaders[phase])</span><br><span class=\"line\">            epoch_acc = running_corrects / len(dataloaders[phase])</span><br><span class=\"line\"></span><br><span class=\"line\">            print(<span class=\"string\">'&#123;&#125; Loss: &#123;:.4f&#125; Acc: &#123;:.4f&#125;'</span>.format(</span><br><span class=\"line\">                phase, epoch_loss, epoch_acc))</span><br><span class=\"line\"></span><br><span class=\"line\">            <span class=\"comment\"># deep copy the model</span></span><br><span class=\"line\">            <span class=\"keyword\">if</span> phase == <span class=\"string\">'val'</span> <span class=\"keyword\">and</span> epoch_acc &gt; best_acc:</span><br><span class=\"line\">                best_acc = epoch_acc</span><br><span class=\"line\">                best_model_wts = copy.deepcopy(model.state_dict())</span><br><span class=\"line\"></span><br><span class=\"line\">    time_elapsed = time.time() - since</span><br><span class=\"line\">    print(<span class=\"string\">'Training complete in &#123;:.0f&#125;m &#123;:.0f&#125;s'</span>.format(</span><br><span class=\"line\">        time_elapsed // <span class=\"number\">60</span>, time_elapsed % <span class=\"number\">60</span>))</span><br><span class=\"line\">    print(<span class=\"string\">'Best val Acc: &#123;:4f&#125;'</span>.format(best_acc))</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># load best model weights</span></span><br><span class=\"line\">    time_stamp = time.strftime(<span class=\"string\">'%Y-%m-%d-%H-%M-%S'</span>,time.localtime(time.time()))</span><br><span class=\"line\">    model.load_state_dict(best_model_wts,<span class=\"string\">'./&#123;&#125;-best_model.pth'</span>.formator(time_stamp))</span><br><span class=\"line\">    <span class=\"keyword\">return</span> model</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">main</span><span class=\"params\">()</span>:</span></span><br><span class=\"line\">    <span class=\"comment\"># --------------------- init parameter --------------------#</span></span><br><span class=\"line\">    n_classes = <span class=\"number\">131</span></span><br><span class=\"line\">    batch_size = <span class=\"number\">1</span></span><br><span class=\"line\">    best_acc = <span class=\"number\">0.</span></span><br><span class=\"line\">    expochs = <span class=\"number\">25</span></span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># ------------------------- model------------------------- #</span></span><br><span class=\"line\">    net = Net(n_classes=n_classes)</span><br><span class=\"line\">    net.to(device)</span><br><span class=\"line\">    </span><br><span class=\"line\">    criterion = nn.CrossEntropyLoss()</span><br><span class=\"line\">    optimizer = optim.SGD(net.parameters(), lr=<span class=\"number\">0.001</span>, momentum=<span class=\"number\">0.9</span>)</span><br><span class=\"line\">    exp_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=<span class=\"number\">7</span>, gamma=<span class=\"number\">0.1</span>)</span><br><span class=\"line\">    <span class=\"comment\"># ------------------------ data load---------------------- #</span></span><br><span class=\"line\">    dataset = LoadDogData(data_dir=<span class=\"string\">'./dataset/JsonData/'</span>,</span><br><span class=\"line\">                          mode=<span class=\"string\">'train'</span>,</span><br><span class=\"line\">                          transforms=data_transforms[<span class=\"string\">'train'</span>])</span><br><span class=\"line\">    train_loaders = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=<span class=\"literal\">True</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">    dataset = LoadDogData(data_dir=<span class=\"string\">'./dataset/JsonData/'</span>,</span><br><span class=\"line\">                          mode=<span class=\"string\">'valid'</span>,</span><br><span class=\"line\">                          transforms=data_transforms[<span class=\"string\">'valid'</span>])</span><br><span class=\"line\"></span><br><span class=\"line\">    valid_loaders = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=<span class=\"literal\">True</span>)</span><br><span class=\"line\">    </span><br><span class=\"line\">    dataloaders = &#123;</span><br><span class=\"line\">        <span class=\"string\">'train'</span>:train_loaders,</span><br><span class=\"line\">        <span class=\"string\">'val'</span>:valid_loaders</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    </span><br><span class=\"line\">    train_model(net, criterion, optimizer, exp_lr_scheduler,dataloaders,num_epochs=expochs)</span><br><span class=\"line\">    </span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">if</span> __name__==<span class=\"string\">'__main__'</span>:</span><br><span class=\"line\">    main()</span><br></pre></td></tr></table></figure>\n","categories":[],"tags":["CV"]},{"title":"TsinghuaDogs-2","url":"https://hahally.github.io//articles/TsinghuaDogs-2/","content":"<h3 id=\"import-package\"><a href=\"#import-package\" class=\"headerlink\" title=\"import package\"></a>import package</h3><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> json</span><br><span class=\"line\"><span class=\"keyword\">import</span> os</span><br><span class=\"line\"><span class=\"keyword\">import</span> time</span><br><span class=\"line\"><span class=\"keyword\">from</span> tqdm <span class=\"keyword\">import</span> tqdm</span><br><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\"><span class=\"keyword\">from</span> math <span class=\"keyword\">import</span> sqrt</span><br><span class=\"line\"><span class=\"keyword\">import</span> cv2</span><br><span class=\"line\"><span class=\"keyword\">import</span> matplotlib.pyplot <span class=\"keyword\">as</span> plt</span><br><span class=\"line\">%matplotlib inline</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">import</span> warnings</span><br><span class=\"line\"></span><br><span class=\"line\">warnings.filterwarnings(<span class=\"string\">\"ignore\"</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">import</span> tensorflow <span class=\"keyword\">as</span> tf</span><br><span class=\"line\"><span class=\"keyword\">from</span> tensorflow.keras <span class=\"keyword\">import</span> datasets, layers, Model</span><br><span class=\"line\"><span class=\"keyword\">from</span> tensorflow.keras.applications.vgg16 <span class=\"keyword\">import</span> VGG16, preprocess_input, decode_predictions</span><br><span class=\"line\"></span><br><span class=\"line\">tf.debugging.set_log_device_placement(<span class=\"literal\">True</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">print(<span class=\"string\">\"Tensorflow Version:\"</span>, tf.__version__)</span><br><span class=\"line\"></span><br><span class=\"line\">print(<span class=\"string\">\"Num GPUs Available: \"</span>,</span><br><span class=\"line\">      len(tf.config.experimental.list_physical_devices(<span class=\"string\">'GPU'</span>)))</span><br></pre></td></tr></table></figure>\n<h3 id=\"load-dataset\"><a href=\"#load-dataset\" class=\"headerlink\" title=\"load dataset\"></a>load dataset</h3><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># load data</span></span><br><span class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">LoadData</span><span class=\"params\">()</span>:</span></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">__init__</span><span class=\"params\">(self,data_dir,mode=<span class=\"string\">'train'</span>)</span>:</span></span><br><span class=\"line\">        super().__init__()</span><br><span class=\"line\">        self.mode = mode.upper()</span><br><span class=\"line\">        self.data_dir = data_dir</span><br><span class=\"line\">        </span><br><span class=\"line\">        <span class=\"keyword\">assert</span> self.mode <span class=\"keyword\">in</span> [<span class=\"string\">'TRAIN'</span>,<span class=\"string\">'VALID'</span>]</span><br><span class=\"line\">        </span><br><span class=\"line\">        <span class=\"keyword\">with</span> open(os.path.join(self.data_dir, self.mode + <span class=\"string\">'_images.json'</span>), <span class=\"string\">'r'</span>) <span class=\"keyword\">as</span> j:</span><br><span class=\"line\">            self.images = json.load(j)</span><br><span class=\"line\">        </span><br><span class=\"line\">        <span class=\"keyword\">with</span> open(os.path.join(self.data_dir, self.mode + <span class=\"string\">'_objects.json'</span>), <span class=\"string\">'r'</span>) <span class=\"keyword\">as</span> j:</span><br><span class=\"line\">            self.objects = json.load(j)</span><br><span class=\"line\">            </span><br><span class=\"line\">        <span class=\"keyword\">assert</span> len(self.images) == len(self.objects)</span><br><span class=\"line\"></span><br><span class=\"line\">        self.total_len = len(self.images)</span><br><span class=\"line\"></span><br><span class=\"line\">        print(<span class=\"string\">\"[*] Loading &#123;&#125; &#123;&#125; images.\"</span>.format(self.mode,self.total_len))</span><br><span class=\"line\">    </span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">__getitem__</span><span class=\"params\">(self, idx)</span>:</span></span><br><span class=\"line\">        </span><br><span class=\"line\"><span class=\"comment\">#         image = cv2.imread('./dataset/low-resolution/'+self.images[idx])</span></span><br><span class=\"line\"><span class=\"comment\">#         image = cv2.cvtColor(image,cv2.COLOR_BGR2RGB).astype(\"float32\")</span></span><br><span class=\"line\">        image = self.images[idx]</span><br><span class=\"line\">        objects = self.objects[idx]</span><br><span class=\"line\">        </span><br><span class=\"line\">        labels = np.array(objects[<span class=\"string\">'labels'</span>]) - <span class=\"number\">1</span></span><br><span class=\"line\">        </span><br><span class=\"line\">        <span class=\"keyword\">return</span> image, labels</span><br><span class=\"line\">    </span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">load_data</span><span class=\"params\">(self)</span>:</span></span><br><span class=\"line\">        </span><br><span class=\"line\">        labels = [ np.array(item[<span class=\"string\">'labels'</span>]) - <span class=\"number\">1.</span> <span class=\"keyword\">for</span> item <span class=\"keyword\">in</span> self.objects]</span><br><span class=\"line\">        </span><br><span class=\"line\">        labels = np.array(labels).reshape([<span class=\"number\">-1</span>])</span><br><span class=\"line\"></span><br><span class=\"line\">        images = self.images</span><br><span class=\"line\">        <span class=\"keyword\">return</span> images,labels</span><br><span class=\"line\">    </span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">__len__</span><span class=\"params\">(self)</span>:</span></span><br><span class=\"line\">        <span class=\"keyword\">return</span> len(self.images)</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">get_data</span><span class=\"params\">(data_dir,mode=<span class=\"string\">'train'</span>,n_mode=<span class=\"number\">100</span>,n_classes)</span>:</span></span><br><span class=\"line\">    mode = mode.upper()</span><br><span class=\"line\">    <span class=\"keyword\">assert</span> mode <span class=\"keyword\">in</span> [<span class=\"string\">'TRAIN'</span>,<span class=\"string\">'VALID'</span>]</span><br><span class=\"line\">    <span class=\"keyword\">with</span> open(os.path.join(data_dir, mode + <span class=\"string\">'_images.json'</span>), <span class=\"string\">'r'</span>) <span class=\"keyword\">as</span> j:</span><br><span class=\"line\">        images = json.load(j)</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">with</span> open(os.path.join(data_dir, mode + <span class=\"string\">'_objects.json'</span>), <span class=\"string\">'r'</span>) <span class=\"keyword\">as</span> j:</span><br><span class=\"line\">        objects = json.load(j)</span><br><span class=\"line\">    </span><br><span class=\"line\">    <span class=\"keyword\">assert</span> len(images) == len(objects)</span><br><span class=\"line\"></span><br><span class=\"line\">    labels = []</span><br><span class=\"line\">    imgs = []</span><br><span class=\"line\">    count = &#123;str(i):<span class=\"number\">0</span> <span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> range(n_classes)&#125;</span><br><span class=\"line\">        </span><br><span class=\"line\">    <span class=\"keyword\">for</span> item <span class=\"keyword\">in</span> images:</span><br><span class=\"line\">        label = int(item.split(<span class=\"string\">'-'</span>)[<span class=\"number\">1</span>][<span class=\"number\">-3</span>:]) - <span class=\"number\">1</span></span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"keyword\">if</span> label&lt;n_classes:</span><br><span class=\"line\">            <span class=\"keyword\">if</span> count[str(label)]&gt;=n_mode:</span><br><span class=\"line\">                <span class=\"keyword\">continue</span></span><br><span class=\"line\">            count[str(label)] += <span class=\"number\">1</span></span><br><span class=\"line\">            labels.append(label)</span><br><span class=\"line\">            imgs.append(item)</span><br><span class=\"line\">            </span><br><span class=\"line\">    print(<span class=\"string\">\"[*] Loading &#123;&#125; &#123;&#125; images.\"</span>.format(mode,len(imgs)))</span><br><span class=\"line\">    <span class=\"keyword\">return</span> imgs,labels</span><br></pre></td></tr></table></figure>\n<h3 id=\"images-precess\"><a href=\"#images-precess\" class=\"headerlink\" title=\"images precess\"></a>images precess</h3><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">normalize</span><span class=\"params\">(x)</span>:</span></span><br><span class=\"line\">    <span class=\"comment\"># 标准化</span></span><br><span class=\"line\">    <span class=\"comment\"># x: [224, 224, 3]</span></span><br><span class=\"line\">    <span class=\"comment\"># mean: [224, 224, 3], std: [3]</span></span><br><span class=\"line\">    img_mean = tf.constant([<span class=\"number\">0.485</span>, <span class=\"number\">0.456</span>, <span class=\"number\">0.406</span>])</span><br><span class=\"line\">    img_std = tf.constant([<span class=\"number\">0.229</span>, <span class=\"number\">0.224</span>, <span class=\"number\">0.225</span>])</span><br><span class=\"line\">    </span><br><span class=\"line\">    x = (x - img_mean)/img_std</span><br><span class=\"line\">    </span><br><span class=\"line\">    <span class=\"keyword\">return</span> x</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">preprocess</span><span class=\"params\">(x,y)</span>:</span></span><br><span class=\"line\">    con = []</span><br><span class=\"line\">    <span class=\"keyword\">for</span> item <span class=\"keyword\">in</span> x:</span><br><span class=\"line\">        item = item.numpy().decode()</span><br><span class=\"line\"></span><br><span class=\"line\">        img = plt.imread(<span class=\"string\">'./dataset/low-resolution/'</span>+item)</span><br><span class=\"line\">        img = cv2.resize(img,(<span class=\"number\">244</span>,<span class=\"number\">244</span>))</span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"comment\"># 图像增强</span></span><br><span class=\"line\">        img = tf.image.random_flip_left_right(img) <span class=\"comment\"># 左右镜像</span></span><br><span class=\"line\">        img= tf.image.random_crop(img, [<span class=\"number\">224</span>, <span class=\"number\">224</span>, <span class=\"number\">3</span>]) <span class=\"comment\"># 随机裁剪</span></span><br><span class=\"line\">        img = tf.cast(img, dtype=tf.float32) / <span class=\"number\">255.</span></span><br><span class=\"line\">        img = normalize(img) <span class=\"comment\"># 标准化</span></span><br><span class=\"line\">        </span><br><span class=\"line\">        con.append(tf.expand_dims(img,axis=<span class=\"number\">0</span>))</span><br><span class=\"line\">       </span><br><span class=\"line\">    images = tf.concat(con,axis=<span class=\"number\">0</span>)</span><br><span class=\"line\">    labels = tf.convert_to_tensor(y) <span class=\"comment\"># 转换成张量</span></span><br><span class=\"line\">    </span><br><span class=\"line\">    <span class=\"keyword\">return</span> images,labels</span><br></pre></td></tr></table></figure>\n<h3 id=\"build-model\"><a href=\"#build-model\" class=\"headerlink\" title=\"build model\"></a>build model</h3><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># Build model</span></span><br><span class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">BCNN</span><span class=\"params\">(Model)</span>:</span></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">__init__</span><span class=\"params\">(self,num_classes)</span>:</span></span><br><span class=\"line\">        super(BCNN,self).__init__()</span><br><span class=\"line\"><span class=\"comment\">#         self.resnet50 = ResNet50(weights='imagenet',</span></span><br><span class=\"line\"><span class=\"comment\">#                                  pooling=None,</span></span><br><span class=\"line\"><span class=\"comment\">#                                  include_top=False,</span></span><br><span class=\"line\"><span class=\"comment\">#                                  input_shape=(224, 224, 3))</span></span><br><span class=\"line\">        self.vgg16 = VGG16(weights=<span class=\"string\">'imagenet'</span>,</span><br><span class=\"line\">                           pooling=<span class=\"literal\">None</span>,</span><br><span class=\"line\">                           include_top=<span class=\"literal\">False</span>,</span><br><span class=\"line\">                           input_shape=(<span class=\"number\">224</span>, <span class=\"number\">224</span>, <span class=\"number\">3</span>))</span><br><span class=\"line\"></span><br><span class=\"line\">        self.model_vgg = Model(inputs=self.vgg16.input,</span><br><span class=\"line\">                               outputs=self.vgg16.get_layer(<span class=\"string\">'block5_conv3'</span>).output)</span><br><span class=\"line\">        </span><br><span class=\"line\"><span class=\"comment\">#         self.model_resnet = Model(inputs=ResNet50.input, </span></span><br><span class=\"line\"><span class=\"comment\">#                                   outputs=ResNet50.get_layer('block5_conv3').output)</span></span><br><span class=\"line\">        </span><br><span class=\"line\">        self.flatten = layers.Flatten()</span><br><span class=\"line\">        self.fc = layers.Dense(num_classes, activation=<span class=\"string\">'softmax'</span>)</span><br><span class=\"line\">        </span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">call</span><span class=\"params\">(self, images)</span>:</span></span><br><span class=\"line\">        </span><br><span class=\"line\">        feat = self.model_vgg(images)</span><br><span class=\"line\">        </span><br><span class=\"line\">        feat_size = feat.shape[<span class=\"number\">1</span>]*feat.shape[<span class=\"number\">2</span>]</span><br><span class=\"line\"><span class=\"comment\">#         feat2 = self.model_resnet(images)</span></span><br><span class=\"line\">        <span class=\"comment\"># feat.shape:(d,w,h,c)</span></span><br><span class=\"line\">        x = tf.reshape(feat,(feat.shape[<span class=\"number\">0</span>],feat_size,feat.shape[<span class=\"number\">3</span>]))</span><br><span class=\"line\">        </span><br><span class=\"line\">        out = tf.matmul(x,tf.transpose(x,perm=[<span class=\"number\">0</span>,<span class=\"number\">2</span>,<span class=\"number\">1</span>]))/feat_size</span><br><span class=\"line\">        out = tf.reshape(out,(out.shape[<span class=\"number\">0</span>],<span class=\"number\">-1</span>))</span><br><span class=\"line\">        out = tf.sign(out)*tf.sqrt(tf.abs(out)+<span class=\"number\">1e-10</span>)</span><br><span class=\"line\">        </span><br><span class=\"line\">        out = tf.nn.l2_normalize(out,axis=<span class=\"number\">1</span>)</span><br><span class=\"line\">        </span><br><span class=\"line\">        out = self.flatten(out)</span><br><span class=\"line\">        </span><br><span class=\"line\">        out = self.fc(out)</span><br><span class=\"line\">        </span><br><span class=\"line\">        <span class=\"keyword\">return</span> out</span><br></pre></td></tr></table></figure>\n<h3 id=\"run-code\"><a href=\"#run-code\" class=\"headerlink\" title=\"run code\"></a>run code</h3><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br><span class=\"line\">77</span><br><span class=\"line\">78</span><br><span class=\"line\">79</span><br><span class=\"line\">80</span><br><span class=\"line\">81</span><br><span class=\"line\">82</span><br><span class=\"line\">83</span><br><span class=\"line\">84</span><br><span class=\"line\">85</span><br><span class=\"line\">86</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">@tf.function</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">train_step</span><span class=\"params\">(x, y)</span>:</span></span><br><span class=\"line\">    <span class=\"keyword\">with</span> tf.GradientTape() <span class=\"keyword\">as</span> tape:</span><br><span class=\"line\">        logits = model(x, training=<span class=\"literal\">True</span>)</span><br><span class=\"line\">        loss_value = loss_fn(y, logits)</span><br><span class=\"line\">    grads = tape.gradient(loss_value, model.trainable_weights)</span><br><span class=\"line\">    optimizer.apply_gradients(zip(grads, model.trainable_weights))</span><br><span class=\"line\">    train_acc_metric.update_state(y, logits)</span><br><span class=\"line\">    <span class=\"keyword\">return</span> loss_value</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"meta\">@tf.function</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">test_step</span><span class=\"params\">(x, y)</span>:</span></span><br><span class=\"line\">    val_logits = model(x, training=<span class=\"literal\">False</span>)</span><br><span class=\"line\">    val_acc_metric.update_state(y, val_logits)</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># --------------------------config---------------------------------#</span></span><br><span class=\"line\"></span><br><span class=\"line\">epochs = <span class=\"number\">50</span></span><br><span class=\"line\">batch_size = <span class=\"number\">16</span></span><br><span class=\"line\">num_classes = <span class=\"number\">130</span></span><br><span class=\"line\">save_model_dir = <span class=\"string\">'./modelfiles/'</span></span><br><span class=\"line\"></span><br><span class=\"line\">images, labels = get_data(<span class=\"string\">'./dataset/JsonData/'</span>, mode=<span class=\"string\">'train'</span>, n_mode=<span class=\"number\">200</span>)</span><br><span class=\"line\">trian_db = tf.data.Dataset.from_tensor_slices((images, labels))</span><br><span class=\"line\">trian_db = trian_db.shuffle(<span class=\"number\">50</span>).batch(<span class=\"number\">1</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">images, labels = get_data(<span class=\"string\">'./dataset/JsonData/'</span>, mode=<span class=\"string\">'valid'</span>, n_mode=<span class=\"number\">20</span>)</span><br><span class=\"line\">valid_db = tf.data.Dataset.from_tensor_slices((images, labels))</span><br><span class=\"line\">valid_db = valid_db.shuffle(<span class=\"number\">50</span>).batch(<span class=\"number\">1</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">loss_fn = tf.keras.losses.SparseCategoricalCrossentropy()</span><br><span class=\"line\">optimizer = tf.keras.optimizers.Adam()</span><br><span class=\"line\">train_acc_metric = tf.keras.metrics.SparseCategoricalAccuracy()</span><br><span class=\"line\">val_acc_metric = tf.keras.metrics.SparseCategoricalAccuracy()</span><br><span class=\"line\"></span><br><span class=\"line\">model = BCNN(num_classes=num_classes)</span><br><span class=\"line\">model.build(input_shape=(<span class=\"number\">16</span>, <span class=\"number\">224</span>, <span class=\"number\">224</span>, <span class=\"number\">3</span>))</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># ---------------------------------------------------------------- #</span></span><br><span class=\"line\"></span><br><span class=\"line\">best_acc = <span class=\"number\">0</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">for</span> epoch <span class=\"keyword\">in</span> range(epochs):</span><br><span class=\"line\">    print(<span class=\"string\">\"\\nStart of epoch %d\"</span> % (epoch, ))</span><br><span class=\"line\">    start_time = time.time()</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># Iterate over the batches of the dataset.</span></span><br><span class=\"line\">    <span class=\"keyword\">for</span> step, (x, y) <span class=\"keyword\">in</span> enumerate(trian_db):</span><br><span class=\"line\">        x_batch_train, y_batch_train = preprocess(x, y)</span><br><span class=\"line\">        loss_value = train_step(x_batch_train, y_batch_train)</span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"comment\"># Log every 200 batches.</span></span><br><span class=\"line\">        <span class=\"keyword\">if</span> step % <span class=\"number\">100</span> == <span class=\"number\">0</span>:</span><br><span class=\"line\">            print(<span class=\"string\">'Epoch:'</span>, epoch, <span class=\"string\">' Step:'</span>, step, <span class=\"string\">'Training loss:'</span>,</span><br><span class=\"line\">                  float(loss_value))</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># Display metrics at the end of each epoch.</span></span><br><span class=\"line\">    train_acc = train_acc_metric.result()</span><br><span class=\"line\">    print(<span class=\"string\">\"Training acc over epoch: %.4f\"</span> % (float(train_acc), ))</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># Reset training metrics at the end of each epoch</span></span><br><span class=\"line\">    train_acc_metric.reset_states()</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># Run a validation loop at the end of each epoch.</span></span><br><span class=\"line\">    <span class=\"keyword\">for</span> step, (x, y) <span class=\"keyword\">in</span> enumerate(valid_db):</span><br><span class=\"line\">        x_batch_val, y_batch_val = preprocess(x, y)</span><br><span class=\"line\">        test_step(x_batch_val, y_batch_val)</span><br><span class=\"line\"></span><br><span class=\"line\">    val_acc = val_acc_metric.result()</span><br><span class=\"line\">    val_acc_metric.reset_states()</span><br><span class=\"line\"></span><br><span class=\"line\">    print(<span class=\"string\">\"Validation acc: %.4f\"</span> % (float(val_acc), ))</span><br><span class=\"line\">    print(<span class=\"string\">\"Time taken: %.2fs\"</span> % (time.time() - start_time))</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">if</span> best_acc &lt; val_acc:</span><br><span class=\"line\">        best_acc = val_acc</span><br><span class=\"line\">        print(<span class=\"string\">'Valid in epoch'</span>, epoch, <span class=\"string\">'Accuracy is'</span>, val_acc,</span><br><span class=\"line\">              <span class=\"string\">'Best accuracy is'</span>, best_acc)</span><br><span class=\"line\"></span><br><span class=\"line\">        time_stamp = time.strftime(<span class=\"string\">'%Y-%m-%d-%H-%M-%S'</span>,</span><br><span class=\"line\">                                   time.localtime(time.time()))</span><br><span class=\"line\">        model.save_weights(</span><br><span class=\"line\">            os.path.join(save_model_dirav, time_stamp + <span class=\"string\">'.checkpoint'</span>))</span><br><span class=\"line\">        print(<span class=\"string\">'saved total model weights; timestamp:'</span>, time_stamp)</span><br></pre></td></tr></table></figure>\n","categories":[],"tags":["CV"]},{"title":"A09","url":"https://hahally.github.io//articles/A09/","content":"<h3 id=\"数据说明\"><a href=\"#数据说明\" class=\"headerlink\" title=\"数据说明\"></a>数据说明</h3><p>来源：第十二届服创大赛A类数据<a href=\"http://www.fwwb.org.cn/topic/show/6c22faa0-c905-4482-a0bc-3dfe11657565\" target=\"_blank\" rel=\"noopener\">【A09】轨道交通智慧客流分析预测【八维通】</a></p>\n<p>示例数据包含:</p>\n<ul>\n<li>行程数据<code>trips.csv</code></li>\n<li>用户数据<code>users.csv</code></li>\n<li>站点名称数据<code>station.csv</code></li>\n<li>2020年全年节假日数据<code>workdays.csv</code></li>\n</ul>\n<hr>\n<p>trips.csv：</p>\n<div class=\"table-container\">\n<table>\n<thead>\n<tr>\n<th>说明</th>\n<th>类型说明</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>用户id</td>\n<td>与user.csv 表中用户id进行关联，可以获取用户对应的行程</td>\n</tr>\n<tr>\n<td>进站名</td>\n<td></td>\n</tr>\n<tr>\n<td>进站时间</td>\n<td>YYYY-MM-DD hh:mm:ss</td>\n</tr>\n<tr>\n<td>出站</td>\n<td></td>\n</tr>\n<tr>\n<td>出站时间</td>\n<td>YYYY-MM-DD hh:mm:ss</td>\n</tr>\n<tr>\n<td>渠道类型</td>\n<td>本例子中不使用</td>\n</tr>\n<tr>\n<td>票价</td>\n<td>单位分</td>\n</tr>\n</tbody>\n</table>\n</div>\n<hr>\n<p>users.csv:</p>\n<div class=\"table-container\">\n<table>\n<thead>\n<tr>\n<th>说明</th>\n<th>类型说明</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>说明</td>\n<td>类型说明</td>\n</tr>\n<tr>\n<td>用户id</td>\n<td>和trip.csv里面的用户ID关联可获取用户对应的行程</td>\n</tr>\n<tr>\n<td>省市</td>\n<td></td>\n</tr>\n<tr>\n<td>出生年份</td>\n<td></td>\n</tr>\n<tr>\n<td>性别</td>\n<td>0 男，1 女</td>\n</tr>\n</tbody>\n</table>\n</div>\n<hr>\n<p>station.csv:</p>\n<div class=\"table-container\">\n<table>\n<thead>\n<tr>\n<th>说明</th>\n<th>类型说明</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>站点id</td>\n<td>无业务意义</td>\n</tr>\n<tr>\n<td>站点名</td>\n<td></td>\n</tr>\n<tr>\n<td>线路名</td>\n<td></td>\n</tr>\n<tr>\n<td>站点所在区</td>\n</tr>\n</tbody>\n</table>\n</div>\n<hr>\n<p>workdays.csv:</p>\n<div class=\"table-container\">\n<table>\n<thead>\n<tr>\n<th>说明</th>\n<th>类型</th>\n<th>类型说明</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>日期</td>\n<td>string</td>\n<td>YYYYMMDD</td>\n</tr>\n<tr>\n<td>节假日属性</td>\n<td>枚举</td>\n<td>1，2，或3</td>\n</tr>\n</tbody>\n</table>\n</div>\n<p>1为工作日（包括周末调休变成的工作日）；2为正常周末；3为节假日，包括法定节假日，以及与法定节假日相连的周末。</p>\n<hr>\n<h3 id=\"导入相关库\"><a href=\"#导入相关库\" class=\"headerlink\" title=\"导入相关库\"></a>导入相关库</h3><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> pandas <span class=\"keyword\">as</span> pd </span><br><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\"><span class=\"keyword\">import</span> matplotlib.pyplot <span class=\"keyword\">as</span> plt</span><br><span class=\"line\"><span class=\"keyword\">import</span> seaborn <span class=\"keyword\">as</span> sns</span><br><span class=\"line\">%matplotlib inline</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">#ignore warnings</span></span><br><span class=\"line\"><span class=\"keyword\">import</span> warnings</span><br><span class=\"line\">warnings.filterwarnings(<span class=\"string\">'ignore'</span>)</span><br></pre></td></tr></table></figure>\n<h3 id=\"trips-csv\"><a href=\"#trips-csv\" class=\"headerlink\" title=\"trips.csv\"></a>trips.csv</h3><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">trips = pd.read_csv(<span class=\"string\">'./trips.csv'</span>)</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 基本信息</span></span><br><span class=\"line\">trips.info()</span><br></pre></td></tr></table></figure>\n<pre><code>&lt;class &#39;pandas.core.frame.DataFrame&#39;&gt;\nRangeIndex: 791995 entries, 0 to 791994\nData columns (total 7 columns):\n用户ID    791995 non-null object\n进站名称    791995 non-null object\n进站时间    791995 non-null object\n出站名称    791995 non-null object\n出站时间    791995 non-null object\n渠道编号    791995 non-null int64\n价格      791995 non-null int64\ndtypes: int64(2), object(5)\nmemory usage: 42.3+ MB\n</code></pre><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 浏览数据集</span></span><br><span class=\"line\">trips.sample(<span class=\"number\">10</span>)</span><br></pre></td></tr></table></figure>\n<div>\n\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>用户ID</th>\n      <th>进站名称</th>\n      <th>进站时间</th>\n      <th>出站名称</th>\n      <th>出站时间</th>\n      <th>渠道编号</th>\n      <th>价格</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>361317</th>\n      <td>309d068b9686b17c2eea0f7396d6a3ce</td>\n      <td>Sta34</td>\n      <td>2020-06-14 11:59:47</td>\n      <td>Sta108</td>\n      <td>2020-06-14 12:27:01</td>\n      <td>2</td>\n      <td>400</td>\n    </tr>\n    <tr>\n      <th>369815</th>\n      <td>5f60d49862e08647d83cba6b88826a7c</td>\n      <td>Sta163</td>\n      <td>2020-04-11 09:45:12</td>\n      <td>Sta161</td>\n      <td>2020-04-11 10:21:50</td>\n      <td>2</td>\n      <td>400</td>\n    </tr>\n    <tr>\n      <th>24683</th>\n      <td>456baf61774e89b0f0ecd66561dc1ec3</td>\n      <td>Sta134</td>\n      <td>2020-03-09 19:17:07</td>\n      <td>Sta135</td>\n      <td>2020-03-09 19:24:20</td>\n      <td>3</td>\n      <td>200</td>\n    </tr>\n    <tr>\n      <th>265739</th>\n      <td>8259141547ffe7508d9ed0640064222e</td>\n      <td>Sta63</td>\n      <td>2020-06-19 09:39:06</td>\n      <td>Sta151</td>\n      <td>2020-06-19 10:09:06</td>\n      <td>3</td>\n      <td>400</td>\n    </tr>\n    <tr>\n      <th>360005</th>\n      <td>8e630d272f05413355bd4054ec57e1e4</td>\n      <td>Sta46</td>\n      <td>2020-03-22 14:30:38</td>\n      <td>Sta55</td>\n      <td>2020-03-22 15:05:00</td>\n      <td>3</td>\n      <td>400</td>\n    </tr>\n    <tr>\n      <th>302739</th>\n      <td>93cdc65de998cdfa253308f9e7a722fa</td>\n      <td>Sta49</td>\n      <td>2020-01-15 20:08:53</td>\n      <td>Sta89</td>\n      <td>2020-01-15 20:38:15</td>\n      <td>3</td>\n      <td>500</td>\n    </tr>\n    <tr>\n      <th>577747</th>\n      <td>7829bcf454c66b5bac54b4592f30d1ff</td>\n      <td>Sta137</td>\n      <td>2020-07-03 08:09:22</td>\n      <td>Sta37</td>\n      <td>2020-07-03 08:41:17</td>\n      <td>2</td>\n      <td>400</td>\n    </tr>\n    <tr>\n      <th>449944</th>\n      <td>e45e528ef8575a550847f5b33b732207</td>\n      <td>Sta67</td>\n      <td>2020-06-01 07:52:00</td>\n      <td>Sta100</td>\n      <td>2020-06-01 08:21:47</td>\n      <td>3</td>\n      <td>400</td>\n    </tr>\n    <tr>\n      <th>317479</th>\n      <td>47750740c3ff91bffaac1b92e7d8ac2f</td>\n      <td>Sta25</td>\n      <td>2020-06-15 09:44:47</td>\n      <td>Sta63</td>\n      <td>2020-06-15 10:03:20</td>\n      <td>2</td>\n      <td>300</td>\n    </tr>\n    <tr>\n      <th>430358</th>\n      <td>9fd1d4dae1cbed06dec272607911ed02</td>\n      <td>Sta144</td>\n      <td>2020-06-15 07:56:18</td>\n      <td>Sta20</td>\n      <td>2020-06-15 08:27:03</td>\n      <td>2</td>\n      <td>400</td>\n    </tr>\n  </tbody>\n</table>\n\n\n\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 删除渠道编号</span></span><br><span class=\"line\">trips = trips.drop(labels=<span class=\"string\">'渠道编号'</span>,axis=<span class=\"number\">1</span>)</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">trips.head()</span><br></pre></td></tr></table></figure>\n<p><div></div></p>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>用户ID</th>\n      <th>进站名称</th>\n      <th>进站时间</th>\n      <th>出站名称</th>\n      <th>出站时间</th>\n      <th>价格</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>d4ec5a712f2b24ce226970a8d315dfce</td>\n      <td>Sta18</td>\n      <td>2020-07-15 14:21:58</td>\n      <td>Sta9</td>\n      <td>2020-07-15 14:39:29</td>\n      <td>200</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>328266c5e7a8fccb976029683f723725</td>\n      <td>Sta74</td>\n      <td>2020-07-15 19:40:46</td>\n      <td>Sta133</td>\n      <td>2020-07-15 20:49:00</td>\n      <td>700</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>4ff0e057af749864432d223ae0d0fa49</td>\n      <td>Sta69</td>\n      <td>2020-07-15 20:02:22</td>\n      <td>Sta96</td>\n      <td>2020-07-15 20:17:04</td>\n      <td>300</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>59add5aed8f0d030858c01a78c9c79fe</td>\n      <td>Sta110</td>\n      <td>2020-07-15 16:09:38</td>\n      <td>Sta123</td>\n      <td>2020-07-15 16:39:44</td>\n      <td>400</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>c285b7d3d347f4a1f46c826307bd1b8a</td>\n      <td>Sta36</td>\n      <td>2020-07-15 15:20:39</td>\n      <td>Sta28</td>\n      <td>2020-07-15 15:40:20</td>\n      <td>400</td>\n    </tr>\n  </tbody>\n</table>\n\n\n\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 用户id</span></span><br><span class=\"line\"></span><br><span class=\"line\">id_count = trips.groupby(by=[<span class=\"string\">'用户ID'</span>]).agg(&#123;<span class=\"string\">'用户ID'</span>:[<span class=\"string\">'count'</span>]&#125;).reset_index()</span><br><span class=\"line\">id_count[<span class=\"string\">'用户ID'</span>].describe()</span><br></pre></td></tr></table></figure>\n<p><div></div></p>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>count</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>83049.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>9.536478</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>20.346030</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>3.000000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>8.000000</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>322.000000</td>\n    </tr>\n  </tbody>\n</table>\n\n\n\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 站点</span></span><br><span class=\"line\">len(set(trips[<span class=\"string\">'进站名称'</span>])),len(set(trips[<span class=\"string\">'出站名称'</span>]))</span><br></pre></td></tr></table></figure>\n<pre><code>(168, 168)\n</code></pre><h3 id=\"users-csv\"><a href=\"#users-csv\" class=\"headerlink\" title=\"users.csv\"></a>users.csv</h3><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">users = pd.read_csv(<span class=\"string\">'./users.csv'</span>)</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">users.info()</span><br></pre></td></tr></table></figure>\n<pre><code>&lt;class &#39;pandas.core.frame.DataFrame&#39;&gt;\nRangeIndex: 124782 entries, 0 to 124781\nData columns (total 4 columns):\n用户ID    124782 non-null object\n区域      124782 non-null int64\n出生年份    124782 non-null int64\n性别      124782 non-null int64\ndtypes: int64(3), object(1)\nmemory usage: 3.8+ MB\n</code></pre><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">users.sample(<span class=\"number\">10</span>)</span><br></pre></td></tr></table></figure>\n<p><div></div></p>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>用户ID</th>\n      <th>区域</th>\n      <th>出生年份</th>\n      <th>性别</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>124450</th>\n      <td>659eb8d7aaff22d8898cbab2ce901eb9</td>\n      <td>5224</td>\n      <td>1988</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>49769</th>\n      <td>ab67516f36608867726bea171cd47af1</td>\n      <td>5113</td>\n      <td>1996</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>95642</th>\n      <td>02dafe7577cba98cd85edf8b7b206e3f</td>\n      <td>5107</td>\n      <td>1993</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>30679</th>\n      <td>691fba5ba30776c4d94ecb9f850e9628</td>\n      <td>5001</td>\n      <td>1985</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>80127</th>\n      <td>f29fd257eb729a263900184e4a4177b4</td>\n      <td>5002</td>\n      <td>1985</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>43695</th>\n      <td>616b3fb46a82b41269cd9833d69d9847</td>\n      <td>3212</td>\n      <td>1975</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>118850</th>\n      <td>914962a14711cee5b7d916711c22b4fd</td>\n      <td>1201</td>\n      <td>1967</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>35179</th>\n      <td>d215e6be7597de23b94b79c577aa7569</td>\n      <td>5002</td>\n      <td>1993</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>37903</th>\n      <td>7634c54e4e8c1bb968ead3da0a38fc7b</td>\n      <td>5002</td>\n      <td>1991</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>91696</th>\n      <td>2e3134b064a1a082f0f204dac0cb9899</td>\n      <td>5002</td>\n      <td>1988</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n\n\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 男女比例</span></span><br><span class=\"line\">users[<span class=\"string\">'性别'</span>].value_counts()/users.shape[<span class=\"number\">0</span>]</span><br></pre></td></tr></table></figure>\n<pre><code>1    0.586535\n0    0.413465\nName: 性别, dtype: float64\n</code></pre><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 年龄</span></span><br><span class=\"line\">users[<span class=\"string\">'age'</span>] = <span class=\"number\">2020</span> - users[<span class=\"string\">'出生年份'</span>]</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">users.head()</span><br></pre></td></tr></table></figure>\n<p><div></div></p>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>用户ID</th>\n      <th>区域</th>\n      <th>出生年份</th>\n      <th>性别</th>\n      <th>age</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>4bd084423e63c9bcf3dd66761506d8cf</td>\n      <td>4115</td>\n      <td>1996</td>\n      <td>0</td>\n      <td>24</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>6ce72d2bccd92862119d86713dd4e6fa</td>\n      <td>3623</td>\n      <td>1980</td>\n      <td>1</td>\n      <td>40</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>adc40e61672136ba20fc41ed3736afe1</td>\n      <td>5001</td>\n      <td>1996</td>\n      <td>1</td>\n      <td>24</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>16daef5eb951b4132fdbeb5ede7de172</td>\n      <td>3706</td>\n      <td>1988</td>\n      <td>0</td>\n      <td>32</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5e7c6803e0c584f444b20a96104628cb</td>\n      <td>3301</td>\n      <td>1993</td>\n      <td>1</td>\n      <td>27</td>\n    </tr>\n  </tbody>\n</table>\n\n\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">users.describe()</span><br></pre></td></tr></table></figure>\n<p><div></div></p>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>区域</th>\n      <th>出生年份</th>\n      <th>性别</th>\n      <th>age</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>124782.000000</td>\n      <td>124782.000000</td>\n      <td>124782.000000</td>\n      <td>124782.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>4711.264613</td>\n      <td>1989.136294</td>\n      <td>0.586535</td>\n      <td>30.863706</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>918.747877</td>\n      <td>9.986578</td>\n      <td>0.492457</td>\n      <td>9.986578</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>1101.000000</td>\n      <td>1930.000000</td>\n      <td>0.000000</td>\n      <td>10.000000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>5001.000000</td>\n      <td>1983.000000</td>\n      <td>0.000000</td>\n      <td>23.000000</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>5002.000000</td>\n      <td>1992.000000</td>\n      <td>1.000000</td>\n      <td>28.000000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>5108.000000</td>\n      <td>1997.000000</td>\n      <td>1.000000</td>\n      <td>37.000000</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>6543.000000</td>\n      <td>2010.000000</td>\n      <td>1.000000</td>\n      <td>90.000000</td>\n    </tr>\n  </tbody>\n</table>\n\n\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 省市区域</span></span><br><span class=\"line\">len(set(users[<span class=\"string\">'区域'</span>]))</span><br></pre></td></tr></table></figure>\n<pre><code>450\n</code></pre><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">users[<span class=\"string\">'区域'</span>].value_counts()</span><br></pre></td></tr></table></figure>\n<pre><code>5002    28469\n5001    14904\n5102    12117\n5003     5483\n5116     3713\n        ...  \n3427        1\n5121        1\n4225        1\n6208        1\n6405        1\nName: 区域, Length: 450, dtype: int64\n</code></pre><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># top 20</span></span><br><span class=\"line\">fig, ax = plt.subplots()</span><br><span class=\"line\"></span><br><span class=\"line\">labels = users[<span class=\"string\">'区域'</span>].value_counts().index[:<span class=\"number\">20</span>]</span><br><span class=\"line\"></span><br><span class=\"line\">y_pos = np.arange(len(labels))</span><br><span class=\"line\"></span><br><span class=\"line\">performance = users[<span class=\"string\">'区域'</span>].value_counts().values[:<span class=\"number\">20</span>]</span><br><span class=\"line\"></span><br><span class=\"line\">error = np.random.rand(len(labels))</span><br><span class=\"line\"></span><br><span class=\"line\">ax.barh(y_pos, performance, xerr=error, align=<span class=\"string\">'center'</span>)</span><br><span class=\"line\">ax.set_yticks(y_pos)</span><br><span class=\"line\">ax.set_yticklabels(labels)</span><br><span class=\"line\">ax.invert_yaxis()  <span class=\"comment\"># labels read top-to-bottom</span></span><br><span class=\"line\">ax.set_xlabel(<span class=\"string\">'Counts'</span>)</span><br><span class=\"line\">ax.set_title(<span class=\"string\">'catagory distribution'</span>);<span class=\"comment\"># 加分号只输出图像</span></span><br></pre></td></tr></table></figure>\n<p><img src=\"/articles/A09/output_21_0.png\" alt=\"png\"></p>\n<h3 id=\"station-csv\"><a href=\"#station-csv\" class=\"headerlink\" title=\"station.csv\"></a>station.csv</h3><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">station = pd.read_csv(<span class=\"string\">'./station.csv'</span>)</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">station.info()</span><br></pre></td></tr></table></figure>\n<pre><code>&lt;class &#39;pandas.core.frame.DataFrame&#39;&gt;\nRangeIndex: 163 entries, 0 to 162\nData columns (total 4 columns):\n编号      163 non-null int64\n站点名称    163 non-null object\n线路      163 non-null object\n行政区域    163 non-null object\ndtypes: int64(1), object(3)\nmemory usage: 5.2+ KB\n</code></pre><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">station.sample(<span class=\"number\">10</span>)</span><br></pre></td></tr></table></figure>\n<p><div></div></p>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>编号</th>\n      <th>站点名称</th>\n      <th>线路</th>\n      <th>行政区域</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>138</th>\n      <td>1155</td>\n      <td>Sta145</td>\n      <td>10号线</td>\n      <td>Dist5</td>\n    </tr>\n    <tr>\n      <th>151</th>\n      <td>1172</td>\n      <td>Sta60</td>\n      <td>12号线</td>\n      <td>Dist2</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>1022</td>\n      <td>Sta149</td>\n      <td>1号线</td>\n      <td>Dist3</td>\n    </tr>\n    <tr>\n      <th>103</th>\n      <td>1118</td>\n      <td>Sta118</td>\n      <td>11号线</td>\n      <td>Dist5</td>\n    </tr>\n    <tr>\n      <th>118</th>\n      <td>1134</td>\n      <td>Sta152</td>\n      <td>11号线</td>\n      <td>Dist1</td>\n    </tr>\n    <tr>\n      <th>158</th>\n      <td>1185</td>\n      <td>Sta114</td>\n      <td>10号线</td>\n      <td>Dist5</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>1015</td>\n      <td>Sta80</td>\n      <td>1号线</td>\n      <td>Dist3</td>\n    </tr>\n    <tr>\n      <th>82</th>\n      <td>1094</td>\n      <td>Sta62</td>\n      <td>4号线</td>\n      <td>Dist8</td>\n    </tr>\n    <tr>\n      <th>96</th>\n      <td>1110</td>\n      <td>Sta146</td>\n      <td>11号线</td>\n      <td>Dist6</td>\n    </tr>\n    <tr>\n      <th>60</th>\n      <td>1069</td>\n      <td>Sta39</td>\n      <td>3号线</td>\n      <td>Dist5</td>\n    </tr>\n  </tbody>\n</table>\n\n\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">len(set(station[<span class=\"string\">'行政区域'</span>])),len(set(station[<span class=\"string\">'站点名称'</span>])),len(set(station[<span class=\"string\">'编号'</span>]))</span><br></pre></td></tr></table></figure>\n<pre><code>(9, 163, 163)\n</code></pre><h3 id=\"workdays-csv\"><a href=\"#workdays-csv\" class=\"headerlink\" title=\"workdays.csv\"></a>workdays.csv</h3><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">wd = pd.read_csv(<span class=\"string\">'./workdays2020.csv'</span>,header=<span class=\"literal\">None</span>)</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">wd.info()</span><br></pre></td></tr></table></figure>\n<pre><code>&lt;class &#39;pandas.core.frame.DataFrame&#39;&gt;\nRangeIndex: 366 entries, 0 to 365\nData columns (total 2 columns):\n0    366 non-null int64\n1    366 non-null object\ndtypes: int64(1), object(1)\nmemory usage: 5.8+ KB\n</code></pre><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">wd.sample(<span class=\"number\">5</span>)</span><br></pre></td></tr></table></figure>\n<p><div></div></p>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>349</th>\n      <td>20201215</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>220</th>\n      <td>20200808</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>326</th>\n      <td>20201122</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>106</th>\n      <td>20200416</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>281</th>\n      <td>20201008</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table></div>","categories":[],"tags":[]},{"title":"Tianchi-base-v1","url":"https://hahally.github.io//articles/Tianchi-base-v1/","content":"<h3 id=\"导入相关库\"><a href=\"#导入相关库\" class=\"headerlink\" title=\"导入相关库\"></a>导入相关库</h3><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> pandas <span class=\"keyword\">as</span> pd</span><br><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\"><span class=\"keyword\">import</span> matplotlib.pyplot <span class=\"keyword\">as</span> plt</span><br><span class=\"line\"><span class=\"keyword\">import</span> cv2 <span class=\"keyword\">as</span> cv</span><br><span class=\"line\">%matplotlib inline</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">import</span> os</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">#中文支持matplotlib</span></span><br><span class=\"line\">plt.rcParams[<span class=\"string\">'font.sans-serif'</span>] = [<span class=\"string\">'SimHei'</span>]  <span class=\"comment\"># 步骤一（替换sans-serif字体）</span></span><br><span class=\"line\">plt.rcParams[<span class=\"string\">'axes.unicode_minus'</span>] = <span class=\"literal\">False</span>    <span class=\"comment\"># 步骤二（解决坐标轴负数的负号显示问题）</span></span><br></pre></td></tr></table></figure>\n<h3 id=\"合并-anno-train-json\"><a href=\"#合并-anno-train-json\" class=\"headerlink\" title=\"合并 anno_train.json\"></a>合并 anno_train.json</h3><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">os.listdir(<span class=\"string\">'./dataset/annotations/'</span>)</span><br></pre></td></tr></table></figure>\n<pre><code>[&#39;anno_train1.json&#39;, &#39;anno_train2.json&#39;]\n</code></pre><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 合并两个标准文件</span></span><br><span class=\"line\"></span><br><span class=\"line\">d1 = pd.read_json(<span class=\"string\">'./dataset/annotations/anno_train1.json'</span>)</span><br><span class=\"line\">d2 = pd.read_json(<span class=\"string\">'./dataset/annotations/anno_train2.json'</span>)</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">d = pd.concat([d1,d2],ignore_index=<span class=\"literal\">True</span>)</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">d.to_csv(<span class=\"string\">'./dataset/annotations/anno_train.csv'</span>,index=<span class=\"literal\">False</span>)</span><br></pre></td></tr></table></figure>\n<h3 id=\"数据分析\"><a href=\"#数据分析\" class=\"headerlink\" title=\"数据分析\"></a>数据分析</h3><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">dt = pd.read_csv(<span class=\"string\">'./dataset/annotations/anno_train.csv'</span>)</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">dt.info()</span><br></pre></td></tr></table></figure>\n<pre><code>&lt;class &#39;pandas.core.frame.DataFrame&#39;&gt;\nRangeIndex: 21323 entries, 0 to 21322\nData columns (total 3 columns):\nbbox           21323 non-null object\ndefect_name    21323 non-null object\nname           21323 non-null object\ndtypes: object(3)\nmemory usage: 499.9+ KB\n</code></pre><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"></span><br><span class=\"line\">fig, ax = plt.subplots()</span><br><span class=\"line\"><span class=\"comment\"># Example data</span></span><br><span class=\"line\">labels = dt[<span class=\"string\">'defect_name'</span>].value_counts().index</span><br><span class=\"line\"></span><br><span class=\"line\">y_pos = np.arange(len(labels))</span><br><span class=\"line\"></span><br><span class=\"line\">performance = dt[<span class=\"string\">'defect_name'</span>].value_counts().values</span><br><span class=\"line\"></span><br><span class=\"line\">error = np.random.rand(len(labels))</span><br><span class=\"line\"></span><br><span class=\"line\">ax.barh(y_pos, performance, xerr=error, align=<span class=\"string\">'center'</span>)</span><br><span class=\"line\">ax.set_yticks(y_pos)</span><br><span class=\"line\">ax.set_yticklabels(labels)</span><br><span class=\"line\">ax.invert_yaxis()  <span class=\"comment\"># labels read top-to-bottom</span></span><br><span class=\"line\">ax.set_xlabel(<span class=\"string\">'Counts'</span>)</span><br><span class=\"line\">ax.set_title(<span class=\"string\">'catagory distribution'</span>);<span class=\"comment\"># 加分号只输出图像</span></span><br></pre></td></tr></table></figure>\n<p><img src=\"/articles/Tianchi-base-v1/output_11_0.png\" alt=\"png\"></p>\n","categories":[],"tags":["CV"]},{"title":"Tsinghua Dogs v1","url":"https://hahally.github.io//articles/TsinghuaDogs-1/","content":"<h3 id=\"Tsinghua-Dogs数据集的结构\"><a href=\"#Tsinghua-Dogs数据集的结构\" class=\"headerlink\" title=\"Tsinghua Dogs数据集的结构\"></a>Tsinghua Dogs数据集的结构</h3><p>赛题地址:<a href=\"https://www.educoder.net/competitions/index/Jittor-2\" target=\"_blank\" rel=\"noopener\">https://www.educoder.net/competitions/index/Jittor-2</a></p>\n<p>来源：<a href=\"https://cg.cs.tsinghua.edu.cn/ThuDogs/\" target=\"_blank\" rel=\"noopener\">Tsinghua Dogs数据集官网</a></p>\n<ul>\n<li>low-resolution：130类狗狗的图片集合</li>\n<li>low-annotations：130类狗狗的标注结果，其中包括头部、整个身体的包围框</li>\n<li>TrainAndValList：训练验证集切分</li>\n</ul>\n<p>每一类被分别保存在不同的文件夹里，该文件夹名称格式为：\\$id-$class_id-\\$class_name，其中 \\$class_id 为类别标签，\\$class_name为类别名称，如文件夹名为 220-n000069-Mexican_hairless 的文件对应的标签为 69，文件夹名为 480-n000125-Pekinese 的文件，对应的标签为 125。</p>\n<h3 id=\"查看文件目录结构\"><a href=\"#查看文件目录结构\" class=\"headerlink\" title=\"查看文件目录结构\"></a>查看文件目录结构</h3><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> os</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">os.listdir(<span class=\"string\">'./dataset/'</span>)</span><br></pre></td></tr></table></figure>\n<pre><code>[&#39;low-annotations&#39;, &#39;low-resolution&#39;, &#39;TEST_A&#39;, &#39;TrainAndValList&#39;]\n</code></pre><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">low_annotations = os.listdir(<span class=\"string\">'./dataset/low-annotations'</span>)</span><br><span class=\"line\">low_resolution = os.listdir(<span class=\"string\">'./dataset/low-resolution'</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">len(low_annotations),len(low_resolution),low_annotations[:<span class=\"number\">5</span>],low_resolution[:<span class=\"number\">5</span>]</span><br></pre></td></tr></table></figure>\n<pre><code>(130,\n 131,\n [&#39;1043-n000001-Shiba_Dog&#39;,\n  &#39;1121-n000002-French_bulldog&#39;,\n  &#39;1160-n000003-Siberian_husky&#39;,\n  &#39;1324-n000004-malamute&#39;,\n  &#39;1936-n000005-Pomeranian&#39;],\n [&#39;1043-n000001-Shiba_Dog&#39;,\n  &#39;1121-n000002-French_bulldog&#39;,\n  &#39;1160-n000003-Siberian_husky&#39;,\n  &#39;1324-n000004-malamute&#39;,\n  &#39;1936-n000005-Pomeranian&#39;])\n</code></pre><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 无效文件</span></span><br><span class=\"line\">low_resolution[<span class=\"number\">-1</span>]</span><br></pre></td></tr></table></figure>\n<pre><code>&#39;~$directoryfilecount.xlsx&#39;\n</code></pre><hr>\n<h3 id=\"可视化Tsinghua-Dogs\"><a href=\"#可视化Tsinghua-Dogs\" class=\"headerlink\" title=\"可视化Tsinghua Dogs\"></a>可视化Tsinghua Dogs</h3><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> xml.dom.minidom</span><br><span class=\"line\"><span class=\"keyword\">from</span> xml.dom.minidom <span class=\"keyword\">import</span> parse</span><br><span class=\"line\"><span class=\"keyword\">import</span> cv2</span><br><span class=\"line\"><span class=\"keyword\">import</span> matplotlib.pyplot <span class=\"keyword\">as</span> plt</span><br><span class=\"line\">%matplotlib inline</span><br><span class=\"line\"></span><br><span class=\"line\">DOMTree = parse(<span class=\"string\">'./dataset/low-annotations/1043-n000001-Shiba_Dog/n100001.jpeg.xml'</span>)</span><br><span class=\"line\">collection = DOMTree.documentElement</span><br><span class=\"line\">img = cv2.imread(<span class=\"string\">'./dataset/low-resolution/1043-n000001-Shiba_Dog/n100001.jpeg'</span>)</span><br><span class=\"line\">headbndbox = collection.getElementsByTagName(<span class=\"string\">\"headbndbox\"</span>)[<span class=\"number\">0</span>]</span><br><span class=\"line\">xmin = int(headbndbox.getElementsByTagName(<span class=\"string\">\"xmin\"</span>)[<span class=\"number\">0</span>].childNodes[<span class=\"number\">0</span>].data)</span><br><span class=\"line\">ymin = int(headbndbox.getElementsByTagName(<span class=\"string\">\"ymin\"</span>)[<span class=\"number\">0</span>].childNodes[<span class=\"number\">0</span>].data)</span><br><span class=\"line\">xmax = int(headbndbox.getElementsByTagName(<span class=\"string\">\"xmax\"</span>)[<span class=\"number\">0</span>].childNodes[<span class=\"number\">0</span>].data)</span><br><span class=\"line\">ymax = int(headbndbox.getElementsByTagName(<span class=\"string\">\"ymax\"</span>)[<span class=\"number\">0</span>].childNodes[<span class=\"number\">0</span>].data)</span><br><span class=\"line\">cv2.rectangle(img, (xmin, ymin), (xmax, ymax), (<span class=\"number\">0</span>,<span class=\"number\">255</span>,<span class=\"number\">0</span>), <span class=\"number\">2</span>)</span><br><span class=\"line\">bodybndbox = collection.getElementsByTagName(<span class=\"string\">\"bodybndbox\"</span>)[<span class=\"number\">0</span>]</span><br><span class=\"line\">xmin = int(bodybndbox.getElementsByTagName(<span class=\"string\">\"xmin\"</span>)[<span class=\"number\">0</span>].childNodes[<span class=\"number\">0</span>].data)</span><br><span class=\"line\">ymin = int(bodybndbox.getElementsByTagName(<span class=\"string\">\"ymin\"</span>)[<span class=\"number\">0</span>].childNodes[<span class=\"number\">0</span>].data)</span><br><span class=\"line\">xmax = int(bodybndbox.getElementsByTagName(<span class=\"string\">\"xmax\"</span>)[<span class=\"number\">0</span>].childNodes[<span class=\"number\">0</span>].data)</span><br><span class=\"line\">ymax = int(bodybndbox.getElementsByTagName(<span class=\"string\">\"ymax\"</span>)[<span class=\"number\">0</span>].childNodes[<span class=\"number\">0</span>].data)</span><br><span class=\"line\">cv2.rectangle(img, (xmin, ymin), (xmax, ymax), (<span class=\"number\">0</span>,<span class=\"number\">255</span>,<span class=\"number\">255</span>), <span class=\"number\">2</span>)</span><br><span class=\"line\"><span class=\"keyword\">import</span> pylab <span class=\"keyword\">as</span> pl</span><br><span class=\"line\">pl.figure(figsize=(<span class=\"number\">12</span>,<span class=\"number\">12</span>))</span><br><span class=\"line\">pl.imshow(img[:,:,::<span class=\"number\">-1</span>]);</span><br></pre></td></tr></table></figure>\n<p><img src=\"/articles/TsinghuaDogs-1/output_8_0.png\" alt=\"png\"></p>\n<h3 id=\"xml2csv\"><a href=\"#xml2csv\" class=\"headerlink\" title=\"xml2csv\"></a>xml2csv</h3><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> xml.dom.minidom</span><br><span class=\"line\"><span class=\"keyword\">from</span> xml.dom.minidom <span class=\"keyword\">import</span> parse</span><br><span class=\"line\"><span class=\"keyword\">import</span> pandas <span class=\"keyword\">as</span> pd</span><br><span class=\"line\"><span class=\"keyword\">import</span> os</span><br><span class=\"line\"><span class=\"keyword\">from</span> tqdm <span class=\"keyword\">import</span> tqdm</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 结构化</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">xml2df</span><span class=\"params\">(root_path,xml_filename)</span>:</span></span><br><span class=\"line\">    </span><br><span class=\"line\">    DOMTree = parse(root_path+xml_filename)</span><br><span class=\"line\">    collection = DOMTree.documentElement</span><br><span class=\"line\">    </span><br><span class=\"line\">    folder = str(collection.getElementsByTagName(<span class=\"string\">\"folder\"</span>)[<span class=\"number\">0</span>].childNodes[<span class=\"number\">0</span>].data)</span><br><span class=\"line\">    filename = str(collection.getElementsByTagName(<span class=\"string\">\"filename\"</span>)[<span class=\"number\">0</span>].childNodes[<span class=\"number\">0</span>].data)</span><br><span class=\"line\">    dog_type = str(collection.getElementsByTagName(<span class=\"string\">\"name\"</span>)[<span class=\"number\">0</span>].childNodes[<span class=\"number\">0</span>].data)</span><br><span class=\"line\">    </span><br><span class=\"line\">    headbndbox = collection.getElementsByTagName(<span class=\"string\">\"headbndbox\"</span>)[<span class=\"number\">0</span>]</span><br><span class=\"line\">    head_xmin = int(headbndbox.getElementsByTagName(<span class=\"string\">\"xmin\"</span>)[<span class=\"number\">0</span>].childNodes[<span class=\"number\">0</span>].data)</span><br><span class=\"line\">    head_ymin = int(headbndbox.getElementsByTagName(<span class=\"string\">\"ymin\"</span>)[<span class=\"number\">0</span>].childNodes[<span class=\"number\">0</span>].data)</span><br><span class=\"line\">    head_xmax = int(headbndbox.getElementsByTagName(<span class=\"string\">\"xmax\"</span>)[<span class=\"number\">0</span>].childNodes[<span class=\"number\">0</span>].data)</span><br><span class=\"line\">    head_ymax = int(headbndbox.getElementsByTagName(<span class=\"string\">\"ymax\"</span>)[<span class=\"number\">0</span>].childNodes[<span class=\"number\">0</span>].data)</span><br><span class=\"line\">    </span><br><span class=\"line\">    bodybndbox = collection.getElementsByTagName(<span class=\"string\">\"bodybndbox\"</span>)[<span class=\"number\">0</span>]</span><br><span class=\"line\">    body_xmin = int(bodybndbox.getElementsByTagName(<span class=\"string\">\"xmin\"</span>)[<span class=\"number\">0</span>].childNodes[<span class=\"number\">0</span>].data)</span><br><span class=\"line\">    body_ymin = int(bodybndbox.getElementsByTagName(<span class=\"string\">\"ymin\"</span>)[<span class=\"number\">0</span>].childNodes[<span class=\"number\">0</span>].data)</span><br><span class=\"line\">    body_xmax = int(bodybndbox.getElementsByTagName(<span class=\"string\">\"xmax\"</span>)[<span class=\"number\">0</span>].childNodes[<span class=\"number\">0</span>].data)</span><br><span class=\"line\">    body_ymax = int(bodybndbox.getElementsByTagName(<span class=\"string\">\"ymax\"</span>)[<span class=\"number\">0</span>].childNodes[<span class=\"number\">0</span>].data)</span><br><span class=\"line\">    </span><br><span class=\"line\">    data = &#123;</span><br><span class=\"line\">        <span class=\"string\">'folder'</span>: [folder+<span class=\"string\">'/'</span>+filename],</span><br><span class=\"line\">        <span class=\"string\">'dog_type'</span>: [dog_type],</span><br><span class=\"line\">        <span class=\"string\">'hbox'</span>: [[head_xmin,head_ymin,head_xmax,head_ymax]],</span><br><span class=\"line\">        </span><br><span class=\"line\">        <span class=\"string\">'bbox'</span>: [[body_xmin,body_ymin,body_xmax,body_ymax]],</span><br><span class=\"line\">        <span class=\"string\">'label'</span>:[int(folder.split(<span class=\"string\">'-'</span>)[<span class=\"number\">1</span>][<span class=\"number\">1</span>:].lstrip(<span class=\"string\">'0'</span>))]</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    df = pd.DataFrame(data=data)</span><br><span class=\"line\">    </span><br><span class=\"line\">    <span class=\"keyword\">return</span> df</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">fun</span><span class=\"params\">()</span>:</span></span><br><span class=\"line\">    con = []</span><br><span class=\"line\">    <span class=\"keyword\">for</span> path <span class=\"keyword\">in</span> tqdm(os.listdir(<span class=\"string\">'./dataset/low-annotations/'</span>)):</span><br><span class=\"line\">        <span class=\"keyword\">for</span> file <span class=\"keyword\">in</span> os.listdir(<span class=\"string\">'./dataset/low-annotations/'</span> + path):</span><br><span class=\"line\">            root = <span class=\"string\">'./dataset/low-annotations/'</span> + path + <span class=\"string\">'/'</span></span><br><span class=\"line\">            con.append(xml2df(root, file))</span><br><span class=\"line\">    <span class=\"keyword\">return</span> con</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">con = fun()</span><br></pre></td></tr></table></figure>\n<pre><code>100%|████████████████████████████████████████████████████████████████| 130/130 [03:02&lt;00:00,  1.41s/it]\n</code></pre><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">df = pd.concat(con,ignore_index=<span class=\"literal\">True</span>)</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 70428 张图片</span></span><br><span class=\"line\">df.info()</span><br></pre></td></tr></table></figure>\n<pre><code>&lt;class &#39;pandas.core.frame.DataFrame&#39;&gt;\nRangeIndex: 70428 entries, 0 to 70427\nData columns (total 5 columns):\nbbox        70428 non-null object\ndog_type    70428 non-null object\nfolder      70428 non-null object\nhbox        70428 non-null object\nlabel       70428 non-null int64\ndtypes: int64(1), object(4)\nmemory usage: 2.7+ MB\n</code></pre><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">df.head()</span><br></pre></td></tr></table></figure>\n<div>\n\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>bbox</th>\n      <th>dog_type</th>\n      <th>folder</th>\n      <th>hbox</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>[241, 47, 720, 720]</td>\n      <td>Shiba_Dog</td>\n      <td>1043-n000001-Shiba_Dog/n100001.jpeg</td>\n      <td>[258, 43, 494, 322]</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>[126, 200, 462, 494]</td>\n      <td>Shiba_Dog</td>\n      <td>1043-n000001-Shiba_Dog/n100002.jpeg</td>\n      <td>[348, 206, 440, 300]</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>[81, 0, 587, 720]</td>\n      <td>Shiba_Dog</td>\n      <td>1043-n000001-Shiba_Dog/n100003.jpeg</td>\n      <td>[124, 5, 564, 458]</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>[81, 81, 342, 332]</td>\n      <td>Shiba_Dog</td>\n      <td>1043-n000001-Shiba_Dog/n100004.jpg</td>\n      <td>[244, 146, 333, 260]</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>[104, 97, 234, 391]</td>\n      <td>Shiba_Dog</td>\n      <td>1043-n000001-Shiba_Dog/n100005.jpg</td>\n      <td>[127, 118, 222, 247]</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n\n\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">df.to_csv(<span class=\"string\">'./ImageInfo.csv'</span>,index=<span class=\"literal\">False</span>)</span><br></pre></td></tr></table></figure>\n<hr>\n<h3 id=\"数据划分\"><a href=\"#数据划分\" class=\"headerlink\" title=\"数据划分\"></a>数据划分</h3><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> pandas <span class=\"keyword\">as</span> pd</span><br><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\"><span class=\"keyword\">import</span> matplotlib.pyplot <span class=\"keyword\">as</span> plt</span><br><span class=\"line\"><span class=\"keyword\">import</span> cv2 <span class=\"keyword\">as</span> cv</span><br><span class=\"line\">%matplotlib inline</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">img_path = <span class=\"string\">'./dataset/low-resolution/'</span></span><br><span class=\"line\">info_path = <span class=\"string\">'./dataset/low-annotations/'</span></span><br></pre></td></tr></table></figure>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 训练集</span></span><br><span class=\"line\">train_data = pd.read_csv(<span class=\"string\">'./dataset/TrainAndValList/train.lst'</span>,header=<span class=\"literal\">None</span>)</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 验证集</span></span><br><span class=\"line\">val_data = pd.read_csv(<span class=\"string\">'./dataset/TrainAndValList/validation.lst'</span>,header=<span class=\"literal\">None</span>)</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 完整数据</span></span><br><span class=\"line\">all_data = pd.read_csv(<span class=\"string\">'./ImageInfo.csv'</span>)</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">train_data[<span class=\"string\">'folder'</span>] = train_data[<span class=\"number\">0</span>].apply(<span class=\"keyword\">lambda</span> x:x[<span class=\"number\">3</span>:])</span><br><span class=\"line\">val_data[<span class=\"string\">'folder'</span>] = val_data[<span class=\"number\">0</span>].apply(<span class=\"keyword\">lambda</span> x:x[<span class=\"number\">3</span>:])</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">train_data = train_data.drop(columns=<span class=\"number\">0</span>)</span><br><span class=\"line\">val_data = val_data.drop(columns=<span class=\"number\">0</span>)</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 得到最终划分的数据：train/validation</span></span><br><span class=\"line\">train_data = train_data.merge(all_data,on=[<span class=\"string\">'folder'</span>],how=<span class=\"string\">'left'</span>)</span><br><span class=\"line\">val_data = val_data.merge(all_data,on=[<span class=\"string\">'folder'</span>],how=<span class=\"string\">'left'</span>)</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">train_data.head()</span><br></pre></td></tr></table></figure>\n<p><div></div></p>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>folder</th>\n      <th>bbox</th>\n      <th>dog_type</th>\n      <th>hbox</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1043-n000001-Shiba_Dog/n100001.jpeg</td>\n      <td>[241, 47, 720, 720]</td>\n      <td>Shiba_Dog</td>\n      <td>[258, 43, 494, 322]</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1043-n000001-Shiba_Dog/n100002.jpeg</td>\n      <td>[126, 200, 462, 494]</td>\n      <td>Shiba_Dog</td>\n      <td>[348, 206, 440, 300]</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1043-n000001-Shiba_Dog/n100003.jpeg</td>\n      <td>[81, 0, 587, 720]</td>\n      <td>Shiba_Dog</td>\n      <td>[124, 5, 564, 458]</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1043-n000001-Shiba_Dog/n100004.jpg</td>\n      <td>[81, 81, 342, 332]</td>\n      <td>Shiba_Dog</td>\n      <td>[244, 146, 333, 260]</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1043-n000001-Shiba_Dog/n100005.jpg</td>\n      <td>[104, 97, 234, 391]</td>\n      <td>Shiba_Dog</td>\n      <td>[127, 118, 222, 247]</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n\n\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">val_data.head()</span><br></pre></td></tr></table></figure>\n<p><div></div></p>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>folder</th>\n      <th>bbox</th>\n      <th>dog_type</th>\n      <th>hbox</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1043-n000001-Shiba_Dog/n100032.jpeg</td>\n      <td>[109, 44, 471, 533]</td>\n      <td>Shiba_Dog</td>\n      <td>[282, 60, 455, 279]</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1043-n000001-Shiba_Dog/n100069.jpg</td>\n      <td>[52, 1, 315, 221]</td>\n      <td>Shiba_Dog</td>\n      <td>[206, 15, 309, 141]</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1043-n000001-Shiba_Dog/n100109.jpeg</td>\n      <td>[41, 61, 363, 295]</td>\n      <td>Shiba_Dog</td>\n      <td>[119, 70, 220, 222]</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1043-n000001-Shiba_Dog/n100112.jpg</td>\n      <td>[59, 0, 296, 472]</td>\n      <td>Shiba_Dog</td>\n      <td>[58, 0, 281, 227]</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1043-n000001-Shiba_Dog/n100171.jpg</td>\n      <td>[30, 80, 318, 271]</td>\n      <td>Shiba_Dog</td>\n      <td>[188, 91, 257, 187]</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n\n\n\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">len(train_data),len(val_data),len(all_data)</span><br></pre></td></tr></table></figure>\n<pre><code>(65228, 5200, 70428)\n</code></pre><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 保存(save to csv file)</span></span><br><span class=\"line\">train_data.to_csv(<span class=\"string\">'./train.data.csv'</span>,index=<span class=\"literal\">False</span>)</span><br><span class=\"line\">val_data.to_csv(<span class=\"string\">'./valid.data.csv'</span>,index=<span class=\"literal\">False</span>)</span><br></pre></td></tr></table></figure>\n<h3 id=\"数据分布\"><a href=\"#数据分布\" class=\"headerlink\" title=\"数据分布\"></a>数据分布</h3><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> pandas <span class=\"keyword\">as</span> pd </span><br><span class=\"line\"><span class=\"keyword\">import</span> matplotlib.pyplot <span class=\"keyword\">as</span> plt</span><br><span class=\"line\">%matplotlib inline</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">all_data = pd.read_csv(<span class=\"string\">'./ImageInfo.csv'</span>)</span><br><span class=\"line\">train_data = pd.read_csv(<span class=\"string\">'./train.data.csv'</span>)</span><br><span class=\"line\">val_data = pd.read_csv(<span class=\"string\">'./valid.data.csv'</span>)</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># top 15 类型</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">show</span><span class=\"params\">(d)</span>:</span></span><br><span class=\"line\">    fig = plt.figure(figsize=(<span class=\"number\">15</span>,<span class=\"number\">10</span>))</span><br><span class=\"line\">    plt.pie(d.values,  labels=d.index, autopct=<span class=\"string\">'%1.2f%%'</span>, startangle=<span class=\"number\">160</span>)</span><br><span class=\"line\">    plt.tight_layout()</span><br><span class=\"line\">    </span><br><span class=\"line\"><span class=\"keyword\">for</span> dt <span class=\"keyword\">in</span> [all_data,train_data,val_data]:</span><br><span class=\"line\">    d = dt[<span class=\"string\">'dog_type'</span>].value_counts()[:<span class=\"number\">15</span>]</span><br><span class=\"line\">    show(d)</span><br></pre></td></tr></table></figure>\n<p><img src=\"/articles/TsinghuaDogs-1/output_35_0.png\" alt=\"png\"></p>\n<p><img src=\"/articles/TsinghuaDogs-1/output_35_1.png\" alt=\"png\"></p>\n<p><img src=\"/articles/TsinghuaDogs-1/output_35_2.png\" alt=\"png\"></p>\n<h3 id=\"check-data\"><a href=\"#check-data\" class=\"headerlink\" title=\"check data\"></a>check data</h3><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> pandas <span class=\"keyword\">as</span> pd</span><br><span class=\"line\"><span class=\"keyword\">import</span> matplotlib.pyplot <span class=\"keyword\">as</span> plt</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 查看数据维度</span></span><br><span class=\"line\">all_data = pd.read_csv(<span class=\"string\">'./ImageInfo.csv'</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">root = <span class=\"string\">'./dataset/low-resolution/'</span></span><br><span class=\"line\">all_data[<span class=\"string\">'flag'</span>] = all_data[<span class=\"string\">'folder'</span>].apply(</span><br><span class=\"line\">    <span class=\"keyword\">lambda</span> x: <span class=\"number\">1</span> <span class=\"keyword\">if</span> <span class=\"number\">3</span> == plt.imread(root + x).shape[<span class=\"number\">2</span>] <span class=\"keyword\">else</span> <span class=\"number\">0</span>)</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 有一张图像维度不是 3</span></span><br><span class=\"line\">all_data[<span class=\"string\">'flag'</span>].value_counts()</span><br></pre></td></tr></table></figure>\n<pre><code>1    70427\n0        1\nName: flag, dtype: int64\n</code></pre><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># rgba 图像</span></span><br><span class=\"line\">d = all_data[all_data[<span class=\"string\">'flag'</span>]==<span class=\"number\">0</span>][<span class=\"string\">'folder'</span>].values[<span class=\"number\">0</span>]</span><br><span class=\"line\">plt.imread(<span class=\"string\">'./dataset/low-resolution/'</span>+d).shape</span><br></pre></td></tr></table></figure>\n<pre><code>(189, 213, 4)\n</code></pre><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># delete </span></span><br><span class=\"line\">train_data = pd.read_csv(<span class=\"string\">'./train.data.csv'</span>)</span><br><span class=\"line\">valid_data = pd.read_csv(<span class=\"string\">'./valid.data.csv'</span>)</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">train_data[train_data[<span class=\"string\">'folder'</span>]==d]</span><br></pre></td></tr></table></figure>\n<p><div></div></p>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>folder</th>\n      <th>bbox</th>\n      <th>dog_type</th>\n      <th>hbox</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table>\n\n\n\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">valid_data[valid_data[<span class=\"string\">'folder'</span>]==d]</span><br></pre></td></tr></table></figure>\n<p><div></div></p>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>folder</th>\n      <th>bbox</th>\n      <th>dog_type</th>\n      <th>hbox</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>4375</th>\n      <td>274-n000110-Shetland_sheepdog/n136188.jpg</td>\n      <td>[3, 0, 203, 183]</td>\n      <td>Shetland_sheepdog</td>\n      <td>[10, 4, 85, 68]</td>\n      <td>110</td>\n    </tr>\n  </tbody>\n</table>\n\n\n\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">valid_data = valid_data.drop(</span><br><span class=\"line\">    valid_data[valid_data[<span class=\"string\">'folder'</span>] == d].index).reset_index(drop=<span class=\"literal\">True</span>)</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 重新保存</span></span><br><span class=\"line\">valid_data.to_csv(<span class=\"string\">'./valid.data.csv'</span>,index=<span class=\"literal\">False</span>)</span><br></pre></td></tr></table></figure>\n<h3 id=\"图像增强\"><a href=\"#图像增强\" class=\"headerlink\" title=\"图像增强\"></a>图像增强</h3><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\"><span class=\"keyword\">import</span> random</span><br><span class=\"line\"><span class=\"keyword\">import</span> cv2 <span class=\"keyword\">as</span> cv</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 亮度</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">random_bright</span><span class=\"params\">(img, delta=<span class=\"number\">32</span>)</span>:</span></span><br><span class=\"line\">    <span class=\"string\">\"\"\"Random change bright</span></span><br><span class=\"line\"><span class=\"string\">    </span></span><br><span class=\"line\"><span class=\"string\">    Args:</span></span><br><span class=\"line\"><span class=\"string\">        im(numpy.array): one H,W,3 image</span></span><br><span class=\"line\"><span class=\"string\">        delta(int): bright ratio</span></span><br><span class=\"line\"><span class=\"string\">    \"\"\"</span></span><br><span class=\"line\">    im = np.copy(img)</span><br><span class=\"line\">    <span class=\"keyword\">if</span> random.random() &lt; <span class=\"number\">0.5</span>:</span><br><span class=\"line\">        delta = random.uniform(-delta, delta)</span><br><span class=\"line\">        im += delta</span><br><span class=\"line\">        im = im.clip(min=<span class=\"number\">0</span>, max=<span class=\"number\">255</span>)</span><br><span class=\"line\">    <span class=\"keyword\">return</span> im</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 对比度</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">random_contrast</span><span class=\"params\">(img, lower=<span class=\"number\">0.5</span>, upper=<span class=\"number\">1.5</span>)</span>:</span></span><br><span class=\"line\">    <span class=\"string\">\"\"\"Random change contrast</span></span><br><span class=\"line\"><span class=\"string\">    </span></span><br><span class=\"line\"><span class=\"string\">    Args:</span></span><br><span class=\"line\"><span class=\"string\">        im(numpy.array): one H,W,3 image</span></span><br><span class=\"line\"><span class=\"string\">        lower(float): change lower limit </span></span><br><span class=\"line\"><span class=\"string\">        upper(float): change upper limit</span></span><br><span class=\"line\"><span class=\"string\">    \"\"\"</span></span><br><span class=\"line\">    im = np.copy(img)</span><br><span class=\"line\">    <span class=\"keyword\">if</span> random.random() &lt; <span class=\"number\">0.5</span>:</span><br><span class=\"line\">        alpha = random.uniform(lower, upper)</span><br><span class=\"line\">        im *= alpha</span><br><span class=\"line\">        im = im.clip(min=<span class=\"number\">0</span>, max=<span class=\"number\">255</span>)</span><br><span class=\"line\">    <span class=\"keyword\">return</span> im</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 饱和度</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">random_saturation</span><span class=\"params\">(img, lower=<span class=\"number\">0.5</span>, upper=<span class=\"number\">1.5</span>)</span>:</span></span><br><span class=\"line\">    <span class=\"string\">\"\"\"Random change saturation</span></span><br><span class=\"line\"><span class=\"string\">    </span></span><br><span class=\"line\"><span class=\"string\">    Args:</span></span><br><span class=\"line\"><span class=\"string\">        im(numpy.array): one H,W,3 image</span></span><br><span class=\"line\"><span class=\"string\">        lower(float): change lower limit </span></span><br><span class=\"line\"><span class=\"string\">        upper(float): change upper limit</span></span><br><span class=\"line\"><span class=\"string\">    \"\"\"</span></span><br><span class=\"line\">    im = np.copy(img)</span><br><span class=\"line\">    <span class=\"keyword\">if</span> random.random() &lt; <span class=\"number\">0.5</span>:</span><br><span class=\"line\">        im[:, :, <span class=\"number\">1</span>] *= random.uniform(lower, upper)</span><br><span class=\"line\">    <span class=\"keyword\">return</span> im</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 色调</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">random_hue</span><span class=\"params\">(img, delta=<span class=\"number\">18.0</span>)</span>:</span></span><br><span class=\"line\">    <span class=\"string\">\"\"\"Random change hue</span></span><br><span class=\"line\"><span class=\"string\">    </span></span><br><span class=\"line\"><span class=\"string\">    Args:</span></span><br><span class=\"line\"><span class=\"string\">        im(numpy.array): one H,W,3 image</span></span><br><span class=\"line\"><span class=\"string\">        delta(int): hue ratio</span></span><br><span class=\"line\"><span class=\"string\">    \"\"\"</span></span><br><span class=\"line\">    im = np.copy(img)</span><br><span class=\"line\">    <span class=\"keyword\">if</span> random.random() &lt; <span class=\"number\">0.5</span>:</span><br><span class=\"line\">        im = cv.cvtColor(im, cv.COLOR_RGB2HSV)</span><br><span class=\"line\">        im[:, :, <span class=\"number\">0</span>] += random.uniform(-delta, delta)</span><br><span class=\"line\">        im[:, :, <span class=\"number\">0</span>][im[:, :, <span class=\"number\">0</span>] &gt; <span class=\"number\">360.0</span>] -= <span class=\"number\">360.0</span></span><br><span class=\"line\">        im[:, :, <span class=\"number\">0</span>][im[:, :, <span class=\"number\">0</span>] &lt; <span class=\"number\">0.0</span>] += <span class=\"number\">360.0</span></span><br><span class=\"line\">        im = cv.cvtColor(im, cv.COLOR_HSV2RGB)</span><br><span class=\"line\">    <span class=\"keyword\">return</span> im</span><br></pre></td></tr></table></figure>\n<h3 id=\"数据加载\"><a href=\"#数据加载\" class=\"headerlink\" title=\"数据加载\"></a>数据加载</h3><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> os</span><br><span class=\"line\"><span class=\"keyword\">import</span> cv2 <span class=\"keyword\">as</span> cv</span><br><span class=\"line\"><span class=\"keyword\">import</span> random</span><br><span class=\"line\"><span class=\"keyword\">import</span> pandas <span class=\"keyword\">as</span> pd</span><br><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">DataLoad</span><span class=\"params\">(object)</span>:</span></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">__init__</span><span class=\"params\">(self,folder=<span class=\"string\">'./'</span>,dtype=<span class=\"string\">'train'</span>,shuffle=False)</span>:</span></span><br><span class=\"line\">        self.folder = folder</span><br><span class=\"line\">        self.shuffle = shuffle</span><br><span class=\"line\">        self.dtype = dtype</span><br><span class=\"line\">        </span><br><span class=\"line\">        <span class=\"keyword\">assert</span> self.dtype <span class=\"keyword\">in</span> [<span class=\"string\">'train'</span>,<span class=\"string\">'test'</span>,<span class=\"string\">'valid'</span>]</span><br><span class=\"line\">        </span><br><span class=\"line\">        self.data = pd.read_csv(os.path.join(self.folder+self.dtype+<span class=\"string\">'.data.csv'</span>))</span><br><span class=\"line\">            </span><br><span class=\"line\">        self.mean = [<span class=\"number\">0.485</span>, <span class=\"number\">0.456</span>, <span class=\"number\">0.406</span>]</span><br><span class=\"line\">        self.std = [<span class=\"number\">0.229</span>, <span class=\"number\">0.224</span>, <span class=\"number\">0.225</span>]</span><br><span class=\"line\">        <span class=\"keyword\">if</span> self.shuffle:</span><br><span class=\"line\">            self.data = self.data.sample(frac=<span class=\"number\">1</span>).reset_index(drop=<span class=\"literal\">True</span>)</span><br><span class=\"line\">    </span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">__getitem__</span><span class=\"params\">(self,i)</span>:</span></span><br><span class=\"line\">        dt = self.data.iloc[i]</span><br><span class=\"line\">        image = cv.imread(<span class=\"string\">'./dataset/low-resolution/'</span>+dt[<span class=\"string\">'folder'</span>])</span><br><span class=\"line\">        image = cv.cvtColor(image,cv.COLOR_BGR2RGB).astype(<span class=\"string\">\"float32\"</span>)</span><br><span class=\"line\">        </span><br><span class=\"line\">        bbox = np.array([dt[<span class=\"string\">'bbox'</span>].strip(<span class=\"string\">\"[]\"</span>).split(<span class=\"string\">','</span>)]).astype(<span class=\"string\">\"float32\"</span>)</span><br><span class=\"line\">        hbox = np.array([dt[<span class=\"string\">'hbox'</span>].strip(<span class=\"string\">\"[]\"</span>).split(<span class=\"string\">','</span>)]).astype(<span class=\"string\">\"float32\"</span>)</span><br><span class=\"line\">        label = np.array(dt[<span class=\"string\">'label'</span>])</span><br><span class=\"line\">        </span><br><span class=\"line\">        <span class=\"keyword\">if</span> self.dtype == <span class=\"string\">'train'</span>:</span><br><span class=\"line\">            data_enhance = [random_bright, </span><br><span class=\"line\">                            random_contrast, </span><br><span class=\"line\">                            random_saturation, </span><br><span class=\"line\">                            random_hue]</span><br><span class=\"line\">            </span><br><span class=\"line\">            random.shuffle(data_enhance)</span><br><span class=\"line\">            </span><br><span class=\"line\">            <span class=\"keyword\">for</span> d <span class=\"keyword\">in</span> data_enhance:</span><br><span class=\"line\">                image = d(image)</span><br><span class=\"line\">            </span><br><span class=\"line\"><span class=\"comment\">#             if random.random() &lt; 0.5:</span></span><br><span class=\"line\"><span class=\"comment\">#                 image, boxes = random_expand(image, boxes)            </span></span><br><span class=\"line\"><span class=\"comment\">#             image, boxes, labels = random_crop(image, boxes, labels)           </span></span><br><span class=\"line\"><span class=\"comment\">#             image, boxes = random_flip(image, boxes)</span></span><br><span class=\"line\">            </span><br><span class=\"line\">        height, width, _ = image.shape</span><br><span class=\"line\">        image = cv.resize(image, (<span class=\"number\">300</span>, <span class=\"number\">300</span>))</span><br><span class=\"line\">        image /= <span class=\"number\">255.</span></span><br><span class=\"line\">        image = (image - self.mean) / self.std</span><br><span class=\"line\"><span class=\"comment\">#         image = image.transpose((2,0,1)).astype(\"float32\")</span></span><br><span class=\"line\">        bbox[:,[<span class=\"number\">0</span>,<span class=\"number\">2</span>]] /= width</span><br><span class=\"line\">        </span><br><span class=\"line\">        bbox[:,[<span class=\"number\">1</span>,<span class=\"number\">3</span>]] /= height</span><br><span class=\"line\"></span><br><span class=\"line\">        hbox[:,[<span class=\"number\">0</span>,<span class=\"number\">2</span>]] /= width</span><br><span class=\"line\">        hbox[:,[<span class=\"number\">1</span>,<span class=\"number\">3</span>]] /= height</span><br><span class=\"line\">        </span><br><span class=\"line\">        <span class=\"keyword\">return</span> image, bbox, hbox, label</span><br></pre></td></tr></table></figure>\n<h3 id=\"Build-Model\"><a href=\"#Build-Model\" class=\"headerlink\" title=\"Build Model\"></a>Build Model</h3><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> tensorflow <span class=\"keyword\">as</span> tf</span><br><span class=\"line\"><span class=\"keyword\">from</span> tensorflow.keras <span class=\"keyword\">import</span> datasets, layers, models</span><br><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\"><span class=\"keyword\">import</span> pandas <span class=\"keyword\">as</span> pd</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># VGG16</span></span><br><span class=\"line\"></span><br><span class=\"line\">model = models.Sequential()</span><br><span class=\"line\"></span><br><span class=\"line\">model.add(</span><br><span class=\"line\">    layers.Conv2D(<span class=\"number\">64</span>, (<span class=\"number\">3</span>, <span class=\"number\">3</span>),</span><br><span class=\"line\">                  padding=<span class=\"string\">\"same\"</span>,</span><br><span class=\"line\">                  activation=<span class=\"string\">'relu'</span>,</span><br><span class=\"line\">                  input_shape=(<span class=\"number\">300</span>, <span class=\"number\">300</span>, <span class=\"number\">3</span>)))</span><br><span class=\"line\">model.add(layers.Conv2D(<span class=\"number\">64</span>, (<span class=\"number\">3</span>, <span class=\"number\">3</span>), padding=<span class=\"string\">\"same\"</span>, activation=<span class=\"string\">'relu'</span>))</span><br><span class=\"line\">model.add(layers.MaxPooling2D((<span class=\"number\">2</span>, <span class=\"number\">2</span>), strides=<span class=\"number\">2</span>))</span><br><span class=\"line\"></span><br><span class=\"line\">model.add(layers.Conv2D(<span class=\"number\">128</span>, (<span class=\"number\">3</span>, <span class=\"number\">3</span>), padding=<span class=\"string\">\"same\"</span>, activation=<span class=\"string\">'relu'</span>))</span><br><span class=\"line\">model.add(layers.Conv2D(<span class=\"number\">128</span>, (<span class=\"number\">3</span>, <span class=\"number\">3</span>), padding=<span class=\"string\">\"same\"</span>, activation=<span class=\"string\">'relu'</span>))</span><br><span class=\"line\">model.add(layers.MaxPooling2D((<span class=\"number\">2</span>, <span class=\"number\">2</span>), strides=<span class=\"number\">2</span>))</span><br><span class=\"line\"></span><br><span class=\"line\">model.add(layers.Conv2D(<span class=\"number\">256</span>, (<span class=\"number\">3</span>, <span class=\"number\">3</span>), padding=<span class=\"string\">\"same\"</span>, activation=<span class=\"string\">'relu'</span>))</span><br><span class=\"line\">model.add(layers.Conv2D(<span class=\"number\">256</span>, (<span class=\"number\">3</span>, <span class=\"number\">3</span>), padding=<span class=\"string\">\"same\"</span>, activation=<span class=\"string\">'relu'</span>))</span><br><span class=\"line\">model.add(layers.Conv2D(<span class=\"number\">256</span>, (<span class=\"number\">3</span>, <span class=\"number\">3</span>), padding=<span class=\"string\">\"same\"</span>, activation=<span class=\"string\">'relu'</span>))</span><br><span class=\"line\">model.add(layers.MaxPooling2D((<span class=\"number\">2</span>, <span class=\"number\">2</span>), strides=<span class=\"number\">2</span>))</span><br><span class=\"line\"></span><br><span class=\"line\">model.add(layers.Conv2D(<span class=\"number\">512</span>, (<span class=\"number\">3</span>, <span class=\"number\">3</span>), padding=<span class=\"string\">\"same\"</span>, activation=<span class=\"string\">'relu'</span>))</span><br><span class=\"line\">model.add(layers.Conv2D(<span class=\"number\">512</span>, (<span class=\"number\">3</span>, <span class=\"number\">3</span>), padding=<span class=\"string\">\"same\"</span>, activation=<span class=\"string\">'relu'</span>))</span><br><span class=\"line\">model.add(layers.Conv2D(<span class=\"number\">512</span>, (<span class=\"number\">3</span>, <span class=\"number\">3</span>), padding=<span class=\"string\">\"same\"</span>, activation=<span class=\"string\">'relu'</span>))</span><br><span class=\"line\">model.add(layers.MaxPooling2D((<span class=\"number\">2</span>, <span class=\"number\">2</span>), strides=<span class=\"number\">2</span>))</span><br><span class=\"line\"></span><br><span class=\"line\">model.add(layers.Conv2D(<span class=\"number\">512</span>, (<span class=\"number\">3</span>, <span class=\"number\">3</span>), padding=<span class=\"string\">\"same\"</span>, activation=<span class=\"string\">'relu'</span>))</span><br><span class=\"line\">model.add(layers.Conv2D(<span class=\"number\">512</span>, (<span class=\"number\">3</span>, <span class=\"number\">3</span>), padding=<span class=\"string\">\"same\"</span>, activation=<span class=\"string\">'relu'</span>))</span><br><span class=\"line\">model.add(layers.Conv2D(<span class=\"number\">512</span>, (<span class=\"number\">3</span>, <span class=\"number\">3</span>), padding=<span class=\"string\">\"same\"</span>, activation=<span class=\"string\">'relu'</span>))</span><br><span class=\"line\">model.add(layers.MaxPooling2D((<span class=\"number\">2</span>, <span class=\"number\">2</span>), strides=<span class=\"number\">2</span>))</span><br><span class=\"line\"></span><br><span class=\"line\">model.add(layers.Flatten())</span><br><span class=\"line\">model.add(layers.Dense(<span class=\"number\">256</span>, activation=<span class=\"string\">'relu'</span>))</span><br><span class=\"line\">model.add(layers.Dense(<span class=\"number\">64</span>, activation=<span class=\"string\">'relu'</span>))</span><br><span class=\"line\">model.add(layers.Dense(<span class=\"number\">130</span>))</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">train = DataLoad(shuffle=<span class=\"literal\">True</span>)</span><br><span class=\"line\">valid = DataLoad(dtype=<span class=\"string\">'valid'</span>)</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">cat_data</span><span class=\"params\">(dt,n=<span class=\"number\">100</span>)</span>:</span></span><br><span class=\"line\">    con = []</span><br><span class=\"line\">    lab = []</span><br><span class=\"line\">    <span class=\"keyword\">for</span> i,(image, bbox, hbox, label) <span class=\"keyword\">in</span> enumerate(dt):</span><br><span class=\"line\">        <span class=\"keyword\">if</span> i == n:</span><br><span class=\"line\">            <span class=\"keyword\">break</span></span><br><span class=\"line\">        con.append(image)</span><br><span class=\"line\">        lab.append(label)</span><br><span class=\"line\">    lab = np.array(lab)    </span><br><span class=\"line\">    <span class=\"keyword\">return</span> np.array(con),lab</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">x_train,y_train = cat_data(train,n=<span class=\"number\">200</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">x_test,y_test = cat_data(valid,n=<span class=\"number\">5</span>)</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">y_train = tf.constant(y_train)</span><br><span class=\"line\">y_test = tf.constant(y_test)</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">model.compile(</span><br><span class=\"line\">    optimizer=<span class=\"string\">'adam'</span>,</span><br><span class=\"line\">    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=<span class=\"literal\">True</span>),</span><br><span class=\"line\">    metrics=[<span class=\"string\">'accuracy'</span>])</span><br><span class=\"line\"></span><br><span class=\"line\">history = model.fit(</span><br><span class=\"line\">    x_train,</span><br><span class=\"line\">    y_train,</span><br><span class=\"line\">    epochs=<span class=\"number\">10</span>,</span><br><span class=\"line\">    batch_size=<span class=\"number\">1</span>,</span><br><span class=\"line\">    shuffle=<span class=\"literal\">True</span>,</span><br><span class=\"line\">    validation_data=(x_test, y_test) </span><br><span class=\"line\">)</span><br></pre></td></tr></table></figure>\n<hr>\n<h3 id=\"SSD-Jittor\"><a href=\"#SSD-Jittor\" class=\"headerlink\" title=\"SSD-Jittor:\"></a>SSD-Jittor:</h3><p>New a py file under the root dir: <code>process.py</code></p>\n<p><code>new_parse_annotation()</code> :</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">new_parse_annotation</span><span class=\"params\">(annotation_path)</span>:</span></span><br><span class=\"line\">    </span><br><span class=\"line\">    DOMTree = parse(annotation_path)</span><br><span class=\"line\">    collection = DOMTree.documentElement</span><br><span class=\"line\">    </span><br><span class=\"line\">    folder = str(collection.getElementsByTagName(<span class=\"string\">\"folder\"</span>)[<span class=\"number\">0</span>].childNodes[<span class=\"number\">0</span>].data)</span><br><span class=\"line\"><span class=\"comment\">#     filename = str(collection.getElementsByTagName(\"filename\")[0].childNodes[0].data)</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">#     dog_type = str(collection.getElementsByTagName(\"name\")[0].childNodes[0].data)   </span></span><br><span class=\"line\"><span class=\"comment\">#     headbndbox = collection.getElementsByTagName(\"headbndbox\")[0]</span></span><br><span class=\"line\"><span class=\"comment\">#     head_xmin = int(headbndbox.getElementsByTagName(\"xmin\")[0].childNodes[0].data)</span></span><br><span class=\"line\"><span class=\"comment\">#     head_ymin = int(headbndbox.getElementsByTagName(\"ymin\")[0].childNodes[0].data)</span></span><br><span class=\"line\"><span class=\"comment\">#     head_xmax = int(headbndbox.getElementsByTagName(\"xmax\")[0].childNodes[0].data)</span></span><br><span class=\"line\"><span class=\"comment\">#     head_ymax = int(headbndbox.getElementsByTagName(\"ymax\")[0].childNodes[0].data)</span></span><br><span class=\"line\">    difficult = int(collection.getElementsByTagName(<span class=\"string\">\"difficult\"</span>)[<span class=\"number\">0</span>].childNodes[<span class=\"number\">0</span>].data)</span><br><span class=\"line\">    </span><br><span class=\"line\">    bodybndbox = collection.getElementsByTagName(<span class=\"string\">\"bodybndbox\"</span>)[<span class=\"number\">0</span>]</span><br><span class=\"line\">    body_xmin = int(bodybndbox.getElementsByTagName(<span class=\"string\">\"xmin\"</span>)[<span class=\"number\">0</span>].childNodes[<span class=\"number\">0</span>].data)</span><br><span class=\"line\">    body_ymin = int(bodybndbox.getElementsByTagName(<span class=\"string\">\"ymin\"</span>)[<span class=\"number\">0</span>].childNodes[<span class=\"number\">0</span>].data)</span><br><span class=\"line\">    body_xmax = int(bodybndbox.getElementsByTagName(<span class=\"string\">\"xmax\"</span>)[<span class=\"number\">0</span>].childNodes[<span class=\"number\">0</span>].data)</span><br><span class=\"line\">    body_ymax = int(bodybndbox.getElementsByTagName(<span class=\"string\">\"ymax\"</span>)[<span class=\"number\">0</span>].childNodes[<span class=\"number\">0</span>].data)</span><br><span class=\"line\">    </span><br><span class=\"line\">    data = &#123;</span><br><span class=\"line\">        <span class=\"string\">'boxes'</span>: [[body_xmin - <span class=\"number\">1</span>,body_ymin - <span class=\"number\">1</span>,body_xmax - <span class=\"number\">1</span>,body_ymax - <span class=\"number\">1</span>]],</span><br><span class=\"line\">        <span class=\"string\">'labels'</span>:[int(folder.split(<span class=\"string\">'-'</span>)[<span class=\"number\">1</span>][<span class=\"number\">1</span>:].lstrip(<span class=\"string\">'0'</span>))],</span><br><span class=\"line\">        <span class=\"string\">'difficulties'</span>:[difficult]</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">return</span> data</span><br></pre></td></tr></table></figure>\n<p><code>create_json_data()</code> :</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">create_json_data</span><span class=\"params\">(Lst_dir,anno_dir)</span>:</span></span><br><span class=\"line\">    train_images = list()</span><br><span class=\"line\">    train_objects = list()</span><br><span class=\"line\"></span><br><span class=\"line\">    lst_path = os.path.join(Lst_dir, <span class=\"string\">'train.lst'</span>)</span><br><span class=\"line\">    dt = pd.read_csv(lst_path,header=<span class=\"literal\">None</span>)</span><br><span class=\"line\">    </span><br><span class=\"line\">    <span class=\"keyword\">for</span> item <span class=\"keyword\">in</span> tqdm(dt[<span class=\"number\">0</span>]):</span><br><span class=\"line\">        img = item.split(<span class=\"string\">'/'</span>)[<span class=\"number\">-2</span>] + <span class=\"string\">'/'</span> + item.split(<span class=\"string\">'/'</span>)[<span class=\"number\">-1</span>]</span><br><span class=\"line\">        train_images.append(img)</span><br><span class=\"line\">        anno_path = os.path.join(anno_dir,img) + <span class=\"string\">'.xml'</span></span><br><span class=\"line\">        train_objects.append(new_parse_annotation(anno_path))</span><br><span class=\"line\">        </span><br><span class=\"line\">    <span class=\"keyword\">assert</span> len(train_objects) == len(train_images)</span><br><span class=\"line\">    </span><br><span class=\"line\">    <span class=\"comment\"># Save to file</span></span><br><span class=\"line\">    <span class=\"keyword\">with</span> open(os.path.join(<span class=\"string\">'./dataset/JsonData/'</span>, <span class=\"string\">'TRAIN_images.json'</span>), <span class=\"string\">'w'</span>) <span class=\"keyword\">as</span> j:</span><br><span class=\"line\">        json.dump(train_images, j)</span><br><span class=\"line\">    <span class=\"keyword\">with</span> open(os.path.join(<span class=\"string\">'./dataset/JsonData/'</span>, <span class=\"string\">'TRAIN_objects.json'</span>), <span class=\"string\">'w'</span>) <span class=\"keyword\">as</span> j:</span><br><span class=\"line\">        json.dump(train_objects, j)</span><br><span class=\"line\">    <span class=\"keyword\">with</span> open(os.path.join(<span class=\"string\">'./dataset/JsonData/'</span>, <span class=\"string\">'label_map.json'</span>), <span class=\"string\">'w'</span>) <span class=\"keyword\">as</span> j:</span><br><span class=\"line\">        json.dump(label_map, j)  <span class=\"comment\"># save label map too</span></span><br><span class=\"line\">    </span><br><span class=\"line\">    <span class=\"comment\"># Validation data</span></span><br><span class=\"line\">    test_images = list()</span><br><span class=\"line\">    test_objects = list()</span><br><span class=\"line\">    </span><br><span class=\"line\">    lst_path = os.path.join(Lst_dir, <span class=\"string\">'validation.lst'</span>)</span><br><span class=\"line\">    dt = pd.read_csv(lst_path,header=<span class=\"literal\">None</span>)</span><br><span class=\"line\">    </span><br><span class=\"line\">    <span class=\"keyword\">for</span> item <span class=\"keyword\">in</span> tqdm(dt[<span class=\"number\">0</span>]):</span><br><span class=\"line\">        img = item.split(<span class=\"string\">'/'</span>)[<span class=\"number\">-2</span>] + <span class=\"string\">'/'</span> + item.split(<span class=\"string\">'/'</span>)[<span class=\"number\">-1</span>]</span><br><span class=\"line\">        test_images.append(img)</span><br><span class=\"line\">        </span><br><span class=\"line\">        anno_path = os.path.join(anno_dir,img) + <span class=\"string\">'.xml'</span></span><br><span class=\"line\">        test_objects.append(new_parse_annotation(anno_path))</span><br><span class=\"line\">        </span><br><span class=\"line\">    <span class=\"keyword\">assert</span> len(test_objects) == len(test_images)</span><br><span class=\"line\">    </span><br><span class=\"line\">    <span class=\"comment\"># save to file</span></span><br><span class=\"line\">    <span class=\"keyword\">with</span> open(os.path.join(<span class=\"string\">'./dataset/JsonData/'</span>, <span class=\"string\">'VALID_images.json'</span>), <span class=\"string\">'w'</span>) <span class=\"keyword\">as</span> j:</span><br><span class=\"line\">        json.dump(test_images, j)</span><br><span class=\"line\">    <span class=\"keyword\">with</span> open(os.path.join(<span class=\"string\">'./dataset/JsonData/'</span>, <span class=\"string\">'VALID_objects.json'</span>), <span class=\"string\">'w'</span>) <span class=\"keyword\">as</span> j:</span><br><span class=\"line\">        json.dump(test_objects, j)</span><br><span class=\"line\">        </span><br><span class=\"line\">    print(<span class=\"string\">'Train data:&#123;&#125;,Valid data:&#123;&#125;'</span>.format(len(train_objects),len(test_objects)))</span><br></pre></td></tr></table></figure>\n</div>","categories":[],"tags":["CV"]},{"title":"Titanic","url":"https://hahally.github.io//articles/Titanic/","content":"<h3 id=\"大纲\"><a href=\"#大纲\" class=\"headerlink\" title=\"大纲\"></a>大纲</h3><p><code>Titanic Survival Predictions</code> 可以算是机器学习中的 <code>Hello World</code>了。像kaggle和天池这样的竞赛平台，都将此作为入门的经典题目。</p>\n<ul>\n<li><p>数据：Titanic Survival Predictions</p>\n<ul>\n<li>train.csv：训练集</li>\n<li>test.csv：测试集</li>\n</ul>\n</li>\n<li><p>任务：主要对 <code>train.csv</code> 数据进行处理分析。</p>\n<ul>\n<li>了解和掌握 <code>pandas</code> 透视表的一些基本操作(读取，查看，聚合…)</li>\n<li>了解和掌握一些基本绘图方法</li>\n<li>分析影响游客存活的因素</li>\n<li>分析对缺失值的处理方法</li>\n</ul>\n</li>\n<li><p>数据属性说明(可以参考这里的<a href=\"https://www.kaggle.com/c/titanic/data\" target=\"_blank\" rel=\"noopener\">Data Dictionary</a>)</p>\n<ul>\n<li>PassengerId：id</li>\n<li>Survived：是否存活(0/1)</li>\n<li>Pclass: 舱位类型(1,2,3)</li>\n<li>Name：姓名</li>\n<li>Sex：性别</li>\n<li>Age：年龄</li>\n<li>SibSp：of siblings / spouses aboard the Titanic</li>\n<li>Parch：of parents / children aboard the Titanic</li>\n<li>Ticket：Ticket number</li>\n<li>Fare：票价</li>\n<li>Cabin：房间编号</li>\n<li>Embarked：登船港口</li>\n</ul>\n<ul>\n<li>相关文档：<ul>\n<li><a href=\"https://pandas.pydata.org/pandas-docs/stable/\" target=\"_blank\" rel=\"noopener\">https://pandas.pydata.org/pandas-docs/stable/</a></li>\n<li><a href=\"https://www.pypandas.cn/\" target=\"_blank\" rel=\"noopener\">https://www.pypandas.cn/</a></li>\n<li><a href=\"https://www.matplotlib.org.cn/\" target=\"_blank\" rel=\"noopener\">https://www.matplotlib.org.cn/</a></li>\n<li><a href=\"https://matplotlib.org/\" target=\"_blank\" rel=\"noopener\">https://matplotlib.org/</a></li>\n<li><a href=\"https://www.numpy.org.cn/\" target=\"_blank\" rel=\"noopener\">https://www.numpy.org.cn/</a></li>\n<li><a href=\"https://numpy.org/doc/stable/reference/\" target=\"_blank\" rel=\"noopener\">https://numpy.org/doc/stable/reference/</a></li>\n<li><a href=\"http://seaborn.pydata.org/\" target=\"_blank\" rel=\"noopener\">http://seaborn.pydata.org/</a></li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"导入相关的库\"><a href=\"#导入相关的库\" class=\"headerlink\" title=\"导入相关的库\"></a>导入相关的库</h3><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> pandas <span class=\"keyword\">as</span> pd </span><br><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\"><span class=\"keyword\">import</span> matplotlib.pyplot <span class=\"keyword\">as</span> plt</span><br><span class=\"line\"><span class=\"keyword\">import</span> seaborn <span class=\"keyword\">as</span> sns</span><br><span class=\"line\">%matplotlib inline</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">#ignore warnings</span></span><br><span class=\"line\"><span class=\"keyword\">import</span> warnings</span><br><span class=\"line\">warnings.filterwarnings(<span class=\"string\">'ignore'</span>)</span><br></pre></td></tr></table></figure>\n<h3 id=\"数据预览\"><a href=\"#数据预览\" class=\"headerlink\" title=\"数据预览\"></a>数据预览</h3><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">### 读取数据</span></span><br><span class=\"line\">dt_train = pd.read_csv(<span class=\"string\">'../dataset/train.csv'</span>)</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># head() 函数默认查看前 5 条数据</span></span><br><span class=\"line\">dt_train.head()</span><br></pre></td></tr></table></figure>\n<p><div></div></p>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>PassengerId</th>\n      <th>Survived</th>\n      <th>Pclass</th>\n      <th>Name</th>\n      <th>Sex</th>\n      <th>Age</th>\n      <th>SibSp</th>\n      <th>Parch</th>\n      <th>Ticket</th>\n      <th>Fare</th>\n      <th>Cabin</th>\n      <th>Embarked</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>0</td>\n      <td>3</td>\n      <td>Braund, Mr. Owen Harris</td>\n      <td>male</td>\n      <td>22.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>A/5 21171</td>\n      <td>7.2500</td>\n      <td>NaN</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>1</td>\n      <td>1</td>\n      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n      <td>female</td>\n      <td>38.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>PC 17599</td>\n      <td>71.2833</td>\n      <td>C85</td>\n      <td>C</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>1</td>\n      <td>3</td>\n      <td>Heikkinen, Miss. Laina</td>\n      <td>female</td>\n      <td>26.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>STON/O2. 3101282</td>\n      <td>7.9250</td>\n      <td>NaN</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>1</td>\n      <td>1</td>\n      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n      <td>female</td>\n      <td>35.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>113803</td>\n      <td>53.1000</td>\n      <td>C123</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>0</td>\n      <td>3</td>\n      <td>Allen, Mr. William Henry</td>\n      <td>male</td>\n      <td>35.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>373450</td>\n      <td>8.0500</td>\n      <td>NaN</td>\n      <td>S</td>\n    </tr>\n  </tbody>\n</table>\n\n\n\n\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># sample() 随机采样</span></span><br><span class=\"line\">train.sample(<span class=\"number\">5</span>)</span><br></pre></td></tr></table></figure>\n<div>\n\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>PassengerId</th>\n      <th>Survived</th>\n      <th>Pclass</th>\n      <th>Age</th>\n      <th>SibSp</th>\n      <th>Parch</th>\n      <th>Fare</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>127</th>\n      <td>128</td>\n      <td>1</td>\n      <td>3</td>\n      <td>24.00</td>\n      <td>0</td>\n      <td>0</td>\n      <td>7.1417</td>\n    </tr>\n    <tr>\n      <th>669</th>\n      <td>670</td>\n      <td>1</td>\n      <td>1</td>\n      <td>NaN</td>\n      <td>1</td>\n      <td>0</td>\n      <td>52.0000</td>\n    </tr>\n    <tr>\n      <th>229</th>\n      <td>230</td>\n      <td>0</td>\n      <td>3</td>\n      <td>NaN</td>\n      <td>3</td>\n      <td>1</td>\n      <td>25.4667</td>\n    </tr>\n    <tr>\n      <th>644</th>\n      <td>645</td>\n      <td>1</td>\n      <td>3</td>\n      <td>0.75</td>\n      <td>2</td>\n      <td>1</td>\n      <td>19.2583</td>\n    </tr>\n    <tr>\n      <th>337</th>\n      <td>338</td>\n      <td>1</td>\n      <td>1</td>\n      <td>41.00</td>\n      <td>0</td>\n      <td>0</td>\n      <td>134.5000</td>\n    </tr>\n  </tbody>\n</table>\n\n\n\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># info() 查看数据基本信息</span></span><br><span class=\"line\">dt_train.info()</span><br></pre></td></tr></table></figure>\n<pre><code>&lt;class &#39;pandas.core.frame.DataFrame&#39;&gt;\nRangeIndex: 891 entries, 0 to 890\nData columns (total 12 columns):\nPassengerId    891 non-null int64\nSurvived       891 non-null int64\nPclass         891 non-null int64\nName           891 non-null object\nSex            891 non-null object\nAge            714 non-null float64\nSibSp          891 non-null int64\nParch          891 non-null int64\nTicket         891 non-null object\nFare           891 non-null float64\nCabin          204 non-null object\nEmbarked       889 non-null object\ndtypes: float64(2), int64(5), object(5)\nmemory usage: 83.7+ KB\n</code></pre><p>可以看到总共有 12 columns(12个字段,通过 <code>dt_train.columns</code> 可以得到)。<br>info中也可以大致知道各个字段缺失情况：<code>Age</code>、<code>Fare</code>、<code>Cabin</code>、<code>Embarked</code>都是存在缺失值的。<br>除此外，各个字段的数据类型也一目了然。</p>\n<ul>\n<li>Survived: int</li>\n<li>Pclass: int</li>\n<li>Name: string</li>\n<li>Sex: string</li>\n<li>Age: float</li>\n<li>SibSp: int</li>\n<li>Parch: int</li>\n<li>Ticket: string</li>\n<li>Fare: float</li>\n<li>Cabin: string</li>\n<li>Embarked: string</li>\n</ul>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 获取字段名称</span></span><br><span class=\"line\">dt_train.columns</span><br></pre></td></tr></table></figure>\n<pre><code>Index([&#39;PassengerId&#39;, &#39;Survived&#39;, &#39;Pclass&#39;, &#39;Name&#39;, &#39;Sex&#39;, &#39;Age&#39;, &#39;SibSp&#39;,\n       &#39;Parch&#39;, &#39;Ticket&#39;, &#39;Fare&#39;, &#39;Cabin&#39;, &#39;Embarked&#39;],\n      dtype=&#39;object&#39;)\n</code></pre><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 查看数值类型字段的大致数据分布情况</span></span><br><span class=\"line\">dt_train.describe()</span><br></pre></td></tr></table></figure>\n<div>\n\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>PassengerId</th>\n      <th>Survived</th>\n      <th>Pclass</th>\n      <th>Age</th>\n      <th>SibSp</th>\n      <th>Parch</th>\n      <th>Fare</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>891.000000</td>\n      <td>891.000000</td>\n      <td>891.000000</td>\n      <td>714.000000</td>\n      <td>891.000000</td>\n      <td>891.000000</td>\n      <td>891.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>446.000000</td>\n      <td>0.383838</td>\n      <td>2.308642</td>\n      <td>29.699118</td>\n      <td>0.523008</td>\n      <td>0.381594</td>\n      <td>32.204208</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>257.353842</td>\n      <td>0.486592</td>\n      <td>0.836071</td>\n      <td>14.526497</td>\n      <td>1.102743</td>\n      <td>0.806057</td>\n      <td>49.693429</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>0.420000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>223.500000</td>\n      <td>0.000000</td>\n      <td>2.000000</td>\n      <td>20.125000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>7.910400</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>446.000000</td>\n      <td>0.000000</td>\n      <td>3.000000</td>\n      <td>28.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>14.454200</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>668.500000</td>\n      <td>1.000000</td>\n      <td>3.000000</td>\n      <td>38.000000</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>31.000000</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>891.000000</td>\n      <td>1.000000</td>\n      <td>3.000000</td>\n      <td>80.000000</td>\n      <td>8.000000</td>\n      <td>6.000000</td>\n      <td>512.329200</td>\n    </tr>\n  </tbody>\n</table>\n\n\n\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 查看缺失值分布: 主要年龄特征缺失严重</span></span><br><span class=\"line\">dt_train.isnull().sum()</span><br></pre></td></tr></table></figure>\n<pre><code>PassengerId      0\nSurvived         0\nPclass           0\nName             0\nSex              0\nAge            177\nSibSp            0\nParch            0\nTicket           0\nFare             0\nCabin          687\nEmbarked         2\ndtype: int64\n</code></pre><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 缺失百分比</span></span><br><span class=\"line\">pd.isnull(dt_train).sum()*<span class=\"number\">100</span>/dt_train.shape[<span class=\"number\">0</span>]</span><br></pre></td></tr></table></figure>\n<pre><code>PassengerId     0.000000\nSurvived        0.000000\nPclass          0.000000\nName            0.000000\nSex             0.000000\nAge            19.865320\nSibSp           0.000000\nParch           0.000000\nTicket          0.000000\nFare            0.000000\nCabin          77.104377\nEmbarked        0.224467\ndtype: float64\n</code></pre><p>PS：从数据出发，思考哪些因素或那类特征的人更容易从这场灾难中存活下来</p>\n<h3 id=\"数据可视化\"><a href=\"#数据可视化\" class=\"headerlink\" title=\"数据可视化\"></a>数据可视化</h3><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 绘制条形图观察 性别 特征</span></span><br><span class=\"line\">sns.barplot(x=<span class=\"string\">\"Sex\"</span>, y=<span class=\"string\">\"Survived\"</span>, data=dt_train)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">#print percentages of females vs. males that survive</span></span><br><span class=\"line\">print(</span><br><span class=\"line\">    <span class=\"string\">\"Percentage of females who survived:\"</span>,</span><br><span class=\"line\">    dt_train.Survived[dt_train.Sex == <span class=\"string\">'female'</span>].value_counts(normalize=<span class=\"literal\">True</span>)[<span class=\"number\">1</span>] *</span><br><span class=\"line\">    <span class=\"number\">100</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">print(</span><br><span class=\"line\">    <span class=\"string\">\"Percentage of males who survived:\"</span>,</span><br><span class=\"line\">    dt_train.Survived[dt_train.Sex == <span class=\"string\">'male'</span>].value_counts(normalize=<span class=\"literal\">True</span>)[<span class=\"number\">1</span>] * <span class=\"number\">100</span>)</span><br></pre></td></tr></table></figure>\n<pre><code>Percentage of females who survived: 74.20382165605095\nPercentage of males who survived: 18.890814558058924\n</code></pre><p><img src=\"/articles/Titanic/output_15_1.png\" alt=\"png\"></p>\n<p>从上面可以看到，女性比男性其实具有更高的生存机会。其他特征，可自行类比做图分析。</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 直方图</span></span><br><span class=\"line\"></span><br><span class=\"line\">cols = [<span class=\"string\">'Age'</span>, <span class=\"string\">'SibSp'</span>, <span class=\"string\">'Parch'</span>, <span class=\"string\">'Fare'</span>, <span class=\"string\">'Pclass'</span>]</span><br><span class=\"line\">dt_train[cols].hist(figsize = (<span class=\"number\">15</span>, <span class=\"number\">6</span>), color = <span class=\"string\">'steelblue'</span>, edgecolor = <span class=\"string\">'firebrick'</span>, linewidth = <span class=\"number\">1.5</span>, layout = (<span class=\"number\">2</span>, <span class=\"number\">3</span>));</span><br></pre></td></tr></table></figure>\n<p><img src=\"/articles/Titanic/output_17_0.png\" alt=\"png\"></p>\n<p>从年龄来看，大部分是40岁以下的年轻人；Fare中大部分在一百美元内；Parch与SibSp可以知道独自乘船的人较多；Pclass说明大部分人订的是3等舱。</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 年龄分布情况</span></span><br><span class=\"line\">men = dt_train[dt_train[<span class=\"string\">'Sex'</span>]  == <span class=\"string\">'male'</span>]</span><br><span class=\"line\">women = dt_train[dt_train[<span class=\"string\">'Sex'</span>]  == <span class=\"string\">'female'</span>]</span><br><span class=\"line\"></span><br><span class=\"line\">fig, (ax1, ax2, ax3) = plt.subplots(<span class=\"number\">1</span>, <span class=\"number\">3</span>, figsize = (<span class=\"number\">13</span>, <span class=\"number\">4</span>))</span><br><span class=\"line\"></span><br><span class=\"line\">sns.distplot(dt_train[dt_train[<span class=\"string\">'Survived'</span>] == <span class=\"number\">1</span>][<span class=\"string\">'Age'</span>].dropna(), bins = <span class=\"number\">20</span>, label = <span class=\"string\">'Survived'</span>, ax = ax1, kde = <span class=\"literal\">False</span>)</span><br><span class=\"line\">sns.distplot(dt_train[dt_train[<span class=\"string\">'Survived'</span>] == <span class=\"number\">0</span>][<span class=\"string\">'Age'</span>].dropna(), bins = <span class=\"number\">20</span>, label = <span class=\"string\">'Deceased'</span>, ax = ax1, kde = <span class=\"literal\">False</span>)</span><br><span class=\"line\">ax1.legend()</span><br><span class=\"line\">ax1.set_title(<span class=\"string\">'Age Distribution - All Passengers'</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">sns.distplot(women[women[<span class=\"string\">'Survived'</span>] == <span class=\"number\">1</span>][<span class=\"string\">'Age'</span>].dropna(), bins = <span class=\"number\">20</span>, label = <span class=\"string\">'Survived'</span>, ax = ax2, kde = <span class=\"literal\">False</span>)</span><br><span class=\"line\">sns.distplot(women[women[<span class=\"string\">'Survived'</span>] == <span class=\"number\">0</span>][<span class=\"string\">'Age'</span>].dropna(), bins = <span class=\"number\">20</span>, label = <span class=\"string\">'Deceased'</span>, ax = ax2, kde = <span class=\"literal\">False</span>)</span><br><span class=\"line\">ax2.legend()</span><br><span class=\"line\">ax2.set_title(<span class=\"string\">'Age Distribution - Women'</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">sns.distplot(men[men[<span class=\"string\">'Survived'</span>] == <span class=\"number\">1</span>][<span class=\"string\">'Age'</span>].dropna(), bins = <span class=\"number\">20</span>, label = <span class=\"string\">'Survived'</span>, ax = ax3, kde = <span class=\"literal\">False</span>)</span><br><span class=\"line\">sns.distplot(men[men[<span class=\"string\">'Survived'</span>] == <span class=\"number\">0</span>][<span class=\"string\">'Age'</span>].dropna(), bins = <span class=\"number\">20</span>, label = <span class=\"string\">'Deceased'</span>, ax = ax3, kde = <span class=\"literal\">False</span>)</span><br><span class=\"line\">ax3.legend()</span><br><span class=\"line\">ax3.set_title(<span class=\"string\">'Age Distribution - Men'</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">plt.tight_layout()</span><br></pre></td></tr></table></figure>\n<p><img src=\"/articles/Titanic/output_19_0.png\" alt=\"png\"></p>\n<p>这三幅图似乎表明：</p>\n<ul>\n<li>二三四十岁的人存活率要更高</li>\n<li>十岁以下的年龄段出现的峰值说明婴幼儿也更容易存活下来</li>\n</ul>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 相关性矩阵图</span></span><br><span class=\"line\">names = [<span class=\"string\">'Survived'</span>, <span class=\"string\">'Pclass'</span>, <span class=\"string\">'Sex'</span>, <span class=\"string\">'Age'</span>, <span class=\"string\">'SibSp'</span>, <span class=\"string\">'Parch'</span>, <span class=\"string\">'Fare'</span>]</span><br><span class=\"line\"></span><br><span class=\"line\">correlations = dt_train.corr()</span><br><span class=\"line\">correction = abs(correlations)          <span class=\"comment\"># 取绝对值，只看相关程度 ，不关心正相关还是负相关</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># plot correlation matrix</span></span><br><span class=\"line\">fig = plt.figure()</span><br><span class=\"line\">ax = fig.add_subplot(figsize=(<span class=\"number\">20</span>, <span class=\"number\">20</span>))  <span class=\"comment\">#图的大小为20*20</span></span><br><span class=\"line\"></span><br><span class=\"line\">ax = sns.heatmap(correction,</span><br><span class=\"line\">                 cmap=plt.cm.Greys,</span><br><span class=\"line\">                 linewidths=<span class=\"number\">0.05</span>,</span><br><span class=\"line\">                 vmax=<span class=\"number\">1</span>,</span><br><span class=\"line\">                 vmin=<span class=\"number\">0</span>,</span><br><span class=\"line\">                 annot=<span class=\"literal\">True</span>,</span><br><span class=\"line\">                 annot_kws=&#123;</span><br><span class=\"line\">                     <span class=\"string\">'size'</span>: <span class=\"number\">6</span>,</span><br><span class=\"line\">                     <span class=\"string\">'weight'</span>: <span class=\"string\">'bold'</span></span><br><span class=\"line\">                 &#125;)</span><br><span class=\"line\"><span class=\"comment\">#热力图参数设置（相关系数矩阵，颜色，每个值间隔等）</span></span><br><span class=\"line\">plt.xticks(np.arange(len(names)) + <span class=\"number\">0.5</span>, names)  <span class=\"comment\">#横坐标标注点</span></span><br><span class=\"line\">plt.yticks(np.arange(len(names)) + <span class=\"number\">0.5</span>, names)  <span class=\"comment\">#纵坐标标注点</span></span><br><span class=\"line\">ax.set_title(<span class=\"string\">'Characteristic correlation'</span>)      <span class=\"comment\">#标题设置</span></span><br></pre></td></tr></table></figure>\n<pre><code>Text(0.5,1,&#39;Characteristic correlation&#39;)\n</code></pre><p><img src=\"/articles/Titanic/output_17_1.png\" alt=\"png\"></p>\n<h4 id=\"tips\"><a href=\"#tips\" class=\"headerlink\" title=\"tips\"></a>tips</h4><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># value_counts():返回各个属性的数量</span></span><br><span class=\"line\"><span class=\"comment\"># 这里可以看到 男性 557人，女性 314人</span></span><br><span class=\"line\"><span class=\"comment\"># 参数 normalize=True 时，返回的是各自的比例</span></span><br><span class=\"line\">dt_train[<span class=\"string\">'Sex'</span>].value_counts()</span><br></pre></td></tr></table></figure>\n<pre><code>(male      577\n female    314\n Name: Sex, dtype: int64, &#39; &#39;, male      0.647587\n female    0.352413\n Name: Sex, dtype: float64)\n</code></pre><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">dt_train[<span class=\"string\">'Sex'</span>].value_counts(normalize=<span class=\"literal\">True</span>)</span><br></pre></td></tr></table></figure>\n<pre><code>male      0.647587\nfemale    0.352413\nName: Sex, dtype: float64\n</code></pre><h3 id=\"关于缺失值\"><a href=\"#关于缺失值\" class=\"headerlink\" title=\"关于缺失值\"></a>关于缺失值</h3><p>对于数据中的缺失值如何处理是需要我们结合问题具体分析的。有时会用均值或中位数等统计值来填充，有的也可以用模型进行预测，对于缺失不是很严重的我们甚至可以直接丢弃。</p>\n</div></div>","categories":[],"tags":["data analysis"]},{"title":"oneSimpleDL","url":"https://hahally.github.io//articles/oneSimpleDL/","content":"<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> tensorflow <span class=\"keyword\">as</span> tf</span><br><span class=\"line\"><span class=\"keyword\">from</span> tensorflow.keras <span class=\"keyword\">import</span> datasets, layers, models</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\"><span class=\"keyword\">import</span> matplotlib.pyplot <span class=\"keyword\">as</span> plt</span><br><span class=\"line\">%matplotlib inline</span><br></pre></td></tr></table></figure>\n<hr>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 数据加载</span></span><br><span class=\"line\">f = np.load(<span class=\"string\">'mnist.npz'</span>)</span><br><span class=\"line\">f.files</span><br></pre></td></tr></table></figure>\n<pre><code>[&#39;x_test&#39;, &#39;x_train&#39;, &#39;y_train&#39;, &#39;y_test&#39;]\n</code></pre><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 提取数据</span></span><br><span class=\"line\">data = &#123;&#125;</span><br><span class=\"line\"><span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> f.files:</span><br><span class=\"line\"></span><br><span class=\"line\">    data[i] = f[i]</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">data[<span class=\"string\">'x_test'</span>].shape,data[<span class=\"string\">'x_train'</span>].shape,data[<span class=\"string\">'y_train'</span>].shape,data[<span class=\"string\">'y_test'</span>].shape,</span><br></pre></td></tr></table></figure>\n<pre><code>((10000, 28, 28), (60000, 28, 28), (60000,), (10000,))\n</code></pre><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 可视化</span></span><br><span class=\"line\">plt.imshow(data[<span class=\"string\">'x_train'</span>][<span class=\"number\">0</span>]),data[<span class=\"string\">'y_train'</span>][<span class=\"number\">0</span>]</span><br></pre></td></tr></table></figure>\n<pre><code>(&lt;matplotlib.image.AxesImage at 0x1dcc0eb2860&gt;, 5)\n</code></pre><p><img src=\"/articles/oneSimpleDL/output_5_1.png\" alt=\"png\"></p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 训练集</span></span><br><span class=\"line\">x_train = data[<span class=\"string\">'x_train'</span>]/<span class=\"number\">255.0</span></span><br><span class=\"line\">y_train = data[<span class=\"string\">'y_train'</span>]</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 测试集</span></span><br><span class=\"line\">x_test = data[<span class=\"string\">'x_test'</span>]/<span class=\"number\">255.0</span></span><br><span class=\"line\">y_test = data[<span class=\"string\">'y_test'</span>]</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 增加一个维度变成 [b,h,w,c]</span></span><br><span class=\"line\">x_train = tf.expand_dims(x_train,axis=<span class=\"number\">3</span>)</span><br><span class=\"line\">x_test = tf.expand_dims(x_test,axis=<span class=\"number\">3</span>)</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 卷积网络 LeNet-5</span></span><br><span class=\"line\"></span><br><span class=\"line\">model = models.Sequential()</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 卷积层</span></span><br><span class=\"line\">model.add(layers.Conv2D(<span class=\"number\">6</span>,(<span class=\"number\">3</span>, <span class=\"number\">3</span>), input_shape=(<span class=\"number\">28</span>, <span class=\"number\">28</span>,<span class=\"number\">1</span>)))</span><br><span class=\"line\"><span class=\"comment\"># BN层</span></span><br><span class=\"line\">model.add(layers.BatchNormalization())</span><br><span class=\"line\"><span class=\"comment\"># 池化层</span></span><br><span class=\"line\">model.add(layers.MaxPooling2D((<span class=\"number\">2</span>, <span class=\"number\">2</span>),strides=<span class=\"number\">2</span>))</span><br><span class=\"line\">model.add(layers.ReLU())</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 卷积层</span></span><br><span class=\"line\">model.add(layers.Conv2D(<span class=\"number\">16</span>,(<span class=\"number\">3</span>, <span class=\"number\">3</span>)))</span><br><span class=\"line\"><span class=\"comment\"># BN层</span></span><br><span class=\"line\">model.add(layers.BatchNormalization())</span><br><span class=\"line\"><span class=\"comment\"># 池化层</span></span><br><span class=\"line\">model.add(layers.MaxPooling2D((<span class=\"number\">2</span>, <span class=\"number\">2</span>),strides=<span class=\"number\">2</span>))</span><br><span class=\"line\">model.add(layers.ReLU())</span><br><span class=\"line\"></span><br><span class=\"line\">model.add(layers.Flatten())</span><br><span class=\"line\">model.add(layers.Dense(<span class=\"number\">120</span>, activation=<span class=\"string\">'relu'</span>))</span><br><span class=\"line\">model.add(layers.Dense(<span class=\"number\">84</span>, activation=<span class=\"string\">'relu'</span>))</span><br><span class=\"line\">model.add(layers.Dense(<span class=\"number\">10</span>))</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">model.summary()</span><br></pre></td></tr></table></figure>\n<pre><code>Model: &quot;sequential_2&quot;\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nconv2d_2 (Conv2D)            (None, 26, 26, 6)         60        \n_________________________________________________________________\nbatch_normalization_2 (Batch (None, 26, 26, 6)         24        \n_________________________________________________________________\nmax_pooling2d_2 (MaxPooling2 (None, 13, 13, 6)         0         \n_________________________________________________________________\nre_lu_2 (ReLU)               (None, 13, 13, 6)         0         \n_________________________________________________________________\nconv2d_3 (Conv2D)            (None, 11, 11, 16)        880       \n_________________________________________________________________\nbatch_normalization_3 (Batch (None, 11, 11, 16)        64        \n_________________________________________________________________\nmax_pooling2d_3 (MaxPooling2 (None, 5, 5, 16)          0         \n_________________________________________________________________\nre_lu_3 (ReLU)               (None, 5, 5, 16)          0         \n_________________________________________________________________\nflatten_1 (Flatten)          (None, 400)               0         \n_________________________________________________________________\ndense_3 (Dense)              (None, 120)               48120     \n_________________________________________________________________\ndense_4 (Dense)              (None, 84)                10164     \n_________________________________________________________________\ndense_5 (Dense)              (None, 10)                850       \n=================================================================\nTotal params: 60,162\nTrainable params: 60,118\nNon-trainable params: 44\n_________________________________________________________________\n</code></pre><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 设置 from_logits=True 相当于在最后输出加了一个 softmax</span></span><br><span class=\"line\">model.compile(</span><br><span class=\"line\">    optimizer=<span class=\"string\">'adam'</span>,</span><br><span class=\"line\">    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=<span class=\"literal\">True</span>),</span><br><span class=\"line\">    metrics=[<span class=\"string\">'accuracy'</span>])</span><br><span class=\"line\"></span><br><span class=\"line\">history = model.fit(x_train,</span><br><span class=\"line\">                    y_train,</span><br><span class=\"line\">                    epochs=<span class=\"number\">10</span>,</span><br><span class=\"line\">                    batch_size=<span class=\"number\">200</span>,</span><br><span class=\"line\">                    validation_data=(x_test, y_test))</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">plt.plot(history.history[<span class=\"string\">'accuracy'</span>], label=<span class=\"string\">'accuracy'</span>)</span><br><span class=\"line\">plt.plot(history.history[<span class=\"string\">'val_accuracy'</span>], label = <span class=\"string\">'val_accuracy'</span>)</span><br><span class=\"line\">plt.xlabel(<span class=\"string\">'Epoch'</span>)</span><br><span class=\"line\">plt.ylabel(<span class=\"string\">'Accuracy'</span>)</span><br><span class=\"line\">plt.ylim([<span class=\"number\">0.5</span>, <span class=\"number\">1</span>])</span><br><span class=\"line\">plt.legend(loc=<span class=\"string\">'lower right'</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">test_loss, test_acc = model.evaluate(x_test,  y_test, verbose=<span class=\"number\">2</span>)</span><br></pre></td></tr></table></figure>\n<pre><code>10000/10000 - 2s - loss: 0.0346 - accuracy: 0.9896\n</code></pre><p><img src=\"/articles/oneSimpleDL/output_11_1.png\" alt=\"png\"></p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">test_loss, test_acc</span><br></pre></td></tr></table></figure>\n<pre><code>(0.034577180710506215, 0.9896)\n</code></pre><hr>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">unpickle</span><span class=\"params\">(file)</span>:</span></span><br><span class=\"line\">    <span class=\"keyword\">import</span> pickle</span><br><span class=\"line\">    <span class=\"keyword\">with</span> open(file, <span class=\"string\">'rb'</span>) <span class=\"keyword\">as</span> fo:</span><br><span class=\"line\">        dict = pickle.load(fo, encoding=<span class=\"string\">'bytes'</span>)</span><br><span class=\"line\">    <span class=\"keyword\">return</span> dict</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> os</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">path = <span class=\"string\">'./cifar-10-python/cifar-10-batches-py/'</span></span><br></pre></td></tr></table></figure>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">os.listdir(path)</span><br></pre></td></tr></table></figure>\n<pre><code>[&#39;batches.meta&#39;,\n &#39;data_batch_1&#39;,\n &#39;data_batch_2&#39;,\n &#39;data_batch_3&#39;,\n &#39;data_batch_4&#39;,\n &#39;data_batch_5&#39;,\n &#39;readme.html&#39;,\n &#39;test_batch&#39;]\n</code></pre><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">unpickle(<span class=\"string\">'./cifar-10-python/cifar-10-batches-py/batches.meta'</span>)</span><br></pre></td></tr></table></figure>\n<pre><code>{b&#39;label_names&#39;: [b&#39;airplane&#39;,\n  b&#39;automobile&#39;,\n  b&#39;bird&#39;,\n  b&#39;cat&#39;,\n  b&#39;deer&#39;,\n  b&#39;dog&#39;,\n  b&#39;frog&#39;,\n  b&#39;horse&#39;,\n  b&#39;ship&#39;,\n  b&#39;truck&#39;],\n b&#39;num_cases_per_batch&#39;: 10000,\n b&#39;num_vis&#39;: 3072}\n</code></pre><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">x_train = []</span><br><span class=\"line\">y_train = []</span><br><span class=\"line\"></span><br><span class=\"line\">x_test = []</span><br><span class=\"line\">y_test = []</span><br><span class=\"line\"><span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> os.listdir(path):</span><br><span class=\"line\">    <span class=\"keyword\">if</span> <span class=\"string\">'data'</span> <span class=\"keyword\">in</span> i:</span><br><span class=\"line\">        data_dict = unpickle(path + i)</span><br><span class=\"line\">        x_train.append(data_dict[<span class=\"string\">b'data'</span>].reshape(data_dict[<span class=\"string\">b'data'</span>].shape[<span class=\"number\">0</span>],</span><br><span class=\"line\">                                                  <span class=\"number\">3</span>, <span class=\"number\">32</span>,</span><br><span class=\"line\">                                                  <span class=\"number\">32</span>).transpose(<span class=\"number\">0</span>, <span class=\"number\">2</span>, <span class=\"number\">3</span>, <span class=\"number\">1</span>))</span><br><span class=\"line\">        y_train = y_train + data_dict[<span class=\"string\">b'labels'</span>]</span><br><span class=\"line\">    <span class=\"keyword\">if</span> <span class=\"string\">'test'</span> <span class=\"keyword\">in</span> i:</span><br><span class=\"line\">        test_dict = unpickle(path + i)</span><br><span class=\"line\">        x_test.append(test_dict[<span class=\"string\">b'data'</span>].reshape(test_dict[<span class=\"string\">b'data'</span>].shape[<span class=\"number\">0</span>],</span><br><span class=\"line\">                                                 <span class=\"number\">3</span>, <span class=\"number\">32</span>,</span><br><span class=\"line\">                                                 <span class=\"number\">32</span>).transpose(<span class=\"number\">0</span>, <span class=\"number\">2</span>, <span class=\"number\">3</span>, <span class=\"number\">1</span>))</span><br><span class=\"line\">        y_test = y_test + test_dict[<span class=\"string\">b'labels'</span>]</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">y_train = tf.constant(y_train)</span><br><span class=\"line\">y_test = tf.constant(y_test)</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">y_train.shape,y_test.shape</span><br></pre></td></tr></table></figure>\n<pre><code>(TensorShape([50000]), TensorShape([10000]))\n</code></pre><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">x_train = tf.concat(x_train,axis=<span class=\"number\">0</span>)</span><br><span class=\"line\">x_test = tf.concat(x_test,axis=<span class=\"number\">0</span>)</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">x_train.shape,x_test.shape</span><br></pre></td></tr></table></figure>\n<pre><code>(TensorShape([50000, 32, 32, 3]), TensorShape([10000, 32, 32, 3]))\n</code></pre><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># VGG16</span></span><br><span class=\"line\"></span><br><span class=\"line\">model = models.Sequential()</span><br><span class=\"line\"></span><br><span class=\"line\">model.add(</span><br><span class=\"line\">    layers.Conv2D(<span class=\"number\">64</span>, (<span class=\"number\">3</span>, <span class=\"number\">3</span>),</span><br><span class=\"line\">                  padding=<span class=\"string\">\"same\"</span>,</span><br><span class=\"line\">                  activation=<span class=\"string\">'relu'</span>,</span><br><span class=\"line\">                  input_shape=(<span class=\"number\">32</span>, <span class=\"number\">32</span>, <span class=\"number\">3</span>)))</span><br><span class=\"line\">model.add(layers.Conv2D(<span class=\"number\">64</span>, (<span class=\"number\">3</span>, <span class=\"number\">3</span>), padding=<span class=\"string\">\"same\"</span>, activation=<span class=\"string\">'relu'</span>))</span><br><span class=\"line\">model.add(layers.MaxPooling2D((<span class=\"number\">2</span>, <span class=\"number\">2</span>), strides=<span class=\"number\">2</span>))</span><br><span class=\"line\"></span><br><span class=\"line\">model.add(layers.Conv2D(<span class=\"number\">128</span>, (<span class=\"number\">3</span>, <span class=\"number\">3</span>), padding=<span class=\"string\">\"same\"</span>, activation=<span class=\"string\">'relu'</span>))</span><br><span class=\"line\">model.add(layers.Conv2D(<span class=\"number\">128</span>, (<span class=\"number\">3</span>, <span class=\"number\">3</span>), padding=<span class=\"string\">\"same\"</span>, activation=<span class=\"string\">'relu'</span>))</span><br><span class=\"line\">model.add(layers.MaxPooling2D((<span class=\"number\">2</span>, <span class=\"number\">2</span>), strides=<span class=\"number\">2</span>))</span><br><span class=\"line\"></span><br><span class=\"line\">model.add(layers.Conv2D(<span class=\"number\">256</span>, (<span class=\"number\">3</span>, <span class=\"number\">3</span>), padding=<span class=\"string\">\"same\"</span>, activation=<span class=\"string\">'relu'</span>))</span><br><span class=\"line\">model.add(layers.Conv2D(<span class=\"number\">256</span>, (<span class=\"number\">3</span>, <span class=\"number\">3</span>), padding=<span class=\"string\">\"same\"</span>, activation=<span class=\"string\">'relu'</span>))</span><br><span class=\"line\">model.add(layers.Conv2D(<span class=\"number\">256</span>, (<span class=\"number\">3</span>, <span class=\"number\">3</span>), padding=<span class=\"string\">\"same\"</span>, activation=<span class=\"string\">'relu'</span>))</span><br><span class=\"line\">model.add(layers.MaxPooling2D((<span class=\"number\">2</span>, <span class=\"number\">2</span>), strides=<span class=\"number\">2</span>))</span><br><span class=\"line\"></span><br><span class=\"line\">model.add(layers.Conv2D(<span class=\"number\">512</span>, (<span class=\"number\">3</span>, <span class=\"number\">3</span>), padding=<span class=\"string\">\"same\"</span>, activation=<span class=\"string\">'relu'</span>))</span><br><span class=\"line\">model.add(layers.Conv2D(<span class=\"number\">512</span>, (<span class=\"number\">3</span>, <span class=\"number\">3</span>), padding=<span class=\"string\">\"same\"</span>, activation=<span class=\"string\">'relu'</span>))</span><br><span class=\"line\">model.add(layers.Conv2D(<span class=\"number\">512</span>, (<span class=\"number\">3</span>, <span class=\"number\">3</span>), padding=<span class=\"string\">\"same\"</span>, activation=<span class=\"string\">'relu'</span>))</span><br><span class=\"line\">model.add(layers.MaxPooling2D((<span class=\"number\">2</span>, <span class=\"number\">2</span>), strides=<span class=\"number\">2</span>))</span><br><span class=\"line\"></span><br><span class=\"line\">model.add(layers.Conv2D(<span class=\"number\">512</span>, (<span class=\"number\">3</span>, <span class=\"number\">3</span>), padding=<span class=\"string\">\"same\"</span>, activation=<span class=\"string\">'relu'</span>))</span><br><span class=\"line\">model.add(layers.Conv2D(<span class=\"number\">512</span>, (<span class=\"number\">3</span>, <span class=\"number\">3</span>), padding=<span class=\"string\">\"same\"</span>, activation=<span class=\"string\">'relu'</span>))</span><br><span class=\"line\">model.add(layers.Conv2D(<span class=\"number\">512</span>, (<span class=\"number\">3</span>, <span class=\"number\">3</span>), padding=<span class=\"string\">\"same\"</span>, activation=<span class=\"string\">'relu'</span>))</span><br><span class=\"line\">model.add(layers.MaxPooling2D((<span class=\"number\">2</span>, <span class=\"number\">2</span>), strides=<span class=\"number\">2</span>))</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># model.add(layers.Flatten())</span></span><br><span class=\"line\">model.add(layers.Dense(<span class=\"number\">256</span>, activation=<span class=\"string\">'relu'</span>))</span><br><span class=\"line\">model.add(layers.Dense(<span class=\"number\">64</span>, activation=<span class=\"string\">'relu'</span>))</span><br><span class=\"line\">model.add(layers.Dense(<span class=\"number\">10</span>))</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">model.summary()</span><br></pre></td></tr></table></figure>\n<pre><code>Model: &quot;sequential&quot;\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nconv2d (Conv2D)              (None, 32, 32, 64)        1792      \n_________________________________________________________________\nconv2d_1 (Conv2D)            (None, 32, 32, 64)        36928     \n_________________________________________________________________\nmax_pooling2d (MaxPooling2D) (None, 16, 16, 64)        0         \n_________________________________________________________________\nconv2d_2 (Conv2D)            (None, 16, 16, 128)       73856     \n_________________________________________________________________\nconv2d_3 (Conv2D)            (None, 16, 16, 128)       147584    \n_________________________________________________________________\nmax_pooling2d_1 (MaxPooling2 (None, 8, 8, 128)         0         \n_________________________________________________________________\nconv2d_4 (Conv2D)            (None, 8, 8, 256)         295168    \n_________________________________________________________________\nconv2d_5 (Conv2D)            (None, 8, 8, 256)         590080    \n_________________________________________________________________\nconv2d_6 (Conv2D)            (None, 8, 8, 256)         590080    \n_________________________________________________________________\nmax_pooling2d_2 (MaxPooling2 (None, 4, 4, 256)         0         \n_________________________________________________________________\nconv2d_7 (Conv2D)            (None, 4, 4, 512)         1180160   \n_________________________________________________________________\nconv2d_8 (Conv2D)            (None, 4, 4, 512)         2359808   \n_________________________________________________________________\nconv2d_9 (Conv2D)            (None, 4, 4, 512)         2359808   \n_________________________________________________________________\nmax_pooling2d_3 (MaxPooling2 (None, 2, 2, 512)         0         \n_________________________________________________________________\nconv2d_10 (Conv2D)           (None, 2, 2, 512)         2359808   \n_________________________________________________________________\nconv2d_11 (Conv2D)           (None, 2, 2, 512)         2359808   \n_________________________________________________________________\nconv2d_12 (Conv2D)           (None, 2, 2, 512)         2359808   \n_________________________________________________________________\nmax_pooling2d_4 (MaxPooling2 (None, 1, 1, 512)         0         \n_________________________________________________________________\ndense (Dense)                (None, 1, 1, 256)         131328    \n_________________________________________________________________\ndense_1 (Dense)              (None, 1, 1, 64)          16448     \n_________________________________________________________________\ndense_2 (Dense)              (None, 1, 1, 10)          650       \n=================================================================\nTotal params: 14,863,114\nTrainable params: 14,863,114\nNon-trainable params: 0\n_________________________________________________________________\n</code></pre><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">model.compile(</span><br><span class=\"line\">    optimizer=<span class=\"string\">'adam'</span>,</span><br><span class=\"line\">    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=<span class=\"literal\">True</span>),</span><br><span class=\"line\">    metrics=[<span class=\"string\">'accuracy'</span>])</span><br><span class=\"line\"></span><br><span class=\"line\">history = model.fit(</span><br><span class=\"line\">    x_train,</span><br><span class=\"line\">    y_train,</span><br><span class=\"line\">    epochs=<span class=\"number\">10</span>,</span><br><span class=\"line\">    batch_size=<span class=\"number\">1</span>,</span><br><span class=\"line\">    shuffle=<span class=\"literal\">True</span>,</span><br><span class=\"line\">    validation_data=(x_test, y_test) </span><br><span class=\"line\">)</span><br></pre></td></tr></table></figure>\n","categories":[],"tags":["DeepLearning"]},{"title":"Task5","url":"https://hahally.github.io//articles/Task5/","content":"<h2 id=\"任务说明\"><a href=\"#任务说明\" class=\"headerlink\" title=\"任务说明\"></a>任务说明</h2><ul>\n<li>学习主题：作者关联（数据建模任务），对论文作者关系进行建模，统计最常出现的作者关系；</li>\n<li>学习内容：构建作者关系图，挖掘作者关系</li>\n<li>学习成果：论文作者知识图谱、图关系挖掘</li>\n</ul>\n<h2 id=\"数据处理步骤\"><a href=\"#数据处理步骤\" class=\"headerlink\" title=\"数据处理步骤\"></a>数据处理步骤</h2><p>将作者列表进行处理，并完成统计。具体步骤如下：</p>\n<ul>\n<li>将论文第一作者与其他作者（论文非第一作者）构建图；</li>\n<li>使用图算法统计图中作者与其他作者的联系；</li>\n</ul>\n<h2 id=\"社交网络分析\"><a href=\"#社交网络分析\" class=\"headerlink\" title=\"社交网络分析\"></a>社交网络分析</h2><p>图是复杂网络研究中的一个重要概念。Graph是用<strong>点</strong>和<strong>线</strong>来刻画离散事物集合中的每对事物间以某种方式相联系的数学模型。Graph在现实世界中随处可见，如交通运输图、旅游图、流程图等。利用图可以描述现实生活中的许多事物，如用点可以表示交叉口，点之间的连线表示路径，这样就可以轻而易举的描绘出一个交通运输网络。</p>\n<h3 id=\"图类型\"><a href=\"#图类型\" class=\"headerlink\" title=\"图类型\"></a>图类型</h3><ul>\n<li><p>无向图，忽略了两节点间边的方向。</p>\n</li>\n<li><p>指有向图，考虑了边的有向性。</p>\n</li>\n<li><p>多重无向图，即两个结点之间的边数多于一条，又允许顶点通过同一条边和自己关联。</p>\n</li>\n</ul>\n<h3 id=\"图统计指标\"><a href=\"#图统计指标\" class=\"headerlink\" title=\"图统计指标\"></a>图统计指标</h3><ul>\n<li><p>度：是指和该节点相关联的边的条数，又称关联度。对于有向图，节点的入度 是指进入该节点的边的条数；节点的出度是指从该节点出发的边的条数；</p>\n</li>\n<li><p>迪杰斯特拉路径：.从一个源点到其它各点的最短路径，可使用迪杰斯特拉算法来求最短路径；</p>\n</li>\n<li><p>连通图：在一个无向图 G 中，若从顶点i到顶点j有路径相连，则称i和j是连通的。如果 G 是有向图，那么连接i和j的路径中所有的边都必须同向。如果图中任意两点都是连通的，那么图被称作连通图。如果此图是有向图，则称为强连通图。</p>\n</li>\n</ul>\n<p>对于其他图算法，可以在networkx和igraph两个库中找到。</p>\n<h2 id=\"具体代码以及讲解\"><a href=\"#具体代码以及讲解\" class=\"headerlink\" title=\"具体代码以及讲解\"></a>具体代码以及讲解</h2><p>首先读取我们想要的数据：</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 导入所需的package</span></span><br><span class=\"line\"><span class=\"keyword\">import</span> seaborn <span class=\"keyword\">as</span> sns <span class=\"comment\">#用于画图</span></span><br><span class=\"line\"><span class=\"keyword\">from</span> bs4 <span class=\"keyword\">import</span> BeautifulSoup <span class=\"comment\">#用于爬取arxiv的数据</span></span><br><span class=\"line\"><span class=\"keyword\">import</span> re <span class=\"comment\">#用于正则表达式，匹配字符串的模式</span></span><br><span class=\"line\"><span class=\"keyword\">import</span> requests <span class=\"comment\">#用于网络连接，发送网络请求，使用域名获取对应信息</span></span><br><span class=\"line\"><span class=\"keyword\">import</span> json <span class=\"comment\">#读取数据，我们的数据为json格式的</span></span><br><span class=\"line\"><span class=\"keyword\">import</span> pandas <span class=\"keyword\">as</span> pd <span class=\"comment\">#数据处理，数据分析</span></span><br><span class=\"line\"><span class=\"keyword\">import</span> matplotlib.pyplot <span class=\"keyword\">as</span> plt <span class=\"comment\">#画图工具</span></span><br></pre></td></tr></table></figure>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">readArxivFile</span><span class=\"params\">(path, columns=[<span class=\"string\">'id'</span>, <span class=\"string\">'submitter'</span>, <span class=\"string\">'authors'</span>, <span class=\"string\">'title'</span>, <span class=\"string\">'comments'</span>, <span class=\"string\">'journal-ref'</span>, <span class=\"string\">'doi'</span>,</span></span></span><br><span class=\"line\"><span class=\"function\"><span class=\"params\">       <span class=\"string\">'report-no'</span>, <span class=\"string\">'categories'</span>, <span class=\"string\">'license'</span>, <span class=\"string\">'abstract'</span>, <span class=\"string\">'versions'</span>,</span></span></span><br><span class=\"line\"><span class=\"function\"><span class=\"params\">       <span class=\"string\">'update_date'</span>, <span class=\"string\">'authors_parsed'</span>], count=None)</span>:</span></span><br><span class=\"line\">    <span class=\"string\">'''</span></span><br><span class=\"line\"><span class=\"string\">    定义读取文件的函数</span></span><br><span class=\"line\"><span class=\"string\">        path: 文件路径</span></span><br><span class=\"line\"><span class=\"string\">        columns: 需要选择的列</span></span><br><span class=\"line\"><span class=\"string\">        count: 读取行数</span></span><br><span class=\"line\"><span class=\"string\">    '''</span></span><br><span class=\"line\">    </span><br><span class=\"line\">    data  = []</span><br><span class=\"line\">    <span class=\"keyword\">with</span> open(path, <span class=\"string\">'r'</span>) <span class=\"keyword\">as</span> f: </span><br><span class=\"line\">        <span class=\"keyword\">for</span> idx, line <span class=\"keyword\">in</span> enumerate(f): </span><br><span class=\"line\">            <span class=\"keyword\">if</span> idx == count:</span><br><span class=\"line\">                <span class=\"keyword\">break</span></span><br><span class=\"line\">                </span><br><span class=\"line\">            d = json.loads(line)</span><br><span class=\"line\">            d = &#123;col : d[col] <span class=\"keyword\">for</span> col <span class=\"keyword\">in</span> columns&#125;</span><br><span class=\"line\">            data.append(d)</span><br><span class=\"line\"></span><br><span class=\"line\">    data = pd.DataFrame(data)</span><br><span class=\"line\">    <span class=\"keyword\">return</span> data</span><br><span class=\"line\"></span><br><span class=\"line\">data = readArxivFile(<span class=\"string\">'arxiv-metadata-oai-snapshot.json'</span>, </span><br><span class=\"line\">                     [<span class=\"string\">'id'</span>, <span class=\"string\">'authors_parsed'</span>],</span><br><span class=\"line\">                    <span class=\"number\">200000</span>)</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">data.head()</span><br></pre></td></tr></table></figure>\n<p><div></div></p>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>authors_parsed</th>\n      <th>id</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>[[Balázs, C., ], [Berger, E. L., ], [Nadolsky,...</td>\n      <td>0704.0001</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>[[Streinu, Ileana, ], [Theran, Louis, ]]</td>\n      <td>0704.0002</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>[[Pan, Hongjun, ]]</td>\n      <td>0704.0003</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>[[Callan, David, ]]</td>\n      <td>0704.0004</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>[[Abu-Shammala, Wael, ], [Torchinsky, Alberto, ]]</td>\n      <td>0704.0005</td>\n    </tr>\n  </tbody>\n</table>\n\n\n\n<p>创建作者链接的无向图：</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> networkx <span class=\"keyword\">as</span> nx </span><br><span class=\"line\"><span class=\"comment\"># 创建无向图</span></span><br><span class=\"line\">G = nx.Graph()</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 只用五篇论文进行构建</span></span><br><span class=\"line\"><span class=\"keyword\">for</span> row <span class=\"keyword\">in</span> data.iloc[:<span class=\"number\">5</span>].itertuples():</span><br><span class=\"line\">    authors = row[<span class=\"number\">1</span>]</span><br><span class=\"line\">    authors = [<span class=\"string\">' '</span>.join(x[:<span class=\"number\">-1</span>]) <span class=\"keyword\">for</span> x <span class=\"keyword\">in</span> authors]</span><br><span class=\"line\">    </span><br><span class=\"line\">    <span class=\"comment\"># 第一个作者 与 其他作者链接</span></span><br><span class=\"line\">    <span class=\"keyword\">for</span> author <span class=\"keyword\">in</span> authors[<span class=\"number\">1</span>:]:</span><br><span class=\"line\">        G.add_edge(authors[<span class=\"number\">0</span>],author) <span class=\"comment\">#　添加节点２，３并链接２３节点</span></span><br></pre></td></tr></table></figure>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 将作者关系图进行绘制：</span></span><br><span class=\"line\">nx.draw(G, with_labels=<span class=\"literal\">True</span>)</span><br></pre></td></tr></table></figure>\n<p><img src=\"/articles/Task5/output_6_0.png\" alt=\"png\"></p>\n<p>如果我们500片论文构建图，则可以得到更加完整作者关系，并选择最大联通子图进行绘制，折线图为子图节点度值。</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">for</span> row <span class=\"keyword\">in</span> data.iloc[:<span class=\"number\">500</span>].itertuples():</span><br><span class=\"line\">    authors = row[<span class=\"number\">1</span>]</span><br><span class=\"line\">    authors = [<span class=\"string\">' '</span>.join(x[:<span class=\"number\">-1</span>]) <span class=\"keyword\">for</span> x <span class=\"keyword\">in</span> authors]</span><br><span class=\"line\">    </span><br><span class=\"line\">    <span class=\"comment\"># 第一个作者 与 其他作者链接</span></span><br><span class=\"line\">    <span class=\"keyword\">for</span> author <span class=\"keyword\">in</span> authors[<span class=\"number\">1</span>:]:</span><br><span class=\"line\">        G.add_edge(authors[<span class=\"number\">0</span>],author) <span class=\"comment\">#　添加节点２，３并链接２３节点</span></span><br></pre></td></tr></table></figure>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">degree_sequence = sorted([d <span class=\"keyword\">for</span> n, d <span class=\"keyword\">in</span> G.degree()], reverse=<span class=\"literal\">True</span>)</span><br><span class=\"line\">dmax = max(degree_sequence)</span><br><span class=\"line\"></span><br><span class=\"line\">plt.loglog(degree_sequence, <span class=\"string\">\"b-\"</span>, marker=<span class=\"string\">\"o\"</span>)</span><br><span class=\"line\">plt.title(<span class=\"string\">\"Degree rank plot\"</span>)</span><br><span class=\"line\">plt.ylabel(<span class=\"string\">\"degree\"</span>)</span><br><span class=\"line\">plt.xlabel(<span class=\"string\">\"rank\"</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># draw graph in inset</span></span><br><span class=\"line\">plt.axes([<span class=\"number\">0.45</span>, <span class=\"number\">0.45</span>, <span class=\"number\">0.45</span>, <span class=\"number\">0.45</span>])</span><br><span class=\"line\">Gcc = G.subgraph(sorted(nx.connected_components(G), key=len, reverse=<span class=\"literal\">True</span>)[<span class=\"number\">0</span>])</span><br><span class=\"line\"></span><br><span class=\"line\">pos = nx.spring_layout(Gcc)</span><br><span class=\"line\">plt.axis(<span class=\"string\">\"off\"</span>)</span><br><span class=\"line\">nx.draw_networkx_nodes(Gcc, pos, node_size=<span class=\"number\">20</span>)</span><br><span class=\"line\">nx.draw_networkx_edges(Gcc, pos, alpha=<span class=\"number\">0.4</span>)</span><br><span class=\"line\">plt.show()</span><br></pre></td></tr></table></figure>\n<p><img src=\"/articles/Task5/output_9_0.png\" alt=\"png\"></p>\n","categories":[],"tags":["data analysis"]},{"title":"Task4","url":"https://hahally.github.io//articles/Task4/","content":"<h2 id=\"任务说明\"><a href=\"#任务说明\" class=\"headerlink\" title=\"任务说明\"></a>任务说明</h2><ul>\n<li>学习主题：论文分类（数据建模任务），利用已有数据建模，对新论文进行类别分类；</li>\n<li>学习内容：使用论文标题完成类别分类；</li>\n<li>学习成果：学会文本分类的基本方法、<code>TF-IDF</code>等；</li>\n</ul>\n<h2 id=\"数据处理步骤\"><a href=\"#数据处理步骤\" class=\"headerlink\" title=\"数据处理步骤\"></a>数据处理步骤</h2><p>在原始arxiv论文中论文都有对应的类别，而论文类别是作者填写的。在本次任务中我们可以借助论文的标题和摘要完成：</p>\n<ul>\n<li>对论文标题和摘要进行处理；</li>\n<li>对论文类别进行处理；</li>\n<li>构建文本分类模型；</li>\n</ul>\n<h2 id=\"文本分类思路\"><a href=\"#文本分类思路\" class=\"headerlink\" title=\"文本分类思路\"></a>文本分类思路</h2><ul>\n<li>思路1：TF-IDF+机器学习分类器</li>\n</ul>\n<p>直接使用TF-IDF对文本提取特征，使用分类器进行分类，分类器的选择上可以使用SVM、LR、XGboost等</p>\n<ul>\n<li>思路2：FastText</li>\n</ul>\n<p>FastText是入门款的词向量，利用Facebook提供的FastText工具，可以快速构建分类器</p>\n<ul>\n<li>思路3：WordVec+深度学习分类器</li>\n</ul>\n<p>WordVec是进阶款的词向量，并通过构建深度学习分类完成分类。深度学习分类的网络结构可以选择TextCNN、TextRnn或者BiLSTM。</p>\n<ul>\n<li>思路4：Bert词向量</li>\n</ul>\n<p>Bert是高配款的词向量，具有强大的建模学习能力。</p>\n<h2 id=\"具体代码实现以及讲解\"><a href=\"#具体代码实现以及讲解\" class=\"headerlink\" title=\"具体代码实现以及讲解\"></a>具体代码实现以及讲解</h2><p>为了方便大家入门文本分类，我们选择思路1和思路2给大家讲解。首先完成字段读取：</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 导入所需的package</span></span><br><span class=\"line\"><span class=\"keyword\">import</span> seaborn <span class=\"keyword\">as</span> sns <span class=\"comment\">#用于画图</span></span><br><span class=\"line\"><span class=\"keyword\">from</span> bs4 <span class=\"keyword\">import</span> BeautifulSoup <span class=\"comment\">#用于爬取arxiv的数据</span></span><br><span class=\"line\"><span class=\"keyword\">import</span> re <span class=\"comment\">#用于正则表达式，匹配字符串的模式</span></span><br><span class=\"line\"><span class=\"keyword\">import</span> requests <span class=\"comment\">#用于网络连接，发送网络请求，使用域名获取对应信息</span></span><br><span class=\"line\"><span class=\"keyword\">import</span> json <span class=\"comment\">#读取数据，我们的数据为json格式的</span></span><br><span class=\"line\"><span class=\"keyword\">import</span> pandas <span class=\"keyword\">as</span> pd <span class=\"comment\">#数据处理，数据分析</span></span><br><span class=\"line\"><span class=\"keyword\">import</span> matplotlib.pyplot <span class=\"keyword\">as</span> plt <span class=\"comment\">#画图工具</span></span><br></pre></td></tr></table></figure>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">readArxivFile</span><span class=\"params\">(path, columns=[<span class=\"string\">'id'</span>, <span class=\"string\">'submitter'</span>, <span class=\"string\">'authors'</span>, <span class=\"string\">'title'</span>, <span class=\"string\">'comments'</span>, <span class=\"string\">'journal-ref'</span>, <span class=\"string\">'doi'</span>,</span></span></span><br><span class=\"line\"><span class=\"function\"><span class=\"params\">       <span class=\"string\">'report-no'</span>, <span class=\"string\">'categories'</span>, <span class=\"string\">'license'</span>, <span class=\"string\">'abstract'</span>, <span class=\"string\">'versions'</span>,</span></span></span><br><span class=\"line\"><span class=\"function\"><span class=\"params\">       <span class=\"string\">'update_date'</span>, <span class=\"string\">'authors_parsed'</span>], count=None)</span>:</span></span><br><span class=\"line\">    <span class=\"string\">'''</span></span><br><span class=\"line\"><span class=\"string\">    定义读取文件的函数</span></span><br><span class=\"line\"><span class=\"string\">        path: 文件路径</span></span><br><span class=\"line\"><span class=\"string\">        columns: 需要选择的列</span></span><br><span class=\"line\"><span class=\"string\">        count: 读取行数</span></span><br><span class=\"line\"><span class=\"string\">    '''</span></span><br><span class=\"line\">    </span><br><span class=\"line\">    data  = []</span><br><span class=\"line\">    <span class=\"keyword\">with</span> open(path, <span class=\"string\">'r'</span>) <span class=\"keyword\">as</span> f: </span><br><span class=\"line\">        <span class=\"keyword\">for</span> idx, line <span class=\"keyword\">in</span> enumerate(f): </span><br><span class=\"line\">            <span class=\"keyword\">if</span> idx == count:</span><br><span class=\"line\">                <span class=\"keyword\">break</span></span><br><span class=\"line\">                </span><br><span class=\"line\">            d = json.loads(line)</span><br><span class=\"line\">            d = &#123;col : d[col] <span class=\"keyword\">for</span> col <span class=\"keyword\">in</span> columns&#125;</span><br><span class=\"line\">            data.append(d)</span><br><span class=\"line\"></span><br><span class=\"line\">    data = pd.DataFrame(data)</span><br><span class=\"line\">    <span class=\"keyword\">return</span> data</span><br><span class=\"line\"></span><br><span class=\"line\">data = readArxivFile(<span class=\"string\">'arxiv-metadata-oai-snapshot.json'</span>, </span><br><span class=\"line\">                     [<span class=\"string\">'id'</span>, <span class=\"string\">'title'</span>, <span class=\"string\">'categories'</span>, <span class=\"string\">'abstract'</span>],</span><br><span class=\"line\">                    <span class=\"number\">200000</span>)</span><br></pre></td></tr></table></figure>\n<p>为了方便数据的处理，我们可以将标题和摘要拼接一起完成分类。</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">data[<span class=\"string\">'text'</span>] = data[<span class=\"string\">'title'</span>] + data[<span class=\"string\">'abstract'</span>]</span><br><span class=\"line\"></span><br><span class=\"line\">data[<span class=\"string\">'text'</span>] = data[<span class=\"string\">'text'</span>].apply(<span class=\"keyword\">lambda</span> x: x.replace(<span class=\"string\">'\\n'</span>,<span class=\"string\">' '</span>))</span><br><span class=\"line\">data[<span class=\"string\">'text'</span>] = data[<span class=\"string\">'text'</span>].apply(<span class=\"keyword\">lambda</span> x: x.lower())</span><br><span class=\"line\">data = data.drop([<span class=\"string\">'abstract'</span>, <span class=\"string\">'title'</span>], axis=<span class=\"number\">1</span>)</span><br></pre></td></tr></table></figure>\n<p>由于原始论文有可能有多个类别，所以也需要处理：</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 多个类别，包含子分类</span></span><br><span class=\"line\">data[<span class=\"string\">'categories'</span>] = data[<span class=\"string\">'categories'</span>].apply(<span class=\"keyword\">lambda</span> x : x.split(<span class=\"string\">' '</span>))</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 单个类别，不包含子分类</span></span><br><span class=\"line\">data[<span class=\"string\">'categories_big'</span>] = data[<span class=\"string\">'categories'</span>].apply(<span class=\"keyword\">lambda</span> x : [xx.split(<span class=\"string\">'.'</span>)[<span class=\"number\">0</span>] <span class=\"keyword\">for</span> xx <span class=\"keyword\">in</span> x])</span><br></pre></td></tr></table></figure>\n<p>然后将类别进行编码，这里类别是多个，所以需要多编码：</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">from</span> sklearn.preprocessing <span class=\"keyword\">import</span> MultiLabelBinarizer</span><br><span class=\"line\">mlb = MultiLabelBinarizer()</span><br><span class=\"line\">data_label = mlb.fit_transform(data[<span class=\"string\">'categories_big'</span>].iloc[:])</span><br></pre></td></tr></table></figure>\n<h3 id=\"思路1\"><a href=\"#思路1\" class=\"headerlink\" title=\"思路1\"></a>思路1</h3><p>思路1使用TFIDF提取特征，限制最多4000个单词：</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">from</span> sklearn.feature_extraction.text <span class=\"keyword\">import</span> TfidfVectorizer</span><br><span class=\"line\">vectorizer = TfidfVectorizer(max_features=<span class=\"number\">4000</span>)</span><br><span class=\"line\">data_tfidf = vectorizer.fit_transform(data[<span class=\"string\">'text'</span>].iloc[:])</span><br></pre></td></tr></table></figure>\n<p>由于这里是多标签分类，可以使用sklearn的多标签分类进行封装：</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 划分训练集和验证集</span></span><br><span class=\"line\"><span class=\"keyword\">from</span> sklearn.model_selection <span class=\"keyword\">import</span> train_test_split</span><br><span class=\"line\">x_train, x_test, y_train, y_test = train_test_split(data_tfidf, data_label,</span><br><span class=\"line\">                                                 test_size = <span class=\"number\">0.2</span>,random_state = <span class=\"number\">1</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 构建多标签分类模型</span></span><br><span class=\"line\"><span class=\"keyword\">from</span> sklearn.multioutput <span class=\"keyword\">import</span> MultiOutputClassifier</span><br><span class=\"line\"><span class=\"keyword\">from</span> sklearn.naive_bayes <span class=\"keyword\">import</span> MultinomialNB</span><br><span class=\"line\">clf = MultiOutputClassifier(MultinomialNB()).fit(x_train, y_train)</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">from</span> sklearn.metrics <span class=\"keyword\">import</span> classification_report</span><br><span class=\"line\">print(classification_report(y_test, clf.predict(x_test)))</span><br></pre></td></tr></table></figure>\n<pre><code>              precision    recall  f1-score   support\n\n           0       0.95      0.85      0.89      7925\n           1       0.85      0.79      0.82      7339\n           2       0.77      0.72      0.74      2944\n           3       0.00      0.00      0.00         4\n           4       0.72      0.48      0.58      2123\n           5       0.51      0.66      0.58       987\n           6       0.86      0.38      0.52       544\n           7       0.71      0.69      0.70      3649\n           8       0.76      0.61      0.68      3388\n           9       0.85      0.88      0.87     10745\n          10       0.46      0.13      0.20      1757\n          11       0.79      0.04      0.07       729\n          12       0.45      0.35      0.39       507\n          13       0.54      0.36      0.43      1083\n          14       0.69      0.14      0.24      3441\n          15       0.84      0.20      0.33       655\n          16       0.93      0.16      0.27       268\n          17       0.87      0.43      0.58      2484\n          18       0.82      0.38      0.52       692\n\n   micro avg       0.81      0.65      0.72     51264\n   macro avg       0.70      0.43      0.50     51264\nweighted avg       0.80      0.65      0.69     51264\n samples avg       0.72      0.72      0.70     51264\n</code></pre><p>​    </p>\n<pre><code>d:\\program files\\python\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\nd:\\program files\\python\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\nd:\\program files\\python\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\nd:\\program files\\python\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n</code></pre><h3 id=\"思路2\"><a href=\"#思路2\" class=\"headerlink\" title=\"思路2\"></a>思路2</h3><p>思路2使用深度学习模型，单词进行词嵌入然后训练。将数据集处理进行编码，并进行截断：</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">from</span> sklearn.model_selection <span class=\"keyword\">import</span> train_test_split</span><br><span class=\"line\">x_train, x_test, y_train, y_test = train_test_split(data[<span class=\"string\">'text'</span>].iloc[:<span class=\"number\">100000</span>],</span><br><span class=\"line\">                                                    data_label[:<span class=\"number\">100000</span>],</span><br><span class=\"line\">                                                    test_size=<span class=\"number\">0.95</span>,</span><br><span class=\"line\">                                                    random_state=<span class=\"number\">1</span>)</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># parameter</span></span><br><span class=\"line\">max_features= <span class=\"number\">500</span></span><br><span class=\"line\">max_len= <span class=\"number\">150</span></span><br><span class=\"line\">embed_size=<span class=\"number\">100</span></span><br><span class=\"line\">batch_size = <span class=\"number\">128</span></span><br><span class=\"line\">epochs = <span class=\"number\">5</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">from</span> keras.preprocessing.text <span class=\"keyword\">import</span> Tokenizer</span><br><span class=\"line\"><span class=\"keyword\">from</span> keras.preprocessing <span class=\"keyword\">import</span> sequence</span><br><span class=\"line\"></span><br><span class=\"line\">tokens = Tokenizer(num_words = max_features)</span><br><span class=\"line\">tokens.fit_on_texts(list(data[<span class=\"string\">'text'</span>].iloc[:<span class=\"number\">100000</span>]))</span><br><span class=\"line\"></span><br><span class=\"line\">y_train = data_label[:<span class=\"number\">100000</span>]</span><br><span class=\"line\">x_sub_train = tokens.texts_to_sequences(data[<span class=\"string\">'text'</span>].iloc[:<span class=\"number\">100000</span>])</span><br><span class=\"line\">x_sub_train = sequence.pad_sequences(x_sub_train, maxlen=max_len)</span><br></pre></td></tr></table></figure>\n<pre><code>Using TensorFlow backend.\n</code></pre><p>定义模型并完成训练：</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># LSTM model</span></span><br><span class=\"line\"><span class=\"comment\"># Keras Layers:</span></span><br><span class=\"line\"><span class=\"keyword\">from</span> keras.layers <span class=\"keyword\">import</span> Dense,Input,LSTM,Bidirectional,Activation,Conv1D,GRU</span><br><span class=\"line\"><span class=\"keyword\">from</span> keras.layers <span class=\"keyword\">import</span> Dropout,Embedding,GlobalMaxPooling1D, MaxPooling1D, Add, Flatten</span><br><span class=\"line\"><span class=\"keyword\">from</span> keras.layers <span class=\"keyword\">import</span> GlobalAveragePooling1D, GlobalMaxPooling1D, concatenate, SpatialDropout1D<span class=\"comment\"># Keras Callback Functions:</span></span><br><span class=\"line\"><span class=\"keyword\">from</span> keras.callbacks <span class=\"keyword\">import</span> Callback</span><br><span class=\"line\"><span class=\"keyword\">from</span> keras.callbacks <span class=\"keyword\">import</span> EarlyStopping,ModelCheckpoint</span><br><span class=\"line\"><span class=\"keyword\">from</span> keras <span class=\"keyword\">import</span> initializers, regularizers, constraints, optimizers, layers, callbacks</span><br><span class=\"line\"><span class=\"keyword\">from</span> keras.models <span class=\"keyword\">import</span> Model</span><br><span class=\"line\"><span class=\"keyword\">from</span> keras.optimizers <span class=\"keyword\">import</span> Adam</span><br><span class=\"line\"></span><br><span class=\"line\">sequence_input = Input(shape=(max_len, ))</span><br><span class=\"line\">x = Embedding(max_features, embed_size, trainable=<span class=\"literal\">True</span>)(sequence_input)</span><br><span class=\"line\">x = SpatialDropout1D(<span class=\"number\">0.2</span>)(x)</span><br><span class=\"line\">x = Bidirectional(GRU(<span class=\"number\">128</span>, return_sequences=<span class=\"literal\">True</span>,dropout=<span class=\"number\">0.1</span>,recurrent_dropout=<span class=\"number\">0.1</span>))(x)</span><br><span class=\"line\">x = Conv1D(<span class=\"number\">64</span>, kernel_size = <span class=\"number\">3</span>, padding = <span class=\"string\">\"valid\"</span>, kernel_initializer = <span class=\"string\">\"glorot_uniform\"</span>)(x)</span><br><span class=\"line\">avg_pool = GlobalAveragePooling1D()(x)</span><br><span class=\"line\">max_pool = GlobalMaxPooling1D()(x)</span><br><span class=\"line\">x = concatenate([avg_pool, max_pool]) </span><br><span class=\"line\">preds = Dense(<span class=\"number\">19</span>, activation=<span class=\"string\">\"sigmoid\"</span>)(x)</span><br><span class=\"line\"></span><br><span class=\"line\">model = Model(sequence_input, preds)</span><br><span class=\"line\">model.compile(loss=<span class=\"string\">'binary_crossentropy'</span>,optimizer=Adam(lr=<span class=\"number\">1e-3</span>),metrics=[<span class=\"string\">'accuracy'</span>])</span><br><span class=\"line\">model.fit(x_sub_train, y_train, </span><br><span class=\"line\">          batch_size=batch_size, </span><br><span class=\"line\">          validation_split=<span class=\"number\">0.2</span>,</span><br><span class=\"line\">          epochs=epochs)</span><br></pre></td></tr></table></figure>\n<pre><code>C:\\Users\\ACER\\AppData\\Roaming\\Python\\Python35\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n  &quot;Converting sparse IndexedSlices to a dense Tensor of unknown shape. &quot;\nC:\\Users\\ACER\\AppData\\Roaming\\Python\\Python35\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n  &quot;Converting sparse IndexedSlices to a dense Tensor of unknown shape. &quot;\n\n\nTrain on 80000 samples, validate on 20000 samples\nEpoch 1/5\n80000/80000 [==============================] - 844s 11ms/step - loss: 0.1697 - accuracy: 0.9456 - val_loss: 0.1262 - val_accuracy: 0.9571\nEpoch 2/5\n80000/80000 [==============================] - 858s 11ms/step - loss: 0.1221 - accuracy: 0.9582 - val_loss: 0.1144 - val_accuracy: 0.9599\nEpoch 3/5\n80000/80000 [==============================] - 833s 10ms/step - loss: 0.1131 - accuracy: 0.9599 - val_loss: 0.1097 - val_accuracy: 0.9610\nEpoch 4/5\n80000/80000 [==============================] - 807s 10ms/step - loss: 0.1087 - accuracy: 0.9610 - val_loss: 0.1055 - val_accuracy: 0.9624\nEpoch 5/5\n80000/80000 [==============================] - 791s 10ms/step - loss: 0.1170 - accuracy: 0.9613 - val_loss: 0.1047 - val_accuracy: 0.9623\n\n&lt;keras.callbacks.callbacks.History at 0x2a50566ef98&gt;\n</code></pre>","categories":[],"tags":["data analysis"]},{"title":"Task3","url":"https://hahally.github.io//articles/Task3/","content":"<h2 id=\"任务说明\"><a href=\"#任务说明\" class=\"headerlink\" title=\"任务说明\"></a>任务说明</h2><ul>\n<li>任务主题：论文代码统计，统计所有论文出现代码的相关统计；</li>\n<li>任务内容：使用正则表达式统计代码连接、页数和图表数据；</li>\n<li>任务成果：学习正则表达式统计；</li>\n</ul>\n<h2 id=\"数据处理步骤\"><a href=\"#数据处理步骤\" class=\"headerlink\" title=\"数据处理步骤\"></a>数据处理步骤</h2><p>在原始arxiv数据集中作者经常会在论文的<code>comments</code>或<code>abstract</code>字段中给出具体的代码链接，所以我们需要从这些字段里面找出代码的链接。</p>\n<ul>\n<li>确定数据出现的位置；</li>\n<li>使用正则表达式完成匹配；</li>\n<li>完成相关的统计；</li>\n</ul>\n<h2 id=\"正则表达式\"><a href=\"#正则表达式\" class=\"headerlink\" title=\"正则表达式\"></a>正则表达式</h2><p>正则表达式(regular expression)描述了一种字符串匹配的模式（pattern），可以用来检查一个串是否含有某种子串、将匹配的子串替换或者从某个串中取出符合某个条件的子串等。</p>\n<h4 id=\"普通字符：大写和小写字母、所有数字、所有标点符号和一些其他符号\"><a href=\"#普通字符：大写和小写字母、所有数字、所有标点符号和一些其他符号\" class=\"headerlink\" title=\"普通字符：大写和小写字母、所有数字、所有标点符号和一些其他符号\"></a>普通字符：大写和小写字母、所有数字、所有标点符号和一些其他符号</h4><div class=\"table-container\">\n<table>\n<thead>\n<tr>\n<th>字符</th>\n<th>描述</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><strong>[ABC]</strong></td>\n<td>匹配 […] 中的所有字符，例如 [aeiou] 匹配字符串 “google runoob taobao” 中所有的 e o u a 字母。</td>\n</tr>\n<tr>\n<td><strong><sup><a href=\"#fn_ABC\" id=\"reffn_ABC\">ABC</a></sup></strong></td>\n<td>匹配除了 <strong>[…]</strong> 中字符的所有字符，例如 <strong><sup><a href=\"#fn_aeiou\" id=\"reffn_aeiou\">aeiou</a></sup></strong> 匹配字符串 “google runoob taobao” 中除了 e o u a 字母的所有字母。</td>\n</tr>\n<tr>\n<td><strong>[A-Z]</strong></td>\n<td>[A-Z] 表示一个区间，匹配所有大写字母，[a-z] 表示所有小写字母。</td>\n</tr>\n<tr>\n<td>.</td>\n<td>匹配除换行符（\\n、\\r）之外的任何单个字符，相等于 <strong><sup><a href=\"#fn_\\n\\r\" id=\"reffn_\\n\\r\">\\n\\r</a></sup></strong>。</td>\n</tr>\n<tr>\n<td><strong>[\\s\\S]</strong></td>\n<td>匹配所有。\\s 是匹配所有空白符，包括换行，\\S 非空白符，包括换行。</td>\n</tr>\n<tr>\n<td><strong>\\w</strong></td>\n<td>匹配字母、数字、下划线。等价于 [A-Za-z0-9_]</td>\n</tr>\n</tbody>\n</table>\n</div>\n<h4 id=\"特殊字符：有特殊含义的字符\"><a href=\"#特殊字符：有特殊含义的字符\" class=\"headerlink\" title=\"特殊字符：有特殊含义的字符\"></a>特殊字符：有特殊含义的字符</h4><div class=\"table-container\">\n<table>\n<thead>\n<tr>\n<th style=\"text-align:left\">特别字符</th>\n<th style=\"text-align:left\">描述</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td style=\"text-align:left\">( )</td>\n<td style=\"text-align:left\">标记一个子表达式的开始和结束位置。子表达式可以获取供以后使用。要匹配这些字符，请使用 ( 和 )。</td>\n</tr>\n<tr>\n<td style=\"text-align:left\">*</td>\n<td style=\"text-align:left\">匹配前面的子表达式零次或多次。要匹配 <em> 字符，请使用 \\</em>。</td>\n</tr>\n<tr>\n<td style=\"text-align:left\">+</td>\n<td style=\"text-align:left\">匹配前面的子表达式一次或多次。要匹配 + 字符，请使用 +。</td>\n</tr>\n<tr>\n<td style=\"text-align:left\">.</td>\n<td style=\"text-align:left\">匹配除换行符 \\n 之外的任何单字符。要匹配 . ，请使用 . 。</td>\n</tr>\n<tr>\n<td style=\"text-align:left\">[</td>\n<td style=\"text-align:left\">标记一个中括号表达式的开始。要匹配 [，请使用 [。</td>\n</tr>\n<tr>\n<td style=\"text-align:left\">?</td>\n<td style=\"text-align:left\">匹配前面的子表达式零次或一次，或指明一个非贪婪限定符。要匹配 ? 字符，请使用 \\?。</td>\n</tr>\n<tr>\n<td style=\"text-align:left\">\\</td>\n<td style=\"text-align:left\">将下一个字符标记为或特殊字符、或原义字符、或向后引用、或八进制转义符。例如， ‘n’ 匹配字符 ‘n’。’\\n’ 匹配换行符。序列 ‘\\\\’ 匹配 “\\”，而 ‘(‘ 则匹配 “(“。</td>\n</tr>\n<tr>\n<td style=\"text-align:left\">^</td>\n<td style=\"text-align:left\">匹配输入字符串的开始位置，除非在方括号表达式中使用，当该符号在方括号表达式中使用时，表示不接受该方括号表达式中的字符集合。要匹配 ^ 字符本身，请使用 \\^。</td>\n</tr>\n<tr>\n<td style=\"text-align:left\">{</td>\n<td style=\"text-align:left\">标记限定符表达式的开始。要匹配 {，请使用 \\{。</td>\n</tr>\n<tr>\n<td style=\"text-align:left\">\\</td>\n<td style=\"text-align:left\"></td>\n<td>指明两项之间的一个选择。要匹配 \\</td>\n<td>，请使用 \\</td>\n<td>。</td>\n</tr>\n</tbody>\n</table>\n</div>\n<h4 id=\"限定符\"><a href=\"#限定符\" class=\"headerlink\" title=\"限定符\"></a>限定符</h4><div class=\"table-container\">\n<table>\n<thead>\n<tr>\n<th style=\"text-align:left\">字符</th>\n<th style=\"text-align:left\">描述</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td style=\"text-align:left\">*</td>\n<td style=\"text-align:left\">匹配前面的子表达式零次或多次。例如，zo<em> 能匹配 “z” 以及 “zoo”。</em> 等价于{0,}。</td>\n</tr>\n<tr>\n<td style=\"text-align:left\">+</td>\n<td style=\"text-align:left\">匹配前面的子表达式一次或多次。例如，’zo+’ 能匹配 “zo” 以及 “zoo”，但不能匹配 “z”。+ 等价于 {1,}。</td>\n</tr>\n<tr>\n<td style=\"text-align:left\">?</td>\n<td style=\"text-align:left\">匹配前面的子表达式零次或一次。例如，”do(es)?” 可以匹配 “do” 、 “does” 中的 “does” 、 “doxy” 中的 “do” 。? 等价于 {0,1}。</td>\n</tr>\n<tr>\n<td style=\"text-align:left\">{n}</td>\n<td style=\"text-align:left\">n 是一个非负整数。匹配确定的 n 次。例如，’o{2}’ 不能匹配 “Bob” 中的 ‘o’，但是能匹配 “food” 中的两个 o。</td>\n</tr>\n<tr>\n<td style=\"text-align:left\">{n,}</td>\n<td style=\"text-align:left\">n 是一个非负整数。至少匹配n 次。例如，’o{2,}’ 不能匹配 “Bob” 中的 ‘o’，但能匹配 “foooood” 中的所有 o。’o{1,}’ 等价于 ‘o+’。’o{0,}’ 则等价于 ‘o*’。</td>\n</tr>\n<tr>\n<td style=\"text-align:left\">{n,m}</td>\n<td style=\"text-align:left\">m 和 n 均为非负整数，其中n &lt;= m。最少匹配 n 次且最多匹配 m 次。例如，”o{1,3}” 将匹配 “fooooood” 中的前三个 o。’o{0,1}’ 等价于 ‘o?’。请注意在逗号和两个数之间不能有空格。</td>\n</tr>\n</tbody>\n</table>\n</div>\n<h2 id=\"具体代码实现以及讲解\"><a href=\"#具体代码实现以及讲解\" class=\"headerlink\" title=\"具体代码实现以及讲解\"></a>具体代码实现以及讲解</h2><p>首先我们来统计论文页数，也就是在<code>comments</code>字段中抽取pages和figures和个数，首先完成字段读取。</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 导入所需的package</span></span><br><span class=\"line\"><span class=\"keyword\">import</span> seaborn <span class=\"keyword\">as</span> sns <span class=\"comment\">#用于画图</span></span><br><span class=\"line\"><span class=\"keyword\">from</span> bs4 <span class=\"keyword\">import</span> BeautifulSoup <span class=\"comment\">#用于爬取arxiv的数据</span></span><br><span class=\"line\"><span class=\"keyword\">import</span> re <span class=\"comment\">#用于正则表达式，匹配字符串的模式</span></span><br><span class=\"line\"><span class=\"keyword\">import</span> requests <span class=\"comment\">#用于网络连接，发送网络请求，使用域名获取对应信息</span></span><br><span class=\"line\"><span class=\"keyword\">import</span> json <span class=\"comment\">#读取数据，我们的数据为json格式的</span></span><br><span class=\"line\"><span class=\"keyword\">import</span> pandas <span class=\"keyword\">as</span> pd <span class=\"comment\">#数据处理，数据分析</span></span><br><span class=\"line\"><span class=\"keyword\">import</span> matplotlib.pyplot <span class=\"keyword\">as</span> plt <span class=\"comment\">#画图工具</span></span><br></pre></td></tr></table></figure>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">readArxivFile</span><span class=\"params\">(path,</span></span></span><br><span class=\"line\"><span class=\"function\"><span class=\"params\">                  columns=[</span></span></span><br><span class=\"line\"><span class=\"function\"><span class=\"params\">                      <span class=\"string\">'id'</span>, <span class=\"string\">'submitter'</span>, <span class=\"string\">'authors'</span>, <span class=\"string\">'title'</span>, <span class=\"string\">'comments'</span>,</span></span></span><br><span class=\"line\"><span class=\"function\"><span class=\"params\">                      <span class=\"string\">'journal-ref'</span>, <span class=\"string\">'doi'</span>, <span class=\"string\">'report-no'</span>, <span class=\"string\">'categories'</span>,</span></span></span><br><span class=\"line\"><span class=\"function\"><span class=\"params\">                      <span class=\"string\">'license'</span>, <span class=\"string\">'abstract'</span>, <span class=\"string\">'versions'</span>, <span class=\"string\">'update_date'</span>,</span></span></span><br><span class=\"line\"><span class=\"function\"><span class=\"params\">                      <span class=\"string\">'authors_parsed'</span></span></span></span><br><span class=\"line\"><span class=\"function\"><span class=\"params\">                  ],</span></span></span><br><span class=\"line\"><span class=\"function\"><span class=\"params\">                  count=None)</span>:</span></span><br><span class=\"line\">    <span class=\"string\">'''</span></span><br><span class=\"line\"><span class=\"string\">    定义读取文件的函数</span></span><br><span class=\"line\"><span class=\"string\">        path: 文件路径</span></span><br><span class=\"line\"><span class=\"string\">        columns: 需要选择的列</span></span><br><span class=\"line\"><span class=\"string\">        count: 读取行数</span></span><br><span class=\"line\"><span class=\"string\">    '''</span></span><br><span class=\"line\"></span><br><span class=\"line\">    data = []</span><br><span class=\"line\">    <span class=\"keyword\">with</span> open(path, <span class=\"string\">'r'</span>) <span class=\"keyword\">as</span> f:</span><br><span class=\"line\">        <span class=\"keyword\">for</span> idx, line <span class=\"keyword\">in</span> enumerate(f):</span><br><span class=\"line\">            <span class=\"keyword\">if</span> idx == count:</span><br><span class=\"line\">                <span class=\"keyword\">break</span></span><br><span class=\"line\"></span><br><span class=\"line\">            d = json.loads(line)</span><br><span class=\"line\">            d = &#123;col: d[col] <span class=\"keyword\">for</span> col <span class=\"keyword\">in</span> columns&#125;</span><br><span class=\"line\">            data.append(d)</span><br><span class=\"line\"></span><br><span class=\"line\">    data = pd.DataFrame(data)</span><br><span class=\"line\">    <span class=\"keyword\">return</span> data</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">data = readArxivFile(<span class=\"string\">'arxiv-metadata-oai-2019.json'</span>,</span><br><span class=\"line\">                     [<span class=\"string\">'id'</span>, <span class=\"string\">'abstract'</span>, <span class=\"string\">'categories'</span>, <span class=\"string\">'comments'</span>])</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">data.head()</span><br></pre></td></tr></table></figure>\n<div>\n\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>abstract</th>\n      <th>categories</th>\n      <th>comments</th>\n      <th>id</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>We systematically explore the evolution of t...</td>\n      <td>astro-ph</td>\n      <td>15 pages, 15 figures, 3 tables, submitted to M...</td>\n      <td>0704.0297</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Cofibrations are defined in the category of ...</td>\n      <td>math.AT</td>\n      <td>27 pages</td>\n      <td>0704.0342</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>We explore the effect of an inhomogeneous ma...</td>\n      <td>astro-ph</td>\n      <td>6 pages, 3 figures, accepted in A&amp;A</td>\n      <td>0704.0360</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>This paper has been removed by arXiv adminis...</td>\n      <td>gr-qc</td>\n      <td>This submission has been withdrawn by arXiv ad...</td>\n      <td>0704.0525</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>The most massive elliptical galaxies show a ...</td>\n      <td>astro-ph</td>\n      <td>32 pages (referee format), 9 figures, ApJ acce...</td>\n      <td>0704.0535</td>\n    </tr>\n  </tbody>\n</table>\n\n\n\n\n<p>对pages进行抽取：</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 使用正则表达式匹配，XX pages</span></span><br><span class=\"line\">data[<span class=\"string\">'pages'</span>] = data[<span class=\"string\">'comments'</span>].apply(<span class=\"keyword\">lambda</span> x: re.findall(<span class=\"string\">'[1-9][0-9]* pages'</span>, str(x)))</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 筛选出有pages的论文</span></span><br><span class=\"line\">data = data[data[<span class=\"string\">'pages'</span>].apply(len) &gt; <span class=\"number\">0</span>]</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 由于匹配得到的是一个list，如['19 pages']，需要进行转换</span></span><br><span class=\"line\">data[<span class=\"string\">'pages'</span>] = data[<span class=\"string\">'pages'</span>].apply(<span class=\"keyword\">lambda</span> x: float(x[<span class=\"number\">0</span>].replace(<span class=\"string\">' pages'</span>, <span class=\"string\">''</span>)))</span><br></pre></td></tr></table></figure>\n<p>对pages进行统计，统计结果如下：</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">data[<span class=\"string\">'pages'</span>].describe().astype(int)</span><br></pre></td></tr></table></figure>\n<pre><code>count    80696\nmean        18\nstd         20\nmin          1\n25%          9\n50%         14\n75%         24\nmax       1958\nName: pages, dtype: int32\n</code></pre><p>接下来按照分类统计论文页数，选取了论文的第一个类别的主要类别：</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 选择主要类别</span></span><br><span class=\"line\">data[<span class=\"string\">'categories'</span>] = data[<span class=\"string\">'categories'</span>].apply(<span class=\"keyword\">lambda</span> x: x.split(<span class=\"string\">' '</span>)[<span class=\"number\">0</span>])</span><br><span class=\"line\">data[<span class=\"string\">'categories'</span>] = data[<span class=\"string\">'categories'</span>].apply(<span class=\"keyword\">lambda</span> x: x.split(<span class=\"string\">'.'</span>)[<span class=\"number\">0</span>])</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 每类论文的平均页数</span></span><br><span class=\"line\">plt.figure(figsize=(<span class=\"number\">12</span>, <span class=\"number\">6</span>))</span><br><span class=\"line\">data.groupby([<span class=\"string\">'categories'</span>])[<span class=\"string\">'pages'</span>].mean().plot(kind=<span class=\"string\">'bar'</span>)</span><br></pre></td></tr></table></figure>\n<pre><code>&lt;matplotlib.axes._subplots.AxesSubplot at 0x1e7dc314748&gt;\n</code></pre><p><img src=\"/articles/Task3/output_11_1.png\" alt=\"png\"></p>\n<p>接下来对论文图表个数进行抽取：</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">data[<span class=\"string\">'figures'</span>] = data[<span class=\"string\">'comments'</span>].apply(<span class=\"keyword\">lambda</span> x: re.findall(<span class=\"string\">'[1-9][0-9]* figures'</span>, str(x)))</span><br><span class=\"line\">data = data[data[<span class=\"string\">'figures'</span>].apply(len) &gt; <span class=\"number\">0</span>]</span><br><span class=\"line\">data[<span class=\"string\">'figures'</span>] = data[<span class=\"string\">'figures'</span>].apply(<span class=\"keyword\">lambda</span> x: float(x[<span class=\"number\">0</span>].replace(<span class=\"string\">' figures'</span>, <span class=\"string\">''</span>)))</span><br></pre></td></tr></table></figure>\n<p>最后我们对论文的代码链接进行提取，为了简化任务我们只抽取github链接：</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 筛选包含github的论文</span></span><br><span class=\"line\">data_with_code = data[(data.comments.str.contains(<span class=\"string\">'github'</span>) == <span class=\"literal\">True</span>) |</span><br><span class=\"line\">                      (data.abstract.str.contains(<span class=\"string\">'github'</span>) == <span class=\"literal\">True</span>)]</span><br><span class=\"line\">data_with_code[<span class=\"string\">'text'</span>] = data_with_code[<span class=\"string\">'abstract'</span>].fillna(</span><br><span class=\"line\">    <span class=\"string\">''</span>) + data_with_code[<span class=\"string\">'comments'</span>].fillna(<span class=\"string\">''</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 使用正则表达式匹配论文</span></span><br><span class=\"line\">pattern = <span class=\"string\">'[a-zA-z]+://github[^\\s]*'</span></span><br><span class=\"line\">data_with_code[<span class=\"string\">'code_flag'</span>] = data_with_code[<span class=\"string\">'text'</span>].str.findall(</span><br><span class=\"line\">    pattern).apply(len)</span><br></pre></td></tr></table></figure>\n<p>并对论文按照类别进行绘图：</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">data_with_code = data_with_code[data_with_code[<span class=\"string\">'code_flag'</span>] == <span class=\"number\">1</span>]</span><br><span class=\"line\">plt.figure(figsize=(<span class=\"number\">12</span>, <span class=\"number\">6</span>))</span><br><span class=\"line\">data_with_code.groupby([<span class=\"string\">'categories'</span>])[<span class=\"string\">'code_flag'</span>].count().plot(kind=<span class=\"string\">'bar'</span>)</span><br></pre></td></tr></table></figure>\n<pre><code>&lt;matplotlib.axes._subplots.AxesSubplot at 0x1e710f15ef0&gt;\n</code></pre><p><img src=\"/articles/Task3/output_17_1.png\" alt=\"png\"></p>\n</div>","categories":[],"tags":["data analysis"]},{"title":"Task2","url":"https://hahally.github.io//articles/Task2/","content":"<h2 id=\"任务说明\"><a href=\"#任务说明\" class=\"headerlink\" title=\"任务说明\"></a>任务说明</h2><ul>\n<li>任务主题：论文作者统计，统计所有论文作者出现评率Top10的姓名；</li>\n<li>任务内容：论文作者的统计、使用 <strong>Pandas</strong> 读取数据并使用字符串操作；</li>\n<li>任务成果：学习 <strong>Pandas</strong> 的字符串操作；</li>\n</ul>\n<h2 id=\"数据处理步骤\"><a href=\"#数据处理步骤\" class=\"headerlink\" title=\"数据处理步骤\"></a>数据处理步骤</h2><p>在原始arxiv数据集中论文作者<code>authors</code>字段是一个字符串格式，其中每个作者使用逗号进行分隔分，所以我们我们首先需要完成以下步骤：</p>\n<ul>\n<li>使用逗号对作者进行切分；</li>\n<li>剔除单个作者中非常规的字符；</li>\n</ul>\n<p>具体操作可以参考以下例子：</p>\n<figure class=\"highlight mipsasm\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">C. <span class=\"keyword\">Bal\\\\'azs, </span>E. L. <span class=\"keyword\">Berger, </span>P. M. Nadolsky, C.-P. Yuan</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 切分为，其中\\\\为转义符</span></span><br><span class=\"line\"></span><br><span class=\"line\">C. <span class=\"keyword\">Ba'lazs</span></span><br><span class=\"line\"><span class=\"keyword\">E. </span>L. <span class=\"keyword\">Berger</span></span><br><span class=\"line\"><span class=\"keyword\">P. </span>M. Nadolsky</span><br><span class=\"line\">C.-P. Yuan</span><br></pre></td></tr></table></figure>\n<h2 id=\"字符串处理\"><a href=\"#字符串处理\" class=\"headerlink\" title=\"字符串处理\"></a>字符串处理</h2><p>在Python中字符串是最常用的数据类型，可以使用引号(‘或”)来创建字符串。Python中所有的字符都使用字符串存储，可以使用方括号来截取字符串，如下实例：</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">var1 = <span class=\"string\">'Hello Datawhale!'</span></span><br><span class=\"line\">var2 = <span class=\"string\">\"Python Everwhere!\"</span></span><br><span class=\"line\"> </span><br><span class=\"line\">print(<span class=\"string\">\"var1[-10:]: \"</span>, var1[<span class=\"number\">-10</span>:])</span><br><span class=\"line\">print(<span class=\"string\">\"var2[1:5]: \"</span>, var2[<span class=\"number\">0</span>:<span class=\"number\">7</span>])</span><br></pre></td></tr></table></figure>\n<pre><code>var1[-10:]:  Datawhale!\nvar2[1:5]:  Python \n</code></pre><p>同时在Python中还支持转义符：</p>\n<div class=\"table-container\">\n<table>\n<thead>\n<tr>\n<th>(在行尾时)</th>\n<th>续行符</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>\\\\</td>\n<td>反斜杠符号</td>\n</tr>\n<tr>\n<td>\\’</td>\n<td>单引号</td>\n</tr>\n<tr>\n<td>\\”</td>\n<td>双引号</td>\n</tr>\n<tr>\n<td>\\n</td>\n<td>换行</td>\n</tr>\n<tr>\n<td>\\t</td>\n<td>横向制表符</td>\n</tr>\n<tr>\n<td>\\r</td>\n<td>回车</td>\n</tr>\n</tbody>\n</table>\n</div>\n<p>Python中还内置了很多内置函数，非常方便使用：</p>\n<div class=\"table-container\">\n<table>\n<thead>\n<tr>\n<th style=\"text-align:left\"><strong>方法</strong></th>\n<th style=\"text-align:left\"><strong>描述</strong></th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td style=\"text-align:left\">string.capitalize()</td>\n<td style=\"text-align:left\">把字符串的第一个字符大写</td>\n</tr>\n<tr>\n<td style=\"text-align:left\">string.isalpha()</td>\n<td style=\"text-align:left\">如果 string 至少有一个字符并且所有字符都是字母则返回 True,否则返回 False</td>\n</tr>\n<tr>\n<td style=\"text-align:left\">string.title()</td>\n<td style=\"text-align:left\">返回”标题化”的 string,就是说所有单词都是以大写开始，其余字母均为小写(见 istitle())</td>\n</tr>\n<tr>\n<td style=\"text-align:left\">string.upper()</td>\n<td style=\"text-align:left\">转换 string 中的小写字母为大写</td>\n</tr>\n</tbody>\n</table>\n</div>\n<h2 id=\"具体代码实现以及讲解\"><a href=\"#具体代码实现以及讲解\" class=\"headerlink\" title=\"具体代码实现以及讲解\"></a>具体代码实现以及讲解</h2><h3 id=\"数据读取\"><a href=\"#数据读取\" class=\"headerlink\" title=\"数据读取\"></a>数据读取</h3><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 导入所需的package</span></span><br><span class=\"line\"><span class=\"keyword\">import</span> seaborn <span class=\"keyword\">as</span> sns <span class=\"comment\">#用于画图</span></span><br><span class=\"line\"><span class=\"keyword\">from</span> bs4 <span class=\"keyword\">import</span> BeautifulSoup <span class=\"comment\">#用于爬取arxiv的数据</span></span><br><span class=\"line\"><span class=\"keyword\">import</span> re <span class=\"comment\">#用于正则表达式，匹配字符串的模式</span></span><br><span class=\"line\"><span class=\"keyword\">import</span> requests <span class=\"comment\">#用于网络连接，发送网络请求，使用域名获取对应信息</span></span><br><span class=\"line\"><span class=\"keyword\">import</span> json <span class=\"comment\">#读取数据，我们的数据为json格式的</span></span><br><span class=\"line\"><span class=\"keyword\">import</span> pandas <span class=\"keyword\">as</span> pd <span class=\"comment\">#数据处理，数据分析</span></span><br><span class=\"line\"><span class=\"keyword\">import</span> matplotlib.pyplot <span class=\"keyword\">as</span> plt <span class=\"comment\">#画图工具</span></span><br></pre></td></tr></table></figure>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">readArxivFile</span><span class=\"params\">(path, columns=[<span class=\"string\">'id'</span>, <span class=\"string\">'submitter'</span>, <span class=\"string\">'authors'</span>, <span class=\"string\">'title'</span>, <span class=\"string\">'comments'</span>, <span class=\"string\">'journal-ref'</span>, <span class=\"string\">'doi'</span>,</span></span></span><br><span class=\"line\"><span class=\"function\"><span class=\"params\">       <span class=\"string\">'report-no'</span>, <span class=\"string\">'categories'</span>, <span class=\"string\">'license'</span>, <span class=\"string\">'abstract'</span>, <span class=\"string\">'versions'</span>,</span></span></span><br><span class=\"line\"><span class=\"function\"><span class=\"params\">       <span class=\"string\">'update_date'</span>, <span class=\"string\">'authors_parsed'</span>], count=None)</span>:</span></span><br><span class=\"line\">    <span class=\"string\">'''</span></span><br><span class=\"line\"><span class=\"string\">    定义读取文件的函数</span></span><br><span class=\"line\"><span class=\"string\">        path: 文件路径</span></span><br><span class=\"line\"><span class=\"string\">        columns: 需要选择的列</span></span><br><span class=\"line\"><span class=\"string\">        count: 读取行数</span></span><br><span class=\"line\"><span class=\"string\">    '''</span></span><br><span class=\"line\">    </span><br><span class=\"line\">    data  = []</span><br><span class=\"line\">    <span class=\"keyword\">with</span> open(path, <span class=\"string\">'r'</span>) <span class=\"keyword\">as</span> f: </span><br><span class=\"line\">        <span class=\"keyword\">for</span> idx, line <span class=\"keyword\">in</span> enumerate(f): </span><br><span class=\"line\">            <span class=\"keyword\">if</span> idx == count:</span><br><span class=\"line\">                <span class=\"keyword\">break</span></span><br><span class=\"line\">                </span><br><span class=\"line\">            d = json.loads(line)</span><br><span class=\"line\">            d = &#123;col : d[col] <span class=\"keyword\">for</span> col <span class=\"keyword\">in</span> columns&#125;</span><br><span class=\"line\">            data.append(d)</span><br><span class=\"line\"></span><br><span class=\"line\">    data = pd.DataFrame(data)</span><br><span class=\"line\">    <span class=\"keyword\">return</span> data</span><br><span class=\"line\"></span><br><span class=\"line\">data = readArxivFile(<span class=\"string\">'arxiv-metadata-oai-snapshot.json'</span>, </span><br><span class=\"line\">                     [<span class=\"string\">'id'</span>, <span class=\"string\">'authors'</span>, <span class=\"string\">'categories'</span>, <span class=\"string\">'authors_parsed'</span>],</span><br><span class=\"line\">                    <span class=\"number\">100000</span>)</span><br></pre></td></tr></table></figure>\n<h3 id=\"数据统计\"><a href=\"#数据统计\" class=\"headerlink\" title=\"数据统计\"></a>数据统计</h3><p>接下来我们将完成以下统计操作：</p>\n<ul>\n<li>统计所有作者姓名出现频率的Top10；</li>\n<li>统计所有作者姓（姓名最后一个单词）的出现频率的Top10；</li>\n<li>统计所有作者姓第一个字符的评率；</li>\n</ul>\n<p>为了节约计算时间，下面选择部分类别下的论文进行处理：</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 选择类别为cs.CV下面的论文</span></span><br><span class=\"line\">data2 = data[data[<span class=\"string\">'categories'</span>].apply(<span class=\"keyword\">lambda</span> x: <span class=\"string\">'cs.CV'</span> <span class=\"keyword\">in</span> x)]</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 拼接所有作者</span></span><br><span class=\"line\">all_authors = sum(data2[<span class=\"string\">'authors_parsed'</span>], [])</span><br></pre></td></tr></table></figure>\n<p>处理完成后<code>all_authors</code>变成了所有一个list，其中每个元素为一个作者的姓名。我们首先来完成姓名频率的统计。</p>\n<p>join() 函数</p>\n<figure class=\"highlight armasm\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"symbol\">Docstring</span>:</span><br><span class=\"line\"><span class=\"symbol\">S.join</span>(<span class=\"keyword\">iterable) </span>-&gt; <span class=\"keyword\">str</span></span><br><span class=\"line\"><span class=\"keyword\"></span></span><br><span class=\"line\"><span class=\"keyword\">Return </span>a <span class=\"keyword\">string </span>which is the concatenation of the <span class=\"keyword\">strings </span>in the</span><br><span class=\"line\"><span class=\"keyword\">iterable. </span> The separator <span class=\"keyword\">between </span>elements is S.</span><br></pre></td></tr></table></figure>\n<p><code>iterable</code> : 为可迭代对象</p>\n<p>返回以 S 为分割符的拼接字符串</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 拼接所有的作者</span></span><br><span class=\"line\">authors_names = [<span class=\"string\">' '</span>.join(x) <span class=\"keyword\">for</span> x <span class=\"keyword\">in</span> all_authors]</span><br><span class=\"line\">authors_names = pd.DataFrame(authors_names)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 根据作者频率绘制直方图</span></span><br><span class=\"line\">plt.figure(figsize=(<span class=\"number\">10</span>, <span class=\"number\">6</span>))</span><br><span class=\"line\">authors_names[<span class=\"number\">0</span>].value_counts().head(<span class=\"number\">10</span>).plot(kind=<span class=\"string\">'barh'</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 修改图配置</span></span><br><span class=\"line\">names = authors_names[<span class=\"number\">0</span>].value_counts().index.values[:<span class=\"number\">10</span>]</span><br><span class=\"line\">_ = plt.yticks(range(<span class=\"number\">0</span>, len(names)), names)</span><br><span class=\"line\">plt.ylabel(<span class=\"string\">'Author'</span>)</span><br><span class=\"line\">plt.xlabel(<span class=\"string\">'Count'</span>)</span><br></pre></td></tr></table></figure>\n<pre><code>Text(0.5,0,&#39;Count&#39;)\n</code></pre><p><img src=\"/articles/Task2/output_14_1.png\" alt=\"png\"></p>\n<p>接下来统计姓名姓，也就是<code>authors_parsed</code>字段中作者第一个单词：</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">authors_lastnames = [x[<span class=\"number\">0</span>] <span class=\"keyword\">for</span> x <span class=\"keyword\">in</span> all_authors]</span><br><span class=\"line\">authors_lastnames = pd.DataFrame(authors_lastnames)</span><br><span class=\"line\"></span><br><span class=\"line\">plt.figure(figsize=(<span class=\"number\">10</span>, <span class=\"number\">6</span>))</span><br><span class=\"line\">authors_lastnames[<span class=\"number\">0</span>].value_counts().head(<span class=\"number\">10</span>).plot(kind=<span class=\"string\">'barh'</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">names = authors_lastnames[<span class=\"number\">0</span>].value_counts().index.values[:<span class=\"number\">10</span>]</span><br><span class=\"line\">_ = plt.yticks(range(<span class=\"number\">0</span>, len(names)), names)</span><br><span class=\"line\">plt.ylabel(<span class=\"string\">'Author'</span>)</span><br><span class=\"line\">plt.xlabel(<span class=\"string\">'Count'</span>)</span><br></pre></td></tr></table></figure>\n<pre><code>Text(0.5,0,&#39;Count&#39;)\n</code></pre><p><img src=\"/articles/Task2/output_16_1.png\" alt=\"png\"></p>\n<p>绘制得到的结果，从结果看出这些都是华人或者中国姓氏~</p>\n<p>统计所有作者姓第一个字符的评率，这个流程与上述的类似</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">authors_first = [x[<span class=\"number\">0</span>][<span class=\"number\">0</span>] <span class=\"keyword\">for</span> x <span class=\"keyword\">in</span> all_authors]</span><br><span class=\"line\">authors_first = pd.DataFrame(authors_firs)</span><br><span class=\"line\"></span><br><span class=\"line\">plt.figure(figsize=(<span class=\"number\">10</span>, <span class=\"number\">6</span>))</span><br><span class=\"line\">authors_first[<span class=\"number\">0</span>].value_counts().head(<span class=\"number\">10</span>).plot(kind=<span class=\"string\">'barsh'</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">s = authors_first[<span class=\"number\">0</span>].value_counts().indesx.values[:<span class=\"number\">10</span>]</span><br><span class=\"line\">_ = plt.yticks(range(<span class=\"number\">0</span>, len(s)), s)</span><br><span class=\"line\">plt.ylabel(<span class=\"string\">'Author'</span>)</span><br><span class=\"line\">plt.xlabel(<span class=\"string\">'Count'</span>)</span><br></pre></td></tr></table></figure>\n<pre><code>Text(0.5,0,&#39;Count&#39;)\n</code></pre><p><img src=\"/articles/Task2/output_18_1.png\" alt=\"png\"></p>\n","categories":[],"tags":["data analysis"]},{"title":"Task1","url":"https://hahally.github.io//articles/Task1/","content":"<h2 id=\"任务说明\"><a href=\"#任务说明\" class=\"headerlink\" title=\"任务说明\"></a>任务说明</h2><ul>\n<li>任务主题：论文数量统计，即统计2019年全年计算机各个方向论文数量；</li>\n<li>任务内容：赛题的理解、使用 <strong>Pandas</strong> 读取数据并进行统计；</li>\n<li>任务成果：学习 <strong>Pandas</strong> 的基础操作；</li>\n<li>可参考的学习资料：<a href=\"https://github.com/datawhalechina/joyful-pandas\" target=\"_blank\" rel=\"noopener\">开源组织Datawhale joyful-pandas项目</a></li>\n</ul>\n<h2 id=\"数据集介绍\"><a href=\"#数据集介绍\" class=\"headerlink\" title=\"数据集介绍\"></a>数据集介绍</h2><ul>\n<li>数据集来源：<a href=\"https://www.kaggle.com/Cornell-University/arxiv\" target=\"_blank\" rel=\"noopener\">数据集链接</a>；</li>\n<li>数据集的格式如下：<ul>\n<li><code>id</code>：arXiv ID，可用于访问论文；</li>\n<li><code>submitter</code>：论文提交者；</li>\n<li><code>authors</code>：论文作者；</li>\n<li><code>title</code>：论文标题；</li>\n<li><code>comments</code>：论文页数和图表等其他信息；</li>\n<li><code>journal-ref</code>：论文发表的期刊的信息；</li>\n<li><code>doi</code>：数字对象标识符，<a href=\"https://www.doi.org\" target=\"_blank\" rel=\"noopener\">https://www.doi.org</a>；</li>\n<li><code>report-no</code>：报告编号；</li>\n<li><code>categories</code>：论文在 arXiv 系统的所属类别或标签；</li>\n<li><code>license</code>：文章的许可证；</li>\n<li><code>abstract</code>：论文摘要；</li>\n<li><code>versions</code>：论文版本；</li>\n<li><code>authors_parsed</code>：作者的信息。</li>\n<li><code>update_date</code>：更新时间</li>\n</ul>\n</li>\n</ul>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"string\">\"root\"</span>:&#123;</span><br><span class=\"line\">\t\t<span class=\"string\">\"id\"</span>:<span class=\"built_in\">string</span><span class=\"string\">\"0704.0001\"</span></span><br><span class=\"line\">\t\t<span class=\"string\">\"submitter\"</span>:<span class=\"built_in\">string</span><span class=\"string\">\"Pavel Nadolsky\"</span></span><br><span class=\"line\">\t\t<span class=\"string\">\"authors\"</span>:<span class=\"built_in\">string</span><span class=\"string\">\"C. Bal\\'azs, E. L. Berger, P. M. Nadolsky, C.-P. Yuan\"</span></span><br><span class=\"line\">\t\t<span class=\"string\">\"title\"</span>:<span class=\"built_in\">string</span><span class=\"string\">\"Calculation of prompt diphoton production cross sections at Tevatron and LHC energies\"</span></span><br><span class=\"line\">\t\t<span class=\"string\">\"comments\"</span>:<span class=\"built_in\">string</span><span class=\"string\">\"37 pages, 15 figures; published version\"</span></span><br><span class=\"line\">\t\t<span class=\"string\">\"journal-ref\"</span>:<span class=\"built_in\">string</span><span class=\"string\">\"Phys.Rev.D76:013009,2007\"</span></span><br><span class=\"line\">\t\t<span class=\"string\">\"doi\"</span>:<span class=\"built_in\">string</span><span class=\"string\">\"10.1103/PhysRevD.76.013009\"</span></span><br><span class=\"line\">\t\t<span class=\"string\">\"report-no\"</span>:<span class=\"built_in\">string</span><span class=\"string\">\"ANL-HEP-PR-07-12\"</span></span><br><span class=\"line\">\t\t<span class=\"string\">\"categories\"</span>:<span class=\"built_in\">string</span><span class=\"string\">\"hep-ph\"</span></span><br><span class=\"line\">\t\t<span class=\"string\">\"license\"</span>:<span class=\"literal\">NULL</span></span><br><span class=\"line\">\t\t<span class=\"string\">\"abstract\"</span>:<span class=\"built_in\">string</span><span class=\"string\">\"  A fully differential calculation in perturbative quantum chromodynamics is presented for the production of massive photon pairs at hadron colliders. All next-to-leading order perturbative contributions from quark-antiquark, gluon-(anti)quark, and gluon-gluon subprocesses are included, as well as all-orders resummation of initial-state gluon radiation valid at next-to-next-to leading logarithmic accuracy. The region of phase space is specified in which the calculation is most reliable. Good agreement is demonstrated with data from the Fermilab Tevatron, and predictions are made for more detailed tests with CDF and DO data. Predictions are shown for distributions of diphoton pairs produced at the energy of the Large Hadron Collider (LHC). Distributions of the diphoton pairs from the decay of a Higgs boson are contrasted with those produced from QCD processes at the LHC, showing that enhanced sensitivity to the signal can be obtained with judicious selection of events.\"</span></span><br><span class=\"line\">\t\t<span class=\"string\">\"versions\"</span>:[</span><br><span class=\"line\">\t\t\t\t<span class=\"number\">0</span>:&#123;</span><br><span class=\"line\">\t\t\t\t\t\t<span class=\"string\">\"version\"</span>:<span class=\"built_in\">string</span><span class=\"string\">\"v1\"</span></span><br><span class=\"line\">\t\t\t\t\t\t<span class=\"string\">\"created\"</span>:<span class=\"built_in\">string</span><span class=\"string\">\"Mon, 2 Apr 2007 19:18:42 GMT\"</span></span><br><span class=\"line\">\t\t\t\t\t&#125;</span><br><span class=\"line\">\t\t\t\t<span class=\"number\">1</span>:&#123;</span><br><span class=\"line\">\t\t\t\t\t\t<span class=\"string\">\"version\"</span>:<span class=\"built_in\">string</span><span class=\"string\">\"v2\"</span></span><br><span class=\"line\">\t\t\t\t\t\t<span class=\"string\">\"created\"</span>:<span class=\"built_in\">string</span><span class=\"string\">\"Tue, 24 Jul 2007 20:10:27 GMT\"</span></span><br><span class=\"line\">\t\t\t\t\t&#125;]</span><br><span class=\"line\">\t\t<span class=\"string\">\"update_date\"</span>:<span class=\"built_in\">string</span><span class=\"string\">\"2008-11-26\"</span></span><br><span class=\"line\">\t\t<span class=\"string\">\"authors_parsed\"</span>:[</span><br><span class=\"line\">\t\t\t\t<span class=\"number\">0</span>:[</span><br><span class=\"line\">\t\t\t\t\t\t<span class=\"number\">0</span>:<span class=\"built_in\">string</span><span class=\"string\">\"Balázs\"</span></span><br><span class=\"line\">\t\t\t\t\t\t<span class=\"number\">1</span>:<span class=\"built_in\">string</span><span class=\"string\">\"C.\"</span></span><br><span class=\"line\">\t\t\t\t\t\t<span class=\"number\">2</span>:<span class=\"built_in\">string</span><span class=\"string\">\"\"</span>]</span><br><span class=\"line\">\t\t\t\t<span class=\"number\">1</span>:[</span><br><span class=\"line\">\t\t\t\t\t\t<span class=\"number\">0</span>:<span class=\"built_in\">string</span><span class=\"string\">\"Berger\"</span></span><br><span class=\"line\">\t\t\t\t\t\t<span class=\"number\">1</span>:<span class=\"built_in\">string</span><span class=\"string\">\"E. L.\"</span></span><br><span class=\"line\">\t\t\t\t\t\t<span class=\"number\">2</span>:<span class=\"built_in\">string</span><span class=\"string\">\"\"</span>]</span><br><span class=\"line\">\t\t\t\t<span class=\"number\">2</span>:[</span><br><span class=\"line\">\t\t\t\t\t\t<span class=\"number\">0</span>:<span class=\"built_in\">string</span><span class=\"string\">\"Nadolsky\"</span></span><br><span class=\"line\">\t\t\t\t\t\t<span class=\"number\">1</span>:<span class=\"built_in\">string</span><span class=\"string\">\"P. M.\"</span></span><br><span class=\"line\">\t\t\t\t\t\t<span class=\"number\">2</span>:<span class=\"built_in\">string</span><span class=\"string\">\"\"</span>]</span><br><span class=\"line\">\t\t\t\t<span class=\"number\">3</span>:[</span><br><span class=\"line\">\t\t\t\t\t\t<span class=\"number\">0</span>:<span class=\"built_in\">string</span><span class=\"string\">\"Yuan\"</span></span><br><span class=\"line\">\t\t\t\t\t\t<span class=\"number\">1</span>:<span class=\"built_in\">string</span><span class=\"string\">\"C. -P.\"</span></span><br><span class=\"line\">\t\t\t\t\t\t<span class=\"number\">2</span>:<span class=\"built_in\">string</span><span class=\"string\">\"\"</span>]]</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<h2 id=\"arxiv论文类别介绍\"><a href=\"#arxiv论文类别介绍\" class=\"headerlink\" title=\"arxiv论文类别介绍\"></a>arxiv论文类别介绍</h2><p>我们从arxiv官网，查询到论文的类别名称以及其解释如下。</p>\n<p>链接：<a href=\"https://arxiv.org/help/api/user-manual\" target=\"_blank\" rel=\"noopener\">https://arxiv.org/help/api/user-manual</a>  的 5.3 小节的 Subject Classifications 的部分，或 <a href=\"https://arxiv.org/category_taxonomy\" target=\"_blank\" rel=\"noopener\">https://arxiv.org/category_taxonomy</a>， 具体的153种paper的类别部分如下：</p>\n<figure class=\"highlight\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">'astro-ph': 'Astrophysics',</span><br><span class=\"line\">'astro-ph.CO': 'Cosmology and Nongalactic Astrophysics',</span><br><span class=\"line\">'astro-ph.EP': 'Earth and Planetary Astrophysics',</span><br><span class=\"line\">'astro-ph.GA': 'Astrophysics of Galaxies',</span><br><span class=\"line\">'cs.AI': 'Artificial Intelligence',</span><br><span class=\"line\">'cs.AR': 'Hardware Architecture',</span><br><span class=\"line\">'cs.CC': 'Computational Complexity',</span><br><span class=\"line\">'cs.CE': 'Computational Engineering, Finance, and Science',</span><br><span class=\"line\">'cs.CV': 'Computer Vision and Pattern Recognition',</span><br><span class=\"line\">'cs.CY': 'Computers and Society',</span><br><span class=\"line\">'cs.DB': 'Databases',</span><br><span class=\"line\">'cs.DC': 'Distributed, Parallel, and Cluster Computing',</span><br><span class=\"line\">'cs.DL': 'Digital Libraries',</span><br><span class=\"line\">'cs.NA': 'Numerical Analysis',</span><br><span class=\"line\">'cs.NE': 'Neural and Evolutionary Computing',</span><br><span class=\"line\">'cs.NI': 'Networking and Internet Architecture',</span><br><span class=\"line\">'cs.OH': 'Other Computer Science',</span><br><span class=\"line\">'cs.OS': 'Operating Systems',</span><br></pre></td></tr></table></figure>\n<h2 id=\"具体代码实现以及讲解\"><a href=\"#具体代码实现以及讲解\" class=\"headerlink\" title=\"具体代码实现以及讲解\"></a>具体代码实现以及讲解</h2><h3 id=\"使用pyspark-处理数据\"><a href=\"#使用pyspark-处理数据\" class=\"headerlink\" title=\"使用pyspark 处理数据\"></a>使用pyspark 处理数据</h3><p>脆皮电脑扛不住这么大的内存消耗，所以选择先使用 pyspark 进行初步处理，因为之前用过</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">from</span> pyspark <span class=\"keyword\">import</span> SparkContext,SparkConf</span><br><span class=\"line\"><span class=\"keyword\">from</span> pyspark.sql <span class=\"keyword\">import</span> SparkSession</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 必要的配置</span></span><br><span class=\"line\">conf = SparkConf().setMaster(<span class=\"string\">\"local\"</span>).setAppName(<span class=\"string\">\"dataframe\"</span>).set(</span><br><span class=\"line\">    <span class=\"string\">'spark.local.dir'</span>, <span class=\"string\">'E:\\SparkTemp'</span>)</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 初始化一个spark对象</span></span><br><span class=\"line\">spark = SparkSession.builder.appName(<span class=\"string\">'my_first_app_name'</span>).config(</span><br><span class=\"line\">    conf=conf).getOrCreate()</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 读取 2.69 GB大小的json数据</span></span><br><span class=\"line\">json_data = spark.read.json(<span class=\"string\">'./arxiv-metadata-oai-snapshot.json'</span>)</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 查看列名,14 个item</span></span><br><span class=\"line\">json_data.columns</span><br></pre></td></tr></table></figure>\n<pre><code>[&#39;abstract&#39;,\n &#39;authors&#39;,\n &#39;authors_parsed&#39;,\n &#39;categories&#39;,\n &#39;comments&#39;,\n &#39;doi&#39;,\n &#39;id&#39;,\n &#39;journal-ref&#39;,\n &#39;license&#39;,\n &#39;report-no&#39;,\n &#39;submitter&#39;,\n &#39;title&#39;,\n &#39;update_date&#39;,\n &#39;versions&#39;]\n</code></pre><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 显示 行数 和 列数</span></span><br><span class=\"line\">json_data.count(), len(json_data.columns)</span><br></pre></td></tr></table></figure>\n<pre><code>(1796911, 14)\n</code></pre><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 查看前5行：没有透视表，有点烦人</span></span><br><span class=\"line\">json_data.show(<span class=\"number\">5</span>)</span><br></pre></td></tr></table></figure>\n<pre><code>+--------------------+--------------------+--------------------+---------------+--------------------+--------------------+---------+--------------------+--------------------+----------------+------------------+--------------------+-----------+--------------------+\n|            abstract|             authors|      authors_parsed|     categories|            comments|                 doi|       id|         journal-ref|             license|       report-no|         submitter|               title|update_date|            versions|\n+--------------------+--------------------+--------------------+---------------+--------------------+--------------------+---------+--------------------+--------------------+----------------+------------------+--------------------+-----------+--------------------+\n|  A fully differe...|C. Bal\\&#39;azs, E. L...|[[Balázs, C., ], ...|         hep-ph|37 pages, 15 figu...|10.1103/PhysRevD....|0704.0001|Phys.Rev.D76:0130...|                null|ANL-HEP-PR-07-12|    Pavel Nadolsky|Calculation of pr...| 2008-11-26|[[Mon, 2 Apr 2007...|\n|  We describe a n...|Ileana Streinu an...|[[Streinu, Ileana...|  math.CO cs.CG|To appear in Grap...|                null|0704.0002|                null|http://arxiv.org/...|            null|      Louis Theran|Sparsity-certifyi...| 2008-12-13|[[Sat, 31 Mar 200...|\n|  The evolution o...|         Hongjun Pan|  [[Pan, Hongjun, ]]| physics.gen-ph| 23 pages, 3 figures|                null|0704.0003|                null|                null|            null|       Hongjun Pan|The evolution of ...| 2008-01-13|[[Sun, 1 Apr 2007...|\n|  We show that a ...|        David Callan| [[Callan, David, ]]|        math.CO|            11 pages|                null|0704.0004|                null|                null|            null|      David Callan|A determinant of ...| 2007-05-23|[[Sat, 31 Mar 200...|\n|  In this paper w...|Wael Abu-Shammala...|[[Abu-Shammala, W...|math.CA math.FA|                null|                null|0704.0005|Illinois J. Math....|                null|            null|Alberto Torchinsky|From dyadic $\\Lam...| 2013-10-15|[[Mon, 2 Apr 2007...|\n+--------------------+--------------------+--------------------+---------------+--------------------+--------------------+---------+--------------------+--------------------+----------------+------------------+--------------------+-----------+--------------------+\nonly showing top 5 rows\n</code></pre><p>​    </p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 压缩保存为parquet格式</span></span><br><span class=\"line\">json_data.coalesce(<span class=\"number\">1</span>).write.parquet(<span class=\"string\">'arxiv-metadata-oai-snapshot.parquet'</span>,</span><br><span class=\"line\">                                    mode=<span class=\"string\">'overwrite'</span>)</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 选着要处理的三列数据</span></span><br><span class=\"line\">data = json_data.select([<span class=\"string\">'id'</span>, <span class=\"string\">'categories'</span>, <span class=\"string\">'update_date'</span>])</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 查看，默认前 20 行</span></span><br><span class=\"line\">data.show()</span><br></pre></td></tr></table></figure>\n<pre><code>+---------+-----------------+-----------+\n|       id|       categories|update_date|\n+---------+-----------------+-----------+\n|0704.0001|           hep-ph| 2008-11-26|\n|0704.0002|    math.CO cs.CG| 2008-12-13|\n|0704.0003|   physics.gen-ph| 2008-01-13|\n|0704.0004|          math.CO| 2007-05-23|\n|0704.0005|  math.CA math.FA| 2013-10-15|\n|0704.0006|cond-mat.mes-hall| 2015-05-13|\n|0704.0007|            gr-qc| 2008-11-26|\n|0704.0008|cond-mat.mtrl-sci| 2009-02-05|\n|0704.0009|         astro-ph| 2010-03-18|\n|0704.0010|          math.CO| 2007-05-23|\n|0704.0011|  math.NT math.AG| 2008-08-20|\n|0704.0012|          math.NT| 2007-05-23|\n|0704.0013|          math.NT| 2008-05-26|\n|0704.0014|  math.CA math.AT| 2009-09-29|\n|0704.0015|           hep-th| 2009-11-13|\n|0704.0016|           hep-ph| 2008-12-18|\n|0704.0017|         astro-ph| 2009-06-23|\n|0704.0018|           hep-th| 2007-05-23|\n|0704.0019|  math.PR math.AG| 2007-06-23|\n|0704.0020|           hep-ex| 2015-06-30|\n+---------+-----------------+-----------+\nonly showing top 20 rows\n</code></pre><p>​    </p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 转成 pandas对象，因为只选择了三列，内存消耗在自己电脑承受范围内</span></span><br><span class=\"line\"><span class=\"comment\"># 所以转成pandas对象，通过内存处理起来要快得多</span></span><br><span class=\"line\">df = data.toPandas()</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">df</span><br></pre></td></tr></table></figure>\n<div>\n\n\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>categories</th>\n      <th>update_date</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0704.0001</td>\n      <td>hep-ph</td>\n      <td>2008-11-26</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0704.0002</td>\n      <td>math.CO cs.CG</td>\n      <td>2008-12-13</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0704.0003</td>\n      <td>physics.gen-ph</td>\n      <td>2008-01-13</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0704.0004</td>\n      <td>math.CO</td>\n      <td>2007-05-23</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0704.0005</td>\n      <td>math.CA math.FA</td>\n      <td>2013-10-15</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1796906</th>\n      <td>supr-con/9608008</td>\n      <td>supr-con cond-mat.supr-con</td>\n      <td>2009-10-30</td>\n    </tr>\n    <tr>\n      <th>1796907</th>\n      <td>supr-con/9609001</td>\n      <td>supr-con cond-mat.supr-con</td>\n      <td>2016-11-18</td>\n    </tr>\n    <tr>\n      <th>1796908</th>\n      <td>supr-con/9609002</td>\n      <td>supr-con cond-mat.supr-con</td>\n      <td>2009-10-30</td>\n    </tr>\n    <tr>\n      <th>1796909</th>\n      <td>supr-con/9609003</td>\n      <td>supr-con cond-mat.supr-con</td>\n      <td>2009-10-30</td>\n    </tr>\n    <tr>\n      <th>1796910</th>\n      <td>supr-con/9609004</td>\n      <td>supr-con cond-mat.supr-con</td>\n      <td>2009-10-30</td>\n    </tr>\n  </tbody>\n</table>\n<p>1796911 rows × 3 columns</p>\n\n\n\n\n转成pandas 对象后，就可以方便的按照教程一步一步来了\n\n---\n\n### 导入package并读取原始数据\n\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 导入所需的package</span></span><br><span class=\"line\"><span class=\"keyword\">import</span> seaborn <span class=\"keyword\">as</span> sns <span class=\"comment\">#用于画图</span></span><br><span class=\"line\"><span class=\"keyword\">from</span> bs4 <span class=\"keyword\">import</span> BeautifulSoup <span class=\"comment\">#用于爬取arxiv的数据</span></span><br><span class=\"line\"><span class=\"keyword\">import</span> re <span class=\"comment\">#用于正则表达式，匹配字符串的模式</span></span><br><span class=\"line\"><span class=\"keyword\">import</span> requests <span class=\"comment\">#用于网络连接，发送网络请求，使用域名获取对应信息</span></span><br><span class=\"line\"><span class=\"keyword\">import</span> json <span class=\"comment\">#读取数据，我们的数据为json格式的</span></span><br><span class=\"line\"><span class=\"keyword\">import</span> pandas <span class=\"keyword\">as</span> pd <span class=\"comment\">#数据处理，数据分析</span></span><br><span class=\"line\"><span class=\"keyword\">import</span> matplotlib.pyplot <span class=\"keyword\">as</span> plt <span class=\"comment\">#画图工具</span></span><br></pre></td></tr></table></figure>\n\n### 数据预处理\n\n首先我们先来粗略统计论文的种类信息：\n\n- `count`：一列数据的元素个数；\n- `unique`：一列数据中元素的种类；\n- `top`：一列数据中出现频率最高的元素；\n- `freq`：一列数据中出现频率最高的元素的个数；\n\n\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">df[<span class=\"string\">'categories'</span>].describe()</span><br></pre></td></tr></table></figure>\n\n\n\n\n    count      1796911\n    unique       62055\n    top       astro-ph\n    freq         86914\n    Name: categories, dtype: object\n\n\n\n以上的结果表明：共有1796911个数据，有62055个子类（因为有论文的类别是多个，例如一篇paper的类别是CS.AI & CS.MM和一篇paper的类别是CS.AI & CS.OS属于不同的子类别，这里仅仅是粗略统计），其中最多的种类是astro-ph，即Astrophysics（天体物理学），共出现了86914次。\n\n由于部分论文的类别不止一种，所以下面我们判断在本数据集中共出现了多少种独立的数据集。\n\n\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">unique_categories = set([i <span class=\"keyword\">for</span> l <span class=\"keyword\">in</span> [x.split(<span class=\"string\">' '</span>) <span class=\"keyword\">for</span> x <span class=\"keyword\">in</span> df[<span class=\"string\">\"categories\"</span>]] <span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> l])</span><br><span class=\"line\">len(unique_categories),unique_categories</span><br></pre></td></tr></table></figure>\n\n\n\n\n    (176,\n     {'acc-phys',\n      'adap-org',\n      'alg-geom',\n      'ao-sci',\n      'astro-ph',\n      'astro-ph.CO',\n      'astro-ph.EP',\n      'astro-ph.GA',\n      'astro-ph.HE',\n      'astro-ph.IM',\n      'astro-ph.SR',\n      'atom-ph',\n      'bayes-an',\n      'chao-dyn',\n      'chem-ph',\n      'cmp-lg',\n      'comp-gas',\n      'cond-mat',\n      'cond-mat.dis-nn',\n      'cond-mat.mes-hall',\n      'cond-mat.mtrl-sci',\n      'cond-mat.other',\n      'cond-mat.quant-gas',\n      'cond-mat.soft',\n      'cond-mat.stat-mech',\n      'cond-mat.str-el',\n      'cond-mat.supr-con',\n      'cs.AI',\n      'cs.AR',\n      'cs.CC',\n      'cs.CE',\n      'cs.CG',\n      'cs.CL',\n      'cs.CR',\n      'cs.CV',\n      'cs.CY',\n      'cs.DB',\n      'cs.DC',\n      'cs.DL',\n      'cs.DM',\n      'cs.DS',\n      'cs.ET',\n      'cs.FL',\n      'cs.GL',\n      'cs.GR',\n      'cs.GT',\n      'cs.HC',\n      'cs.IR',\n      'cs.IT',\n      'cs.LG',\n      'cs.LO',\n      'cs.MA',\n      'cs.MM',\n      'cs.MS',\n      'cs.NA',\n      'cs.NE',\n      'cs.NI',\n      'cs.OH',\n      'cs.OS',\n      'cs.PF',\n      'cs.PL',\n      'cs.RO',\n      'cs.SC',\n      'cs.SD',\n      'cs.SE',\n      'cs.SI',\n      'cs.SY',\n      'dg-ga',\n      'econ.EM',\n      'econ.GN',\n      'econ.TH',\n      'eess.AS',\n      'eess.IV',\n      'eess.SP',\n      'eess.SY',\n      'funct-an',\n      'gr-qc',\n      'hep-ex',\n      'hep-lat',\n      'hep-ph',\n      'hep-th',\n      'math-ph',\n      'math.AC',\n      'math.AG',\n      'math.AP',\n      'math.AT',\n      'math.CA',\n      'math.CO',\n      'math.CT',\n      'math.CV',\n      'math.DG',\n      'math.DS',\n      'math.FA',\n      'math.GM',\n      'math.GN',\n      'math.GR',\n      'math.GT',\n      'math.HO',\n      'math.IT',\n      'math.KT',\n      'math.LO',\n      'math.MG',\n      'math.MP',\n      'math.NA',\n      'math.NT',\n      'math.OA',\n      'math.OC',\n      'math.PR',\n      'math.QA',\n      'math.RA',\n      'math.RT',\n      'math.SG',\n      'math.SP',\n      'math.ST',\n      'mtrl-th',\n      'nlin.AO',\n      'nlin.CD',\n      'nlin.CG',\n      'nlin.PS',\n      'nlin.SI',\n      'nucl-ex',\n      'nucl-th',\n      'patt-sol',\n      'physics.acc-ph',\n      'physics.ao-ph',\n      'physics.app-ph',\n      'physics.atm-clus',\n      'physics.atom-ph',\n      'physics.bio-ph',\n      'physics.chem-ph',\n      'physics.class-ph',\n      'physics.comp-ph',\n      'physics.data-an',\n      'physics.ed-ph',\n      'physics.flu-dyn',\n      'physics.gen-ph',\n      'physics.geo-ph',\n      'physics.hist-ph',\n      'physics.ins-det',\n      'physics.med-ph',\n      'physics.optics',\n      'physics.plasm-ph',\n      'physics.pop-ph',\n      'physics.soc-ph',\n      'physics.space-ph',\n      'plasm-ph',\n      'q-alg',\n      'q-bio',\n      'q-bio.BM',\n      'q-bio.CB',\n      'q-bio.GN',\n      'q-bio.MN',\n      'q-bio.NC',\n      'q-bio.OT',\n      'q-bio.PE',\n      'q-bio.QM',\n      'q-bio.SC',\n      'q-bio.TO',\n      'q-fin.CP',\n      'q-fin.EC',\n      'q-fin.GN',\n      'q-fin.MF',\n      'q-fin.PM',\n      'q-fin.PR',\n      'q-fin.RM',\n      'q-fin.ST',\n      'q-fin.TR',\n      'quant-ph',\n      'solv-int',\n      'stat.AP',\n      'stat.CO',\n      'stat.ME',\n      'stat.ML',\n      'stat.OT',\n      'stat.TH',\n      'supr-con'})\n\n\n\n这里使用了 split 函数将多类别使用 “ ”（空格）分开，组成list，并使用 for 循环将独立出现的类别找出来，并使用 set 类别，将重复项去除得到最终所有的独立paper种类。\n\n从以上结果发现，共有176种论文种类，比我们直接从 [https://arxiv.org/help/api/user-manual](https://arxiv.org/help/api/user-manual)  的 5.3 小节的 Subject Classifications 的部分或 [https://arxiv.org/category_taxonomy](https://arxiv.org/category_taxonomy)中的到的类别少，这说明存在一些官网上没有的类别，这是一个小细节。不过对于我们的计算机方向的论文没有影响，依然是以下的40个类别，我们从原数据中提取的和从官网的到的种类是可以一一对应的。\n\n我们的任务要求对于2019年以后的paper进行分析，所以首先对于时间特征进行预处理，从而得到2019年以后的所有种类的论文：\n\n\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">df[<span class=\"string\">\"year\"</span>] = pd.to_datetime(df[<span class=\"string\">\"update_date\"</span>]).dt.year <span class=\"comment\">#将update_date从例如2019-02-20的str变为datetime格式，并提取处year</span></span><br><span class=\"line\"><span class=\"keyword\">del</span> df[<span class=\"string\">\"update_date\"</span>] <span class=\"comment\">#删除 update_date特征，其使命已完成</span></span><br><span class=\"line\">df = df[df[<span class=\"string\">\"year\"</span>] &gt;= <span class=\"number\">2019</span>] <span class=\"comment\">#找出 year 中2019年以后的数据，并将其他数据删除</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># data.groupby(['categories','year']) #以 categories 进行排序，如果同一个categories 相同则使用 year 特征进行排序</span></span><br><span class=\"line\">df.reset_index(drop=<span class=\"literal\">True</span>, inplace=<span class=\"literal\">True</span>) <span class=\"comment\">#重新编号</span></span><br><span class=\"line\">df <span class=\"comment\">#查看结果</span></span><br></pre></td></tr></table></figure>\n\n\n\n\n<div>\n\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>categories</th>\n      <th>year</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0704.0297</td>\n      <td>astro-ph</td>\n      <td>2019</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0704.0342</td>\n      <td>math.AT</td>\n      <td>2019</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0704.0360</td>\n      <td>astro-ph</td>\n      <td>2019</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0704.0525</td>\n      <td>gr-qc</td>\n      <td>2019</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0704.0535</td>\n      <td>astro-ph</td>\n      <td>2019</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>395118</th>\n      <td>quant-ph/9911051</td>\n      <td>quant-ph</td>\n      <td>2020</td>\n    </tr>\n    <tr>\n      <th>395119</th>\n      <td>solv-int/9511005</td>\n      <td>solv-int nlin.SI</td>\n      <td>2019</td>\n    </tr>\n    <tr>\n      <th>395120</th>\n      <td>solv-int/9809008</td>\n      <td>solv-int nlin.SI</td>\n      <td>2019</td>\n    </tr>\n    <tr>\n      <th>395121</th>\n      <td>solv-int/9909010</td>\n      <td>solv-int adap-org hep-th nlin.AO nlin.SI</td>\n      <td>2019</td>\n    </tr>\n    <tr>\n      <th>395122</th>\n      <td>solv-int/9909014</td>\n      <td>solv-int nlin.SI</td>\n      <td>2019</td>\n    </tr>\n  </tbody>\n</table>\n<p>395123 rows × 3 columns</p>\n\n\n\n\n这里我们就已经得到了所有2019年以后的论文，下面我们挑选出计算机领域内的所有文章：\n\n\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">#爬取所有的类别</span></span><br><span class=\"line\">website_url = requests.get(<span class=\"string\">'https://arxiv.org/category_taxonomy'</span>).text <span class=\"comment\">#获取网页的文本数据</span></span><br><span class=\"line\">soup = BeautifulSoup(website_url,<span class=\"string\">'lxml'</span>) <span class=\"comment\">#爬取数据，这里使用lxml的解析器，加速</span></span><br><span class=\"line\">root = soup.find(<span class=\"string\">'div'</span>,&#123;<span class=\"string\">'id'</span>:<span class=\"string\">'category_taxonomy_list'</span>&#125;) <span class=\"comment\">#找出 BeautifulSoup 对应的标签入口</span></span><br><span class=\"line\">tags = root.find_all([<span class=\"string\">\"h2\"</span>,<span class=\"string\">\"h3\"</span>,<span class=\"string\">\"h4\"</span>,<span class=\"string\">\"p\"</span>], recursive=<span class=\"literal\">True</span>) <span class=\"comment\">#读取 tags</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">#初始化 str 和 list 变量</span></span><br><span class=\"line\">level_1_name = <span class=\"string\">\"\"</span></span><br><span class=\"line\">level_2_name = <span class=\"string\">\"\"</span></span><br><span class=\"line\">level_2_code = <span class=\"string\">\"\"</span></span><br><span class=\"line\">level_1_names = []</span><br><span class=\"line\">level_2_codes = []</span><br><span class=\"line\">level_2_names = []</span><br><span class=\"line\">level_3_codes = []</span><br><span class=\"line\">level_3_names = []</span><br><span class=\"line\">level_3_notes = []</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">#进行</span></span><br><span class=\"line\"><span class=\"keyword\">for</span> t <span class=\"keyword\">in</span> tags:</span><br><span class=\"line\">    <span class=\"keyword\">if</span> t.name == <span class=\"string\">\"h2\"</span>:</span><br><span class=\"line\">        level_1_name = t.text    </span><br><span class=\"line\">        level_2_code = t.text</span><br><span class=\"line\">        level_2_name = t.text</span><br><span class=\"line\">    <span class=\"keyword\">elif</span> t.name == <span class=\"string\">\"h3\"</span>:</span><br><span class=\"line\">        raw = t.text</span><br><span class=\"line\">        level_2_code = re.sub(<span class=\"string\">r\"(.*)\\((.*)\\)\"</span>,<span class=\"string\">r\"\\2\"</span>,raw) <span class=\"comment\">#正则表达式：模式字符串：(.*)\\((.*)\\)；被替换字符串\"\\2\"；被处理字符串：raw</span></span><br><span class=\"line\">        level_2_name = re.sub(<span class=\"string\">r\"(.*)\\((.*)\\)\"</span>,<span class=\"string\">r\"\\1\"</span>,raw)</span><br><span class=\"line\">    <span class=\"keyword\">elif</span> t.name == <span class=\"string\">\"h4\"</span>:</span><br><span class=\"line\">        raw = t.text</span><br><span class=\"line\">        level_3_code = re.sub(<span class=\"string\">r\"(.*) \\((.*)\\)\"</span>,<span class=\"string\">r\"\\1\"</span>,raw)</span><br><span class=\"line\">        level_3_name = re.sub(<span class=\"string\">r\"(.*) \\((.*)\\)\"</span>,<span class=\"string\">r\"\\2\"</span>,raw)</span><br><span class=\"line\">    <span class=\"keyword\">elif</span> t.name == <span class=\"string\">\"p\"</span>:</span><br><span class=\"line\">        notes = t.text</span><br><span class=\"line\">        level_1_names.append(level_1_name)</span><br><span class=\"line\">        level_2_names.append(level_2_name)</span><br><span class=\"line\">        level_2_codes.append(level_2_code)</span><br><span class=\"line\">        level_3_names.append(level_3_name)</span><br><span class=\"line\">        level_3_codes.append(level_3_code)</span><br><span class=\"line\">        level_3_notes.append(notes)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">#根据以上信息生成dataframe格式的数据</span></span><br><span class=\"line\">df_taxonomy = pd.DataFrame(&#123;</span><br><span class=\"line\">    <span class=\"string\">'group_name'</span> : level_1_names,</span><br><span class=\"line\">    <span class=\"string\">'archive_name'</span> : level_2_names,</span><br><span class=\"line\">    <span class=\"string\">'archive_id'</span> : level_2_codes,</span><br><span class=\"line\">    <span class=\"string\">'category_name'</span> : level_3_names,</span><br><span class=\"line\">    <span class=\"string\">'categories'</span> : level_3_codes,</span><br><span class=\"line\">    <span class=\"string\">'category_description'</span>: level_3_notes</span><br><span class=\"line\">    </span><br><span class=\"line\">&#125;)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">#按照 \"group_name\" 进行分组，在组内使用 \"archive_name\" 进行排序</span></span><br><span class=\"line\">df_taxonomy.groupby([<span class=\"string\">\"group_name\"</span>,<span class=\"string\">\"archive_name\"</span>])</span><br><span class=\"line\">df_taxonomy</span><br></pre></td></tr></table></figure>\n\n\n\n\n<div>\n\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>archive_id</th>\n      <th>archive_name</th>\n      <th>categories</th>\n      <th>category_description</th>\n      <th>category_name</th>\n      <th>group_name</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Computer Science</td>\n      <td>Computer Science</td>\n      <td>cs.AI</td>\n      <td>Covers all areas of AI except Vision, Robotics...</td>\n      <td>Artificial Intelligence</td>\n      <td>Computer Science</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Computer Science</td>\n      <td>Computer Science</td>\n      <td>cs.AR</td>\n      <td>Covers systems organization and hardware archi...</td>\n      <td>Hardware Architecture</td>\n      <td>Computer Science</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Computer Science</td>\n      <td>Computer Science</td>\n      <td>cs.CC</td>\n      <td>Covers models of computation, complexity class...</td>\n      <td>Computational Complexity</td>\n      <td>Computer Science</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Computer Science</td>\n      <td>Computer Science</td>\n      <td>cs.CE</td>\n      <td>Covers applications of computer science to the...</td>\n      <td>Computational Engineering, Finance, and Science</td>\n      <td>Computer Science</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Computer Science</td>\n      <td>Computer Science</td>\n      <td>cs.CG</td>\n      <td>Roughly includes material in ACM Subject Class...</td>\n      <td>Computational Geometry</td>\n      <td>Computer Science</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>150</th>\n      <td>Statistics</td>\n      <td>Statistics</td>\n      <td>stat.CO</td>\n      <td>Algorithms, Simulation, Visualization</td>\n      <td>Computation</td>\n      <td>Statistics</td>\n    </tr>\n    <tr>\n      <th>151</th>\n      <td>Statistics</td>\n      <td>Statistics</td>\n      <td>stat.ME</td>\n      <td>Design, Surveys, Model Selection, Multiple Tes...</td>\n      <td>Methodology</td>\n      <td>Statistics</td>\n    </tr>\n    <tr>\n      <th>152</th>\n      <td>Statistics</td>\n      <td>Statistics</td>\n      <td>stat.ML</td>\n      <td>Covers machine learning papers (supervised, un...</td>\n      <td>Machine Learning</td>\n      <td>Statistics</td>\n    </tr>\n    <tr>\n      <th>153</th>\n      <td>Statistics</td>\n      <td>Statistics</td>\n      <td>stat.OT</td>\n      <td>Work in statistics that does not fit into the ...</td>\n      <td>Other Statistics</td>\n      <td>Statistics</td>\n    </tr>\n    <tr>\n      <th>154</th>\n      <td>Statistics</td>\n      <td>Statistics</td>\n      <td>stat.TH</td>\n      <td>stat.TH is an alias for math.ST. Asymptotics, ...</td>\n      <td>Statistics Theory</td>\n      <td>Statistics</td>\n    </tr>\n  </tbody>\n</table>\n<p>155 rows × 6 columns</p>\n\n\n\n\n这里主要说明一下上面代码中的正则操作，这里我们使用re.sub来用于替换字符串中的匹配项\n\n- pattern : 正则中的模式字符串。\n- repl : 替换的字符串，也可为一个函数。\n- string : 要被查找替换的原始字符串。\n- count : 模式匹配后替换的最大次数，默认 0 表示替换所有的匹配。\n- flags : 编译时用的匹配模式，数字形式。\n- 其中pattern、repl、string为必选参数\n\nre.sub(pattern, repl, string, count=0, flags=0)\n\n实例如下：\n\n\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> re</span><br><span class=\"line\"></span><br><span class=\"line\">phone = <span class=\"string\">\"2004-959-559 # 这是一个电话号码\"</span></span><br><span class=\"line\"> </span><br><span class=\"line\"><span class=\"comment\"># 删除注释</span></span><br><span class=\"line\">num = re.sub(<span class=\"string\">r'#.*$'</span>, <span class=\"string\">\"\"</span>, phone)</span><br><span class=\"line\"><span class=\"keyword\">print</span> (<span class=\"string\">\"电话号码 : \"</span>, num)</span><br><span class=\"line\"> </span><br><span class=\"line\"><span class=\"comment\"># 移除非数字的内容</span></span><br><span class=\"line\">num = re.sub(<span class=\"string\">r'\\D'</span>, <span class=\"string\">\"\"</span>, phone)</span><br><span class=\"line\"><span class=\"keyword\">print</span> (<span class=\"string\">\"电话号码 : \"</span>, num)</span><br></pre></td></tr></table></figure>\n\n    电话号码 :  2004-959-559 \n    电话号码 :  2004959559\n\n\n详细了解可以参考：[https://www.runoob.com/python3/python3-reg-expressions.html](https://www.runoob.com/python3/python3-reg-expressions.html)\n\n对于我们的代码来说：\n\n\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">re.sub(<span class=\"string\">r\"(.*)\\((.*)\\)\"</span>,<span class=\"string\">r\"\\2\"</span>, <span class=\"string\">\" Astrophysics(astro-ph)\"</span>)</span><br></pre></td></tr></table></figure>\n\n\n\n\n    'astro-ph'\n\n\n\n对应的参数\n\n- 正则中的模式字符串 pattern 的格式为 “任意字符” + “(” + \"任意字符\" + \")\"。\n- 替换的字符串 repl 为第2个分组的内容。\n- 要被查找替换的原始字符串 string 为原始的爬取的数据。\n\n这里推荐大家一个在线正则表达式测试的网站：[https://tool.oschina.net/regex/](https://tool.oschina.net/regex/)\n\n### 数据分析及可视化\n\n接下来我们首先看一下所有大类的paper数量分布：\n\n我们使用merge函数，以两个dataframe共同的属性 “categories” 进行合并，并以 “group_name” 作为类别进行统计，统计结果放入 “id” 列中并排序。\n\n\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># drop_duplicates去重</span></span><br><span class=\"line\">_df = df.merge(df_taxonomy, on=<span class=\"string\">\"categories\"</span>, how=<span class=\"string\">\"left\"</span>).drop_duplicates([<span class=\"string\">\"id\"</span>,<span class=\"string\">\"group_name\"</span>]).groupby(<span class=\"string\">\"group_name\"</span>).agg(&#123;<span class=\"string\">\"id\"</span>:<span class=\"string\">\"count\"</span>&#125;).sort_values(by=<span class=\"string\">\"id\"</span>,ascending=<span class=\"literal\">False</span>).reset_index()</span><br><span class=\"line\"></span><br><span class=\"line\">_df</span><br></pre></td></tr></table></figure>\n\n\n\n\n<div>\n\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>group_name</th>\n      <th>id</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Physics</td>\n      <td>79985</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Mathematics</td>\n      <td>51567</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Computer Science</td>\n      <td>40067</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Statistics</td>\n      <td>4054</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Electrical Engineering and Systems Science</td>\n      <td>3297</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>Quantitative Biology</td>\n      <td>1994</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>Quantitative Finance</td>\n      <td>826</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>Economics</td>\n      <td>576</td>\n    </tr>\n  </tbody>\n</table>\n\n\n\n\n\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 使用饼图进行上图结果的可视化：</span></span><br><span class=\"line\">fig = plt.figure(figsize=(<span class=\"number\">15</span>,<span class=\"number\">12</span>))</span><br><span class=\"line\">explode = (<span class=\"number\">0</span>, <span class=\"number\">0</span>, <span class=\"number\">0</span>, <span class=\"number\">0.2</span>, <span class=\"number\">0.3</span>, <span class=\"number\">0.3</span>, <span class=\"number\">0.2</span>, <span class=\"number\">0.1</span>) </span><br><span class=\"line\">plt.pie(_df[<span class=\"string\">\"id\"</span>],  labels=_df[<span class=\"string\">\"group_name\"</span>], autopct=<span class=\"string\">'%1.2f%%'</span>, startangle=<span class=\"number\">160</span>, explode=explode)</span><br><span class=\"line\">plt.tight_layout()</span><br><span class=\"line\">plt.show()</span><br></pre></td></tr></table></figure>\n<p><img src=\"/articles/Task1/output_39_0.png\" alt></p>\n<p>plt.pie参数说明：参考<a href=\"https://matplotlib.org/api/_as_gen/matplotlib.pyplot.pie.html?highlight=pie#matplotlib.pyplot.pie\" target=\"_blank\" rel=\"noopener\">官方文档</a></p>\n<p>下面统计在计算机各个子领域2019年后的paper数量，我们同样使用 merge 函数，对于两个dataframe 共同的特征 categories  进行合并并且进行查询。然后我们再对于数据进行统计和排序从而得到以下的结果：</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">group_name = <span class=\"string\">\"Computer Science\"</span></span><br><span class=\"line\">cats = df.merge(df_taxonomy,</span><br><span class=\"line\">                  on=<span class=\"string\">\"categories\"</span>).query(<span class=\"string\">\"group_name == @group_name\"</span>)</span><br><span class=\"line\">cats.groupby([<span class=\"string\">\"year\"</span>, <span class=\"string\">\"category_name\"</span></span><br><span class=\"line\">              ]).count().reset_index().pivot(index=<span class=\"string\">\"category_name\"</span>,</span><br><span class=\"line\">                                             columns=<span class=\"string\">\"year\"</span>,</span><br><span class=\"line\">                                             values=<span class=\"string\">\"id\"</span>)</span><br></pre></td></tr></table></figure>\n<div>\n\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th>year</th>\n      <th>2019</th>\n      <th>2020</th>\n    </tr>\n    <tr>\n      <th>category_name</th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>Artificial Intelligence</th>\n      <td>558</td>\n      <td>757</td>\n    </tr>\n    <tr>\n      <th>Computation and Language</th>\n      <td>2153</td>\n      <td>2906</td>\n    </tr>\n    <tr>\n      <th>Computational Complexity</th>\n      <td>131</td>\n      <td>188</td>\n    </tr>\n    <tr>\n      <th>Computational Engineering, Finance, and Science</th>\n      <td>108</td>\n      <td>205</td>\n    </tr>\n    <tr>\n      <th>Computational Geometry</th>\n      <td>199</td>\n      <td>216</td>\n    </tr>\n    <tr>\n      <th>Computer Science and Game Theory</th>\n      <td>281</td>\n      <td>323</td>\n    </tr>\n    <tr>\n      <th>Computer Vision and Pattern Recognition</th>\n      <td>5559</td>\n      <td>6517</td>\n    </tr>\n    <tr>\n      <th>Computers and Society</th>\n      <td>346</td>\n      <td>564</td>\n    </tr>\n    <tr>\n      <th>Cryptography and Security</th>\n      <td>1067</td>\n      <td>1238</td>\n    </tr>\n    <tr>\n      <th>Data Structures and Algorithms</th>\n      <td>711</td>\n      <td>902</td>\n    </tr>\n    <tr>\n      <th>Databases</th>\n      <td>282</td>\n      <td>342</td>\n    </tr>\n    <tr>\n      <th>Digital Libraries</th>\n      <td>125</td>\n      <td>157</td>\n    </tr>\n    <tr>\n      <th>Discrete Mathematics</th>\n      <td>84</td>\n      <td>81</td>\n    </tr>\n    <tr>\n      <th>Distributed, Parallel, and Cluster Computing</th>\n      <td>715</td>\n      <td>774</td>\n    </tr>\n    <tr>\n      <th>Emerging Technologies</th>\n      <td>101</td>\n      <td>84</td>\n    </tr>\n    <tr>\n      <th>Formal Languages and Automata Theory</th>\n      <td>152</td>\n      <td>137</td>\n    </tr>\n    <tr>\n      <th>General Literature</th>\n      <td>5</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>Graphics</th>\n      <td>116</td>\n      <td>151</td>\n    </tr>\n    <tr>\n      <th>Hardware Architecture</th>\n      <td>95</td>\n      <td>159</td>\n    </tr>\n    <tr>\n      <th>Human-Computer Interaction</th>\n      <td>420</td>\n      <td>580</td>\n    </tr>\n    <tr>\n      <th>Information Retrieval</th>\n      <td>245</td>\n      <td>331</td>\n    </tr>\n    <tr>\n      <th>Logic in Computer Science</th>\n      <td>470</td>\n      <td>504</td>\n    </tr>\n    <tr>\n      <th>Machine Learning</th>\n      <td>177</td>\n      <td>538</td>\n    </tr>\n    <tr>\n      <th>Mathematical Software</th>\n      <td>27</td>\n      <td>45</td>\n    </tr>\n    <tr>\n      <th>Multiagent Systems</th>\n      <td>85</td>\n      <td>90</td>\n    </tr>\n    <tr>\n      <th>Multimedia</th>\n      <td>76</td>\n      <td>66</td>\n    </tr>\n    <tr>\n      <th>Networking and Internet Architecture</th>\n      <td>864</td>\n      <td>783</td>\n    </tr>\n    <tr>\n      <th>Neural and Evolutionary Computing</th>\n      <td>235</td>\n      <td>279</td>\n    </tr>\n    <tr>\n      <th>Numerical Analysis</th>\n      <td>40</td>\n      <td>11</td>\n    </tr>\n    <tr>\n      <th>Operating Systems</th>\n      <td>36</td>\n      <td>33</td>\n    </tr>\n    <tr>\n      <th>Other Computer Science</th>\n      <td>67</td>\n      <td>69</td>\n    </tr>\n    <tr>\n      <th>Performance</th>\n      <td>45</td>\n      <td>51</td>\n    </tr>\n    <tr>\n      <th>Programming Languages</th>\n      <td>268</td>\n      <td>294</td>\n    </tr>\n    <tr>\n      <th>Robotics</th>\n      <td>917</td>\n      <td>1298</td>\n    </tr>\n    <tr>\n      <th>Social and Information Networks</th>\n      <td>202</td>\n      <td>325</td>\n    </tr>\n    <tr>\n      <th>Software Engineering</th>\n      <td>659</td>\n      <td>804</td>\n    </tr>\n    <tr>\n      <th>Sound</th>\n      <td>7</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>Symbolic Computation</th>\n      <td>44</td>\n      <td>36</td>\n    </tr>\n    <tr>\n      <th>Systems and Control</th>\n      <td>415</td>\n      <td>133</td>\n    </tr>\n  </tbody>\n</table>\n\n\n\n\n<p>我们可以从结果看出，Computer Vision and Pattern Recognition（计算机视觉与模式识别）类是CS中paper数量最多的子类，遥遥领先于其他的CS子类，并且paper的数量还在逐年增加；另外，Computation and Language（计算与语言）、Cryptography and Security（密码学与安全）以及 Robotics（机器人学）的2019年paper数量均超过1000或接近1000，这与我们的认知是一致的。</p>\n</div></div></div></div></div>","categories":[],"tags":["data analysis"]},{"title":"Algorithm","url":"https://hahally.github.io//articles/Algorithm/","content":"<blockquote>\n<p>2015年  题3</p>\n</blockquote>\n<figure class=\"highlight c\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span><span class=\"meta-string\">&lt;stdio.h&gt;</span></span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">define</span> ElemType int</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">// 调整大根堆</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">HeapAjust</span><span class=\"params\">(ElemType A[], <span class=\"keyword\">int</span> k, <span class=\"keyword\">int</span> len)</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">int</span> i;</span><br><span class=\"line\">    A[<span class=\"number\">0</span>] = A[k];</span><br><span class=\"line\">    <span class=\"keyword\">for</span>(i=<span class=\"number\">2</span>*k;i&lt;=len;i*=<span class=\"number\">2</span>)&#123;</span><br><span class=\"line\">        <span class=\"keyword\">if</span>(i&lt;len&amp;&amp;A[i]&lt;A[i+<span class=\"number\">1</span>]) i++;</span><br><span class=\"line\">        <span class=\"keyword\">if</span>(A[<span class=\"number\">0</span>]&gt;=A[i]) <span class=\"keyword\">break</span>;</span><br><span class=\"line\">        <span class=\"keyword\">else</span>&#123;</span><br><span class=\"line\">            A[k] = A[i];</span><br><span class=\"line\">            k = i;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    A[k] = A[<span class=\"number\">0</span>];</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">// 建立大根堆</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">BuildMaxHeap</span><span class=\"params\">(ElemType A[], <span class=\"keyword\">int</span> len)</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">int</span> i = len/<span class=\"number\">2</span>;</span><br><span class=\"line\">    <span class=\"keyword\">for</span>(;i&gt;<span class=\"number\">0</span>;i--)&#123;</span><br><span class=\"line\">        HeapAjust(A,i,len);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">// 堆排序</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">HeapSort</span><span class=\"params\">(ElemType A[],<span class=\"keyword\">int</span> len,<span class=\"keyword\">int</span> n)</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">int</span> i;</span><br><span class=\"line\">    <span class=\"keyword\">int</span> topn = <span class=\"number\">0</span>;</span><br><span class=\"line\"></span><br><span class=\"line\">    ElemType temp;</span><br><span class=\"line\">    BuildMaxHeap(A,len);</span><br><span class=\"line\">    <span class=\"keyword\">for</span>(i = len;i&gt;=<span class=\"number\">1</span>;i--)&#123;</span><br><span class=\"line\">        <span class=\"comment\">// Swap(A[i],A[1]);</span></span><br><span class=\"line\">        topn++;</span><br><span class=\"line\">        <span class=\"keyword\">if</span>(topn&lt;=n) <span class=\"built_in\">printf</span>(<span class=\"string\">\"%d\\t\"</span>,A[<span class=\"number\">1</span>]);</span><br><span class=\"line\"></span><br><span class=\"line\">        temp = A[i];</span><br><span class=\"line\">        A[i] = A[<span class=\"number\">1</span>];</span><br><span class=\"line\">        A[<span class=\"number\">1</span>] = temp;</span><br><span class=\"line\"></span><br><span class=\"line\">        HeapAjust(A,<span class=\"number\">1</span>,i<span class=\"number\">-1</span>);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">main</span><span class=\"params\">()</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">int</span> len = <span class=\"number\">10</span>;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">// A[0] 存储长度</span></span><br><span class=\"line\">    ElemType A[] = &#123;<span class=\"number\">10</span>,<span class=\"number\">1</span>,<span class=\"number\">2</span>,<span class=\"number\">3</span>,<span class=\"number\">4</span>,<span class=\"number\">5</span>,<span class=\"number\">6</span>,<span class=\"number\">7</span>,<span class=\"number\">8</span>,<span class=\"number\">9</span>,<span class=\"number\">10</span>&#125;;</span><br><span class=\"line\">    HeapSort(A,len,<span class=\"number\">5</span>);</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<blockquote>\n<p>2015年 题1</p>\n</blockquote>\n<figure class=\"highlight c\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span><span class=\"meta-string\">&lt;stdio.h&gt;</span></span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">define</span> MaxSize 50</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">define</span> ElemType int</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">typedef</span> <span class=\"class\"><span class=\"keyword\">struct</span>&#123;</span></span><br><span class=\"line\">    ElemType data[MaxSize];</span><br><span class=\"line\">    <span class=\"keyword\">int</span> top;</span><br><span class=\"line\">&#125;SqStack;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">// 初始化</span></span><br><span class=\"line\"><span class=\"function\">SqStack <span class=\"title\">InitStack</span><span class=\"params\">(SqStack s)</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">    s.top = <span class=\"number\">-1</span>;</span><br><span class=\"line\">    <span class=\"keyword\">return</span> s;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">// 判栈空</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">IsEmptyStack</span><span class=\"params\">(SqStack s)</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">if</span> (s.top == <span class=\"number\">-1</span>) <span class=\"keyword\">return</span> <span class=\"number\">1</span>;</span><br><span class=\"line\">    <span class=\"keyword\">else</span> <span class=\"keyword\">return</span> <span class=\"number\">0</span>;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">// 进栈</span></span><br><span class=\"line\"><span class=\"function\">SqStack <span class=\"title\">Push</span><span class=\"params\">(SqStack s, ElemType e)</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">if</span> (s.top == MaxSize - <span class=\"number\">1</span>);</span><br><span class=\"line\">    <span class=\"keyword\">else</span> s.data[++s.top] = e;</span><br><span class=\"line\">    <span class=\"keyword\">return</span> s;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">// 出栈</span></span><br><span class=\"line\"><span class=\"function\">ElemType <span class=\"title\">Pop</span><span class=\"params\">(SqStack *s)</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">    ElemType e;</span><br><span class=\"line\">    <span class=\"keyword\">if</span> (s-&gt;top == <span class=\"number\">-1</span>) <span class=\"built_in\">printf</span>(<span class=\"string\">\"栈空\\n\"</span>);</span><br><span class=\"line\">    <span class=\"keyword\">else</span> e = s-&gt;data[s-&gt;top--];</span><br><span class=\"line\">    <span class=\"keyword\">return</span> e;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">// 进制转换</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">Conversion</span><span class=\"params\">()</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">    SqStack s;</span><br><span class=\"line\">    ElemType e;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">int</span> N;</span><br><span class=\"line\"></span><br><span class=\"line\">    s = InitStack(s);</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"built_in\">scanf</span>(<span class=\"string\">\"%d\"</span>,&amp;N);</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">while</span>(N!=<span class=\"number\">0</span>)&#123;</span><br><span class=\"line\">        s = Push(s,N%<span class=\"number\">8</span>);</span><br><span class=\"line\">        N = N/<span class=\"number\">8</span>;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">while</span>(IsEmptyStack(s)==<span class=\"number\">0</span>)&#123;</span><br><span class=\"line\">        e = Pop(&amp;s);</span><br><span class=\"line\">        <span class=\"built_in\">printf</span>(<span class=\"string\">\"%d\"</span>,e);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">main</span><span class=\"params\">()</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">    Conversion();</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">return</span> <span class=\"number\">0</span>;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<blockquote>\n<p>2015 题2</p>\n</blockquote>\n<figure class=\"highlight c\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span><span class=\"meta-string\">&lt;stdio.h&gt;</span></span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span><span class=\"meta-string\">&lt;malloc.h&gt;</span></span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">typedef</span> <span class=\"class\"><span class=\"keyword\">struct</span> <span class=\"title\">BiTNode</span>&#123;</span></span><br><span class=\"line\">    <span class=\"keyword\">int</span> data;</span><br><span class=\"line\">    <span class=\"class\"><span class=\"keyword\">struct</span> <span class=\"title\">BiTNode</span> *<span class=\"title\">lchild</span>,*<span class=\"title\">rchild</span>;</span></span><br><span class=\"line\">&#125;BiTNode,*BiTree;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\">BiTree <span class=\"title\">CreatBiTree</span><span class=\"params\">(BiTree T)</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">int</span> ch;</span><br><span class=\"line\">    <span class=\"built_in\">scanf</span>(<span class=\"string\">\"%d\"</span>,&amp;ch);</span><br><span class=\"line\">    <span class=\"keyword\">if</span>(ch==<span class=\"number\">0</span>) T=<span class=\"literal\">NULL</span>;</span><br><span class=\"line\">    <span class=\"keyword\">else</span>&#123;</span><br><span class=\"line\">        T = (BiTree)<span class=\"built_in\">malloc</span>(<span class=\"keyword\">sizeof</span>(BiTNode));</span><br><span class=\"line\">        T-&gt;data = ch;</span><br><span class=\"line\">        T-&gt;lchild = CreatBiTree(T-&gt;lchild);</span><br><span class=\"line\">        T-&gt;rchild = CreatBiTree(T-&gt;rchild);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    <span class=\"keyword\">return</span> T;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">PreOrder</span><span class=\"params\">(BiTree T)</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;  <span class=\"comment\">//前序遍历二叉树bt</span></span><br><span class=\"line\">    <span class=\"keyword\">if</span>(T)</span><br><span class=\"line\">    &#123;</span><br><span class=\"line\">    <span class=\"built_in\">printf</span>(<span class=\"string\">\"%d\"</span>,T-&gt;data);                <span class=\"comment\">//访问节点的数据域</span></span><br><span class=\"line\">    PreOrder(T-&gt;lchild);                 <span class=\"comment\">//前序遍历bt的左子树</span></span><br><span class=\"line\">    PreOrder(T-&gt;rchild);                 <span class=\"comment\">//前序遍历bt的右子树</span></span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">InOrder</span><span class=\"params\">(BiTree T)</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">if</span>(T!=<span class=\"literal\">NULL</span>)&#123;</span><br><span class=\"line\">        InOrder(T-&gt;lchild);</span><br><span class=\"line\">        <span class=\"built_in\">printf</span>(<span class=\"string\">\"%d\"</span>,T-&gt;data);</span><br><span class=\"line\">        InOrder(T-&gt;rchild);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">PostOrder</span><span class=\"params\">(BiTree T)</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">if</span>(T!=<span class=\"literal\">NULL</span>)&#123;</span><br><span class=\"line\">        InOrder(T-&gt;lchild);</span><br><span class=\"line\">        InOrder(T-&gt;rchild);</span><br><span class=\"line\">        <span class=\"built_in\">printf</span>(<span class=\"string\">\"%d\"</span>,T-&gt;data);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\">BiTree <span class=\"title\">Destroy</span><span class=\"params\">(BiTree T)</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">if</span>(T!=<span class=\"literal\">NULL</span>)&#123;</span><br><span class=\"line\">        Destroy(T-&gt;lchild);</span><br><span class=\"line\">        Destroy(T-&gt;rchild);</span><br><span class=\"line\">        <span class=\"built_in\">free</span>(T);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    <span class=\"keyword\">return</span> T;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">main</span><span class=\"params\">()</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">    BiTree T;</span><br><span class=\"line\">    T = CreatBiTree(T);</span><br><span class=\"line\">    PreOrder(T);</span><br><span class=\"line\">    InOrder(T);</span><br><span class=\"line\">    PostOrder(T);</span><br><span class=\"line\">    T = Destroy(T);</span><br><span class=\"line\">    <span class=\"keyword\">if</span>(T) <span class=\"built_in\">printf</span>(<span class=\"string\">\"空\"</span>);</span><br><span class=\"line\">    <span class=\"keyword\">return</span> <span class=\"number\">0</span>;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<blockquote>\n<p>2017 题1</p>\n</blockquote>\n<figure class=\"highlight c\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br><span class=\"line\">77</span><br><span class=\"line\">78</span><br><span class=\"line\">79</span><br><span class=\"line\">80</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span><span class=\"meta-string\">&lt;stdio.h&gt;</span></span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span><span class=\"meta-string\">&lt;malloc.h&gt;</span></span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">/**</span></span><br><span class=\"line\"><span class=\"comment\">判断回文</span></span><br><span class=\"line\"><span class=\"comment\">*/</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">define</span> ElemType char</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">typedef</span> <span class=\"class\"><span class=\"keyword\">struct</span> <span class=\"title\">LNode</span>&#123;</span></span><br><span class=\"line\">    ElemType data;</span><br><span class=\"line\">    <span class=\"class\"><span class=\"keyword\">struct</span> <span class=\"title\">LNode</span> *<span class=\"title\">next</span>;</span></span><br><span class=\"line\">&#125;LNode,*LinkList;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">// 尾插法</span></span><br><span class=\"line\"><span class=\"function\">LinkList <span class=\"title\">List_TaiInsert</span><span class=\"params\">(LinkList L)</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">char</span> ch;</span><br><span class=\"line\">    LNode *s;</span><br><span class=\"line\">    LNode *r;</span><br><span class=\"line\">    L = (LinkList)<span class=\"built_in\">malloc</span>(<span class=\"keyword\">sizeof</span>(LNode));</span><br><span class=\"line\">    r = L;</span><br><span class=\"line\">    <span class=\"built_in\">scanf</span>(<span class=\"string\">\"%c\"</span>,&amp;ch);</span><br><span class=\"line\">    <span class=\"keyword\">while</span>(ch!=<span class=\"string\">'\\n'</span>)&#123;</span><br><span class=\"line\">        s = (LNode *)<span class=\"built_in\">malloc</span>(<span class=\"keyword\">sizeof</span>(LNode));</span><br><span class=\"line\">        s-&gt;data = ch;</span><br><span class=\"line\">        r-&gt;next = s;</span><br><span class=\"line\">        r = s;</span><br><span class=\"line\">        <span class=\"built_in\">scanf</span>(<span class=\"string\">\"%c\"</span>,&amp;ch);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    r-&gt;next = <span class=\"literal\">NULL</span>;</span><br><span class=\"line\">    <span class=\"keyword\">return</span> L;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">GetLen</span><span class=\"params\">(LinkList L)</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">int</span> len = <span class=\"number\">0</span>;</span><br><span class=\"line\">    <span class=\"keyword\">while</span>(L-&gt;next)&#123;</span><br><span class=\"line\">        len++;</span><br><span class=\"line\">        L = L-&gt;next;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    <span class=\"keyword\">return</span> len;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\">LNode *<span class=\"title\">GetElem</span><span class=\"params\">(LinkList L,<span class=\"keyword\">int</span> i)</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">int</span> j = <span class=\"number\">0</span>;</span><br><span class=\"line\">    LNode *p = L;</span><br><span class=\"line\">    <span class=\"keyword\">if</span>(i&lt;<span class=\"number\">1</span>||i&gt;GetLen(p)) <span class=\"keyword\">return</span> <span class=\"literal\">NULL</span>;</span><br><span class=\"line\">    <span class=\"keyword\">while</span>(j&lt;i)&#123;</span><br><span class=\"line\">        p = p-&gt;next;</span><br><span class=\"line\">        j++;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    <span class=\"keyword\">return</span> p;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">check</span><span class=\"params\">(LinkList L)</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">int</span> i,len;</span><br><span class=\"line\">    len = GetLen(L);</span><br><span class=\"line\">    LNode *p,*s;</span><br><span class=\"line\">    <span class=\"keyword\">for</span>(i=<span class=\"number\">1</span>;i&lt;=len/<span class=\"number\">2</span>;i++)&#123;</span><br><span class=\"line\">        p = GetElem(L,i);</span><br><span class=\"line\">        s = GetElem(L,len-i+<span class=\"number\">1</span>);</span><br><span class=\"line\">        <span class=\"keyword\">if</span>(p-&gt;data!=s-&gt;data) <span class=\"keyword\">return</span> <span class=\"number\">0</span>;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    <span class=\"keyword\">return</span> <span class=\"number\">1</span>;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">main</span><span class=\"params\">()</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">int</span> flag;</span><br><span class=\"line\">    LinkList L;</span><br><span class=\"line\">    L = List_TaiInsert(L);</span><br><span class=\"line\">    flag =check(L);</span><br><span class=\"line\">    <span class=\"keyword\">if</span>(flag) <span class=\"built_in\">printf</span>(<span class=\"string\">\"Yes\"</span>);</span><br><span class=\"line\">    <span class=\"keyword\">else</span> <span class=\"built_in\">printf</span>(<span class=\"string\">\"No\"</span>);</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">return</span> <span class=\"number\">0</span>;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<blockquote>\n<p>2016 题1</p>\n</blockquote>\n<figure class=\"highlight c\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br><span class=\"line\">77</span><br><span class=\"line\">78</span><br><span class=\"line\">79</span><br><span class=\"line\">80</span><br><span class=\"line\">81</span><br><span class=\"line\">82</span><br><span class=\"line\">83</span><br><span class=\"line\">84</span><br><span class=\"line\">85</span><br><span class=\"line\">86</span><br><span class=\"line\">87</span><br><span class=\"line\">88</span><br><span class=\"line\">89</span><br><span class=\"line\">90</span><br><span class=\"line\">91</span><br><span class=\"line\">92</span><br><span class=\"line\">93</span><br><span class=\"line\">94</span><br><span class=\"line\">95</span><br><span class=\"line\">96</span><br><span class=\"line\">97</span><br><span class=\"line\">98</span><br><span class=\"line\">99</span><br><span class=\"line\">100</span><br><span class=\"line\">101</span><br><span class=\"line\">102</span><br><span class=\"line\">103</span><br><span class=\"line\">104</span><br><span class=\"line\">105</span><br><span class=\"line\">106</span><br><span class=\"line\">107</span><br><span class=\"line\">108</span><br><span class=\"line\">109</span><br><span class=\"line\">110</span><br><span class=\"line\">111</span><br><span class=\"line\">112</span><br><span class=\"line\">113</span><br><span class=\"line\">114</span><br><span class=\"line\">115</span><br><span class=\"line\">116</span><br><span class=\"line\">117</span><br><span class=\"line\">118</span><br><span class=\"line\">119</span><br><span class=\"line\">120</span><br><span class=\"line\">121</span><br><span class=\"line\">122</span><br><span class=\"line\">123</span><br><span class=\"line\">124</span><br><span class=\"line\">125</span><br><span class=\"line\">126</span><br><span class=\"line\">127</span><br><span class=\"line\">128</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span><span class=\"meta-string\">&lt;stdio.h&gt;</span></span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span><span class=\"meta-string\">&lt;malloc.h&gt;</span></span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">define</span> MaxSize 50</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">define</span> ElemType char</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">typedef</span> <span class=\"class\"><span class=\"keyword\">struct</span> <span class=\"title\">QNode</span>&#123;</span></span><br><span class=\"line\">    ElemType data;</span><br><span class=\"line\">    <span class=\"class\"><span class=\"keyword\">struct</span> <span class=\"title\">QNode</span> *<span class=\"title\">next</span>;</span></span><br><span class=\"line\">&#125;QNode,*QueuePtr;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">typedef</span> <span class=\"class\"><span class=\"keyword\">struct</span></span></span><br><span class=\"line\"><span class=\"class\">&#123;</span></span><br><span class=\"line\">    QueuePtr front,rear;</span><br><span class=\"line\">&#125;LinkQueue;</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">typedef</span> <span class=\"class\"><span class=\"keyword\">struct</span>&#123;</span></span><br><span class=\"line\">    ElemType data[MaxSize];</span><br><span class=\"line\">    <span class=\"keyword\">int</span> top;</span><br><span class=\"line\">&#125;SqStack;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">// 初始化</span></span><br><span class=\"line\"><span class=\"function\">SqStack <span class=\"title\">InitStack</span><span class=\"params\">(SqStack s)</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">    s.top = <span class=\"number\">-1</span>;</span><br><span class=\"line\">    <span class=\"keyword\">return</span> s;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">// 判栈空</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">IsEmptyStack</span><span class=\"params\">(SqStack s)</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">if</span> (s.top == <span class=\"number\">-1</span>) <span class=\"keyword\">return</span> <span class=\"number\">1</span>;</span><br><span class=\"line\">    <span class=\"keyword\">else</span> <span class=\"keyword\">return</span> <span class=\"number\">0</span>;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">// 进栈</span></span><br><span class=\"line\"><span class=\"function\">SqStack <span class=\"title\">Push</span><span class=\"params\">(SqStack s, ElemType e)</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">if</span> (s.top == MaxSize - <span class=\"number\">1</span>);</span><br><span class=\"line\">    <span class=\"keyword\">else</span> s.data[++s.top] = e;</span><br><span class=\"line\">    <span class=\"keyword\">return</span> s;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">// 出栈</span></span><br><span class=\"line\"><span class=\"function\">SqStack <span class=\"title\">Pop</span><span class=\"params\">(SqStack s,ElemType *e)</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">    <span class=\"comment\">//ElemType e;</span></span><br><span class=\"line\">    <span class=\"keyword\">if</span> (s.top == <span class=\"number\">-1</span>) <span class=\"built_in\">printf</span>(<span class=\"string\">\"栈空\\n\"</span>);</span><br><span class=\"line\">    <span class=\"keyword\">else</span> *e = s.data[s.top--];</span><br><span class=\"line\">    <span class=\"keyword\">return</span> s;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">// 队列初始化</span></span><br><span class=\"line\"><span class=\"function\">LinkQueue <span class=\"title\">InitQueue</span><span class=\"params\">(LinkQueue Q)</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">    Q.front = (QNode *)<span class=\"built_in\">malloc</span>(<span class=\"keyword\">sizeof</span>(QNode));</span><br><span class=\"line\">    Q.rear = Q.front;</span><br><span class=\"line\">    Q.front-&gt;next = <span class=\"literal\">NULL</span>;</span><br><span class=\"line\">    <span class=\"keyword\">return</span> Q;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">// 队空判断</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">IsEmptyQueue</span><span class=\"params\">(LinkQueue Q)</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">if</span>(Q.front==Q.rear) <span class=\"keyword\">return</span> <span class=\"number\">1</span>;</span><br><span class=\"line\">    <span class=\"keyword\">else</span> <span class=\"keyword\">return</span> <span class=\"number\">0</span>;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">// 入队</span></span><br><span class=\"line\"><span class=\"function\">LinkQueue <span class=\"title\">EnQueue</span><span class=\"params\">(LinkQueue Q,ElemType e)</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">    QNode *s = (QNode *)<span class=\"built_in\">malloc</span>(<span class=\"keyword\">sizeof</span>(QNode));</span><br><span class=\"line\">    s-&gt;data = e;</span><br><span class=\"line\">    s-&gt;next = <span class=\"literal\">NULL</span>;</span><br><span class=\"line\">    Q.rear-&gt;next = s;</span><br><span class=\"line\">    Q.rear = s;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">return</span> Q;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">// 出队</span></span><br><span class=\"line\"><span class=\"function\">LinkQueue <span class=\"title\">DeQueue</span><span class=\"params\">(LinkQueue Q,ElemType *e)</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">    QNode *p;</span><br><span class=\"line\">    <span class=\"keyword\">if</span>(Q.rear==Q.front) <span class=\"keyword\">return</span> Q;</span><br><span class=\"line\">    p = Q.front-&gt;next;</span><br><span class=\"line\">    Q.front-&gt;next = p-&gt;next;</span><br><span class=\"line\">    *e = p-&gt;data;</span><br><span class=\"line\">    <span class=\"keyword\">if</span>(Q.rear==p) Q.rear = Q.front;</span><br><span class=\"line\">    <span class=\"built_in\">free</span>(p);</span><br><span class=\"line\">    <span class=\"keyword\">return</span> Q;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">check</span><span class=\"params\">(SqStack S,LinkQueue Q)</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">    ElemType e1,e2;</span><br><span class=\"line\">    <span class=\"keyword\">while</span>((!IsEmptyStack(S))&amp;&amp;(!IsEmptyQueue(Q)))&#123;</span><br><span class=\"line\">        S = Pop(S,&amp;e1);</span><br><span class=\"line\">        Q = DeQueue(Q,&amp;e2);</span><br><span class=\"line\">        <span class=\"keyword\">if</span>(e1!=e2) <span class=\"keyword\">return</span> <span class=\"number\">0</span>;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    <span class=\"keyword\">return</span> <span class=\"number\">1</span>;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">main</span><span class=\"params\">()</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">    SqStack S;</span><br><span class=\"line\">    LinkQueue Q;</span><br><span class=\"line\">    ElemType ch;</span><br><span class=\"line\"></span><br><span class=\"line\">    S = InitStack(S);</span><br><span class=\"line\">    Q = InitQueue(Q);</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"built_in\">scanf</span>(<span class=\"string\">\"%c\"</span>,&amp;ch);</span><br><span class=\"line\">    <span class=\"keyword\">while</span>(ch!=<span class=\"string\">'\\n'</span>)&#123;</span><br><span class=\"line\">        S = Push(S,ch);</span><br><span class=\"line\">        Q = EnQueue(Q,ch);</span><br><span class=\"line\">        <span class=\"built_in\">scanf</span>(<span class=\"string\">\"%c\"</span>,&amp;ch);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">if</span>(check(S,Q)) <span class=\"built_in\">printf</span>(<span class=\"string\">\"Yes\"</span>);</span><br><span class=\"line\">    <span class=\"keyword\">else</span> <span class=\"built_in\">printf</span>(<span class=\"string\">\"No\"</span>);</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">return</span> <span class=\"number\">0</span>;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<blockquote>\n<p>2018 题1</p>\n</blockquote>\n<figure class=\"highlight c\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span><span class=\"meta-string\">&lt;stdio.h&gt;</span></span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span><span class=\"meta-string\">&lt;malloc.h&gt;</span></span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">define</span> ElemType char</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">typedef</span> <span class=\"class\"><span class=\"keyword\">struct</span> <span class=\"title\">LNode</span></span></span><br><span class=\"line\"><span class=\"class\">&#123;</span></span><br><span class=\"line\">    ElemType data;</span><br><span class=\"line\">    <span class=\"class\"><span class=\"keyword\">struct</span> <span class=\"title\">LNode</span> *<span class=\"title\">next</span>;</span></span><br><span class=\"line\">&#125;LNode,*LinkList;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\">LinkList <span class=\"title\">List_TaiInsert</span><span class=\"params\">(LinkList L)</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">    ElemType ch;</span><br><span class=\"line\">    LNode *s,*r;</span><br><span class=\"line\">    L = (LinkList)<span class=\"built_in\">malloc</span>(<span class=\"keyword\">sizeof</span>(LNode));</span><br><span class=\"line\">    r = L;</span><br><span class=\"line\">    <span class=\"built_in\">scanf</span>(<span class=\"string\">\"%c\"</span>,&amp;ch);</span><br><span class=\"line\">    <span class=\"keyword\">while</span>(ch!=<span class=\"string\">'\\n'</span>)&#123;</span><br><span class=\"line\">        s = (LNode *)<span class=\"built_in\">malloc</span>(<span class=\"keyword\">sizeof</span>(LNode));</span><br><span class=\"line\">        s-&gt;data = ch;</span><br><span class=\"line\">        r-&gt;next = s;</span><br><span class=\"line\">        r = s;</span><br><span class=\"line\">        <span class=\"built_in\">scanf</span>(<span class=\"string\">\"%c\"</span>,&amp;ch);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    r-&gt;next = <span class=\"literal\">NULL</span>;</span><br><span class=\"line\">    <span class=\"keyword\">return</span> L;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">// 合并两个有序单链表</span></span><br><span class=\"line\"><span class=\"function\">LinkList <span class=\"title\">MergeList</span><span class=\"params\">(LinkList A,LinkList B,LinkList Lc)</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">    LNode *C;</span><br><span class=\"line\"></span><br><span class=\"line\">    C = A;</span><br><span class=\"line\">    Lc = C;</span><br><span class=\"line\">    A = A-&gt;next;</span><br><span class=\"line\">    B = B-&gt;next;</span><br><span class=\"line\">    <span class=\"keyword\">while</span>(A&amp;&amp;B)&#123;</span><br><span class=\"line\">        <span class=\"keyword\">if</span>(A-&gt;data&lt;=B-&gt;data)&#123;</span><br><span class=\"line\">            C-&gt;next = A;</span><br><span class=\"line\">            C = A;</span><br><span class=\"line\">            A = A-&gt;next;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        <span class=\"keyword\">else</span>&#123;</span><br><span class=\"line\">            C-&gt;next = B;</span><br><span class=\"line\">            C= B;</span><br><span class=\"line\">            B = B-&gt;next;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    C-&gt;next = A?A:B;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">return</span> Lc;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">main</span><span class=\"params\">()</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">    LinkList A,B,Lc;</span><br><span class=\"line\">    A = List_TaiInsert(A);</span><br><span class=\"line\">    B = List_TaiInsert(B);</span><br><span class=\"line\"></span><br><span class=\"line\">    Lc = MergeList(A,B,Lc);</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">while</span>(Lc-&gt;next)&#123;</span><br><span class=\"line\">        Lc = Lc-&gt;next;</span><br><span class=\"line\">        <span class=\"built_in\">printf</span>(<span class=\"string\">\"%c\"</span>,Lc-&gt;data);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">return</span> <span class=\"number\">0</span>;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<blockquote>\n<p>2019 题1</p>\n</blockquote>\n<figure class=\"highlight c\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span><span class=\"meta-string\">&lt;stdio.h&gt;</span></span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">define</span> ElemType int</span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">define</span> MaxSize 50</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">typedef</span> <span class=\"class\"><span class=\"keyword\">struct</span></span></span><br><span class=\"line\"><span class=\"class\">&#123;</span></span><br><span class=\"line\">    ElemType data[MaxSize];</span><br><span class=\"line\">    <span class=\"keyword\">int</span> front,cont;</span><br><span class=\"line\">&#125;Queue;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\">Queue <span class=\"title\">InitQueue</span><span class=\"params\">(Queue Q)</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">    Q.front = <span class=\"number\">-1</span>;</span><br><span class=\"line\">    Q.cont = <span class=\"number\">0</span>;</span><br><span class=\"line\">    <span class=\"keyword\">return</span> Q;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\">Queue <span class=\"title\">EnQueue</span><span class=\"params\">(Queue Q,ElemType e)</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">if</span>(Q.cont==MaxSize) <span class=\"keyword\">return</span> Q;</span><br><span class=\"line\">    <span class=\"keyword\">if</span>(Q.front==<span class=\"number\">-1</span>) Q.front = <span class=\"number\">0</span>;</span><br><span class=\"line\">    ++Q.cont;</span><br><span class=\"line\">    Q.data[(Q.front+Q.cont<span class=\"number\">-1</span>)%MaxSize] = e;</span><br><span class=\"line\">    <span class=\"keyword\">return</span> Q;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\">Queue <span class=\"title\">DeQueue</span><span class=\"params\">(Queue Q,ElemType *e)</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">if</span>(Q.cont==<span class=\"number\">0</span>) <span class=\"keyword\">return</span> Q;</span><br><span class=\"line\">    *e = Q.data[Q.front];</span><br><span class=\"line\">    Q.cont--;</span><br><span class=\"line\">    Q.front = (++Q.front)%MaxSize;</span><br><span class=\"line\">    <span class=\"keyword\">return</span> Q;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">main</span><span class=\"params\">()</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">    Queue Q;</span><br><span class=\"line\">    <span class=\"keyword\">int</span> e;</span><br><span class=\"line\">    Q = InitQueue(Q);</span><br><span class=\"line\">    Q = EnQueue(Q,<span class=\"number\">1</span>);</span><br><span class=\"line\">    Q = EnQueue(Q,<span class=\"number\">2</span>);</span><br><span class=\"line\">    Q = EnQueue(Q,<span class=\"number\">3</span>);</span><br><span class=\"line\">    Q = EnQueue(Q,<span class=\"number\">4</span>);</span><br><span class=\"line\"></span><br><span class=\"line\">    Q = DeQueue(Q,&amp;e);</span><br><span class=\"line\">    <span class=\"built_in\">printf</span>(<span class=\"string\">\"%d\\n\"</span>,e);</span><br><span class=\"line\"></span><br><span class=\"line\">    Q = DeQueue(Q,&amp;e);</span><br><span class=\"line\">    <span class=\"built_in\">printf</span>(<span class=\"string\">\"%d\\n\"</span>,e);</span><br><span class=\"line\">    <span class=\"keyword\">return</span> <span class=\"number\">0</span>;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<blockquote>\n<p>最大深度</p>\n</blockquote>\n<figure class=\"highlight c\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br><span class=\"line\">77</span><br><span class=\"line\">78</span><br><span class=\"line\">79</span><br><span class=\"line\">80</span><br><span class=\"line\">81</span><br><span class=\"line\">82</span><br><span class=\"line\">83</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span><span class=\"meta-string\">&lt;stdio.h&gt;</span></span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span><span class=\"meta-string\">&lt;malloc.h&gt;</span></span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">define</span> MaxSize 50</span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">define</span> ElemType char</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">typedef</span> <span class=\"class\"><span class=\"keyword\">struct</span> <span class=\"title\">BiTNode</span>&#123;</span></span><br><span class=\"line\">    ElemType data;</span><br><span class=\"line\">    <span class=\"class\"><span class=\"keyword\">struct</span> <span class=\"title\">BiTNode</span> *<span class=\"title\">lchild</span>,*<span class=\"title\">rchild</span>;</span></span><br><span class=\"line\">&#125;BiTNode,*BiTree;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\">BiTree <span class=\"title\">CreatBiTree</span><span class=\"params\">(BiTree T)</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">    ElemType ch;</span><br><span class=\"line\">    <span class=\"built_in\">scanf</span>(<span class=\"string\">\"%c\"</span>,&amp;ch);</span><br><span class=\"line\">    <span class=\"keyword\">if</span>(ch==<span class=\"string\">'\\n'</span>) T=<span class=\"literal\">NULL</span>;</span><br><span class=\"line\">    <span class=\"keyword\">else</span>&#123;</span><br><span class=\"line\">        T = (BiTree)<span class=\"built_in\">malloc</span>(<span class=\"keyword\">sizeof</span>(BiTNode));</span><br><span class=\"line\">        T-&gt;data = ch;</span><br><span class=\"line\">        T-&gt;lchild = CreatBiTree(T-&gt;lchild);</span><br><span class=\"line\">        T-&gt;rchild = CreatBiTree(T-&gt;rchild);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    <span class=\"keyword\">return</span> T;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">typedef</span> <span class=\"class\"><span class=\"keyword\">struct</span></span></span><br><span class=\"line\"><span class=\"class\">&#123;</span></span><br><span class=\"line\">    BiTree data[MaxSize];</span><br><span class=\"line\">    <span class=\"keyword\">int</span> top;</span><br><span class=\"line\">&#125;SqStack;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">// 初始化</span></span><br><span class=\"line\"><span class=\"function\">SqStack <span class=\"title\">InitStack</span><span class=\"params\">(SqStack s)</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">    s.top = <span class=\"number\">-1</span>;</span><br><span class=\"line\">    <span class=\"keyword\">return</span> s;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">// 判栈空</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">IsEmptyStack</span><span class=\"params\">(SqStack s)</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">if</span> (s.top == <span class=\"number\">-1</span>) <span class=\"keyword\">return</span> <span class=\"number\">1</span>;</span><br><span class=\"line\">    <span class=\"keyword\">else</span> <span class=\"keyword\">return</span> <span class=\"number\">0</span>;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">// 进栈</span></span><br><span class=\"line\"><span class=\"function\">SqStack <span class=\"title\">Push</span><span class=\"params\">(SqStack s, BiTree e)</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">if</span> (s.top == MaxSize - <span class=\"number\">1</span>);</span><br><span class=\"line\">    <span class=\"keyword\">else</span> s.data[++s.top] = e;</span><br><span class=\"line\">    <span class=\"keyword\">return</span> s;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">// 出栈</span></span><br><span class=\"line\"><span class=\"function\">SqStack <span class=\"title\">Pop</span><span class=\"params\">(SqStack s,BiTree *e)</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">if</span> (s.top == <span class=\"number\">-1</span>) <span class=\"built_in\">printf</span>(<span class=\"string\">\"栈空\\n\"</span>);</span><br><span class=\"line\">    <span class=\"keyword\">else</span> *e = s.data[s.top--];</span><br><span class=\"line\">    <span class=\"keyword\">return</span> s;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">GetDepth</span><span class=\"params\">(BiTree T)</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">int</span> LD=<span class=\"number\">0</span>,RD=<span class=\"number\">0</span>;</span><br><span class=\"line\">    <span class=\"keyword\">if</span>(T)</span><br><span class=\"line\">    &#123;</span><br><span class=\"line\">        LD = GetDepth(T-&gt;lchild);</span><br><span class=\"line\">        RD = GetDepth(T-&gt;rchild);</span><br><span class=\"line\">        <span class=\"keyword\">return</span> (LD&gt;RD?LD:RD)+<span class=\"number\">1</span>;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    <span class=\"keyword\">else</span></span><br><span class=\"line\">    &#123;</span><br><span class=\"line\">        <span class=\"keyword\">return</span> <span class=\"number\">0</span>;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">main</span><span class=\"params\">()</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">    BiTree T;</span><br><span class=\"line\">    T = CreatBiTree(T);</span><br><span class=\"line\">    <span class=\"built_in\">printf</span>(<span class=\"string\">\"\\n%d\\n\"</span>,GetDepth(T));</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n","categories":[],"tags":["c/c++"]},{"title":"单片机实习日记","url":"https://hahally.github.io//articles/单片机实习日记/","content":"<blockquote>\n<p><em>I know nothing but my ignorance.</em></p>\n</blockquote>\n<h3 id=\"5月18日\"><a href=\"#5月18日\" class=\"headerlink\" title=\"5月18日\"></a>5月18日</h3><p>今天是单片机实习的第一天，因为疫情原因变成了线上开展。</p>\n<p>上午，老师把六个选题都一一讲解了一遍，并告诉我们一些在实习过程中可能会出现的一些问题和注意事项。老师讲完后，我们就开始组队和选题了。</p>\n<p>在经过一番并不激烈的讨论后，我们组选择了第二个项目：<strong>数字频率计设计</strong> </p>\n<p>一、基本要求：</p>\n<p>测量待测 <code>TTL</code> 电平信号的频率</p>\n<ol>\n<li>频率范围：10 Hz ~ 50kHz，全测量范围误差不大于 1%；</li>\n<li>用液晶屏 <code>LCD1602</code> 显示数值和单位，可显示频率及周期；</li>\n<li>数据刷新率每秒三次以上；</li>\n<li>在同一台单片机上自行设计测试用信号源；</li>\n<li>通过串口通信在远程单片机（仿真环境）显示测量结果。</li>\n</ol>\n<p>二、扩展要求</p>\n<ol>\n<li>占空比测量</li>\n<li>在保证数据刷新率和精度的基础上拓展测量频率范围</li>\n</ol>\n<p>下午，我们组四个人开始查文献讨论总体方案和分工。又是一番并不激烈的讨论后，我们确定好了分工。我选择了串口通信功能的实现。</p>\n<h3 id=\"5月19日\"><a href=\"#5月19日\" class=\"headerlink\" title=\"5月19日\"></a>5月19日</h3><p>上午确定分工合作的一些细节部分的设计，资源的分配，引脚的功能等等。然后，听老师讲一些知识点。</p>\n<p>下午，我开始查找串口通信的资料文献。最终确定采用异步通信的方式实现串口通信。接着开始着重异步通信方面的资料查询。经过一番并不困难的翻阅后，大致了解了异步通信的 4 种方式以及定时器的知识。</p>\n<p>52单片机有三个定时器/计数器，与串口通信有关的就是 T1定时器了。定时器/计数器的实质是加 1 计数器(高 8 位 和低 8 位 两个寄存器组成)。<code>TMOD</code> 是确定工作方式和功能的寄存器；<code>TCON</code> 是控制 T0、T1 的启动和停止及设置溢出标志的寄存器。</p>\n<p><strong><code>TMOD</code></strong>:</p>\n<div class=\"table-container\">\n<table>\n<thead>\n<tr>\n<th style=\"text-align:center\">位序号</th>\n<th style=\"text-align:center\">D7</th>\n<th style=\"text-align:center\">D6</th>\n<th style=\"text-align:center\">D5</th>\n<th style=\"text-align:center\">D4</th>\n<th style=\"text-align:center\">D3</th>\n<th style=\"text-align:center\">D2</th>\n<th style=\"text-align:center\">D1</th>\n<th style=\"text-align:center\">D0</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td style=\"text-align:center\">位符号</td>\n<td style=\"text-align:center\">$GATE$</td>\n<td style=\"text-align:center\">$C/\\overline{\\text{T}}$</td>\n<td style=\"text-align:center\">$M1$</td>\n<td style=\"text-align:center\">$M0$</td>\n<td style=\"text-align:center\">$GATE$</td>\n<td style=\"text-align:center\">$C/\\overline{\\text{T}}$</td>\n<td style=\"text-align:center\">$M1$</td>\n<td style=\"text-align:center\">$M0$</td>\n</tr>\n</tbody>\n</table>\n</div>\n<p><code>D7~D4</code> 为 <code>T1</code> 定时器，<code>D3~D0</code> 为 <code>T0</code> 定时器。$C/\\overline{\\text{T}}$ 为 0 时为定时器模式，为 1 时为计数器模式，<code>M1</code> 和 <code>M0</code> 是工作方式选择位。</p>\n<div class=\"table-container\">\n<table>\n<thead>\n<tr>\n<th style=\"text-align:center\">M1</th>\n<th style=\"text-align:center\">M0</th>\n<th style=\"text-align:center\">工作方式</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td style=\"text-align:center\">0</td>\n<td style=\"text-align:center\">0</td>\n<td style=\"text-align:center\">方式0，为13位定时器/计数器</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">0</td>\n<td style=\"text-align:center\">1</td>\n<td style=\"text-align:center\">方式1，为16位定时器/计数器</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">1</td>\n<td style=\"text-align:center\">0</td>\n<td style=\"text-align:center\">方式2，8位初值自动重装的8位定时器/计数器</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">1</td>\n<td style=\"text-align:center\">1</td>\n<td style=\"text-align:center\">方式3，仅适用于 T0，分成两个8位计数器，T1停止计数</td>\n</tr>\n</tbody>\n</table>\n</div>\n<p><strong><code>TCON</code></strong></p>\n<div class=\"table-container\">\n<table>\n<thead>\n<tr>\n<th style=\"text-align:center\">位序号</th>\n<th style=\"text-align:center\">D7</th>\n<th style=\"text-align:center\">D6</th>\n<th style=\"text-align:center\">D5</th>\n<th style=\"text-align:center\">D4</th>\n<th style=\"text-align:center\">D3</th>\n<th style=\"text-align:center\">D2</th>\n<th style=\"text-align:center\">D1</th>\n<th style=\"text-align:center\">D0</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td style=\"text-align:center\">位符号</td>\n<td style=\"text-align:center\">$TF1$</td>\n<td style=\"text-align:center\">$TR1$</td>\n<td style=\"text-align:center\">$TF0$</td>\n<td style=\"text-align:center\">$TR0$</td>\n<td style=\"text-align:center\">$IE1$</td>\n<td style=\"text-align:center\">$IT1$</td>\n<td style=\"text-align:center\">$IE0$</td>\n<td style=\"text-align:center\">$IT0$</td>\n</tr>\n</tbody>\n</table>\n</div>\n<h3 id=\"5月20日\"><a href=\"#5月20日\" class=\"headerlink\" title=\"5月20日\"></a>5月20日</h3><p>经过昨天一天的查阅学习，已经对串口通信有了比较全面的了解。所以，今天就是先把串口通信的一些必要环境准备好。下载串口助手和虚拟串口工具，然后测试串口助手。在一番并不花里胡哨的操作后，基本操作都会了。接着就是准备仿真下的串口测试了。在 <code>protues</code> 上，点来点去，又是一番行云流水且不花里胡哨的操作后，仿真环境也搭建好了。然后开始敲代码，在 <code>keil</code> 这个外表朴实无华但功能强大的软件上，敲下第一个简单串口通信的代码。然后结合串口助手观察效果。这样一个发送单个字符的例子就测试成功了。</p>\n<h3 id=\"5月21日\"><a href=\"#5月21日\" class=\"headerlink\" title=\"5月21日\"></a>5月21日</h3><p>今天是周四，上午老师照常开了小小的线上例会。交我们一些小小的调试技巧之类的。在昨天的基础上，今天继续修改代码，实现发送和接收功能。上午把整个代码框架写了出来，本以为会是顺顺利利的一天。但是下午的调试，着实不太顺利。先是，接收的数据并不是期望的数据，在一顿微操后，发现是接收数据的数组出现了溢出现象。调好后，又发现接收的数据有些错位了。又是一顿 <code>Debug</code> 后，自己定义一个简单通信协议，在数据头尾加上标志位，以确保接收方正确接收到期望数据。来来回回这样折腾后，仿真串口通信是没有问题了。</p>\n<h3 id=\"5月22日\"><a href=\"#5月22日\" class=\"headerlink\" title=\"5月22日\"></a>5月22日</h3><p>一觉醒来还是周五，是的，昨晚熬到了十二点。精力显然有些不充沛的我，还是打开了电脑，接着干了。队友那边的频率测量 和<code>LCD</code> 显示功能已经就绪了。今天可以整一块测试一下了。拿到他们的代码后，便开始调试。红红火火恍恍惚惚，就这样一顿朴实无华而实用的 <code>CV</code>大法过后，加以小小微操作为辅助，就调好了。</p>\n<h3 id=\"5月25日\"><a href=\"#5月25日\" class=\"headerlink\" title=\"5月25日\"></a>5月25日</h3><p>短暂的周末一晃就过去了。新的一周，继续干。现在只剩下信号源了。查资料，敲代码，仿真。陷入循环状态。进度十分缓慢。浑浑噩噩，一天就这样结束了。</p>\n<h3 id=\"5月26日\"><a href=\"#5月26日\" class=\"headerlink\" title=\"5月26日\"></a>5月26日</h3><p>距离实习结束，迫在眉睫。但是，实在有些精神疲惫了。打开和昨天一样的软件一样的文件，开始改代码。一番操作，以为成了。结果，一到高频信号，就不受调制了，无法准确控制信号频率的改变。</p>\n<h3 id=\"5月27日\"><a href=\"#5月27日\" class=\"headerlink\" title=\"5月27日\"></a>5月27日</h3><p>今天开始在开发板上进行真机测试，果然不出所料，仿真和真机不一样。一天的疯狂调试，勉强调好，差强人意的样子。</p>\n","categories":["Diary"],"tags":["单片机"]},{"title":"CSRent","url":"https://hahally.github.io//articles/CSRent/","content":"<blockquote>\n<p>交互式Python爬虫分析实例小项目</p>\n</blockquote>\n<p>先抛出项目地址吧： <a href=\"http://dblab.xmu.edu.cn/blog/2355/#more-2355\" target=\"_blank\" rel=\"noopener\">厦门大学数据库实验室</a></p>\n<h3 id=\"项目简述\"><a href=\"#项目简述\" class=\"headerlink\" title=\"项目简述\"></a>项目简述</h3><p>实现一个简单的交互式的租房信息分析展示 $web$ 平台。</p>\n<p>数据来源 ： <a href=\"http://www.xhj.com/zufang/\" target=\"_blank\" rel=\"noopener\">http://www.xhj.com/zufang/</a></p>\n<p><strong>技术栈</strong> ：</p>\n<ul>\n<li>$python$ 爬虫</li>\n<li>$pyspark$ 数据分析</li>\n<li>$flask$  $web$ 后端</li>\n<li>$pyecharts$  可视化</li>\n</ul>\n<p><strong>最终呈现效果</strong> ：</p>\n<p><img src=\"/articles/CSRent/image-20200517220605897.png\" alt=\"image-20200517220605897\"></p>\n<p><img src=\"/articles/CSRent/image-20200517220645343.png\" alt=\"image-20200517220645343\"></p>\n<h3 id=\"租房信息爬取\"><a href=\"#租房信息爬取\" class=\"headerlink\" title=\"租房信息爬取\"></a>租房信息爬取</h3><p>地址： <a href=\"http://www.xhj.com/zufang/\" target=\"_blank\" rel=\"noopener\">http://www.xhj.com/zufang/</a></p>\n<p><img src=\"/articles/CSRent/image-20200517222251986.png\" alt=\"image-20200517222251986\"></p>\n<p><strong>网页分析</strong></p>\n<h4 id=\"地址分析\"><a href=\"#地址分析\" class=\"headerlink\" title=\"地址分析\"></a>地址分析</h4><p>在 <em>区域找房</em>  一栏找到长沙的各个区域。这里选取了长沙的六个区：【天心区、芙蓉区、开福区、岳麓区、雨花区、望城】</p>\n<p>逐个点击 六个区可以观察到每个区域都对应有 $40$ 页 ，而且地址可以简单按下面这样方式拼接：</p>\n<figure class=\"highlight awk\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">http:<span class=\"regexp\">//</span>www.xhj.com<span class=\"regexp\">/zufang/</span> + 区域+<span class=\"regexp\">/pg + 页码/</span></span><br></pre></td></tr></table></figure>\n<p>所以代码中可以这样构造地址：</p>\n<figure class=\"highlight ini\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"attr\">base_url</span> = <span class=\"string\">'http://www.xhj.com/zufang/'</span></span><br><span class=\"line\"><span class=\"attr\">param</span> = [<span class=\"string\">'tianxinqu'</span>,<span class=\"string\">'furongqu'</span>,<span class=\"string\">'kaifuqu'</span>,<span class=\"string\">'yueluqu'</span>,<span class=\"string\">'yuhuaqu'</span>,<span class=\"string\">'wangcheng'</span>]</span><br><span class=\"line\"><span class=\"comment\"># region in param</span></span><br><span class=\"line\"><span class=\"attr\">url</span> = base_url + region + <span class=\"string\">'/pg%d/'</span>%i <span class=\"comment\"># region为区域，i 为页码</span></span><br></pre></td></tr></table></figure>\n<p>这样很容易就可以通过两个循环来爬取我们需要的数据了。</p>\n<h4 id=\"源码分析\"><a href=\"#源码分析\" class=\"headerlink\" title=\"源码分析\"></a>源码分析</h4><p>通过开发者工具查看源码：</p>\n<p><img src=\"/articles/CSRent/image-20200517223429820.png\" alt=\"image-20200517223429820\"></p>\n<p>显然，这个网站的前端非常的给力，结构一目了然，而且没有动态加载。要是能改为 $ajax$ 的请求方式加载数据或许会更友好。</p>\n<p>不用仔细观察都可以看见，每个租房信息都被一个 <code>&lt;div​ class=&quot;lp_wrap&quot;&gt;...&lt;/div&gt;​</code> 包裹着。</p>\n<p>我们很容易就可以通过 $xpath$ 定位到每个租房信息，像这样：</p>\n<figure class=\"highlight ini\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># html is the source code of webpage.</span></span><br><span class=\"line\"><span class=\"attr\">div</span> = html.xpath(<span class=\"string\">'//*/div[@class=\"lp_wrap\"]'</span>)</span><br></pre></td></tr></table></figure>\n<p>这样提取的 <code>div​</code> 对象为一个 $list$ 。最后将结果保存在 <code>rent_info.csv</code> 中。</p>\n<h4 id=\"补充\"><a href=\"#补充\" class=\"headerlink\" title=\"补充\"></a>补充</h4><p>经过这么一波并不花里胡哨的简单操作和分析，基本上可以写出对应的代码了。但是，这看似普普通通的网站，还是会封你的 $ip$ 的。所以，一般的加 <code>headers[&#39;User-Agent&#39;]​</code>  已经不行了。这里，我选择了添加代理来绕过它的反爬机制。【备注：很久之前爬过免费高匿代理存放在 <code>mongodb</code> 中】</p>\n<p>(此处省略个几百字)一顿花里胡哨的操作后，数据库中的代理 $ip$ 果然已经基本失效了。毕竟一年多了。</p>\n<p>后面发现，这个网站只会封你半分钟不到好像(应该是的，被禁后，刷新了好几下网页，然后刷回来了)。所以说，代码中是不是可以通过设置休眠时间来降低访问速度呢。三思过后，放弃的这个想法，这样的做法好像一点都不干脆利落。还是决定自己做个代理池算了。</p>\n<p>于是开启了免费代理的寻找之路，又是一顿的花里胡哨操作后(此处省略几百字)。很多 <strong>西刺代理</strong> 这样的免费代理网站已经迭代升级了，不在是曾经那个亚子了。它也开始封我 $ip$ 了。差点当场炸裂开来……因为它不是封你一两分钟酱紫玩玩。</p>\n<p>不过没关系，多爬几个这样的网站就可以有比较多得代理了。如果不想爬也不打紧，不妨逛一逛这里<a href=\"https://ip.ihuan.me/\" target=\"_blank\" rel=\"noopener\">小幻http代理</a>  </p>\n<p>支持批量提取，十分友好，可以帮我们省十几行代码了。</p>\n<p><strong>一点建议</strong></p>\n<p>记得用我们的目标网站测试一下这些免费代理是否失效。</p>\n<p><strong>下面是我选出来的比较好的</strong></p>\n<figure class=\"highlight rust\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">proxies = [</span><br><span class=\"line\">    &#123;<span class=\"symbol\">'https</span>':<span class=\"string\">\"https://221.6.201.18:9999\"</span>&#125;,</span><br><span class=\"line\">    &#123;<span class=\"symbol\">'http</span>': <span class=\"symbol\">'http</span>:<span class=\"comment\">//39.137.69.9:80'&#125;,</span></span><br><span class=\"line\">    &#123;<span class=\"symbol\">'https</span>': <span class=\"symbol\">'https</span>:<span class=\"comment\">//221.122.91.64:80'&#125;,</span></span><br><span class=\"line\">    &#123;<span class=\"symbol\">'http</span>': <span class=\"symbol\">'http</span>:<span class=\"comment\">//39.137.69.8:8080'&#125;,</span></span><br><span class=\"line\">    &#123;<span class=\"symbol\">'http</span>': <span class=\"symbol\">'http</span>:<span class=\"comment\">//125.59.223.27:8380'&#125;,</span></span><br><span class=\"line\">    &#123;<span class=\"symbol\">'http</span><span class=\"string\">':'</span>http:<span class=\"comment\">//118.212.104.22:9999'&#125;,</span></span><br><span class=\"line\">    &#123;<span class=\"symbol\">'https</span><span class=\"string\">':'</span>https:<span class=\"comment\">//47.106.59.75:3128'&#125;,</span></span><br><span class=\"line\">    &#123;<span class=\"symbol\">'http</span><span class=\"string\">':'</span>http:<span class=\"comment\">//221.180.170.104:8080'&#125;,</span></span><br><span class=\"line\">    &#123;<span class=\"symbol\">'http</span>': <span class=\"symbol\">'http</span>:<span class=\"comment\">//113.59.99.138:8910'&#125;,</span></span><br><span class=\"line\">    &#123;<span class=\"symbol\">'http</span><span class=\"string\">':'</span>http:<span class=\"comment\">//123.194.231.55:8197'&#125;,</span></span><br><span class=\"line\">    &#123;<span class=\"symbol\">'https</span><span class=\"string\">':'</span>https:<span class=\"comment\">//218.60.8.99:3129'&#125;,</span></span><br><span class=\"line\">    &#123;<span class=\"symbol\">'http</span>': <span class=\"symbol\">'http</span>:<span class=\"comment\">//218.58.194.162:8060'&#125;,</span></span><br><span class=\"line\">    &#123;<span class=\"symbol\">'https</span>': <span class=\"symbol\">'https</span>:<span class=\"comment\">//221.122.91.64:80'&#125;</span></span><br><span class=\"line\">]</span><br></pre></td></tr></table></figure>\n<h3 id=\"pyspark-数据分析\"><a href=\"#pyspark-数据分析\" class=\"headerlink\" title=\"pyspark 数据分析\"></a>pyspark 数据分析</h3><p>这一步主要使用 <code>pyspark.sql.SparkSession</code> 来操作。从 <code>rent_info.csv</code> 中读取数据获得一个 <code>DataFrame</code> 对象，然后通过一系列动作(过滤筛选，聚合，统计)完成简单分析。</p>\n<h3 id=\"flask-后端\"><a href=\"#flask-后端\" class=\"headerlink\" title=\"flask 后端\"></a>flask 后端</h3><p>使用 <code>flask_socketio.SocketIO</code>  来注册一个 <code>flask app</code> 对象。调用 <code>run</code> 方法启动服务。</p>\n<figure class=\"highlight routeros\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">app = Flask(__name__)</span><br><span class=\"line\">app.config[<span class=\"string\">'SECRET_KEY'</span>] = <span class=\"string\">'xmudblab'</span></span><br><span class=\"line\">socketio = SocketIO(app)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">if</span> __name__ == <span class=\"string\">'__main__'</span>:</span><br><span class=\"line\">    socketio.<span class=\"builtin-name\">run</span>(app, <span class=\"attribute\">debug</span>=<span class=\"literal\">True</span>)</span><br></pre></td></tr></table></figure>\n<p>剩下的就是一些简单的路由配置(通过装饰器来实现)：</p>\n<figure class=\"highlight ruby\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 客户端访问 http://127.0.0.1:5000/，可以看到index界面</span></span><br><span class=\"line\">@app.route(<span class=\"string\">\"/\"</span>)</span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">handle_mes</span><span class=\"params\">()</span></span><span class=\"symbol\">:</span></span><br><span class=\"line\">    <span class=\"keyword\">return</span> render_template(<span class=\"string\">\"index.html\"</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 对客户端发来的start_spider事件作出相应</span></span><br><span class=\"line\">@socketio.on(<span class=\"string\">\"start_spider\"</span>)</span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">start_spider</span><span class=\"params\">(message)</span></span><span class=\"symbol\">:</span></span><br><span class=\"line\">    print(message)</span><br><span class=\"line\">    run_spider()</span><br><span class=\"line\">    socketio.emit(<span class=\"string\">'get_result'</span>, &#123;<span class=\"string\">'data'</span>: <span class=\"string\">\"请获取最后结果\"</span>&#125;)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 对客户端发来的/Get_result事件作出相应</span></span><br><span class=\"line\">@app.route(<span class=\"string\">\"/Get_result\"</span>)</span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">Get_result</span><span class=\"params\">()</span></span><span class=\"symbol\">:</span></span><br><span class=\"line\">    <span class=\"keyword\">return</span> render_template(<span class=\"string\">\"result.html\"</span>)</span><br></pre></td></tr></table></figure>\n<h3 id=\"socketio-补充\"><a href=\"#socketio-补充\" class=\"headerlink\" title=\"socketio 补充\"></a>socketio 补充</h3><p>使用 <code>socketio</code> 可以轻松实现 <code>web</code> 后台和前端的信息交互，这种连接是基于 <code>websocket</code> 协议的全双工通信。</p>\n<p>前端 <code>socketio</code> 库</p>\n<figure class=\"highlight xml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">script</span> <span class=\"attr\">src</span>=<span class=\"string\">\"static/js/socket.io.js\"</span>&gt;</span><span class=\"tag\">&lt;/<span class=\"name\">script</span>&gt;</span></span><br></pre></td></tr></table></figure>\n<blockquote>\n<p>未完待续…..</p>\n</blockquote>\n<h3 id=\"改进空间\"><a href=\"#改进空间\" class=\"headerlink\" title=\"改进空间\"></a>改进空间</h3><p>整个项目中，<code>spark</code> 的强大好像并没有发挥出来。毕竟 <code>spark</code> 在实时数据处理方面可是碾压 <code>mapreduce</code>的，好像一套组合拳，只使出了一点花拳绣腿。不妨大点想象一下，能不能实现一个实时房租信息交互系统，通过可视化工具在地图上直观的显示租房信息，每隔一小段时间更新数据，同时发送邮件提醒。甚至结合微信小程序在移动端也能查看。</p>\n<p>嗯，想一想，挺好的。但是，这里的数据来源的可信度还有待考察。或许应该去 <a href=\"https://cs.zu.ke.com/zufang/changshaxian/\" target=\"_blank\" rel=\"noopener\">贝壳找房</a> 看看(当事人非常后悔)。怎么开始就没想到去贝壳找。【不是打广告/手动滑稽】</p>\n<hr>\n","categories":["projdemo"],"tags":["爬虫"]},{"title":"Scrapy","url":"https://hahally.github.io//articles/Scrapy/","content":"<h3 id=\"写在前面\"><a href=\"#写在前面\" class=\"headerlink\" title=\"写在前面\"></a>写在前面</h3><p>在很久之前就已经学过了爬虫。那时还是懵懵懂懂的小白，学了一点基础，就买来一本书，然后就开干。代码倒是写了不少，但是没有什么拿的出手的。之后，便又匆匆忙忙的转战 web ，学起了 Django 。这一入坑，不知不觉差不多快一年了。最后发现自己知道的依旧凤毛麟角。没有基础的计算机网络知识，没有良好的代码编写规范……</p>\n<p>意识到问题后，开始试着阅读官方文档，去看协议，看源码。这些天看了 http 协议，计算机网络基础，python 文档，以及 Scrapy 文档。不得不说，看完后虽然记住的不多，但是大致是怎么一回事，多多少少还是了解了。比如，当初的爬虫程序，为什么要设置 <code>header</code> 、<code>cookie</code> 、<code>session</code> 什么的。还有 <code>request</code> 和 <code>response</code> 的含义。</p>\n<p>这些天看了一下 Scrapy 的 <a href=\"https://doc.scrapy.org/en/latest/intro/overview.html\" target=\"_blank\" rel=\"noopener\">官方文档</a>，对这个框架有了一些了解。正如文档中所提到的，scrapy 框架很大程度上借鉴了 Django ，这也是为什么现在的我重新来看待它时，比之前要轻松太多了。</p>\n<h3 id=\"关于-Scrapy\"><a href=\"#关于-Scrapy\" class=\"headerlink\" title=\"关于 Scrapy\"></a>关于 Scrapy</h3><blockquote>\n<p>Scrapy is an application framework for crawling web sites and extracting structured data which can be used for a wide range of useful applications, like data mining, information processing or historical archival.</p>\n</blockquote>\n<p>学习一个框架，得明白，它是什么？怎么做？更深入为什么要这样做？</p>\n<h5 id=\"是什么？\"><a href=\"#是什么？\" class=\"headerlink\" title=\"是什么？\"></a>是什么？</h5><p>简而言之,就是一个支持分布式的，可扩展的，用于批量爬取网站并提取结构化数据的异步应用程序框架。值得一提的是，Scrapy 是用 <a href=\"https://twistedmatrix.com/trac/\" target=\"_blank\" rel=\"noopener\">Twisted</a> 编写的，<a href=\"https://twistedmatrix.com/trac/\" target=\"_blank\" rel=\"noopener\">Twisted</a> 是一种流行的 Python 事件驱动的网络框架。因此，它是使用非阻塞（又称为异步）代码并发实现的。</p>\n<p>Scrapy 有着丰富的命令行工具，交互式控制台，内置支持以多种格式(json、xml、csv)等。</p>\n<h5 id=\"怎么做？\"><a href=\"#怎么做？\" class=\"headerlink\" title=\"怎么做？\"></a>怎么做？</h5><p>要使用 Scrapy ，我们不得不先安装它。文档为我们提供的良好的 <a href=\"https://doc.scrapy.org/en/latest/intro/install.html\" target=\"_blank\" rel=\"noopener\">安装指南</a> 。</p>\n<p>我们只需要这样做：</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">pip install Scrapy</span><br></pre></td></tr></table></figure>\n<p>不过我们不得不知道下面文档中提到的：</p>\n<blockquote>\n<p>Scrapy is written in pure Python and depends on a few key Python packages (among others)</p>\n</blockquote>\n<p>Scrapy 需要一些依赖包：</p>\n<ul>\n<li><a href=\"http://lxml.de/\" target=\"_blank\" rel=\"noopener\">lxml</a>，高效的XML和HTML解析器</li>\n<li><a href=\"https://pypi.python.org/pypi/parsel\" target=\"_blank\" rel=\"noopener\">parsel</a>，是在lxml之上编写的HTML / XML数据提取库</li>\n<li><a href=\"https://pypi.python.org/pypi/w3lib\" target=\"_blank\" rel=\"noopener\">w3lib</a>，用于处理URL和网页编码的多功能帮助器</li>\n<li><a href=\"https://twistedmatrix.com/\" target=\"_blank\" rel=\"noopener\">twisted</a>，异步网络框架</li>\n<li><a href=\"https://cryptography.io/\" target=\"_blank\" rel=\"noopener\">cryptography</a> 和 <a href=\"https://pypi.python.org/pypi/pyOpenSSL\" target=\"_blank\" rel=\"noopener\">pyOpenSSL</a> ，以处理各种网络级安全需求</li>\n</ul>\n<p>其中还有一些版本要求：</p>\n<ul>\n<li>Twisted 14.0</li>\n<li>lxml 3.4</li>\n<li>pyOpenSSL 0.14</li>\n</ul>\n<p>如果你没有这些依赖包，那你不得不考虑先安装依赖。在此建议使用清华源下载，这样可以避免不必要的 Time out 。如下：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">pip install [example_modul] -i https:&#x2F;&#x2F;pypi.tuna.tsinghua.edu.cn&#x2F;simple&#x2F;</span><br></pre></td></tr></table></figure>\n<p>安装完成后，就可以开始按接下来的<a href=\"https://doc.scrapy.org/en/latest/intro/tutorial.html\" target=\"_blank\" rel=\"noopener\">教程</a> 学习了。</p>\n<p>像这样创建一个项目：</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">&gt;</span><span class=\"bash\"> scrapy startproject tutorial</span></span><br></pre></td></tr></table></figure>\n<p>编写自己的爬虫类：</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> scrapy</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">QuotesSpider</span><span class=\"params\">(scrapy.Spider)</span>:</span></span><br><span class=\"line\">    name = <span class=\"string\">\"quotes\"</span></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">start_requests</span><span class=\"params\">(self)</span>:</span></span><br><span class=\"line\">        urls = [</span><br><span class=\"line\">            <span class=\"string\">'http://quotes.toscrape.com/page/1/'</span>,</span><br><span class=\"line\">            <span class=\"string\">'http://quotes.toscrape.com/page/2/'</span>,</span><br><span class=\"line\">        ]</span><br><span class=\"line\">        <span class=\"keyword\">for</span> url <span class=\"keyword\">in</span> urls:</span><br><span class=\"line\">            <span class=\"keyword\">yield</span> scrapy.Request(url=url, callback=self.parse)</span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">parse</span><span class=\"params\">(self, response)</span>:</span></span><br><span class=\"line\">        page = response.url.split(<span class=\"string\">\"/\"</span>)[<span class=\"number\">-2</span>]</span><br><span class=\"line\">        filename = <span class=\"string\">'quotes-%s.html'</span> % page</span><br><span class=\"line\">        <span class=\"keyword\">with</span> open(filename, <span class=\"string\">'wb'</span>) <span class=\"keyword\">as</span> f:</span><br><span class=\"line\">            f.write(response.body)</span><br><span class=\"line\">        self.log(<span class=\"string\">'Saved file %s'</span> % filename)</span><br></pre></td></tr></table></figure>\n<p>运行项目：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&gt; scrapy crawl quotes</span><br></pre></td></tr></table></figure>\n<p>至此，一个基本可以运行的 Scrapy 项目就成型了。</p>\n<h5 id=\"框架概述\"><a href=\"#框架概述\" class=\"headerlink\" title=\"框架概述\"></a><a href=\"https://doc.scrapy.org/en/latest/topics/architecture.html\" target=\"_blank\" rel=\"noopener\">框架概述</a></h5><p>在依葫芦画瓢的完成一个 Scrapy 项目的编写后，要想明白为什么要这样编写我们的爬虫程序，就不得不了解这个框架的一些细节。</p>\n<p>Scrapy的体系结构及组件如下图所示：</p>\n<p><img src=\"https://doc.scrapy.org/en/latest/_images/scrapy_architecture_02.png\"></p>\n<p>对照着 Scrapy 的项目结构：</p>\n<figure class=\"highlight livecodeserver\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">tutorial/</span><br><span class=\"line\">    scrapy.cfg            <span class=\"comment\"># deploy configuration file</span></span><br><span class=\"line\"></span><br><span class=\"line\">    tutorial/             <span class=\"comment\"># project's Python module, you'll import your code from here</span></span><br><span class=\"line\">        __init__.py</span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"keyword\">items</span>.py          <span class=\"comment\"># project items definition file</span></span><br><span class=\"line\"></span><br><span class=\"line\">        middlewares.py    <span class=\"comment\"># project middlewares file</span></span><br><span class=\"line\"></span><br><span class=\"line\">        pipelines.py      <span class=\"comment\"># project pipelines file</span></span><br><span class=\"line\"></span><br><span class=\"line\">        settings.py       <span class=\"comment\"># project settings file</span></span><br><span class=\"line\"></span><br><span class=\"line\">        spiders/          <span class=\"comment\"># a directory where you'll later put your spiders</span></span><br><span class=\"line\">            __init__.py</span><br><span class=\"line\">            quotes_spider.py  <span class=\"comment\"># a spider written by yourself</span></span><br></pre></td></tr></table></figure>\n<p>学过 Django 就会发现，这个框架简直就是套着它的设计模式来的。全局设置的 <code>settings.py</code> 、项目的管道 <code>pipelines.py</code> 、强大可扩展的中间件 <code>middlewares.py</code> 、以及类似模型的 <code>items.py</code> 。从图中我们不难发现，spiders可以对 requests 和 response 进行处理。而中间件 middlewares还可以对 items 进行处理。 管道 pipelines 对输出的 items 进行最后的清洗。所以，在我们明白要对数据做怎样处理时，只需要在对应的地方按要求编写我们的代码来达到我们的目的即可。</p>\n<p>一个例子：如果我们需要对最后清洗的数据保存到一个文件(如：json文件)中，那么你可能就要在管道 <code>pipelines.py</code> 中编写合适代码来实现。像这样子：</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> json</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">JsonWriterPipeline</span><span class=\"params\">(object)</span>:</span></span><br><span class=\"line\">\t</span><br><span class=\"line\"><span class=\"meta\">    @classmethod</span></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">from_crawler</span><span class=\"params\">(cls, crawler)</span>:</span></span><br><span class=\"line\">        </span><br><span class=\"line\">        <span class=\"keyword\">return</span> cls(crawler)</span><br><span class=\"line\">        </span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">open_spider</span><span class=\"params\">(self, spider)</span>:</span></span><br><span class=\"line\">        self.file = open(<span class=\"string\">'items.jl'</span>, <span class=\"string\">'w'</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">close_spider</span><span class=\"params\">(self, spider)</span>:</span></span><br><span class=\"line\">        self.file.close()</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">process_item</span><span class=\"params\">(self, item, spider)</span>:</span></span><br><span class=\"line\">        line = json.dumps(dict(item)) + <span class=\"string\">\"\\n\"</span></span><br><span class=\"line\">        self.file.write(line)</span><br><span class=\"line\">        <span class=\"keyword\">return</span> item</span><br></pre></td></tr></table></figure>\n<ul>\n<li><p>process_item (self, item, spider)</p>\n<blockquote>\n<p>每个项目管道组件均调用此方法，返回一个 item 对象，返回 Twisted Deferred 或引发 DropItem 异常。</p>\n<p>如果要使用自己的管道，那么就不得不实现此方法。</p>\n</blockquote>\n</li>\n</ul>\n<p>  除此之外，还可以实现下面几种方法：</p>\n<ul>\n<li><p>open_spider(self, spider)</p>\n<blockquote>\n<p>This method is called when the spider is opened.</p>\n</blockquote>\n</li>\n<li><p>close_spider(self, spider)</p>\n<blockquote>\n<p>This method is called when the spider is closed.</p>\n</blockquote>\n</li>\n<li><p>from_crawler(cls, crawler)</p>\n<blockquote>\n<p>If present, this classmethod is called to create a pipeline instance from a Crawler. It must return a new instance of the pipeline. Crawler object provides access to all Scrapy core components like settings and signals; it is a way for pipeline to access them and hook its functionality into Scrapy.</p>\n</blockquote>\n<p>编写完自己的 Item Pipeline后，我们还需要在 <code>settings.py</code> 中激活才能使用。像这样：</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">ITEM_PIPELINES = &#123;</span><br><span class=\"line\">    <span class=\"string\">'myproject.pipelines.JsonWriterPipeline'</span>: <span class=\"number\">800</span>,</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>需要注意的是，管道组件以字典的形式配置，并分配一整数值(0 ~ 1000)，项目将按升序方式依次执行。</p>\n</li>\n</ul>\n<hr>\n<p>补一篇关于 Scrapy 的笔记算是对很久之前的一个总结吧！</p>\n<blockquote>\n<p>路漫漫其修远兮吾将上下而求索。</p>\n<p>I know nothing but my ignorance.</p>\n</blockquote>\n","categories":["Scrapy"],"tags":["爬虫"]},{"title":"Scrapy工作流程","url":"https://hahally.github.io//articles/Scrapy工作流程/","content":"<h3 id=\"Scrapy-框架中的数据流\"><a href=\"#Scrapy-框架中的数据流\" class=\"headerlink\" title=\"Scrapy 框架中的数据流\"></a>Scrapy 框架中的数据流</h3><p><img src=\"https://doc.scrapy.org/en/latest/_images/scrapy_architecture_02.png\"></p>\n<p>尽管文档中这样提到：Scrapy中的数据流由执行引擎控制，如下所示</p>\n<ol>\n<li>The <a href=\"https://doc.scrapy.org/en/latest/topics/architecture.html#component-engine\" target=\"_blank\" rel=\"noopener\">Engine</a> gets the initial Requests to crawl from the <a href=\"https://doc.scrapy.org/en/latest/topics/architecture.html#component-spiders\" target=\"_blank\" rel=\"noopener\">Spider</a>.</li>\n<li>The <a href=\"https://doc.scrapy.org/en/latest/topics/architecture.html#component-engine\" target=\"_blank\" rel=\"noopener\">Engine</a> schedules the Requests in the <a href=\"https://doc.scrapy.org/en/latest/topics/architecture.html#component-scheduler\" target=\"_blank\" rel=\"noopener\">Scheduler</a> and asks for the next Requests to crawl.</li>\n<li>The <a href=\"https://doc.scrapy.org/en/latest/topics/architecture.html#component-scheduler\" target=\"_blank\" rel=\"noopener\">Scheduler</a> returns the next Requests to the <a href=\"https://doc.scrapy.org/en/latest/topics/architecture.html#component-engine\" target=\"_blank\" rel=\"noopener\">Engine</a>.</li>\n<li>The <a href=\"https://doc.scrapy.org/en/latest/topics/architecture.html#component-engine\" target=\"_blank\" rel=\"noopener\">Engine</a> sends the Requests to the <a href=\"https://doc.scrapy.org/en/latest/topics/architecture.html#component-downloader\" target=\"_blank\" rel=\"noopener\">Downloader</a>, passing through the <a href=\"https://doc.scrapy.org/en/latest/topics/architecture.html#component-downloader-middleware\" target=\"_blank\" rel=\"noopener\">Downloader Middlewares</a> (see <a href=\"https://doc.scrapy.org/en/latest/topics/downloader-middleware.html#scrapy.downloadermiddlewares.DownloaderMiddleware.process_request\" target=\"_blank\" rel=\"noopener\"><code>process_request()</code></a>).</li>\n<li>Once the page finishes downloading the <a href=\"https://doc.scrapy.org/en/latest/topics/architecture.html#component-downloader\" target=\"_blank\" rel=\"noopener\">Downloader</a> generates a Response (with that page) and sends it to the Engine, passing through the <a href=\"https://doc.scrapy.org/en/latest/topics/architecture.html#component-downloader-middleware\" target=\"_blank\" rel=\"noopener\">Downloader Middlewares</a> (see <a href=\"https://doc.scrapy.org/en/latest/topics/downloader-middleware.html#scrapy.downloadermiddlewares.DownloaderMiddleware.process_response\" target=\"_blank\" rel=\"noopener\"><code>process_response()</code></a>).</li>\n<li>The <a href=\"https://doc.scrapy.org/en/latest/topics/architecture.html#component-engine\" target=\"_blank\" rel=\"noopener\">Engine</a> receives the Response from the <a href=\"https://doc.scrapy.org/en/latest/topics/architecture.html#component-downloader\" target=\"_blank\" rel=\"noopener\">Downloader</a> and sends it to the <a href=\"https://doc.scrapy.org/en/latest/topics/architecture.html#component-spiders\" target=\"_blank\" rel=\"noopener\">Spider</a> for processing, passing through the <a href=\"https://doc.scrapy.org/en/latest/topics/architecture.html#component-spider-middleware\" target=\"_blank\" rel=\"noopener\">Spider Middleware</a> (see <a href=\"https://doc.scrapy.org/en/latest/topics/spider-middleware.html#scrapy.spidermiddlewares.SpiderMiddleware.process_spider_input\" target=\"_blank\" rel=\"noopener\"><code>process_spider_input()</code></a>).</li>\n<li>The <a href=\"https://doc.scrapy.org/en/latest/topics/architecture.html#component-spiders\" target=\"_blank\" rel=\"noopener\">Spider</a> processes the Response and returns scraped items and new Requests (to follow) to the <a href=\"https://doc.scrapy.org/en/latest/topics/architecture.html#component-engine\" target=\"_blank\" rel=\"noopener\">Engine</a>, passing through the <a href=\"https://doc.scrapy.org/en/latest/topics/architecture.html#component-spider-middleware\" target=\"_blank\" rel=\"noopener\">Spider Middleware</a> (see <a href=\"https://doc.scrapy.org/en/latest/topics/spider-middleware.html#scrapy.spidermiddlewares.SpiderMiddleware.process_spider_output\" target=\"_blank\" rel=\"noopener\"><code>process_spider_output()</code></a>).</li>\n<li>The <a href=\"https://doc.scrapy.org/en/latest/topics/architecture.html#component-engine\" target=\"_blank\" rel=\"noopener\">Engine</a> sends processed items to <a href=\"https://doc.scrapy.org/en/latest/topics/architecture.html#component-pipelines\" target=\"_blank\" rel=\"noopener\">Item Pipelines</a>, then send processed Requests to the <a href=\"https://doc.scrapy.org/en/latest/topics/architecture.html#component-scheduler\" target=\"_blank\" rel=\"noopener\">Scheduler</a> and asks for possible next Requests to crawl.</li>\n<li>The process repeats (from step 1) until there are no more requests from the <a href=\"https://doc.scrapy.org/en/latest/topics/architecture.html#component-scheduler\" target=\"_blank\" rel=\"noopener\">Scheduler</a>.</li>\n</ol>\n<p>但是具体到程序中是如何体现的呢？在项目运行时，控制台中就有输出提示信息。如果要更直观的体现，不妨在每步对应的函数中打印自己设置的提示信息。例如：在自己的项目管道中可以这样做</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">class MyPipeline(object):</span><br><span class=\"line\">    # 在 open_spider 以及 parse 之后执行</span><br><span class=\"line\">    def process_item(self, item, spider):</span><br><span class=\"line\">        print(&quot;----- process_item -----&quot; )</span><br><span class=\"line\">        return item</span><br><span class=\"line\"></span><br><span class=\"line\">    # 在 from_crawler 之后执行</span><br><span class=\"line\">    def open_spider(self, spider):</span><br><span class=\"line\">        print(&quot;------------ open_spider --------------&quot;)</span><br><span class=\"line\"></span><br><span class=\"line\">    # 在 process_item 之后执行</span><br><span class=\"line\">    def close_spider(self, spider):</span><br><span class=\"line\">        print(&quot;------------ close_spider --------------&quot;)</span><br><span class=\"line\"></span><br><span class=\"line\">    # 最先执行</span><br><span class=\"line\">    @classmethod</span><br><span class=\"line\">    def from_crawler(cls, crawler):</span><br><span class=\"line\">        print(&quot;------------ from_crawler --------------&quot;)</span><br><span class=\"line\"></span><br><span class=\"line\">        return cls()</span><br></pre></td></tr></table></figure>\n<p>项目运行后，就可以看见他们的输出顺序了：</p>\n<figure class=\"highlight brainfuck\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">--<span class=\"literal\">-</span><span class=\"literal\">-</span><span class=\"literal\">-</span><span class=\"literal\">-</span><span class=\"literal\">-</span><span class=\"literal\">-</span><span class=\"literal\">-</span><span class=\"literal\">-</span><span class=\"literal\">-</span><span class=\"literal\">-</span> <span class=\"comment\">from_crawler</span> --<span class=\"literal\">-</span><span class=\"literal\">-</span><span class=\"literal\">-</span><span class=\"literal\">-</span><span class=\"literal\">-</span><span class=\"literal\">-</span><span class=\"literal\">-</span><span class=\"literal\">-</span><span class=\"literal\">-</span><span class=\"literal\">-</span><span class=\"literal\">-</span><span class=\"literal\">-</span></span><br><span class=\"line\">--<span class=\"literal\">-</span><span class=\"literal\">-</span><span class=\"literal\">-</span><span class=\"literal\">-</span><span class=\"literal\">-</span><span class=\"literal\">-</span><span class=\"literal\">-</span><span class=\"literal\">-</span><span class=\"literal\">-</span><span class=\"literal\">-</span> <span class=\"comment\">open_spider</span>  --<span class=\"literal\">-</span><span class=\"literal\">-</span><span class=\"literal\">-</span><span class=\"literal\">-</span><span class=\"literal\">-</span><span class=\"literal\">-</span><span class=\"literal\">-</span><span class=\"literal\">-</span><span class=\"literal\">-</span><span class=\"literal\">-</span><span class=\"literal\">-</span><span class=\"literal\">-</span></span><br><span class=\"line\">--<span class=\"literal\">-</span><span class=\"literal\">-</span><span class=\"literal\">-</span><span class=\"literal\">-</span><span class=\"literal\">-</span><span class=\"literal\">-</span><span class=\"literal\">-</span><span class=\"literal\">-</span><span class=\"literal\">-</span><span class=\"literal\">-</span> <span class=\"comment\">process_item</span> --<span class=\"literal\">-</span><span class=\"literal\">-</span><span class=\"literal\">-</span><span class=\"literal\">-</span><span class=\"literal\">-</span><span class=\"literal\">-</span><span class=\"literal\">-</span><span class=\"literal\">-</span><span class=\"literal\">-</span><span class=\"literal\">-</span><span class=\"literal\">-</span><span class=\"literal\">-</span></span><br><span class=\"line\">--<span class=\"literal\">-</span><span class=\"literal\">-</span><span class=\"literal\">-</span><span class=\"literal\">-</span><span class=\"literal\">-</span><span class=\"literal\">-</span><span class=\"literal\">-</span><span class=\"literal\">-</span><span class=\"literal\">-</span><span class=\"literal\">-</span> <span class=\"comment\">close_spider</span> --<span class=\"literal\">-</span><span class=\"literal\">-</span><span class=\"literal\">-</span><span class=\"literal\">-</span><span class=\"literal\">-</span><span class=\"literal\">-</span><span class=\"literal\">-</span><span class=\"literal\">-</span><span class=\"literal\">-</span><span class=\"literal\">-</span><span class=\"literal\">-</span><span class=\"literal\">-</span></span><br></pre></td></tr></table></figure>\n<p>了解框架的处理逻辑对我们编写高效代码是很有好处的。</p>\n","categories":["Scrapy"],"tags":["爬虫"]},{"title":"CopyText","url":"https://hahally.github.io//articles/CopyText/","content":"<blockquote>\n<pre><code>  auth : hahally\n\n  start : 2020.1.11\n</code></pre></blockquote>\n<h3 id=\"Django\"><a href=\"#Django\" class=\"headerlink\" title=\"Django\"></a>Django</h3><p>常用命令</p>\n<blockquote>\n<pre><code> django-admin startproject locallibrary   # 创建项目\n python manage.py startapp catalog        # 创建应用\n python manage.py runserver               # 启动服务\n python manage.py makemigrations          # 数据库迁移\n python manage.py migrate\n python manage.py createsuperuser         # 创建管理员账号\n</code></pre></blockquote>\n<pre><code>views.py\n    posts.content = markdown.markdown(\n    posts.content,\n    extensions = [\n        # 包含 缩写、表格等常用扩展\n        &#39;markdown.extensions.extra&#39;,\n        # 语法高亮扩展\n        &#39;markdown.extensions.codehilite&#39;,\n        ]\n    )\n</code></pre><h3 id=\"Scrapy-常用命令\"><a href=\"#Scrapy-常用命令\" class=\"headerlink\" title=\"Scrapy 常用命令\"></a>Scrapy 常用命令</h3><blockquote>\n<pre><code>           scrapy startproject proj     # 创建项目\n           scrapy crawl spider_name     # 运行爬虫\n</code></pre></blockquote>\n<h3 id=\"python-第三方库安装源\"><a href=\"#python-第三方库安装源\" class=\"headerlink\" title=\"python 第三方库安装源\"></a>python 第三方库安装源</h3><pre><code>清华大学镜像\nhttps://pypi.tuna.tsinghua.edu.cn/simple/\n阿里云\nhttp://mirrors.aliyun.com/pypi/simple/\n中科大镜像\nhttps://pypi.mirrors.ustc.edu.cn/simple/\n豆瓣镜像\nhttp://pypi.douban.com/simple/\n中科大镜像2\nhttp://pypi.mirrors.ustc.edu.cn/simple/\n</code></pre><hr>\n<h3 id=\"笔记\"><a href=\"#笔记\" class=\"headerlink\" title=\"笔记\"></a>笔记</h3><pre><code>      Auth       : hahally\ncreateTime       : 2019.10.26\n  abstract       : 大数据辅修学习笔记\n</code></pre><h4 id=\"jdk环境变量配置\"><a href=\"#jdk环境变量配置\" class=\"headerlink\" title=\"jdk环境变量配置\"></a><code>jdk</code>环境变量配置</h4><pre><code>    在、/etc/profile或~/.bashrc中的文件底部\n    JAVA_HOME=/usr/java/jdk1.8.0_162\n    JRE_HOME=$JAVA_HOME/jre\n    CLASS_PATH=.:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar:$JRE_HOME/lib\n    PATH=$PATH:$JAVA_HOME/bin:$JRE_HOME/bin\n    export JAVA_HOME JRE_HOME CLASS_PATH PATH\n    [root@master~]# source /etc/profile   使配置生效\n</code></pre><h4 id=\"windows-dos-命令\"><a href=\"#windows-dos-命令\" class=\"headerlink\" title=\"windows dos 命令\"></a><code>windows dos</code> 命令</h4><pre><code>    C:\\Users\\ACER&gt;netstat -aon|findstr &quot;8081&quot;      查看端口号\n    C:\\Users\\ACER&gt;taskkill /f /t /im 10144         杀掉进程\n</code></pre><h4 id=\"Linux命令\"><a href=\"#Linux命令\" class=\"headerlink\" title=\"Linux命令\"></a><code>Linux</code>命令</h4><figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@master~]# tar -zxvf [*].tar.gz -C [路径]   解压</span><br><span class=\"line\">[root@master~]# yum -y remove firewalld          卸载防火墙</span><br><span class=\"line\">[root@master~]# systemctl stop/status/start firewalld 停止/查看状态/启动/防火墙服务</span><br><span class=\"line\">[root@master~]# netstat -tunlp|grep 端口号        查看端口占用情况</span><br><span class=\"line\">[root@master~]# sudo passwd root        设置root密码</span><br><span class=\"line\">[root@master~]# sudo ln -s /usr/local/jdk1.8.0_162/bin/ bin   创建软链接</span><br><span class=\"line\">[root@master~]# cp [-r] file/filedir filepath        复制文件或目录</span><br><span class=\"line\"></span><br><span class=\"line\">ubuntu ens33丢失重连</span><br><span class=\"line\">[root@master~]# sudo service network-manager stop</span><br><span class=\"line\">[root@master~]# sudo rm /var/lib/NetworkManager/NetworkManager.state</span><br><span class=\"line\">[root@master~]# sudo service network-manager start</span><br><span class=\"line\">[root@master~]# sudo gedit /etc/NetworkManager/NetworkManager.conf    #（把false改成true）</span><br><span class=\"line\">[root@master~]# sudo service network-manager restart</span><br><span class=\"line\"></span><br><span class=\"line\">centos ens33丢失重连</span><br><span class=\"line\">[root@master~]# systemctl stop NetworkManager</span><br><span class=\"line\">[root@master~]# systemctl disable NetworkManager</span><br><span class=\"line\">[root@master~]# sudo ifup ens33         重新连接ens33</span><br><span class=\"line\">[root@master~]# systemctl restart network</span><br><span class=\"line\">[root@master~]# systemctl start NetworkManager</span><br><span class=\"line\"></span><br><span class=\"line\">[root@master~]# sudo ps -e |grep ssh    查看ssh服务是否启动</span><br></pre></td></tr></table></figure>\n<h4 id=\"git-命令\"><a href=\"#git-命令\" class=\"headerlink\" title=\"git 命令\"></a><code>git</code> 命令</h4><figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">git init   初始化</span><br><span class=\"line\">git add filename  将上传文件加到缓冲区</span><br><span class=\"line\">git commit [-m] [注释]</span><br><span class=\"line\">git remote add origin https://github.com/[用户名名]/[仓库名].git</span><br><span class=\"line\">git push -u origin master -f    上传到远程仓库分支</span><br><span class=\"line\">git clone https://github.com/[用户名名]/[仓库名].git        拉取代码</span><br></pre></td></tr></table></figure>\n<h4 id=\"docker命令\"><a href=\"#docker命令\" class=\"headerlink\" title=\"docker命令\"></a><code>docker</code>命令</h4><figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@master~]# sudo docker run -it -v /home/hahally/myimage:/data --name slave2 -h slave2 new_image:newhadoop /bin/bash      运行容器指定共享目录</span><br><span class=\"line\">[root@master~]# sudo docker start slave2      启动容器</span><br><span class=\"line\">[root@master~]# sudo docker exec -i -t s2 /bin/bash\t\t进入容器</span><br><span class=\"line\">[root@master~]# docker commit master new_image:tag    提交容器</span><br><span class=\"line\">[root@master~]# sudo docker rm contianername          删除容器</span><br><span class=\"line\">[root@master~]# sudo docker rmi imagesname            删除镜像</span><br><span class=\"line\">[root@master~]# sudo docker rename name1 name2        重新命名容器</span><br></pre></td></tr></table></figure>\n<h4 id=\"hadoop命令\"><a href=\"#hadoop命令\" class=\"headerlink\" title=\"hadoop命令\"></a><code>hadoop</code>命令</h4><figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@master~]# hadoop dfsadmin -report      命令查看磁盘使用情况</span><br><span class=\"line\">[root@master~]# hadoop jar hadoop-mapreduce-examples-2.7.5.jar wordcount /wordcount/input  /wordcount/output 运行jar包</span><br><span class=\"line\">[root@master~]# hadoop dfsadmin -safemode leave    退出安全模式</span><br><span class=\"line\">[root@master~]# hadoop jar  x.jar  MainClassName[主类名称] [inputPath] [outputPath]</span><br></pre></td></tr></table></figure>\n<h4 id=\"运行hadoop自带MapReduce程序\"><a href=\"#运行hadoop自带MapReduce程序\" class=\"headerlink\" title=\"运行hadoop自带MapReduce程序\"></a>运行<code>hadoop</code>自带<code>MapReduce</code>程序</h4><figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@master hadoop-2.7.5]# hadoop fs -mkdir -p /wordcount/input              [创建一个目录]</span><br><span class=\"line\">[root@master hadoop-2.7.5]# hadoop fs -put a.txt  b.txt  /wordcount/input     [将文件上传到input文件夹中]</span><br><span class=\"line\">[root@master hadoop-2.7.5]# cd share/hadoop/mapreduce/                        [进入程序所在目录]</span><br><span class=\"line\">[root@master mapreduce]# hadoop jar hadoop-mapreduce-examples-2.7.5.jar wordcount /wordcount/input  /wordcount/output   [运行jar包]</span><br><span class=\"line\">[root@master mapreduce]# hadoop fs -cat /wordcount/output/part-r-00000     [查看输出结果]</span><br></pre></td></tr></table></figure>\n<h4 id=\"Spark\"><a href=\"#Spark\" class=\"headerlink\" title=\"Spark\"></a>Spark</h4><p>环境变量<br><figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">vim ~/.bashrc</span><br><span class=\"line\"><span class=\"meta\">#</span><span class=\"bash\"> 现在我们的环境变量配置看起来像这样</span></span><br><span class=\"line\">export HADOOP_HOME=/usr/local/hadoop</span><br><span class=\"line\">export SPARK_HOME=/usr/local/spark</span><br><span class=\"line\">export PYTHONPATH=$SPARK_HOME/python:$SPARK_HOME/python/lib/py4j-0.10.7-src.zip:$PYTHONPATH</span><br><span class=\"line\">export PYSPARK_PYTHON=python3</span><br><span class=\"line\">export JAVA_HOME=/usr/local/java/jdk1.8.0_171</span><br><span class=\"line\">export JRE_HOME=$&#123;JAVA_HOME&#125;/jre</span><br><span class=\"line\">export CLASSPATH=.:$&#123;JAVA_HOME&#125;/jre/lib/rt.jar:$&#123;JAVA_HOME&#125;/lib/dt.jar:$&#123;JAVA_HOME&#125;/lib/tools.jar</span><br><span class=\"line\">export PATH=$PATH:$&#123;JAVA_HOME&#125;/bin</span><br><span class=\"line\">export PATH=$PATH:/usr/local/hadoop/bin:/usr/local/hadoop/sbin:/usr/local/spark/bin:/usr/local/spark/sbin:$PATH</span><br><span class=\"line\">export LD_LIBRARY_PATH=$HADOOP_HOME/lib/native:$LD_LIBRARY_PYTHON</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"meta\">#</span><span class=\"bash\"> 使配置生效</span></span><br><span class=\"line\">source ~/.bashrc</span><br></pre></td></tr></table></figure><br><code>spark-env.sh</code><br><figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">cd /usr/local/spark</span><br><span class=\"line\">cp ./conf/spark-env.sh.template ./conf/spark-env.sh</span><br><span class=\"line\">vim ./conf/spark-env.sh</span><br><span class=\"line\"><span class=\"meta\">#</span><span class=\"bash\"> 在最后一行添加如下配置信息：</span></span><br><span class=\"line\"></span><br><span class=\"line\">export SPARK_DIST_CLASSPATH=$(/usr/local/hadoop/bin/hadoop classpath)</span><br><span class=\"line\">export HADOOP_CONF_DIR=/usr/local/hadoop/ect/hadoop</span><br><span class=\"line\">export YARN_CONF_DIR=/usr/local/hadoop/etc/hadoop</span><br></pre></td></tr></table></figure><br>运行<br><figure class=\"highlight crystal\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">/usr/local/spark/bin/run-example SparkPi <span class=\"comment\"># 运行例子</span></span><br><span class=\"line\">/usr/local/spark、bin/run-example SparkPi <span class=\"number\">2</span>&gt;&amp;<span class=\"number\">1</span> | grep <span class=\"string\">\"Pi is roughly\"</span></span><br><span class=\"line\">/usr/local/spark/bin/spark-submit ../examples/src/main/python/pi.py <span class=\"number\">2</span>&gt;&amp;<span class=\"number\">1</span> | grep <span class=\"string\">'Pi'</span></span><br><span class=\"line\">/usr/local/spark/bin/spark-submit --master yarn --deploy-mode cluster /usr/local/spark/examples/src/main/python/wordcount.py <span class=\"symbol\">hdfs:</span>/<span class=\"regexp\">/master:9000/words</span>.txt</span><br></pre></td></tr></table></figure></p>\n<h4 id=\"注意点\"><a href=\"#注意点\" class=\"headerlink\" title=\"注意点\"></a>注意点</h4><p>运行<code>jar</code>包时，先删掉 <code>/output</code>文件夹，否则无法发查看输出结果</p>\n<figure class=\"highlight routeros\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"builtin-name\">export</span> <span class=\"attribute\">JAVA_HOME</span>=/usr/local/jdk1.8.0_162</span><br><span class=\"line\"><span class=\"builtin-name\">export</span> <span class=\"attribute\">JRE_HOME</span>=<span class=\"variable\">$&#123;JAVA_HOME&#125;</span>/jre</span><br><span class=\"line\"><span class=\"builtin-name\">export</span> <span class=\"attribute\">CLASSPATH</span>=.:$&#123;JAVA_HOME&#125;/lib:<span class=\"variable\">$&#123;JRE_HOME&#125;</span>/lib</span><br><span class=\"line\"><span class=\"builtin-name\">export</span> <span class=\"attribute\">HADOOP_HOME</span>=/usr/local/hadoop-2.7.5</span><br><span class=\"line\"><span class=\"builtin-name\">export</span> <span class=\"attribute\">PATH</span>=<span class=\"variable\">$PATH</span>:$JAVA_HOME/bin:$HADOOP_HOME/bin:$HADOOP_HOME/sbin:/usr/local/hbase-1.3.6/bin</span><br><span class=\"line\"><span class=\"builtin-name\">export</span> <span class=\"attribute\">HBASE_HOME</span>=/usr/local/hbase-1.3.6</span><br><span class=\"line\"><span class=\"builtin-name\">export</span> <span class=\"attribute\">HBASE_CLASSPATH</span>=/usr/local/hbase-1.3.6/lib/hbase-common-1.3.6.jar:/usr/local/hbase-1.3.6/lib/</span><br><span class=\"line\">hbase-server-1.3.6.jar</span><br></pre></td></tr></table></figure>","categories":["copyText"],"tags":[]},{"title":"Django中的分页","url":"https://hahally.github.io//articles/Django中的分页/","content":"<h3 id=\"写在前面\"><a href=\"#写在前面\" class=\"headerlink\" title=\"写在前面\"></a>写在前面</h3><p>随着自己写的博客日益增加，博客列表页的展示也逐渐变得有些力不从心。要浏览所有的博客就不得不疯狂的滑鼠标。冗长的页面带来的体验十分的差劲。这个时候不得不将他们做一下简单分页处理。分页的方式有很多，而便捷的 Django 为我们准备了十分友好的类 <code>Paginator</code> 来帮助我们进行分页。</p>\n<hr>\n<h3 id=\"Paginator-对象\"><a href=\"#Paginator-对象\" class=\"headerlink\" title=\"Paginator 对象\"></a>Paginator 对象</h3><p>先看看源码中的初始化或者说构造方法:</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">Paginator</span>:</span></span><br><span class=\"line\">\t<span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">__init__</span><span class=\"params\">(self, object_list, per_page, orphans=<span class=\"number\">0</span>,allow_empty_first_page=True)</span>:</span></span><br><span class=\"line\">\t\tself.object_list = object_list</span><br><span class=\"line\">\t\tself._check_object_list_is_ordered()</span><br><span class=\"line\">\t\tself.per_page = int(per_page)</span><br><span class=\"line\">\t\tself.orphans = int(orphans)</span><br><span class=\"line\">\t\tself.allow_empty_first_page = allow_empty_first_page</span><br></pre></td></tr></table></figure>\n<p>显然，要创建一个 Paginator 对象, 就不得不提供 object_list 和 per_page 对象。</p>\n<p><code>object_list</code></p>\n<blockquote>\n<p>A list, tuple, QuerySet, or other sliceable object with a count() or <strong>len</strong>() method. For consistent pagination, QuerySets should be ordered, e.g. with an order_by() clause or with a default ordering on the model.</p>\n</blockquote>\n<p>从这段文档说明中，可以大致了解 object_list 是个这样的对象：列表、元组、QuerySet…同时，文档建议如果是 QuerySet 对象的话，应当对其进行排序，如使用 order_by() 方法，或者采用模型中默认的排序方法。</p>\n<p><code>per_page</code></p>\n<blockquote>\n<p>The maximum number of items to include on a page, not including orphans (see the orphans optional argument below).</p>\n</blockquote>\n<p>显然，per_page 指的是每页要展示的选项最大个数。例如：每页显示 5 篇文章，那么就是 <code>per_page=5</code>。同时也强调，不包括 orphans。</p>\n<p><code>orphans</code></p>\n<blockquote>\n<p>Use this when you don’t want to have a last page with very few items. If the last page would normally have a number of items less than or equal to orphans, then those items will be added to the previous page (which becomes the last page) instead of leaving the items on a page by themselves. For example, with 23 items, per_page=10, and orphans=3, there will be two pages; the first page with 10 items and the second (and last) page with 13 items. orphans defaults to zero, which means pages are never combined and the last page may have one item.</p>\n</blockquote>\n<p>orphans 顾名思义就是孤儿的意思。通俗来讲就是，在分页时，发现最后一页可能就只有一两个选项去了，如果觉得最后一页只是很少一部分，不想单独占一页，那么就可以将其添加在前一页中。而 orphans 值恰恰就是这样一个阈值，当小于它时，就可以将剩下那部分加到前一页中。假设我们有 23 个选项，每页展示是个选项，那么最多可以分成 3 页，第三页就只有 3 个选项。如果我们设置 orphans 大于等于 3，那么第一页是 10，第二页是 13 了。</p>\n<hr>\n<h3 id=\"如何使用\"><a href=\"#如何使用\" class=\"headerlink\" title=\"如何使用\"></a>如何使用</h3><p>文档中给出了一个十分详细的例子供我们参考：</p>\n<p>在我们的视图 views.py 中：</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">from</span> django.core.paginator <span class=\"keyword\">import</span> Paginator</span><br><span class=\"line\"><span class=\"keyword\">from</span> django.shortcuts <span class=\"keyword\">import</span> render</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">listing</span><span class=\"params\">(request)</span>:</span></span><br><span class=\"line\">    contact_list = Contacts.objects.all()</span><br><span class=\"line\">    paginator = Paginator(contact_list, <span class=\"number\">25</span>) <span class=\"comment\"># Show 25 contacts per page</span></span><br><span class=\"line\">    page = request.GET.get(<span class=\"string\">'page'</span>)</span><br><span class=\"line\">    contacts = paginator.get_page(page)</span><br><span class=\"line\">    <span class=\"keyword\">return</span> render(request, <span class=\"string\">'list.html'</span>, &#123;<span class=\"string\">'contacts'</span>: contacts&#125;)</span><br></pre></td></tr></table></figure>\n<p>在我们的模板 list.html 中：</p>\n<figure class=\"highlight django\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"template-tag\">&#123;% <span class=\"name\"><span class=\"name\">for</span></span> contact <span class=\"keyword\">in</span> contacts %&#125;</span></span><br><span class=\"line\"><span class=\"xml\">    </span><span class=\"comment\">&#123;# Each \"contact\" is a Contact model object. #&#125;</span></span><br><span class=\"line\"><span class=\"xml\">    </span><span class=\"template-variable\">&#123;&#123; contact.full_name|<span class=\"name\">upper</span> &#125;&#125;</span><span class=\"xml\"><span class=\"tag\">&lt;<span class=\"name\">br</span>&gt;</span></span></span><br><span class=\"line\"><span class=\"xml\">    ...</span></span><br><span class=\"line\"><span class=\"template-tag\">&#123;% <span class=\"name\"><span class=\"name\">endfor</span></span> %&#125;</span></span><br><span class=\"line\"><span class=\"xml\"><span class=\"tag\">&lt;<span class=\"name\">div</span> <span class=\"attr\">class</span>=<span class=\"string\">\"pagination\"</span>&gt;</span></span></span><br><span class=\"line\"><span class=\"xml\">    <span class=\"tag\">&lt;<span class=\"name\">span</span> <span class=\"attr\">class</span>=<span class=\"string\">\"step-links\"</span>&gt;</span></span></span><br><span class=\"line\"><span class=\"xml\">        </span><span class=\"template-tag\">&#123;% <span class=\"name\"><span class=\"name\">if</span></span> contacts.has_previous %&#125;</span></span><br><span class=\"line\"><span class=\"xml\">            <span class=\"tag\">&lt;<span class=\"name\">a</span> <span class=\"attr\">href</span>=<span class=\"string\">\"?page=1\"</span>&gt;</span><span class=\"symbol\">&amp;laquo;</span> first<span class=\"tag\">&lt;/<span class=\"name\">a</span>&gt;</span></span></span><br><span class=\"line\"><span class=\"xml\">            <span class=\"tag\">&lt;<span class=\"name\">a</span> <span class=\"attr\">href</span>=<span class=\"string\">\"?page=</span></span></span><span class=\"template-variable\">&#123;&#123; contacts.previous_page_number &#125;&#125;</span><span class=\"xml\"><span class=\"tag\"><span class=\"string\">\"</span>&gt;</span>previous<span class=\"tag\">&lt;/<span class=\"name\">a</span>&gt;</span></span></span><br><span class=\"line\"><span class=\"xml\">        </span><span class=\"template-tag\">&#123;% <span class=\"name\"><span class=\"name\">endif</span></span> %&#125;</span></span><br><span class=\"line\"><span class=\"xml\">        <span class=\"tag\">&lt;<span class=\"name\">span</span> <span class=\"attr\">class</span>=<span class=\"string\">\"current\"</span>&gt;</span></span></span><br><span class=\"line\"><span class=\"xml\">            Page </span><span class=\"template-variable\">&#123;&#123; contacts.number &#125;&#125;</span><span class=\"xml\"> of </span><span class=\"template-variable\">&#123;&#123; contacts.paginator.num_pages &#125;&#125;</span><span class=\"xml\">.</span></span><br><span class=\"line\"><span class=\"xml\">        <span class=\"tag\">&lt;/<span class=\"name\">span</span>&gt;</span></span></span><br><span class=\"line\"><span class=\"xml\">        </span><span class=\"template-tag\">&#123;% <span class=\"name\"><span class=\"name\">if</span></span> contacts.has_next %&#125;</span></span><br><span class=\"line\"><span class=\"xml\">            <span class=\"tag\">&lt;<span class=\"name\">a</span> <span class=\"attr\">href</span>=<span class=\"string\">\"?page=</span></span></span><span class=\"template-variable\">&#123;&#123; contacts.next_page_number &#125;&#125;</span><span class=\"xml\"><span class=\"tag\"><span class=\"string\">\"</span>&gt;</span>next<span class=\"tag\">&lt;/<span class=\"name\">a</span>&gt;</span></span></span><br><span class=\"line\"><span class=\"xml\">            <span class=\"tag\">&lt;<span class=\"name\">a</span> <span class=\"attr\">href</span>=<span class=\"string\">\"?page=</span></span></span><span class=\"template-variable\">&#123;&#123; contacts.paginator.num_pages &#125;&#125;</span><span class=\"xml\"><span class=\"tag\"><span class=\"string\">\"</span>&gt;</span>last <span class=\"symbol\">&amp;raquo;</span><span class=\"tag\">&lt;/<span class=\"name\">a</span>&gt;</span></span></span><br><span class=\"line\"><span class=\"xml\">        </span><span class=\"template-tag\">&#123;% <span class=\"name\"><span class=\"name\">endif</span></span> %&#125;</span></span><br><span class=\"line\"><span class=\"xml\">    <span class=\"tag\">&lt;/<span class=\"name\">span</span>&gt;</span></span></span><br><span class=\"line\"><span class=\"xml\"><span class=\"tag\">&lt;/<span class=\"name\">div</span>&gt;</span></span></span><br></pre></td></tr></table></figure>\n<p>一点点注释：</p>\n<blockquote>\n<pre><code>has_previous() 判断是否有上一页\nhas_next() 判断是否有上一页\nprevious_page_number() 返回上一个页码\ncontacts.number 一个基于 1 的页码\npaginator.num_pages() 页码的基于 1 的范围迭代器\n</code></pre></blockquote>\n<p>获取更多可以参考 <a href=\"https://docs.djangoproject.com/zh-hans/2.1/topics/pagination/#example\" target=\"_blank\" rel=\"noopener\">官方文档</a></p>\n<hr>\n<h3 id=\"欢迎参观\"><a href=\"#欢迎参观\" class=\"headerlink\" title=\"欢迎参观\"></a>欢迎参观</h3><p>学Django时，顺便写了简单的<a href=\"http://114.55.102.217/blog/\" target=\"_blank\" rel=\"noopener\">个人博客</a>。前端用的<a href=\"https://www.bootcss.com/\" target=\"_blank\" rel=\"noopener\">bootstrap</a>框架。笔记都会同步的。</p>\n","categories":["Django"],"tags":["后端"]},{"title":"about","url":"https://hahally.github.io/about/index.html","content":"","categories":[],"tags":[]},{"title":"category","url":"https://hahally.github.io/category/index.html","content":"","categories":[],"tags":[]},{"title":"search","url":"https://hahally.github.io/search/index.html","content":"","categories":[],"tags":[]},{"title":"tag","url":"https://hahally.github.io/tag/index.html","content":"","categories":[],"tags":[]},{"title":"","url":"https://hahally.github.io/css/personal-style.css","content":"@font-face {\n  font-family: \"Meiryo\";\n  src: url(\"/fonts/Meiryo.eot\");\n  /* IE9 */\n  src: url(\"/fonts/Meiryo.eot?#iefix\") format(\"embedded-opentype\"), /* IE6-IE8 */\n  url(\"/fonts/Meiryo.woff\") format(\"woff\"), /* chrome, firefox */\n  url(\"/fonts/Meiryo.ttf\") format(\"truetype\"), /* chrome, firefox, opera, Safari, Android, iOS 4.2+ */\n  url(\"/fonts/Meiryo.svg#Meiryo\") format(\"svg\");\n  /* iOS 4.1- */\n  font-style: normal;\n  font-weight: normal;\n}\nhtml.page-home {\n  /*background-image: url('/images/bg.jpg')*/\n  /*background: linear-gradient( #1abc9c, transparent), linear-gradient( 90deg, skyblue, transparent), linear-gradient( -90deg, coral, transparent);*/\n  /*background-blend-mode: screen;*/\n  /*background: linear-gradient(to left, #5f2c82, #49a09d);*/\n}","categories":[],"tags":[]}]